name,version,name.1,wmc,dit,noc,cbo,rfc,lcom,ca,ce,npm,lcom3,loc,dam,moa,mfa,cam,ic,cbm,amc,max_cc,avg_cc,bug,code
lucene,2.2,org.apache.lucene.search.FuzzyQuery,10,3,0,13,42,7,1,12,9,0.638888889,280,0.5,0,0.72,0.285714286,3,4,26.6,6,1.4,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.util.PriorityQueue;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;


public class FuzzyQuery extends MultiTermQuery {
  
  public final static float defaultMinSimilarity = 0.5f;
  public final static int defaultPrefixLength = 0;
  
  private float minimumSimilarity;
  private int prefixLength;
  
  
  public FuzzyQuery(Term term, float minimumSimilarity, int prefixLength) throws IllegalArgumentException {
    super(term);
    
    if (minimumSimilarity >= 1.0f)
      throw new IllegalArgumentException(""minimumSimilarity >= 1"");
    else if (minimumSimilarity < 0.0f)
      throw new IllegalArgumentException(""minimumSimilarity < 0"");
    if (prefixLength < 0)
      throw new IllegalArgumentException(""prefixLength < 0"");
    
    this.minimumSimilarity = minimumSimilarity;
    this.prefixLength = prefixLength;
  }
  
  
  public FuzzyQuery(Term term, float minimumSimilarity) throws IllegalArgumentException {
      this(term, minimumSimilarity, defaultPrefixLength);
  }

  
  public FuzzyQuery(Term term) {
    this(term, defaultMinSimilarity, defaultPrefixLength);
  }
  
  
  public float getMinSimilarity() {
    return minimumSimilarity;
  }
    
  
  public int getPrefixLength() {
    return prefixLength;
  }

  protected FilteredTermEnum getEnum(IndexReader reader) throws IOException {
    return new FuzzyTermEnum(reader, getTerm(), minimumSimilarity, prefixLength);
  }
  
  public Query rewrite(IndexReader reader) throws IOException {
    FilteredTermEnum enumerator = getEnum(reader);
    int maxClauseCount = BooleanQuery.getMaxClauseCount();
    ScoreTermQueue stQueue = new ScoreTermQueue(maxClauseCount);
    
    try {
      do {
        float minScore = 0.0f;
        float score = 0.0f;
        Term t = enumerator.term();
        if (t != null) {
          score = enumerator.difference();
          
          
          if(stQueue.size() < maxClauseCount || score > minScore){
            stQueue.insert(new ScoreTerm(t, score));
            minScore = ((ScoreTerm)stQueue.top()).score; 
          }
        }
      } while (enumerator.next());
    } finally {
      enumerator.close();
    }
    
    BooleanQuery query = new BooleanQuery(true);
    int size = stQueue.size();
    for(int i = 0; i < size; i++){
      ScoreTerm st = (ScoreTerm) stQueue.pop();
      TermQuery tq = new TermQuery(st.term);      
      tq.setBoost(getBoost() * st.score); 
      query.add(tq, BooleanClause.Occur.SHOULD);          
    }

    return query;
  }
    
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    Term term = getTerm();
    if (!term.field().equals(field)) {
        buffer.append(term.field());
        buffer.append("":"");
    }
    buffer.append(term.text());
    buffer.append('~');
    buffer.append(Float.toString(minimumSimilarity));
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }
  
  protected static class ScoreTerm {
    public Term term;
    public float score;
    
    public ScoreTerm(Term term, float score){
      this.term = term;
      this.score = score;
    }
  }
  
  protected static class ScoreTermQueue extends PriorityQueue {
    
    public ScoreTermQueue(int size){
      initialize(size);
    }
    
    
    protected boolean lessThan(Object a, Object b) {
      ScoreTerm termA = (ScoreTerm)a;
      ScoreTerm termB = (ScoreTerm)b;
      if (termA.score == termB.score)
        return termA.term.compareTo(termB.term) > 0;
      else
        return termA.score < termB.score;
    }
    
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof FuzzyQuery)) return false;
    if (!super.equals(o)) return false;

    final FuzzyQuery fuzzyQuery = (FuzzyQuery) o;

    if (minimumSimilarity != fuzzyQuery.minimumSimilarity) return false;
    if (prefixLength != fuzzyQuery.prefixLength) return false;

    return true;
  }

  public int hashCode() {
    int result = super.hashCode();
    result = 29 * result + minimumSimilarity != +0.0f ? Float.floatToIntBits(minimumSimilarity) : 0;
    result = 29 * result + prefixLength;
    return result;
  }
}
"
lucene,2.2,org.apache.lucene.index.MultiLevelSkipListReader,10,1,1,4,21,0,1,3,1,0.619047619,477,1.0,1,0.0,0.5,0,0,45.3,2,1.0,1,"package org.apache.lucene.index;



import java.io.IOException;
import java.util.Arrays;

import org.apache.lucene.store.BufferedIndexInput;
import org.apache.lucene.store.IndexInput;


abstract class MultiLevelSkipListReader {
  
  private int maxNumberOfSkipLevels; 
  
  
  private int numberOfSkipLevels;
  
  
  
  
  
  
  
  
  private int numberOfLevelsToBuffer = 1;
  
  private int docCount;
  private boolean haveSkipped;
  
  private IndexInput[] skipStream;    
  private long skipPointer[];         
  private int skipInterval[];         
  private int[] numSkipped;           
    
  private int[] skipDoc;              
  private int lastDoc;                
  private long[] childPointer;        
  private long lastChildPointer;      
  
  private boolean inputIsBuffered;
  
  public MultiLevelSkipListReader(IndexInput skipStream, int maxSkipLevels, int skipInterval) {
    this.skipStream = new IndexInput[maxSkipLevels];
    this.skipPointer = new long[maxSkipLevels];
    this.childPointer = new long[maxSkipLevels];
    this.numSkipped = new int[maxSkipLevels];
    this.maxNumberOfSkipLevels = maxSkipLevels;
    this.skipInterval = new int[maxSkipLevels];
    this.skipStream [0]= skipStream;
    this.inputIsBuffered = (skipStream instanceof BufferedIndexInput);
    this.skipInterval[0] = skipInterval;
    for (int i = 1; i < maxSkipLevels; i++) {
      
      this.skipInterval[i] = this.skipInterval[i - 1] * skipInterval;
    }
    skipDoc = new int[maxSkipLevels];
  }

  
  
  int getDoc() {
    return lastDoc;
  }
  
  
  
  int skipTo(int target) throws IOException {
    if (!haveSkipped) {
      
      loadSkipLevels();
      haveSkipped = true;
    }
  
    
    
    int level = 0;
    while (level < numberOfSkipLevels - 1 && target > skipDoc[level + 1]) {
      level++;
    }    

    while (level >= 0) {
      if (target > skipDoc[level]) {
        if (!loadNextSkip(level)) {
          continue;
        }
      } else {
        
        if (level > 0 && lastChildPointer > skipStream[level - 1].getFilePointer()) {
          seekChild(level - 1);
        } 
        level--;
      }
    }
    
    return numSkipped[0] - skipInterval[0] - 1;
  }
  
  private boolean loadNextSkip(int level) throws IOException {
    
    
    setLastSkipData(level);
      
    numSkipped[level] += skipInterval[level];
      
    if (numSkipped[level] > docCount) {
      
      skipDoc[level] = Integer.MAX_VALUE;
      if (numberOfSkipLevels > level) numberOfSkipLevels = level; 
      return false;
    }

    
    skipDoc[level] += readSkipData(level, skipStream[level]);
    
    if (level != 0) {
      
      childPointer[level] = skipStream[level].readVLong() + skipPointer[level - 1];
    }
    
    return true;

  }
  
  
  protected void seekChild(int level) throws IOException {
    skipStream[level].seek(lastChildPointer);
    numSkipped[level] = numSkipped[level + 1] - skipInterval[level + 1];
    skipDoc[level] = lastDoc;
    if (level > 0) {
        childPointer[level] = skipStream[level].readVLong() + skipPointer[level - 1];
    }
  }
  
  void close() throws IOException {
    for (int i = 1; i < skipStream.length; i++) {
      if (skipStream[i] != null) {
        skipStream[i].close();
      }
    }
  }

  
  void init(long skipPointer, int df) {
    this.skipPointer[0] = skipPointer;
    this.docCount = df;
    Arrays.fill(skipDoc, 0);
    Arrays.fill(numSkipped, 0);
    haveSkipped = false;
    for (int i = 1; i < numberOfSkipLevels; i++) {
      skipStream[0] = null;
    }
  }
  
  
  private void loadSkipLevels() throws IOException {
    numberOfSkipLevels = docCount == 0 ? 0 : (int) Math.floor(Math.log(docCount) / Math.log(skipInterval[0]));
    if (numberOfSkipLevels > maxNumberOfSkipLevels) {
      numberOfSkipLevels = maxNumberOfSkipLevels;
    }

    skipStream[0].seek(skipPointer[0]);
    
    int toBuffer = numberOfLevelsToBuffer;
    
    for (int i = numberOfSkipLevels - 1; i > 0; i--) {
      
      long length = skipStream[0].readVLong();
      
      
      skipPointer[i] = skipStream[0].getFilePointer();
      if (toBuffer > 0) {
        
        skipStream[i] = new SkipBuffer(skipStream[0], (int) length);
        toBuffer--;
      } else {
        
        skipStream[i] = (IndexInput) skipStream[0].clone();
        if (inputIsBuffered && length < BufferedIndexInput.BUFFER_SIZE) {
          ((BufferedIndexInput) skipStream[i]).setBufferSize((int) length);
        }
        
        
        skipStream[0].seek(skipStream[0].getFilePointer() + length);
      }
    }
   
    
    skipPointer[0] = skipStream[0].getFilePointer();
  }
  
    
  protected abstract int readSkipData(int level, IndexInput skipStream) throws IOException;
  
  
  protected void setLastSkipData(int level) {
    lastDoc = skipDoc[level];
    lastChildPointer = childPointer[level];
  }

  
  
  private final static class SkipBuffer extends IndexInput {
    private byte[] data;
    private long pointer;
    private int pos;
    
    SkipBuffer(IndexInput input, int length) throws IOException {
      data = new byte[length];
      pointer = input.getFilePointer();
      input.readBytes(data, 0, length);
    }
    
    public void close() throws IOException {
      data = null;
    }

    public long getFilePointer() {
      return pointer + pos;
    }

    public long length() {
      return data.length;
    }

    public byte readByte() throws IOException {
      return data[pos++];
    }

    public void readBytes(byte[] b, int offset, int len) throws IOException {
      System.arraycopy(data, pos, b, offset, len);
      pos += len;
    }

    public void seek(long pos) throws IOException {
      this.pos =  (int) (pos - pointer);
    }
    
  }
}
"
lucene,2.2,org.apache.lucene.store.RAMDirectory,17,2,0,11,42,0,2,10,15,0.5625,393,0.333333333,0,0.586206897,0.352941176,1,5,21.94117647,2,0.8824,2,"package org.apache.lucene.store;



import java.io.IOException;
import java.io.FileNotFoundException;
import java.io.File;
import java.io.Serializable;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Set;


public class RAMDirectory extends Directory implements Serializable {

  private static final long serialVersionUID = 1l;

  HashMap fileMap = new HashMap();
  long sizeInBytes = 0;
  
  
  
  

  
  public RAMDirectory() {
    setLockFactory(new SingleInstanceLockFactory());
  }

  
  public RAMDirectory(Directory dir) throws IOException {
    this(dir, false);
  }
  
  private RAMDirectory(Directory dir, boolean closeDir) throws IOException {
    this();
    Directory.copy(dir, this, closeDir);
  }

  
  public RAMDirectory(File dir) throws IOException {
    this(FSDirectory.getDirectory(dir), true);
  }

  
  public RAMDirectory(String dir) throws IOException {
    this(FSDirectory.getDirectory(dir), true);
  }

  
  public synchronized final String[] list() {
    ensureOpen();
    Set fileNames = fileMap.keySet();
    String[] result = new String[fileNames.size()];
    int i = 0;
    Iterator it = fileNames.iterator();
    while (it.hasNext())
      result[i++] = (String)it.next();
    return result;
  }

  
  public final boolean fileExists(String name) {
    ensureOpen();
    RAMFile file;
    synchronized (this) {
      file = (RAMFile)fileMap.get(name);
    }
    return file != null;
  }

  
  public final long fileModified(String name) throws IOException {
    ensureOpen();
    RAMFile file;
    synchronized (this) {
      file = (RAMFile)fileMap.get(name);
    }
    if (file==null)
      throw new FileNotFoundException(name);
    return file.getLastModified();
  }

  
  public void touchFile(String name) throws IOException {
    ensureOpen();
    RAMFile file;
    synchronized (this) {
      file = (RAMFile)fileMap.get(name);
    }
    if (file==null)
      throw new FileNotFoundException(name);
    
    long ts2, ts1 = System.currentTimeMillis();
    do {
      try {
        Thread.sleep(0, 1);
      } catch (InterruptedException e) {}
      ts2 = System.currentTimeMillis();
    } while(ts1 == ts2);
    
    file.setLastModified(ts2);
  }

  
  public final long fileLength(String name) throws IOException {
    ensureOpen();
    RAMFile file;
    synchronized (this) {
      file = (RAMFile)fileMap.get(name);
    }
    if (file==null)
      throw new FileNotFoundException(name);
    return file.getLength();
  }
  
  
  public synchronized final long sizeInBytes() {
    ensureOpen();
    return sizeInBytes;
  }
  
  
  public synchronized void deleteFile(String name) throws IOException {
    ensureOpen();
    RAMFile file = (RAMFile)fileMap.get(name);
    if (file!=null) {
        fileMap.remove(name);
        file.directory = null;
        sizeInBytes -= file.sizeInBytes;       
    } else
      throw new FileNotFoundException(name);
  }

  
  public synchronized final void renameFile(String from, String to) throws IOException {
    ensureOpen();
    RAMFile fromFile = (RAMFile)fileMap.get(from);
    if (fromFile==null)
      throw new FileNotFoundException(from);
    RAMFile toFile = (RAMFile)fileMap.get(to);
    if (toFile!=null) {
      sizeInBytes -= toFile.sizeInBytes;       
      toFile.directory = null;
    }
    fileMap.remove(from);
    fileMap.put(to, fromFile);
  }

  
  public IndexOutput createOutput(String name) {
    ensureOpen();
    RAMFile file = new RAMFile(this);
    synchronized (this) {
      RAMFile existing = (RAMFile)fileMap.get(name);
      if (existing!=null) {
        sizeInBytes -= existing.sizeInBytes;
        existing.directory = null;
      }
      fileMap.put(name, file);
    }
    return new RAMOutputStream(file);
  }

  
  public IndexInput openInput(String name) throws IOException {
    ensureOpen();
    RAMFile file;
    synchronized (this) {
      file = (RAMFile)fileMap.get(name);
    }
    if (file == null)
      throw new FileNotFoundException(name);
    return new RAMInputStream(file);
  }

  
  public void close() {
    fileMap = null;
  }

  
  protected final void ensureOpen() throws AlreadyClosedException {
    if (fileMap == null) {
      throw new AlreadyClosedException(""this RAMDirectory is closed"");
    }
  }
}
"
lucene,2.2,org.apache.lucene.search.spans.SpanQuery,5,2,5,17,7,10,12,6,4,2.0,14,0.0,0,0.75,0.466666667,1,1,1.8,1,0.8,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.Weight;
import org.apache.lucene.search.Searcher;


public abstract class SpanQuery extends Query {
  
  public abstract Spans getSpans(IndexReader reader) throws IOException;

  
  public abstract String getField();

  
  public abstract Collection getTerms();

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new SpanWeight(this, searcher);
  }

}

"
lucene,2.2,org.apache.lucene.index.TermPositions,4,1,0,23,4,6,22,1,4,2.0,4,0.0,0,0.0,0.5,0,0,0.0,1,1.0,1,"package org.apache.lucene.index;



import java.io.IOException;



public interface TermPositions
    extends TermDocs
{
    
    int nextPosition() throws IOException;
    
    
    
    int getPayloadLength();
    
    
    
    byte[] getPayload(byte[] data, int offset) throws IOException;

  
   
    public boolean isPayloadAvailable();

}
"
lucene,2.2,org.apache.lucene.search.function.DocValues,14,1,6,16,19,79,15,1,11,0.723076923,133,1.0,0,0.0,0.785714286,0,0,8.142857143,3,1.0,1,"package org.apache.lucene.search.function;



import org.apache.lucene.search.Explanation;


public abstract class DocValues {
  

  private int nVals;
  
  
  public DocValues (int nVals) {
    this.nVals = nVals;
  }
  
  
  private DocValues () {
    
  }
  
  public abstract float floatVal(int doc);
  
  
  public int intVal(int doc) { 
    return (int) floatVal(doc);
  }
  
  
  public long longVal(int doc) {
    return (long) floatVal(doc);
  }

  
  public double doubleVal(int doc) {
    return (double) floatVal(doc);
  }
  
  
  public String strVal(int doc) {
    return Float.toString(floatVal(doc));
  }
  
  
  public abstract String toString(int doc);
  
  
  public Explanation explain(int doc) {
    return new Explanation(floatVal(doc), toString(doc));
  }
  
  
  Object getInnerArray() {
    return new Object[0];
  }

  
  private float minVal;
  private float maxVal;
  private float avgVal;
  private boolean computed=false;
  
  private void compute () {
    if (computed) {
      return;
    }
    minVal = Float.MAX_VALUE;
    maxVal = 0;
    float sum = 0;
    for (int i=0; i<nVals; i++) {
      float val = floatVal(i); 
      sum += val;
      minVal = Math.min(minVal,val);
      maxVal = Math.max(maxVal,val);
    }
    avgVal = sum / nVals;
    computed = true;
  }
  
  public float getMinValue () {
    compute();
    return minVal;
  }
  
  
  public float getMaxValue () {
    compute();
    return maxVal;
  }
  
  
  public float getAverageValue () {
    compute();
    return avgVal;
  }

}
"
lucene,2.2,org.apache.lucene.analysis.standard.CharStream,12,1,0,3,12,66,3,0,12,2.0,12,0.0,0,0.0,0.583333333,0,0,0.0,1,1.0,0,"
package org.apache.lucene.analysis.standard;



public interface CharStream {

  
  char readChar() throws java.io.IOException;

  
  int getColumn();

  
  int getLine();

  
  int getEndColumn();

  
  int getEndLine();

  
  int getBeginColumn();

  
  int getBeginLine();

  
  void backup(int amount);

  
  char BeginToken() throws java.io.IOException;

  
  String GetImage();

  
  char[] GetSuffix(int len);

  
  void Done();

}
"
lucene,2.2,org.apache.lucene.analysis.standard.FastCharStream,14,1,0,2,25,3,1,1,13,0.602564103,237,0.0,0,0.0,0.404761905,0,0,15.5,1,0.9286,0,"
package org.apache.lucene.analysis.standard;



import java.io.*;


public final class FastCharStream implements CharStream {
  char[] buffer = null;

  int bufferLength = 0;				  
  int bufferPosition = 0;			  
  
  int tokenStart = 0;				  
  int bufferStart = 0;				  

  Reader input;					  

  
  public FastCharStream(Reader r) {
    input = r;
  }

  public final char readChar() throws IOException {
    if (bufferPosition >= bufferLength)
      refill();
    return buffer[bufferPosition++];
  }

  private final void refill() throws IOException {
    int newPosition = bufferLength - tokenStart;

    if (tokenStart == 0) {			  
      if (buffer == null) {			  
	buffer = new char[2048];		  
      } else if (bufferLength == buffer.length) { 
	char[] newBuffer = new char[buffer.length*2];
	System.arraycopy(buffer, 0, newBuffer, 0, bufferLength);
	buffer = newBuffer;
      }
    } else {					  
      System.arraycopy(buffer, tokenStart, buffer, 0, newPosition);
    }

    bufferLength = newPosition;			  
    bufferPosition = newPosition;
    bufferStart += tokenStart;
    tokenStart = 0;

    int charsRead =				  
      input.read(buffer, newPosition, buffer.length-newPosition);
    if (charsRead == -1)
      throw new IOException(""read past eof"");
    else
      bufferLength += charsRead;
  }

  public final char BeginToken() throws IOException {
    tokenStart = bufferPosition;
    return readChar();
  }

  public final void backup(int amount) {
    bufferPosition -= amount;
  }

  public final String GetImage() {
    return new String(buffer, tokenStart, bufferPosition - tokenStart);
  }

  public final char[] GetSuffix(int len) {
    char[] value = new char[len];
    System.arraycopy(buffer, bufferPosition - len, value, 0, len);
    return value;
  }

  public final void Done() {
    try {
      input.close();
    } catch (IOException e) {
      System.err.println(""Caught: "" + e + ""; ignoring."");
    }
  }

  public final int getColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getLine() {
    return 1;
  }
  public final int getEndColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getEndLine() {
    return 1;
  }
  public final int getBeginColumn() {
    return bufferStart + tokenStart;
  }
  public final int getBeginLine() {
    return 1;
  }
}
"
lucene,2.2,org.apache.lucene.search.FieldCacheImpl,14,1,0,22,29,67,9,22,12,0.897435897,199,0.333333333,12,0.0,0.403846154,0,0,12.35714286,1,0.8571,4,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermDocs;
import org.apache.lucene.index.TermEnum;

import java.io.IOException;
import java.util.Locale;
import java.util.Map;
import java.util.WeakHashMap;
import java.util.HashMap;


class FieldCacheImpl
implements FieldCache {
	
  
  abstract static class Cache {
    private final Map readerCache = new WeakHashMap();
    
    protected abstract Object createValue(IndexReader reader, Object key)
        throws IOException;

    public Object get(IndexReader reader, Object key) throws IOException {
      Map innerCache;
      Object value;
      synchronized (readerCache) {
        innerCache = (Map) readerCache.get(reader);
        if (innerCache == null) {
          innerCache = new HashMap();
          readerCache.put(reader, innerCache);
          value = null;
        } else {
          value = innerCache.get(key);
        }
        if (value == null) {
          value = new CreationPlaceholder();
          innerCache.put(key, value);
        }
      }
      if (value instanceof CreationPlaceholder) {
        synchronized (value) {
          CreationPlaceholder progress = (CreationPlaceholder) value;
          if (progress.value == null) {
            progress.value = createValue(reader, key);
            synchronized (readerCache) {
              innerCache.put(key, progress.value);
            }
          }
          return progress.value;
        }
      }
      return value;
    }
  }

  static final class CreationPlaceholder {
    Object value;
  }

  
  static class Entry {
    final String field;        
    final int type;            
    final Object custom;       
    final Locale locale;       

    
    Entry (String field, int type, Locale locale) {
      this.field = field.intern();
      this.type = type;
      this.custom = null;
      this.locale = locale;
    }

    
    Entry (String field, Object custom) {
      this.field = field.intern();
      this.type = SortField.CUSTOM;
      this.custom = custom;
      this.locale = null;
    }

    
    public boolean equals (Object o) {
      if (o instanceof Entry) {
        Entry other = (Entry) o;
        if (other.field == field && other.type == type) {
          if (other.locale == null ? locale == null : other.locale.equals(locale)) {
            if (other.custom == null) {
              if (custom == null) return true;
            } else if (other.custom.equals (custom)) {
              return true;
            }
          }
        }
      }
      return false;
    }

    
    public int hashCode() {
      return field.hashCode() ^ type ^ (custom==null ? 0 : custom.hashCode()) ^ (locale==null ? 0 : locale.hashCode());
    }
  }

  private static final ByteParser BYTE_PARSER = new ByteParser() {
    public byte parseByte(String value) {
      return Byte.parseByte(value);
    }
  };

  private static final ShortParser SHORT_PARSER = new ShortParser() {
    public short parseShort(String value) {
      return Short.parseShort(value);
    }
  };

  private static final IntParser INT_PARSER = new IntParser() {
      public int parseInt(String value) {
        return Integer.parseInt(value);
      }
  };

  private static final FloatParser FLOAT_PARSER = new FloatParser() {
      public float parseFloat(String value) {
        return Float.parseFloat(value);
      }
  };

  
  public byte[] getBytes (IndexReader reader, String field) throws IOException {
    return getBytes(reader, field, BYTE_PARSER);
  }

  
  public byte[] getBytes(IndexReader reader, String field, ByteParser parser)
      throws IOException {
    return (byte[]) bytesCache.get(reader, new Entry(field, parser));
  }

  Cache bytesCache = new Cache() {

    protected Object createValue(IndexReader reader, Object entryKey)
        throws IOException {
      Entry entry = (Entry) entryKey;
      String field = entry.field;
      ByteParser parser = (ByteParser) entry.custom;
      final byte[] retArray = new byte[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          byte termval = parser.parseByte(term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      return retArray;
    }
  };
  
  
  public short[] getShorts (IndexReader reader, String field) throws IOException {
    return getShorts(reader, field, SHORT_PARSER);
  }

  
  public short[] getShorts(IndexReader reader, String field, ShortParser parser)
      throws IOException {
    return (short[]) shortsCache.get(reader, new Entry(field, parser));
  }

  Cache shortsCache = new Cache() {

    protected Object createValue(IndexReader reader, Object entryKey)
        throws IOException {
      Entry entry = (Entry) entryKey;
      String field = entry.field;
      ShortParser parser = (ShortParser) entry.custom;
      final short[] retArray = new short[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          short termval = parser.parseShort(term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      return retArray;
    }
  };
  
  
  public int[] getInts (IndexReader reader, String field) throws IOException {
    return getInts(reader, field, INT_PARSER);
  }

  
  public int[] getInts(IndexReader reader, String field, IntParser parser)
      throws IOException {
    return (int[]) intsCache.get(reader, new Entry(field, parser));
  }

  Cache intsCache = new Cache() {

    protected Object createValue(IndexReader reader, Object entryKey)
        throws IOException {
      Entry entry = (Entry) entryKey;
      String field = entry.field;
      IntParser parser = (IntParser) entry.custom;
      final int[] retArray = new int[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          int termval = parser.parseInt(term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      return retArray;
    }
  };

  
  public float[] getFloats (IndexReader reader, String field)
    throws IOException {
    return getFloats(reader, field, FLOAT_PARSER);
  }

  
  public float[] getFloats(IndexReader reader, String field, FloatParser parser)
      throws IOException {
    return (float[]) floatsCache.get(reader, new Entry(field, parser));
  }

  Cache floatsCache = new Cache() {

    protected Object createValue(IndexReader reader, Object entryKey)
        throws IOException {
      Entry entry = (Entry) entryKey;
      String field = entry.field;
      FloatParser parser = (FloatParser) entry.custom;
      final float[] retArray = new float[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          float termval = parser.parseFloat(term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      return retArray;
    }
  };

  
  public String[] getStrings(IndexReader reader, String field)
      throws IOException {
    return (String[]) stringsCache.get(reader, field);
  }

  Cache stringsCache = new Cache() {

    protected Object createValue(IndexReader reader, Object fieldKey)
        throws IOException {
      String field = ((String) fieldKey).intern();
      final String[] retArray = new String[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          String termval = term.text();
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      return retArray;
    }
  };

  
  public StringIndex getStringIndex(IndexReader reader, String field)
      throws IOException {
    return (StringIndex) stringsIndexCache.get(reader, field);
  }

  Cache stringsIndexCache = new Cache() {

    protected Object createValue(IndexReader reader, Object fieldKey)
        throws IOException {
      String field = ((String) fieldKey).intern();
      final int[] retArray = new int[reader.maxDoc()];
      String[] mterms = new String[reader.maxDoc()+1];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      int t = 0;  

      
      
      
      
      mterms[t++] = null;

      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;

          
          
          if (t >= mterms.length) throw new RuntimeException (""there are more terms than "" +
                  ""documents in field \"""" + field + ""\"", but it's impossible to sort on "" +
                  ""tokenized fields"");
          mterms[t] = term.text();

          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = t;
          }

          t++;
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }

      if (t == 0) {
        
        
        mterms = new String[1];
      } else if (t < mterms.length) {
        
        
        String[] terms = new String[t];
        System.arraycopy (mterms, 0, terms, 0, t);
        mterms = terms;
      }

      StringIndex value = new StringIndex (retArray, mterms);
      return value;
    }
  };

  
  

  
  

	
  public Object getAuto(IndexReader reader, String field) throws IOException {
    return autoCache.get(reader, field);
  }

  Cache autoCache = new Cache() {

    protected Object createValue(IndexReader reader, Object fieldKey)
        throws IOException {
      String field = ((String)fieldKey).intern();
      TermEnum enumerator = reader.terms (new Term (field, """"));
      try {
        Term term = enumerator.term();
        if (term == null) {
          throw new RuntimeException (""no terms in field "" + field + "" - cannot determine sort type"");
        }
        Object ret = null;
        if (term.field() == field) {
          String termtext = term.text().trim();

          

          
          try {
            Integer.parseInt (termtext);
            ret = getInts (reader, field);
          } catch (NumberFormatException nfe1) {
            try {
              Float.parseFloat (termtext);
              ret = getFloats (reader, field);
            } catch (NumberFormatException nfe2) {
              ret = getStringIndex (reader, field);
            }
          }          
        } else {
          throw new RuntimeException (""field \"""" + field + ""\"" does not appear to be indexed"");
        }
        return ret;
      } finally {
        enumerator.close();
      }
    }
  };

  
  public Comparable[] getCustom(IndexReader reader, String field,
      SortComparator comparator) throws IOException {
    return (Comparable[]) customCache.get(reader, new Entry(field, comparator));
  }

  Cache customCache = new Cache() {

    protected Object createValue(IndexReader reader, Object entryKey)
        throws IOException {
      Entry entry = (Entry) entryKey;
      String field = entry.field;
      SortComparator comparator = (SortComparator) entry.custom;
      final Comparable[] retArray = new Comparable[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          Comparable termval = comparator.getComparable (term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      return retArray;
    }
  };
  
}

"
lucene,2.2,org.apache.lucene.document.LoadFirstFieldSelector,2,1,0,2,3,1,0,2,2,2.0,7,0.0,0,0.0,0.75,0,0,2.5,1,0.5,0,"package org.apache.lucene.document;




public class LoadFirstFieldSelector implements FieldSelector {

  public FieldSelectorResult accept(String fieldName) {
    return FieldSelectorResult.LOAD_AND_BREAK;
  }
}"
lucene,2.2,org.apache.lucene.index.SegmentInfo,18,1,0,12,44,0,8,4,4,0.678733032,981,0.461538462,1,0.0,0.243055556,0,0,52.77777778,4,1.3333,3,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.IndexInput;
import java.io.IOException;
import java.util.List;
import java.util.ArrayList;

final class SegmentInfo {

  static final int NO = -1;          
  static final int YES = 1;          
  static final int CHECK_DIR = 0;    
  static final int WITHOUT_GEN = 0;  

  public String name;				  
  public int docCount;				  
  public Directory dir;				  

  private boolean preLockless;                    
                                                  

  private long delGen;                            
                                                  
                                                  
                                                  
   
  private long[] normGen;                         
                                                  
                                                  
                                                  
                                                  
                                                  
                                                  
                                                  

  private byte isCompoundFile;                    
                                                  
                                                  

  private boolean hasSingleNormFile;              
                                                  
                                                  
                                                  
                                                  
  
  private List files;                             
                                                  

  public SegmentInfo(String name, int docCount, Directory dir) {
    this.name = name;
    this.docCount = docCount;
    this.dir = dir;
    delGen = NO;
    isCompoundFile = CHECK_DIR;
    preLockless = true;
    hasSingleNormFile = false;
  }

  public SegmentInfo(String name, int docCount, Directory dir, boolean isCompoundFile, boolean hasSingleNormFile) { 
    this(name, docCount, dir);
    this.isCompoundFile = (byte) (isCompoundFile ? YES : NO);
    this.hasSingleNormFile = hasSingleNormFile;
    preLockless = false;
  }

  
  void reset(SegmentInfo src) {
    files = null;
    name = src.name;
    docCount = src.docCount;
    dir = src.dir;
    preLockless = src.preLockless;
    delGen = src.delGen;
    if (src.normGen == null) {
      normGen = null;
    } else {
      normGen = new long[src.normGen.length];
      System.arraycopy(src.normGen, 0, normGen, 0, src.normGen.length);
    }
    isCompoundFile = src.isCompoundFile;
    hasSingleNormFile = src.hasSingleNormFile;
  }

  
  SegmentInfo(Directory dir, int format, IndexInput input) throws IOException {
    this.dir = dir;
    name = input.readString();
    docCount = input.readInt();
    if (format <= SegmentInfos.FORMAT_LOCKLESS) {
      delGen = input.readLong();
      if (format <= SegmentInfos.FORMAT_SINGLE_NORM_FILE) {
        hasSingleNormFile = (1 == input.readByte());
      } else {
        hasSingleNormFile = false;
      }
      int numNormGen = input.readInt();
      if (numNormGen == NO) {
        normGen = null;
      } else {
        normGen = new long[numNormGen];
        for(int j=0;j<numNormGen;j++) {
          normGen[j] = input.readLong();
        }
      }
      isCompoundFile = input.readByte();
      preLockless = (isCompoundFile == CHECK_DIR);
    } else {
      delGen = CHECK_DIR;
      normGen = null;
      isCompoundFile = CHECK_DIR;
      preLockless = true;
      hasSingleNormFile = false;
    }
  }
  
  void setNumFields(int numFields) {
    if (normGen == null) {
      
      
      
      normGen = new long[numFields];

      if (preLockless) {
        
        
        
      } else {
        
        
        for(int i=0;i<numFields;i++) {
          normGen[i] = NO;
        }
      }
    }
  }

  boolean hasDeletions()
    throws IOException {
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    if (delGen == NO) {
      return false;
    } else if (delGen >= YES) {
      return true;
    } else {
      return dir.fileExists(getDelFileName());
    }
  }

  void advanceDelGen() {
    
    if (delGen == NO) {
      delGen = YES;
    } else {
      delGen++;
    }
    files = null;
  }

  void clearDelGen() {
    delGen = NO;
    files = null;
  }

  public Object clone () {
    SegmentInfo si = new SegmentInfo(name, docCount, dir);
    si.isCompoundFile = isCompoundFile;
    si.delGen = delGen;
    si.preLockless = preLockless;
    si.hasSingleNormFile = hasSingleNormFile;
    if (normGen != null) {
      si.normGen = (long[]) normGen.clone();
    }
    return si;
  }

  String getDelFileName() {
    if (delGen == NO) {
      
      
      return null;
    } else {
      
      return IndexFileNames.fileNameFromGeneration(name, ""."" + IndexFileNames.DELETES_EXTENSION, delGen); 
    }
  }

  
  boolean hasSeparateNorms(int fieldNumber)
    throws IOException {
    if ((normGen == null && preLockless) || (normGen != null && normGen[fieldNumber] == CHECK_DIR)) {
      
      String fileName = name + "".s"" + fieldNumber;
      return dir.fileExists(fileName);
    } else if (normGen == null || normGen[fieldNumber] == NO) {
      return false;
    } else {
      return true;
    }
  }

  
  boolean hasSeparateNorms()
    throws IOException {
    if (normGen == null) {
      if (!preLockless) {
        
        
        return false;
      } else {
        
        
        
        String[] result = dir.list();
        if (result == null)
          throw new IOException(""cannot read directory "" + dir + "": list() returned null"");
        
        String pattern;
        pattern = name + "".s"";
        int patternLength = pattern.length();
        for(int i = 0; i < result.length; i++){
          if(result[i].startsWith(pattern) && Character.isDigit(result[i].charAt(patternLength)))
            return true;
        }
        return false;
      }
    } else {
      
      
      
      for(int i=0;i<normGen.length;i++) {
        if (normGen[i] >= YES) {
          return true;
        }
      }
      
      
      for(int i=0;i<normGen.length;i++) {
        if (normGen[i] == CHECK_DIR) {
          if (hasSeparateNorms(i)) {
            return true;
          }
        }
      }
    }

    return false;
  }

  
  void advanceNormGen(int fieldIndex) {
    if (normGen[fieldIndex] == NO) {
      normGen[fieldIndex] = YES;
    } else {
      normGen[fieldIndex]++;
    }
    files = null;
  }

  
  String getNormFileName(int number) throws IOException {
    String prefix;

    long gen;
    if (normGen == null) {
      gen = CHECK_DIR;
    } else {
      gen = normGen[number];
    }
    
    if (hasSeparateNorms(number)) {
      
      prefix = "".s"";
      return IndexFileNames.fileNameFromGeneration(name, prefix + number, gen);
    }

    if (hasSingleNormFile) {
      
      prefix = ""."" + IndexFileNames.NORMS_EXTENSION;
      return IndexFileNames.fileNameFromGeneration(name, prefix, WITHOUT_GEN);
    }
      
    
    prefix = "".f"";
    return IndexFileNames.fileNameFromGeneration(name, prefix + number, WITHOUT_GEN);
  }

  
  void setUseCompoundFile(boolean isCompoundFile) {
    if (isCompoundFile) {
      this.isCompoundFile = YES;
    } else {
      this.isCompoundFile = NO;
    }
    files = null;
  }

  
  boolean getUseCompoundFile() throws IOException {
    if (isCompoundFile == NO) {
      return false;
    } else if (isCompoundFile == YES) {
      return true;
    } else {
      return dir.fileExists(name + ""."" + IndexFileNames.COMPOUND_FILE_EXTENSION);
    }
  }
  
  
  void write(IndexOutput output)
    throws IOException {
    output.writeString(name);
    output.writeInt(docCount);
    output.writeLong(delGen);
    output.writeByte((byte) (hasSingleNormFile ? 1:0));
    if (normGen == null) {
      output.writeInt(NO);
    } else {
      output.writeInt(normGen.length);
      for(int j = 0; j < normGen.length; j++) {
        output.writeLong(normGen[j]);
      }
    }
    output.writeByte(isCompoundFile);
  }

  

  public List files() throws IOException {

    if (files != null) {
      
      return files;
    }
    
    files = new ArrayList();
    
    boolean useCompoundFile = getUseCompoundFile();

    if (useCompoundFile) {
      files.add(name + ""."" + IndexFileNames.COMPOUND_FILE_EXTENSION);
    } else {
      for (int i = 0; i < IndexFileNames.INDEX_EXTENSIONS_IN_COMPOUND_FILE.length; i++) {
        String ext = IndexFileNames.INDEX_EXTENSIONS_IN_COMPOUND_FILE[i];
        String fileName = name + ""."" + ext;
        if (dir.fileExists(fileName)) {
          files.add(fileName);
        }
      }
    }

    String delFileName = IndexFileNames.fileNameFromGeneration(name, ""."" + IndexFileNames.DELETES_EXTENSION, delGen);
    if (delFileName != null && (delGen >= YES || dir.fileExists(delFileName))) {
      files.add(delFileName);
    }

    
    if (normGen != null) {
      for(int i=0;i<normGen.length;i++) {
        long gen = normGen[i];
        if (gen >= YES) {
          
          files.add(IndexFileNames.fileNameFromGeneration(name, ""."" + IndexFileNames.SEPARATE_NORMS_EXTENSION + i, gen));
        } else if (NO == gen) {
          
          
          if (!hasSingleNormFile && !useCompoundFile) {
            String fileName = name + ""."" + IndexFileNames.PLAIN_NORMS_EXTENSION + i;
            if (dir.fileExists(fileName)) {
              files.add(fileName);
            }
          }
        } else if (CHECK_DIR == gen) {
          
          String fileName = null;
          if (useCompoundFile) {
            fileName = name + ""."" + IndexFileNames.SEPARATE_NORMS_EXTENSION + i;
          } else if (!hasSingleNormFile) {
            fileName = name + ""."" + IndexFileNames.PLAIN_NORMS_EXTENSION + i;
          }
          if (fileName != null && dir.fileExists(fileName)) {
            files.add(fileName);
          }
        }
      }
    } else if (preLockless || (!hasSingleNormFile && !useCompoundFile)) {
      
      
      String prefix;
      if (useCompoundFile)
        prefix = name + ""."" + IndexFileNames.SEPARATE_NORMS_EXTENSION;
      else
        prefix = name + ""."" + IndexFileNames.PLAIN_NORMS_EXTENSION;
      int prefixLength = prefix.length();
      String[] allFiles = dir.list();
      if (allFiles == null)
        throw new IOException(""cannot read directory "" + dir + "": list() returned null"");
      for(int i=0;i<allFiles.length;i++) {
        String fileName = allFiles[i];
        if (fileName.length() > prefixLength && Character.isDigit(fileName.charAt(prefixLength)) && fileName.startsWith(prefix)) {
          files.add(fileName);
        }
      }
    }
    return files;
  }
}
"
lucene,2.2,org.apache.lucene.store.BufferedIndexInput,15,2,2,4,30,21,3,1,9,0.705357143,438,0.625,0,0.538461538,0.328571429,1,4,27.66666667,7,1.2667,3,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class BufferedIndexInput extends IndexInput {

  
  public static final int BUFFER_SIZE = 1024;

  private int bufferSize = BUFFER_SIZE;

  private byte[] buffer;

  private long bufferStart = 0;			  
  private int bufferLength = 0;			  
  private int bufferPosition = 0;		  

  public byte readByte() throws IOException {
    if (bufferPosition >= bufferLength)
      refill();
    return buffer[bufferPosition++];
  }

  public BufferedIndexInput() {}

  
  public BufferedIndexInput(int bufferSize) {
    checkBufferSize(bufferSize);
    this.bufferSize = bufferSize;
  }

  
  public void setBufferSize(int newSize) {
    assert buffer == null || bufferSize == buffer.length;
    if (newSize != bufferSize) {
      checkBufferSize(newSize);
      bufferSize = newSize;
      if (buffer != null) {
        
        
        
        byte[] newBuffer = new byte[newSize];
        final int leftInBuffer = bufferLength-bufferPosition;
        final int numToCopy;
        if (leftInBuffer > newSize)
          numToCopy = newSize;
        else
          numToCopy = leftInBuffer;
        System.arraycopy(buffer, bufferPosition, newBuffer, 0, numToCopy);
        bufferStart += bufferPosition;
        bufferPosition = 0;
        bufferLength = numToCopy;
        buffer = newBuffer;
      }
    }
  }

  
  public int getBufferSize() {
    return bufferSize;
  }

  private void checkBufferSize(int bufferSize) {
    if (bufferSize <= 0)
      throw new IllegalArgumentException(""bufferSize must be greater than 0 (got "" + bufferSize + "")"");
  }

  public void readBytes(byte[] b, int offset, int len) throws IOException {
    if(len <= (bufferLength-bufferPosition)){
      
      if(len>0) 
        System.arraycopy(buffer, bufferPosition, b, offset, len);
      bufferPosition+=len;
    } else {
      
      int available = bufferLength - bufferPosition;
      if(available > 0){
        System.arraycopy(buffer, bufferPosition, b, offset, available);
        offset += available;
        len -= available;
        bufferPosition += available;
      }
      
      if(len<bufferSize){
        
        
        refill();
        if(bufferLength<len){
          
          System.arraycopy(buffer, 0, b, offset, bufferLength);
          throw new IOException(""read past EOF"");
        } else {
          System.arraycopy(buffer, 0, b, offset, len);
          bufferPosition=len;
        }
      } else {
        
        
        
        
        long after = bufferStart+bufferPosition+len;
        if(after > length())
          throw new IOException(""read past EOF"");
        readInternal(b, offset, len);
        bufferStart = after;
        bufferPosition = 0;
        bufferLength = 0;                    
      }
    }
  }

  private void refill() throws IOException {
    long start = bufferStart + bufferPosition;
    long end = start + bufferSize;
    if (end > length())				  
      end = length();
    bufferLength = (int)(end - start);
    if (bufferLength <= 0)
      throw new IOException(""read past EOF"");

    if (buffer == null) {
      buffer = new byte[bufferSize];		  
      seekInternal(bufferStart);
    }
    readInternal(buffer, 0, bufferLength);

    bufferStart = start;
    bufferPosition = 0;
  }

  
  protected abstract void readInternal(byte[] b, int offset, int length)
          throws IOException;

  public long getFilePointer() { return bufferStart + bufferPosition; }

  public void seek(long pos) throws IOException {
    if (pos >= bufferStart && pos < (bufferStart + bufferLength))
      bufferPosition = (int)(pos - bufferStart);  
    else {
      bufferStart = pos;
      bufferPosition = 0;
      bufferLength = 0;				  
      seekInternal(pos);
    }
  }

  
  protected abstract void seekInternal(long pos) throws IOException;

  public Object clone() {
    BufferedIndexInput clone = (BufferedIndexInput)super.clone();

    clone.buffer = null;
    clone.bufferLength = 0;
    clone.bufferPosition = 0;
    clone.bufferStart = getFilePointer();

    return clone;
  }

}
"
lucene,2.2,org.apache.lucene.index.TermInfosWriter,6,1,0,9,29,0,2,7,0,0.45,395,0.666666667,5,0.0,0.479166667,0,0,62.83333333,1,0.6667,3,"package org.apache.lucene.index;




import java.io.IOException;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.Directory;
import org.apache.lucene.util.StringHelper;



final class TermInfosWriter {
  
  public static final int FORMAT = -3;

  private FieldInfos fieldInfos;
  private IndexOutput output;
  private Term lastTerm = new Term("""", """");
  private TermInfo lastTi = new TermInfo();
  private long size = 0;

  
  
  
  
  
  

  
  int indexInterval = 128;

  
  int skipInterval = 16;
  
  
  int maxSkipLevels = 10;

  private long lastIndexPointer = 0;
  private boolean isIndex = false;

  private TermInfosWriter other = null;

  TermInfosWriter(Directory directory, String segment, FieldInfos fis,
                  int interval)
       throws IOException {
    initialize(directory, segment, fis, interval, false);
    other = new TermInfosWriter(directory, segment, fis, interval, true);
    other.other = this;
  }

  private TermInfosWriter(Directory directory, String segment, FieldInfos fis,
                          int interval, boolean isIndex) throws IOException {
    initialize(directory, segment, fis, interval, isIndex);
  }

  private void initialize(Directory directory, String segment, FieldInfos fis,
                          int interval, boolean isi) throws IOException {
    indexInterval = interval;
    fieldInfos = fis;
    isIndex = isi;
    output = directory.createOutput(segment + (isIndex ? "".tii"" : "".tis""));
    output.writeInt(FORMAT);                      
    output.writeLong(0);                          
    output.writeInt(indexInterval);             
    output.writeInt(skipInterval);              
    output.writeInt(maxSkipLevels);              
  }

  
  final void add(Term term, TermInfo ti)
       throws CorruptIndexException, IOException {
    if (!isIndex && term.compareTo(lastTerm) <= 0)
      throw new CorruptIndexException(""term out of order (\"""" + term + 
          ""\"".compareTo(\"""" + lastTerm + ""\"") <= 0)"");
    if (ti.freqPointer < lastTi.freqPointer)
      throw new CorruptIndexException(""freqPointer out of order ("" + ti.freqPointer +
          "" < "" + lastTi.freqPointer + "")"");
    if (ti.proxPointer < lastTi.proxPointer)
      throw new CorruptIndexException(""proxPointer out of order ("" + ti.proxPointer + 
          "" < "" + lastTi.proxPointer + "")"");

    if (!isIndex && size % indexInterval == 0)
      other.add(lastTerm, lastTi);                      

    writeTerm(term);                                    
    output.writeVInt(ti.docFreq);                       
    output.writeVLong(ti.freqPointer - lastTi.freqPointer); 
    output.writeVLong(ti.proxPointer - lastTi.proxPointer);

    if (ti.docFreq >= skipInterval) {
      output.writeVInt(ti.skipOffset);
    }

    if (isIndex) {
      output.writeVLong(other.output.getFilePointer() - lastIndexPointer);
      lastIndexPointer = other.output.getFilePointer(); 
    }

    lastTi.set(ti);
    size++;
  }

  private final void writeTerm(Term term)
       throws IOException {
    int start = StringHelper.stringDifference(lastTerm.text, term.text);
    int length = term.text.length() - start;

    output.writeVInt(start);                   
    output.writeVInt(length);                  
    output.writeChars(term.text, start, length);  

    output.writeVInt(fieldInfos.fieldNumber(term.field)); 

    lastTerm = term;
  }



  
  final void close() throws IOException {
    output.seek(4);          
    output.writeLong(size);
    output.close();

    if (!isIndex)
      other.close();
  }

}
"
lucene,2.2,org.apache.lucene.index.DefaultSkipListReader,8,2,0,3,15,0,1,2,0,0.571428571,158,1.0,0,0.5625,0.425,1,3,17.875,1,0.875,0,"package org.apache.lucene.index;



import java.io.IOException;
import java.util.Arrays;

import org.apache.lucene.store.IndexInput;


class DefaultSkipListReader extends MultiLevelSkipListReader {
  private boolean currentFieldStoresPayloads;
  private long freqPointer[];
  private long proxPointer[];
  private int payloadLength[];
  
  private long lastFreqPointer;
  private long lastProxPointer;
  private int lastPayloadLength;
                           

  DefaultSkipListReader(IndexInput skipStream, int maxSkipLevels, int skipInterval) {
    super(skipStream, maxSkipLevels, skipInterval);
    freqPointer = new long[maxSkipLevels];
    proxPointer = new long[maxSkipLevels];
    payloadLength = new int[maxSkipLevels];
  }
  
  void init(long skipPointer, long freqBasePointer, long proxBasePointer, int df, boolean storesPayloads) {
    super.init(skipPointer, df);
    this.currentFieldStoresPayloads = storesPayloads;
    lastFreqPointer = freqBasePointer;
    lastProxPointer = proxBasePointer;

    Arrays.fill(freqPointer, freqBasePointer);
    Arrays.fill(proxPointer, proxBasePointer);
    Arrays.fill(payloadLength, 0);
  }

  
  long getFreqPointer() {
    return lastFreqPointer;
  }

  
  long getProxPointer() {
    return lastProxPointer;
  }
  
  
  int getPayloadLength() {
    return lastPayloadLength;
  }
  
  protected void seekChild(int level) throws IOException {
    super.seekChild(level);
    freqPointer[level] = lastFreqPointer;
    proxPointer[level] = lastProxPointer;
    payloadLength[level] = lastPayloadLength;
  }
  
  protected void setLastSkipData(int level) {
    super.setLastSkipData(level);
    lastFreqPointer = freqPointer[level];
    lastProxPointer = proxPointer[level];
    lastPayloadLength = payloadLength[level];
  }


  protected int readSkipData(int level, IndexInput skipStream) throws IOException {
    int delta;
    if (currentFieldStoresPayloads) {
      
      
      
      
      
      delta = skipStream.readVInt();
      if ((delta & 1) != 0) {
        payloadLength[level] = skipStream.readVInt();
      }
      delta >>>= 1;
    } else {
      delta = skipStream.readVInt();
    }
    freqPointer[level] += skipStream.readVInt();
    proxPointer[level] += skipStream.readVInt();
    
    return delta;
  }
}
"
lucene,2.2,org.apache.lucene.search.MultiSearcher,16,2,1,22,53,0,2,21,14,0.466666667,577,1.0,1,0.594594595,0.23125,1,5,34.875,6,1.25,0,"package org.apache.lucene.search;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.index.CorruptIndexException;
import org.apache.lucene.index.Term;

import java.io.IOException;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;


public class MultiSearcher extends Searcher {
    
  private static class CachedDfSource extends Searcher {
    private Map dfMap; 
    private int maxDoc; 

    public CachedDfSource(Map dfMap, int maxDoc, Similarity similarity) {
      this.dfMap = dfMap;
      this.maxDoc = maxDoc;
      setSimilarity(similarity);
    }

    public int docFreq(Term term) {
      int df;
      try {
        df = ((Integer) dfMap.get(term)).intValue();
      } catch (NullPointerException e) {
        throw new IllegalArgumentException(""df for term "" + term.text()
            + "" not available"");
      }
      return df;
    }

    public int[] docFreqs(Term[] terms) {
      int[] result = new int[terms.length];
      for (int i = 0; i < terms.length; i++) {
        result[i] = docFreq(terms[i]);
      }
      return result;
    }

    public int maxDoc() {
      return maxDoc;
    }

    public Query rewrite(Query query) {
      
      
      
      
      return query;
    }

    public void close() {
      throw new UnsupportedOperationException();
    }

    public Document doc(int i) {
      throw new UnsupportedOperationException();
    }
    
    public Document doc(int i, FieldSelector fieldSelector) {
        throw new UnsupportedOperationException();
    }

    public Explanation explain(Weight weight,int doc) {
      throw new UnsupportedOperationException();
    }

    public void search(Weight weight, Filter filter, HitCollector results) {
      throw new UnsupportedOperationException();
    }

    public TopDocs search(Weight weight,Filter filter,int n) {
      throw new UnsupportedOperationException();
    }

    public TopFieldDocs search(Weight weight,Filter filter,int n,Sort sort) {
      throw new UnsupportedOperationException();
    }
  }


  private Searchable[] searchables;
  private int[] starts;
  private int maxDoc = 0;

  
  public MultiSearcher(Searchable[] searchables) throws IOException {
    this.searchables = searchables;

    starts = new int[searchables.length + 1];	  
    for (int i = 0; i < searchables.length; i++) {
      starts[i] = maxDoc;
      maxDoc += searchables[i].maxDoc();          
    }
    starts[searchables.length] = maxDoc;
  }
  
  
  public Searchable[] getSearchables() {
    return searchables;
  }

  protected int[] getStarts() {
  	return starts;
  }

  
  public void close() throws IOException {
    for (int i = 0; i < searchables.length; i++)
      searchables[i].close();
  }

  public int docFreq(Term term) throws IOException {
    int docFreq = 0;
    for (int i = 0; i < searchables.length; i++)
      docFreq += searchables[i].docFreq(term);
    return docFreq;
  }

  
  public Document doc(int n) throws CorruptIndexException, IOException {
    int i = subSearcher(n);			  
    return searchables[i].doc(n - starts[i]);	  
  }

  
  public Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
    int i = subSearcher(n);			  
    return searchables[i].doc(n - starts[i], fieldSelector);	  
  }
  
  
  public int subSearcher(int n) {                 
    
    int lo = 0;					  
    int hi = searchables.length - 1;		  
						  
    while (hi >= lo) {
      int mid = (lo + hi) >> 1;
      int midValue = starts[mid];
      if (n < midValue)
	hi = mid - 1;
      else if (n > midValue)
	lo = mid + 1;
      else {                                      
        while (mid+1 < searchables.length && starts[mid+1] == midValue) {
          mid++;                                  
        }
	return mid;
      }
    }
    return hi;
  }

  
  public int subDoc(int n) {
    return n - starts[subSearcher(n)];
  }

  public int maxDoc() throws IOException {
    return maxDoc;
  }

  public TopDocs search(Weight weight, Filter filter, int nDocs)
  throws IOException {

    HitQueue hq = new HitQueue(nDocs);
    int totalHits = 0;

    for (int i = 0; i < searchables.length; i++) { 
      TopDocs docs = searchables[i].search(weight, filter, nDocs);
      totalHits += docs.totalHits;		  
      ScoreDoc[] scoreDocs = docs.scoreDocs;
      for (int j = 0; j < scoreDocs.length; j++) { 
	ScoreDoc scoreDoc = scoreDocs[j];
        scoreDoc.doc += starts[i];                
        if(!hq.insert(scoreDoc))
            break;                                
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size()-1; i >= 0; i--)	  
      scoreDocs[i] = (ScoreDoc)hq.pop();
    
    float maxScore = (totalHits==0) ? Float.NEGATIVE_INFINITY : scoreDocs[0].score;
    
    return new TopDocs(totalHits, scoreDocs, maxScore);
  }

  public TopFieldDocs search (Weight weight, Filter filter, int n, Sort sort)
  throws IOException {
    FieldDocSortedHitQueue hq = null;
    int totalHits = 0;

    float maxScore=Float.NEGATIVE_INFINITY;
    
    for (int i = 0; i < searchables.length; i++) { 
      TopFieldDocs docs = searchables[i].search (weight, filter, n, sort);
      
      if (hq == null) hq = new FieldDocSortedHitQueue (docs.fields, n);
      totalHits += docs.totalHits;		  
      maxScore = Math.max(maxScore, docs.getMaxScore());
      ScoreDoc[] scoreDocs = docs.scoreDocs;
      for (int j = 0; j < scoreDocs.length; j++) { 
        ScoreDoc scoreDoc = scoreDocs[j];
        scoreDoc.doc += starts[i];                
        if (!hq.insert (scoreDoc))
          break;                                  
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size() - 1; i >= 0; i--)	  
      scoreDocs[i] = (ScoreDoc) hq.pop();

    return new TopFieldDocs (totalHits, scoreDocs, hq.getFields(), maxScore);
  }


  
  public void search(Weight weight, Filter filter, final HitCollector results)
    throws IOException {
    for (int i = 0; i < searchables.length; i++) {

      final int start = starts[i];

      searchables[i].search(weight, filter, new HitCollector() {
	  public void collect(int doc, float score) {
	    results.collect(doc + start, score);
	  }
	});

    }
  }

  public Query rewrite(Query original) throws IOException {
    Query[] queries = new Query[searchables.length];
    for (int i = 0; i < searchables.length; i++) {
      queries[i] = searchables[i].rewrite(original);
    }
    return queries[0].combine(queries);
  }

  public Explanation explain(Weight weight, int doc) throws IOException {
    int i = subSearcher(doc);			  
    return searchables[i].explain(weight,doc-starts[i]); 
  }

  
  protected Weight createWeight(Query original) throws IOException {
    
    Query rewrittenQuery = rewrite(original);

    
    Set terms = new HashSet();
    rewrittenQuery.extractTerms(terms);

    
    Term[] allTermsArray = new Term[terms.size()];
    terms.toArray(allTermsArray);
    int[] aggregatedDfs = new int[terms.size()];
    for (int i = 0; i < searchables.length; i++) {
      int[] dfs = searchables[i].docFreqs(allTermsArray);
      for(int j=0; j<aggregatedDfs.length; j++){
        aggregatedDfs[j] += dfs[j];
      }
    }

    HashMap dfMap = new HashMap();
    for(int i=0; i<allTermsArray.length; i++) {
      dfMap.put(allTermsArray[i], new Integer(aggregatedDfs[i]));
    }

    
    int numDocs = maxDoc();
    CachedDfSource cacheSim = new CachedDfSource(dfMap, numDocs, getSimilarity());

    return rewrittenQuery.weight(cacheSim);
  }

}
"
lucene,2.2,org.apache.lucene.search.Searchable,11,1,0,18,11,55,6,12,11,2.0,11,0.0,0,0.0,0.263636364,0,0,0.0,1,1.0,2,"package org.apache.lucene.search;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.CorruptIndexException;

import java.io.IOException;       


public interface Searchable extends java.rmi.Remote {
  
  void search(Weight weight, Filter filter, HitCollector results)
  throws IOException;


  
  void close() throws IOException;

  
  int docFreq(Term term) throws IOException;

  
  int[] docFreqs(Term[] terms) throws IOException;

  
  int maxDoc() throws IOException;

  
  TopDocs search(Weight weight, Filter filter, int n) throws IOException;

  
  Document doc(int i) throws CorruptIndexException, IOException;

  
  Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException;
  
  
  Query rewrite(Query query) throws IOException;

  
  Explanation explain(Weight weight, int doc) throws IOException;

  
  TopFieldDocs search(Weight weight, Filter filter, int n, Sort sort)
  throws IOException;

}
"
lucene,2.2,org.apache.lucene.search.MultiPhraseQuery,17,2,0,12,55,12,3,10,13,0.625,407,1.0,0,0.428571429,0.158823529,2,4,22.70588235,7,2.0588,2,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.*;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.MultipleTermPositions;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class MultiPhraseQuery extends Query {
  private String field;
  private ArrayList termArrays = new ArrayList();
  private Vector positions = new Vector();

  private int slop = 0;

  
  public void setSlop(int s) { slop = s; }

  
  public int getSlop() { return slop; }

  
  public void add(Term term) { add(new Term[]{term}); }

  
  public void add(Term[] terms) {
    int position = 0;
    if (positions.size() > 0)
      position = ((Integer) positions.lastElement()).intValue() + 1;

    add(terms, position);
  }

  
  public void add(Term[] terms, int position) {
    if (termArrays.size() == 0)
      field = terms[0].field();

    for (int i = 0; i < terms.length; i++) {
      if (terms[i].field() != field) {
        throw new IllegalArgumentException(
            ""All phrase terms must be in the same field ("" + field + ""): ""
                + terms[i]);
      }
    }

    termArrays.add(terms);
    positions.addElement(new Integer(position));
  }

  
  public List getTermArrays() {
	  return Collections.unmodifiableList(termArrays);
  }

  
  public int[] getPositions() {
    int[] result = new int[positions.size()];
    for (int i = 0; i < positions.size(); i++)
      result[i] = ((Integer) positions.elementAt(i)).intValue();
    return result;
  }

  
  public void extractTerms(Set terms) {
    for (Iterator iter = termArrays.iterator(); iter.hasNext();) {
      Term[] arr = (Term[])iter.next();
      for (int i=0; i<arr.length; i++) {
        terms.add(arr[i]);
      }
    }
  }


  private class MultiPhraseWeight implements Weight {
    private Similarity similarity;
    private float value;
    private float idf;
    private float queryNorm;
    private float queryWeight;

    public MultiPhraseWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);

      
      Iterator i = termArrays.iterator();
      while (i.hasNext()) {
        Term[] terms = (Term[])i.next();
        for (int j=0; j<terms.length; j++) {
          idf += getSimilarity(searcher).idf(terms[j], searcher);
        }
      }
    }

    public Query getQuery() { return MultiPhraseQuery.this; }
    public float getValue() { return value; }

    public float sumOfSquaredWeights() {
      queryWeight = idf * getBoost();             
      return queryWeight * queryWeight;           
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= queryNorm;                   
      value = queryWeight * idf;                  
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      if (termArrays.size() == 0)                  
        return null;

      TermPositions[] tps = new TermPositions[termArrays.size()];
      for (int i=0; i<tps.length; i++) {
        Term[] terms = (Term[])termArrays.get(i);

        TermPositions p;
        if (terms.length > 1)
          p = new MultipleTermPositions(reader, terms);
        else
          p = reader.termPositions(terms[0]);

        if (p == null)
          return null;

        tps[i] = p;
      }

      if (slop == 0)
        return new ExactPhraseScorer(this, tps, getPositions(), similarity,
                                     reader.norms(field));
      else
        return new SloppyPhraseScorer(this, tps, getPositions(), similarity,
                                      slop, reader.norms(field));
    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {
      ComplexExplanation result = new ComplexExplanation();
      result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");

      Explanation idfExpl = new Explanation(idf, ""idf(""+getQuery()+"")"");

      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

      Explanation boostExpl = new Explanation(getBoost(), ""boost"");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);

      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      
      ComplexExplanation fieldExpl = new ComplexExplanation();
      fieldExpl.setDescription(""fieldWeight(""+getQuery()+"" in ""+doc+
                               ""), product of:"");

      Explanation tfExpl = scorer(reader).explain(doc);
      fieldExpl.addDetail(tfExpl);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setMatch(Boolean.valueOf(tfExpl.isMatch()));
      fieldExpl.setValue(tfExpl.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);
      result.setMatch(fieldExpl.getMatch());

      
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }
  }

  public Query rewrite(IndexReader reader) {
    if (termArrays.size() == 1) {                 
      Term[] terms = (Term[])termArrays.get(0);
      BooleanQuery boq = new BooleanQuery(true);
      for (int i=0; i<terms.length; i++) {
        boq.add(new TermQuery(terms[i]), BooleanClause.Occur.SHOULD);
      }
      boq.setBoost(getBoost());
      return boq;
    } else {
      return this;
    }
  }

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new MultiPhraseWeight(searcher);
  }

  
  public final String toString(String f) {
    StringBuffer buffer = new StringBuffer();
    if (!field.equals(f)) {
      buffer.append(field);
      buffer.append("":"");
    }

    buffer.append(""\"""");
    Iterator i = termArrays.iterator();
    while (i.hasNext()) {
      Term[] terms = (Term[])i.next();
      if (terms.length > 1) {
        buffer.append(""("");
        for (int j = 0; j < terms.length; j++) {
          buffer.append(terms[j].text());
          if (j < terms.length-1)
            buffer.append("" "");
        }
        buffer.append("")"");
      } else {
        buffer.append(terms[0].text());
      }
      if (i.hasNext())
        buffer.append("" "");
    }
    buffer.append(""\"""");

    if (slop != 0) {
      buffer.append(""~"");
      buffer.append(slop);
    }

    buffer.append(ToStringUtils.boost(getBoost()));

    return buffer.toString();
  }


  
  public boolean equals(Object o) {
    if (!(o instanceof MultiPhraseQuery)) return false;
    MultiPhraseQuery other = (MultiPhraseQuery)o;
    return this.getBoost() == other.getBoost()
      && this.slop == other.slop
      && this.termArrays.equals(other.termArrays)
      && this.positions.equals(other.positions);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost())
      ^ slop
      ^ termArrays.hashCode()
      ^ positions.hashCode()
      ^ 0x4AC65113;
  }
}
"
lucene,2.2,org.apache.lucene.store.IndexOutput,15,1,2,19,18,105,19,0,15,2.0,196,0.0,0,0.0,0.311111111,0,0,12.06666667,1,0.9333,2,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class IndexOutput {

  
  public abstract void writeByte(byte b) throws IOException;

  
  public void writeBytes(byte[] b, int length) throws IOException {
    writeBytes(b, 0, length);
  }

  
  public abstract void writeBytes(byte[] b, int offset, int length) throws IOException;

  
  public void writeInt(int i) throws IOException {
    writeByte((byte)(i >> 24));
    writeByte((byte)(i >> 16));
    writeByte((byte)(i >>  8));
    writeByte((byte) i);
  }

  
  public void writeVInt(int i) throws IOException {
    while ((i & ~0x7F) != 0) {
      writeByte((byte)((i & 0x7f) | 0x80));
      i >>>= 7;
    }
    writeByte((byte)i);
  }

  
  public void writeLong(long i) throws IOException {
    writeInt((int) (i >> 32));
    writeInt((int) i);
  }

  
  public void writeVLong(long i) throws IOException {
    while ((i & ~0x7F) != 0) {
      writeByte((byte)((i & 0x7f) | 0x80));
      i >>>= 7;
    }
    writeByte((byte)i);
  }

  
  public void writeString(String s) throws IOException {
    int length = s.length();
    writeVInt(length);
    writeChars(s, 0, length);
  }

  
  public void writeChars(String s, int start, int length)
       throws IOException {
    final int end = start + length;
    for (int i = start; i < end; i++) {
      final int code = (int)s.charAt(i);
      if (code >= 0x01 && code <= 0x7F)
	writeByte((byte)code);
      else if (((code >= 0x80) && (code <= 0x7FF)) || code == 0) {
	writeByte((byte)(0xC0 | (code >> 6)));
	writeByte((byte)(0x80 | (code & 0x3F)));
      } else {
	writeByte((byte)(0xE0 | (code >>> 12)));
	writeByte((byte)(0x80 | ((code >> 6) & 0x3F)));
	writeByte((byte)(0x80 | (code & 0x3F)));
      }
    }
  }

  
  public abstract void flush() throws IOException;

  
  public abstract void close() throws IOException;

  
  public abstract long getFilePointer();

  
  public abstract void seek(long pos) throws IOException;

  
  public abstract long length() throws IOException;


}
"
lucene,2.2,org.apache.lucene.analysis.WordlistLoader,4,1,0,2,17,6,2,0,4,2.0,147,0.0,0,0.0,0.333333333,0,0,35.75,1,0.75,0,"package org.apache.lucene.analysis;



import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.io.Reader;
import java.util.HashMap;
import java.util.HashSet;


public class WordlistLoader {

  
  public static HashSet getWordSet(File wordfile) throws IOException {
    HashSet result = new HashSet();
    FileReader reader = null;
    try {
      reader = new FileReader(wordfile);
      result = getWordSet(reader);
    }
    finally {
      if (reader != null)
        reader.close();
    }
    return result;
  }

  
  public static HashSet getWordSet(Reader reader) throws IOException {
    HashSet result = new HashSet();
    BufferedReader br = null;
    try {
      if (reader instanceof BufferedReader) {
        br = (BufferedReader) reader;
      } else {
        br = new BufferedReader(reader);
      }
      String word = null;
      while ((word = br.readLine()) != null) {
        result.add(word.trim());
      }
    }
    finally {
      if (br != null)
        br.close();
    }
    return result;
  }

  
  public static HashMap getStemDict(File wordstemfile) throws IOException {
    if (wordstemfile == null)
      throw new NullPointerException(""wordstemfile may not be null"");
    HashMap result = new HashMap();
    BufferedReader br = null;
    FileReader fr = null;
    try {
      fr = new FileReader(wordstemfile);
      br = new BufferedReader(fr);
      String line;
      while ((line = br.readLine()) != null) {
        String[] wordstem = line.split(""\t"", 2);
        result.put(wordstem[0], wordstem[1]);
      }
    } finally {
      if (fr != null)
        fr.close();
      if (br != null)
        br.close();
    }
    return result;
  }

}
"
lucene,2.2,org.apache.lucene.search.spans.TermSpans,8,1,0,6,19,0,3,3,8,0.666666667,160,1.0,2,0.0,0.34375,0,0,18.25,3,1.125,0,"package org.apache.lucene.search.spans;



import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;

import java.io.IOException;


public class TermSpans implements Spans {
  protected TermPositions positions;
  protected Term term;
  protected int doc;
  protected int freq;
  protected int count;
  protected int position;


  public TermSpans(TermPositions positions, Term term) throws IOException {

    this.positions = positions;
    this.term = term;
    doc = -1;
  }

  public boolean next() throws IOException {
    if (count == freq) {
      if (!positions.next()) {
        doc = Integer.MAX_VALUE;
        return false;
      }
      doc = positions.doc();
      freq = positions.freq();
      count = 0;
    }
    position = positions.nextPosition();
    count++;
    return true;
  }

  public boolean skipTo(int target) throws IOException {
    
    if (doc >= target) {
      return true;
    }

    if (!positions.skipTo(target)) {
      doc = Integer.MAX_VALUE;
      return false;
    }

    doc = positions.doc();
    freq = positions.freq();
    count = 0;

    position = positions.nextPosition();
    count++;

    return true;
  }

  public int doc() {
    return doc;
  }

  public int start() {
    return position;
  }

  public int end() {
    return position + 1;
  }

  public String toString() {
    return ""spans("" + term.toString() + "")@"" +
            (doc == -1 ? ""START"" : (doc == Integer.MAX_VALUE) ? ""END"" : doc + ""-"" + position);
  }


  public TermPositions getPositions() {
    return positions;
  }
}
"
lucene,2.2,org.apache.lucene.analysis.LowerCaseFilter,2,3,0,4,5,1,1,3,2,2.0,21,0.0,0,0.8,0.75,0,0,9.5,1,0.5,1,"package org.apache.lucene.analysis;



import java.io.IOException;


public final class LowerCaseFilter extends TokenFilter {
  public LowerCaseFilter(TokenStream in) {
    super(in);
  }

  public final Token next() throws IOException {
    Token t = input.next();

    if (t == null)
      return null;

    t.termText = t.termText.toLowerCase();

    return t;
  }
}
"
lucene,2.2,org.apache.lucene.index.MultiReader,28,2,0,17,61,0,1,16,17,0.682539683,664,1.0,1,0.697674419,0.157738095,1,9,22.46428571,6,1.3929,4,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.store.Directory;

import java.io.IOException;
import java.util.Collection;
import java.util.HashSet;
import java.util.Hashtable;
import java.util.Set;


public class MultiReader extends IndexReader {
  private IndexReader[] subReaders;
  private int[] starts;                           
  private Hashtable normsCache = new Hashtable();
  private int maxDoc = 0;
  private int numDocs = -1;
  private boolean hasDeletions = false;

 
  public MultiReader(IndexReader[] subReaders) throws IOException {
    super(subReaders.length == 0 ? null : subReaders[0].directory());
    initialize(subReaders);
  }

  
  MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders) {
    super(directory, sis, closeDirectory);
    initialize(subReaders);
  }

  private void initialize(IndexReader[] subReaders) {
    this.subReaders = subReaders;
    starts = new int[subReaders.length + 1];    
    for (int i = 0; i < subReaders.length; i++) {
      starts[i] = maxDoc;
      maxDoc += subReaders[i].maxDoc();      

      if (subReaders[i].hasDeletions())
        hasDeletions = true;
    }
    starts[subReaders.length] = maxDoc;
  }


  public TermFreqVector[] getTermFreqVectors(int n) throws IOException {
    ensureOpen();
    int i = readerIndex(n);        
    return subReaders[i].getTermFreqVectors(n - starts[i]); 
  }

  public TermFreqVector getTermFreqVector(int n, String field)
      throws IOException {
    ensureOpen();
    int i = readerIndex(n);        
    return subReaders[i].getTermFreqVector(n - starts[i], field);
  }

  public synchronized int numDocs() {
    
    if (numDocs == -1) {        
      int n = 0;                
      for (int i = 0; i < subReaders.length; i++)
        n += subReaders[i].numDocs();      
      numDocs = n;
    }
    return numDocs;
  }

  public int maxDoc() {
    
    return maxDoc;
  }

  
  public Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
    ensureOpen();
    int i = readerIndex(n);                          
    return subReaders[i].document(n - starts[i], fieldSelector);    
  }

  public boolean isDeleted(int n) {
    
    int i = readerIndex(n);                           
    return subReaders[i].isDeleted(n - starts[i]);    
  }

  public boolean hasDeletions() {
    
    return hasDeletions;
  }

  protected void doDelete(int n) throws CorruptIndexException, IOException {
    numDocs = -1;                             
    int i = readerIndex(n);                   
    subReaders[i].deleteDocument(n - starts[i]);      
    hasDeletions = true;
  }

  protected void doUndeleteAll() throws CorruptIndexException, IOException {
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].undeleteAll();

    hasDeletions = false;
    numDocs = -1;                                 
  }

  private int readerIndex(int n) {    
    int lo = 0;                                      
    int hi = subReaders.length - 1;                  

    while (hi >= lo) {
      int mid = (lo + hi) >> 1;
      int midValue = starts[mid];
      if (n < midValue)
        hi = mid - 1;
      else if (n > midValue)
        lo = mid + 1;
      else {                                      
        while (mid+1 < subReaders.length && starts[mid+1] == midValue) {
          mid++;                                  
        }
        return mid;
      }
    }
    return hi;
  }

  public boolean hasNorms(String field) throws IOException {
    ensureOpen();
    for (int i = 0; i < subReaders.length; i++) {
      if (subReaders[i].hasNorms(field)) return true;
    }
    return false;
  }

  private byte[] ones;
  private byte[] fakeNorms() {
    if (ones==null) ones=SegmentReader.createFakeNorms(maxDoc());
    return ones;
  }

  public synchronized byte[] norms(String field) throws IOException {
    ensureOpen();
    byte[] bytes = (byte[])normsCache.get(field);
    if (bytes != null)
      return bytes;          
    if (!hasNorms(field))
      return fakeNorms();

    bytes = new byte[maxDoc()];
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].norms(field, bytes, starts[i]);
    normsCache.put(field, bytes);      
    return bytes;
  }

  public synchronized void norms(String field, byte[] result, int offset)
    throws IOException {
    ensureOpen();
    byte[] bytes = (byte[])normsCache.get(field);
    if (bytes==null && !hasNorms(field)) bytes=fakeNorms();
    if (bytes != null)                            
      System.arraycopy(bytes, 0, result, offset, maxDoc());

    for (int i = 0; i < subReaders.length; i++)      
      subReaders[i].norms(field, result, offset + starts[i]);
  }

  protected void doSetNorm(int n, String field, byte value)
    throws CorruptIndexException, IOException {
    normsCache.remove(field);                         
    int i = readerIndex(n);                           
    subReaders[i].setNorm(n-starts[i], field, value); 
  }

  public TermEnum terms() throws IOException {
    ensureOpen();
    return new MultiTermEnum(subReaders, starts, null);
  }

  public TermEnum terms(Term term) throws IOException {
    ensureOpen();
    return new MultiTermEnum(subReaders, starts, term);
  }

  public int docFreq(Term t) throws IOException {
    ensureOpen();
    int total = 0;          
    for (int i = 0; i < subReaders.length; i++)
      total += subReaders[i].docFreq(t);
    return total;
  }

  public TermDocs termDocs() throws IOException {
    ensureOpen();
    return new MultiTermDocs(subReaders, starts);
  }

  public TermPositions termPositions() throws IOException {
    ensureOpen();
    return new MultiTermPositions(subReaders, starts);
  }

  protected void doCommit() throws IOException {
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].commit();
  }

  void startCommit() {
    super.startCommit();
    for (int i = 0; i < subReaders.length; i++) {
      subReaders[i].startCommit();
    }
  }

  void rollbackCommit() {
    super.rollbackCommit();
    for (int i = 0; i < subReaders.length; i++) {
      subReaders[i].rollbackCommit();
    }
  }

  protected synchronized void doClose() throws IOException {
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].close();
  }

  public Collection getFieldNames (IndexReader.FieldOption fieldNames) {
    
    ensureOpen();
    Set fieldSet = new HashSet();
    for (int i = 0; i < subReaders.length; i++) {
      IndexReader reader = subReaders[i];
      Collection names = reader.getFieldNames(fieldNames);
      fieldSet.addAll(names);
    }
    return fieldSet;
  }
  
}

class MultiTermEnum extends TermEnum {
  private SegmentMergeQueue queue;

  private Term term;
  private int docFreq;

  public MultiTermEnum(IndexReader[] readers, int[] starts, Term t)
    throws IOException {
    queue = new SegmentMergeQueue(readers.length);
    for (int i = 0; i < readers.length; i++) {
      IndexReader reader = readers[i];
      TermEnum termEnum;

      if (t != null) {
        termEnum = reader.terms(t);
      } else
        termEnum = reader.terms();

      SegmentMergeInfo smi = new SegmentMergeInfo(starts[i], termEnum, reader);
      if (t == null ? smi.next() : termEnum.term() != null)
        queue.put(smi);          
      else
        smi.close();
    }

    if (t != null && queue.size() > 0) {
      next();
    }
  }

  public boolean next() throws IOException {
    SegmentMergeInfo top = (SegmentMergeInfo)queue.top();
    if (top == null) {
      term = null;
      return false;
    }

    term = top.term;
    docFreq = 0;

    while (top != null && term.compareTo(top.term) == 0) {
      queue.pop();
      docFreq += top.termEnum.docFreq();    
      if (top.next())
        queue.put(top);          
      else
        top.close();          
      top = (SegmentMergeInfo)queue.top();
    }
    return true;
  }

  public Term term() {
    return term;
  }

  public int docFreq() {
    return docFreq;
  }

  public void close() throws IOException {
    queue.close();
  }
}

class MultiTermDocs implements TermDocs {
  protected IndexReader[] readers;
  protected int[] starts;
  protected Term term;

  protected int base = 0;
  protected int pointer = 0;

  private TermDocs[] readerTermDocs;
  protected TermDocs current;              

  public MultiTermDocs(IndexReader[] r, int[] s) {
    readers = r;
    starts = s;

    readerTermDocs = new TermDocs[r.length];
  }

  public int doc() {
    return base + current.doc();
  }
  public int freq() {
    return current.freq();
  }

  public void seek(Term term) {
    this.term = term;
    this.base = 0;
    this.pointer = 0;
    this.current = null;
  }

  public void seek(TermEnum termEnum) throws IOException {
    seek(termEnum.term());
  }

  public boolean next() throws IOException {
    for(;;) {
      if (current!=null && current.next()) {
        return true;
      }
      else if (pointer < readers.length) {
        base = starts[pointer];
        current = termDocs(pointer++);
      } else {
        return false;
      }
    }
  }

  
  public int read(final int[] docs, final int[] freqs) throws IOException {
    while (true) {
      while (current == null) {
        if (pointer < readers.length) {      
          base = starts[pointer];
          current = termDocs(pointer++);
        } else {
          return 0;
        }
      }
      int end = current.read(docs, freqs);
      if (end == 0) {          
        current = null;
      } else {            
        final int b = base;        
        for (int i = 0; i < end; i++)
         docs[i] += b;
        return end;
      }
    }
  }

  
  public boolean skipTo(int target) throws IOException {
    for(;;) {
      if (current != null && current.skipTo(target-base)) {
        return true;
      } else if (pointer < readers.length) {
        base = starts[pointer];
        current = termDocs(pointer++);
      } else
        return false;
    }
  }

  private TermDocs termDocs(int i) throws IOException {
    if (term == null)
      return null;
    TermDocs result = readerTermDocs[i];
    if (result == null)
      result = readerTermDocs[i] = termDocs(readers[i]);
    result.seek(term);
    return result;
  }

  protected TermDocs termDocs(IndexReader reader)
    throws IOException {
    return reader.termDocs();
  }

  public void close() throws IOException {
    for (int i = 0; i < readerTermDocs.length; i++) {
      if (readerTermDocs[i] != null)
        readerTermDocs[i].close();
    }
  }
}

class MultiTermPositions extends MultiTermDocs implements TermPositions {
  public MultiTermPositions(IndexReader[] r, int[] s) {
    super(r,s);
  }

  protected TermDocs termDocs(IndexReader reader) throws IOException {
    return (TermDocs)reader.termPositions();
  }

  public int nextPosition() throws IOException {
    return ((TermPositions)current).nextPosition();
  }
  
  public int getPayloadLength() {
    return ((TermPositions)current).getPayloadLength();
  }
   
  public byte[] getPayload(byte[] data, int offset) throws IOException {
    return ((TermPositions)current).getPayload(data, offset);
  }


  
  public boolean isPayloadAvailable() {
    return ((TermPositions) current).isPayloadAvailable();
  }
}
"
lucene,2.2,org.apache.lucene.search.spans.SpanScorer,7,2,1,7,25,0,2,5,5,0.520833333,201,1.0,2,0.571428571,0.30952381,1,3,26.57142857,1,0.8571,1,"package org.apache.lucene.search.spans;



import org.apache.lucene.search.Explanation;
import org.apache.lucene.search.Scorer;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.search.Weight;

import java.io.IOException;


public class SpanScorer extends Scorer {
  protected Spans spans;
  protected Weight weight;
  protected byte[] norms;
  protected float value;

  protected boolean firstTime = true;
  protected boolean more = true;

  protected int doc;
  protected float freq;

  protected SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms)
    throws IOException {
    super(similarity);
    this.spans = spans;
    this.norms = norms;
    this.weight = weight;
    this.value = weight.getValue();
    doc = -1;
  }

  public boolean next() throws IOException {
    if (firstTime) {
      more = spans.next();
      firstTime = false;
    }
    return setFreqCurrentDoc();
  }

  public boolean skipTo(int target) throws IOException {
    if (firstTime) {
      more = spans.skipTo(target);
      firstTime = false;
    }
    if (! more) {
      return false;
    }
    if (spans.doc() < target) { 
      more = spans.skipTo(target);
    }
    return setFreqCurrentDoc();
  }

  protected boolean setFreqCurrentDoc() throws IOException {
    if (! more) {
      return false;
    }
    doc = spans.doc();
    freq = 0.0f;
    while (more && doc == spans.doc()) {
      int matchLength = spans.end() - spans.start();
      freq += getSimilarity().sloppyFreq(matchLength);
      more = spans.next();
    }
    return more || (freq != 0);
  }

  public int doc() { return doc; }

  public float score() throws IOException {
    float raw = getSimilarity().tf(freq) * value; 
    return raw * Similarity.decodeNorm(norms[doc]); 
  }

  public Explanation explain(final int doc) throws IOException {
    Explanation tfExplanation = new Explanation();

    skipTo(doc);

    float phraseFreq = (doc() == doc) ? freq : 0.0f;
    tfExplanation.setValue(getSimilarity().tf(phraseFreq));
    tfExplanation.setDescription(""tf(phraseFreq="" + phraseFreq + "")"");

    return tfExplanation;
  }

}
"
lucene,2.2,org.apache.lucene.search.spans.SpanNearQuery,12,3,0,8,47,0,2,8,12,0.590909091,353,1.0,0,0.592592593,0.208333333,2,2,28.08333333,7,1.75,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.List;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Set;


import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class SpanNearQuery extends SpanQuery {
  private List clauses;
  private int slop;
  private boolean inOrder;

  private String field;

  
  public SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder) {

    
    this.clauses = new ArrayList(clauses.length);
    for (int i = 0; i < clauses.length; i++) {
      SpanQuery clause = clauses[i];
      if (i == 0) {                               
        field = clause.getField();
      } else if (!clause.getField().equals(field)) {
        throw new IllegalArgumentException(""Clauses must have same field."");
      }
      this.clauses.add(clause);
    }

    this.slop = slop;
    this.inOrder = inOrder;
  }

  
  public SpanQuery[] getClauses() {
    return (SpanQuery[])clauses.toArray(new SpanQuery[clauses.size()]);
  }

  
  public int getSlop() { return slop; }

  
  public boolean isInOrder() { return inOrder; }

  public String getField() { return field; }
  
  
  public Collection getTerms() {
    Collection terms = new ArrayList();
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      terms.addAll(clause.getTerms());
    }
    return terms;
  }
  
  public void extractTerms(Set terms) {
	    Iterator i = clauses.iterator();
	    while (i.hasNext()) {
	      SpanQuery clause = (SpanQuery)i.next();
	      clause.extractTerms(terms);
	    }
  }  
  

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanNear(["");
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      buffer.append(clause.toString(field));
      if (i.hasNext()) {
        buffer.append("", "");
      }
    }
    buffer.append(""], "");
    buffer.append(slop);
    buffer.append("", "");
    buffer.append(inOrder);
    buffer.append("")"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  public Spans getSpans(final IndexReader reader) throws IOException {
    if (clauses.size() == 0)                      
      return new SpanOrQuery(getClauses()).getSpans(reader);

    if (clauses.size() == 1)                      
      return ((SpanQuery)clauses.get(0)).getSpans(reader);

    return inOrder
            ? (Spans) new NearSpansOrdered(this, reader)
            : (Spans) new NearSpansUnordered(this, reader);
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanNearQuery clone = null;
    for (int i = 0 ; i < clauses.size(); i++) {
      SpanQuery c = (SpanQuery)clauses.get(i);
      SpanQuery query = (SpanQuery) c.rewrite(reader);
      if (query != c) {                     
        if (clone == null)
          clone = (SpanNearQuery) this.clone();
        clone.clauses.set(i,query);
      }
    }
    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

  
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof SpanNearQuery)) return false;

    final SpanNearQuery spanNearQuery = (SpanNearQuery) o;

    if (inOrder != spanNearQuery.inOrder) return false;
    if (slop != spanNearQuery.slop) return false;
    if (!clauses.equals(spanNearQuery.clauses)) return false;

    return getBoost() == spanNearQuery.getBoost();
  }

  public int hashCode() {
    int result;
    result = clauses.hashCode();
    
    
    
    result ^= (result << 14) | (result >>> 19);  
    result += Float.floatToRawIntBits(getBoost());
    result += slop;
    result ^= (inOrder ? 0x99AFD3BD : 0);
    return result;
  }
}
"
lucene,2.2,org.apache.lucene.document.Document,17,1,0,24,39,0,22,2,17,0.5,415,0.5,0,0.0,0.426470588,0,0,23.29411765,5,2.5882,5,"package org.apache.lucene.document;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Hits;
import org.apache.lucene.search.Searcher;

import java.util.*;             



public final class Document implements java.io.Serializable {
  List fields = new Vector();
  private float boost = 1.0f;

  
  public Document() {}


  
  public void setBoost(float boost) {
    this.boost = boost;
  }

  
  public float getBoost() {
    return boost;
  }

  
  public final void add(Fieldable field) {
    fields.add(field);
  }
  
  
  public final void removeField(String name) {
    Iterator it = fields.iterator();
    while (it.hasNext()) {
      Fieldable field = (Fieldable)it.next();
      if (field.name().equals(name)) {
        it.remove();
        return;
      }
    }
  }
  
  
  public final void removeFields(String name) {
    Iterator it = fields.iterator();
    while (it.hasNext()) {
      Fieldable field = (Fieldable)it.next();
      if (field.name().equals(name)) {
        it.remove();
      }
    }
  }

  
  public final Field getField(String name) {
    for (int i = 0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      if (field.name().equals(name))
        return field;
    }
    return null;
  }


 
 public Fieldable getFieldable(String name) {
   for (int i = 0; i < fields.size(); i++) {
     Fieldable field = (Fieldable)fields.get(i);
     if (field.name().equals(name))
       return field;
   }
   return null;
 }

  
  public final String get(String name) {
    for (int i = 0; i < fields.size(); i++) {
      Fieldable field = (Fieldable)fields.get(i);
      if (field.name().equals(name) && (!field.isBinary()))
        return field.stringValue();
    }
    return null;
  }

  
  public final Enumeration fields() {
    return ((Vector)fields).elements();
  }

  
  public final List getFields() {
    return fields;
  }

  
   public final Field[] getFields(String name) {
     List result = new ArrayList();
     for (int i = 0; i < fields.size(); i++) {
       Field field = (Field)fields.get(i);
       if (field.name().equals(name)) {
         result.add(field);
       }
     }

     if (result.size() == 0)
       return null;

     return (Field[])result.toArray(new Field[result.size()]);
   }


  
   public Fieldable[] getFieldables(String name) {
     List result = new ArrayList();
     for (int i = 0; i < fields.size(); i++) {
       Fieldable field = (Fieldable)fields.get(i);
       if (field.name().equals(name)) {
         result.add(field);
       }
     }

     if (result.size() == 0)
       return null;

     return (Fieldable[])result.toArray(new Fieldable[result.size()]);
   }


  
  public final String[] getValues(String name) {
    List result = new ArrayList();
    for (int i = 0; i < fields.size(); i++) {
      Fieldable field = (Fieldable)fields.get(i);
      if (field.name().equals(name) && (!field.isBinary()))
        result.add(field.stringValue());
    }
    
    if (result.size() == 0)
      return null;
    
    return (String[])result.toArray(new String[result.size()]);
  }

  
  public final byte[][] getBinaryValues(String name) {
    List result = new ArrayList();
    for (int i = 0; i < fields.size(); i++) {
      Fieldable field = (Fieldable)fields.get(i);
      if (field.name().equals(name) && (field.isBinary()))
        result.add(field.binaryValue());
    }
  
    if (result.size() == 0)
      return null;
  
    return (byte[][])result.toArray(new byte[result.size()][]);
  }
  
  
  public final byte[] getBinaryValue(String name) {
    for (int i=0; i < fields.size(); i++) {
      Fieldable field = (Fieldable)fields.get(i);
      if (field.name().equals(name) && (field.isBinary()))
        return field.binaryValue();
    }
    return null;
  }
  
  
  public final String toString() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""Document<"");
    for (int i = 0; i < fields.size(); i++) {
      Fieldable field = (Fieldable)fields.get(i);
      buffer.append(field.toString());
      if (i != fields.size()-1)
        buffer.append("" "");
    }
    buffer.append("">"");
    return buffer.toString();
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.CharStream,12,1,0,3,12,66,3,0,12,2.0,12,0.0,0,0.0,0.583333333,0,0,0.0,1,1.0,2,"
package org.apache.lucene.queryParser;



public interface CharStream {

  
  char readChar() throws java.io.IOException;

  
  int getColumn();

  
  int getLine();

  
  int getEndColumn();

  
  int getEndLine();

  
  int getBeginColumn();

  
  int getBeginLine();

  
  void backup(int amount);

  
  char BeginToken() throws java.io.IOException;

  
  String GetImage();

  
  char[] GetSuffix(int len);

  
  void Done();

}
"
lucene,2.2,org.apache.lucene.search.PhrasePositions,5,1,0,6,12,0,5,1,0,0.678571429,95,0.0,2,0.0,0.533333333,0,0,16.6,1,0.8,0,"package org.apache.lucene.search;



import java.io.IOException;
import org.apache.lucene.index.*;


final class PhrasePositions {
  int doc;					  
  int position;					  
  int count;					  
  int offset;					  
  TermPositions tp;				  
  PhrasePositions next;				  
  boolean repeats;       

  PhrasePositions(TermPositions t, int o) {
    tp = t;
    offset = o;
  }

  final boolean next() throws IOException {	  
    if (!tp.next()) {
      tp.close();				  
      doc = Integer.MAX_VALUE;			  
      return false;
    }
    doc = tp.doc();
    position = 0;
    return true;
  }

  final boolean skipTo(int target) throws IOException {
    if (!tp.skipTo(target)) {
      tp.close();				  
      doc = Integer.MAX_VALUE;			  
      return false;
    }
    doc = tp.doc();
    position = 0;
    return true;
  }


  final void firstPosition() throws IOException {
    count = tp.freq();				  
    nextPosition();
  }

  
  final boolean nextPosition() throws IOException {
    if (count-- > 0) {				  
      position = tp.nextPosition() - offset;
      return true;
    } else
      return false;
  }
}
"
lucene,2.2,org.apache.lucene.search.SloppyPhraseScorer,4,3,0,9,19,0,3,7,0,0.555555556,326,1.0,1,0.869565217,0.34375,1,1,79.75,4,1.5,1,"package org.apache.lucene.search;



import org.apache.lucene.index.TermPositions;

import java.io.IOException;
import java.util.Arrays;
import java.util.Comparator;
import java.util.HashMap;

final class SloppyPhraseScorer extends PhraseScorer {
    private int slop;
    private PhrasePositions repeats[];
    private boolean checkedRepeats;

    SloppyPhraseScorer(Weight weight, TermPositions[] tps, int[] offsets, Similarity similarity,
                       int slop, byte[] norms) {
        super(weight, tps, offsets, similarity, norms);
        this.slop = slop;
    }

    
    protected final float phraseFreq() throws IOException {
        int end = initPhrasePositions();
        
        float freq = 0.0f;
        boolean done = (end<0);
        while (!done) {
            PhrasePositions pp = (PhrasePositions) pq.pop();
            int start = pp.position;
            int next = ((PhrasePositions) pq.top()).position;

            boolean tpsDiffer = true;
            for (int pos = start; pos <= next || !tpsDiffer; pos = pp.position) {
                if (pos<=next && tpsDiffer)
                    start = pos;				  
                if (!pp.nextPosition()) {
                    done = true;          
                    break;
                }
                tpsDiffer = !pp.repeats || termPositionsDiffer(pp);
            }

            int matchLength = end - start;
            if (matchLength <= slop)
                freq += getSimilarity().sloppyFreq(matchLength); 

            if (pp.position > end)
                end = pp.position;
            pq.put(pp);				  
        }

        return freq;
    }
    
    
    
    private int initPhrasePositions() throws IOException {
        int end = 0;
        
        
        if (checkedRepeats && repeats==null) {
            
            pq.clear();
            for (PhrasePositions pp = first; pp != null; pp = pp.next) {
                pp.firstPosition();
                if (pp.position > end)
                    end = pp.position;
                pq.put(pp);         
            }
            return end;
        }
        
        
        for (PhrasePositions pp = first; pp != null; pp = pp.next)
            pp.firstPosition();
        
        
        if (!checkedRepeats) {
            checkedRepeats = true;
            
            HashMap m = null;
            for (PhrasePositions pp = first; pp != null; pp = pp.next) {
                int tpPos = pp.position + pp.offset;
                for (PhrasePositions pp2 = pp.next; pp2 != null; pp2 = pp2.next) {
                    int tpPos2 = pp2.position + pp2.offset;
                    if (tpPos2 == tpPos) { 
                        if (m == null)
                            m = new HashMap();
                        pp.repeats = true;
                        pp2.repeats = true;
                        m.put(pp,null);
                        m.put(pp2,null);
                    }
                }
            }
            if (m!=null)
                repeats = (PhrasePositions[]) m.keySet().toArray(new PhrasePositions[0]);
        }
        
        
        if (repeats!=null) {
            
            Arrays.sort(repeats,  new Comparator() {
                public int compare(Object x, Object y) {
                    return ((PhrasePositions) y).offset - ((PhrasePositions) x).offset;
                }});
            
            for (int i = 0; i < repeats.length; i++) {
                PhrasePositions pp = repeats[i];
                while (!termPositionsDiffer(pp)) {
                  if (!pp.nextPosition())
                      return -1;    
                } 
            }
        }
      
        
        pq.clear();
        for (PhrasePositions pp = first; pp != null; pp = pp.next) {
            if (pp.position > end)
                end = pp.position;
            pq.put(pp);         
        }

        return end;
    }

    
    
    private boolean termPositionsDiffer(PhrasePositions pp) {
        
        
        
        
        int tpPos = pp.position + pp.offset;
        for (int i = 0; i < repeats.length; i++) {
            PhrasePositions pp2 = repeats[i];
            if (pp2 == pp)
                continue;
            int tpPos2 = pp2.position + pp2.offset;
            if (tpPos2 == tpPos)
                return false;
        }
        return true;
    }
}
"
lucene,2.2,org.apache.lucene.index.FieldInfos,20,1,0,18,51,164,12,6,16,0.940789474,482,0.25,0,0.0,0.261111111,0,0,22.7,8,1.5,2,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.Fieldable;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;

import java.io.IOException;
import java.util.*;


final class FieldInfos {
  
  static final byte IS_INDEXED = 0x1;
  static final byte STORE_TERMVECTOR = 0x2;
  static final byte STORE_POSITIONS_WITH_TERMVECTOR = 0x4;
  static final byte STORE_OFFSET_WITH_TERMVECTOR = 0x8;
  static final byte OMIT_NORMS = 0x10;
  static final byte STORE_PAYLOADS = 0x20;
  
  private ArrayList byNumber = new ArrayList();
  private HashMap byName = new HashMap();

  FieldInfos() { }

  
  FieldInfos(Directory d, String name) throws IOException {
    IndexInput input = d.openInput(name);
    try {
      read(input);
    } finally {
      input.close();
    }
  }

  
  public void add(Document doc) {
    List fields = doc.getFields();
    Iterator fieldIterator = fields.iterator();
    while (fieldIterator.hasNext()) {
      Fieldable field = (Fieldable) fieldIterator.next();
      add(field.name(), field.isIndexed(), field.isTermVectorStored(), field.isStorePositionWithTermVector(),
              field.isStoreOffsetWithTermVector(), field.getOmitNorms());
    }
  }
  
  
  public void addIndexed(Collection names, boolean storeTermVectors, boolean storePositionWithTermVector, 
                         boolean storeOffsetWithTermVector) {
    Iterator i = names.iterator();
    while (i.hasNext()) {
      add((String)i.next(), true, storeTermVectors, storePositionWithTermVector, storeOffsetWithTermVector);
    }
  }

  
  public void add(Collection names, boolean isIndexed) {
    Iterator i = names.iterator();
    while (i.hasNext()) {
      add((String)i.next(), isIndexed);
    }
  }

  
  public void add(String name, boolean isIndexed) {
    add(name, isIndexed, false, false, false, false);
  }

  
  public void add(String name, boolean isIndexed, boolean storeTermVector){
    add(name, isIndexed, storeTermVector, false, false, false);
  }
  
  
  public void add(String name, boolean isIndexed, boolean storeTermVector,
                  boolean storePositionWithTermVector, boolean storeOffsetWithTermVector) {

    add(name, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, false);
  }

    
  public void add(String name, boolean isIndexed, boolean storeTermVector,
                  boolean storePositionWithTermVector, boolean storeOffsetWithTermVector, boolean omitNorms) {
    add(name, isIndexed, storeTermVector, storePositionWithTermVector,
        storeOffsetWithTermVector, omitNorms, false);
  }
  
  
  public FieldInfo add(String name, boolean isIndexed, boolean storeTermVector,
                       boolean storePositionWithTermVector, boolean storeOffsetWithTermVector,
                       boolean omitNorms, boolean storePayloads) {
    FieldInfo fi = fieldInfo(name);
    if (fi == null) {
      return addInternal(name, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads);
    } else {
      if (fi.isIndexed != isIndexed) {
        fi.isIndexed = true;                      
      }
      if (fi.storeTermVector != storeTermVector) {
        fi.storeTermVector = true;                
      }
      if (fi.storePositionWithTermVector != storePositionWithTermVector) {
        fi.storePositionWithTermVector = true;                
      }
      if (fi.storeOffsetWithTermVector != storeOffsetWithTermVector) {
        fi.storeOffsetWithTermVector = true;                
      }
      if (fi.omitNorms != omitNorms) {
        fi.omitNorms = false;                
      }
      if (fi.storePayloads != storePayloads) {
        fi.storePayloads = true;
      }

    }
    return fi;
  }

  private FieldInfo addInternal(String name, boolean isIndexed,
                                boolean storeTermVector, boolean storePositionWithTermVector, 
                                boolean storeOffsetWithTermVector, boolean omitNorms, boolean storePayloads) {
    FieldInfo fi =
      new FieldInfo(name, isIndexed, byNumber.size(), storeTermVector, storePositionWithTermVector,
              storeOffsetWithTermVector, omitNorms, storePayloads);
    byNumber.add(fi);
    byName.put(name, fi);
    return fi;
  }

  public int fieldNumber(String fieldName) {
    try {
      FieldInfo fi = fieldInfo(fieldName);
      if (fi != null)
        return fi.number;
    }
    catch (IndexOutOfBoundsException ioobe) {
      return -1;
    }
    return -1;
  }

  public FieldInfo fieldInfo(String fieldName) {
    return (FieldInfo) byName.get(fieldName);
  }

    
  public String fieldName(int fieldNumber) {
    try {
      return fieldInfo(fieldNumber).name;
    }
    catch (NullPointerException npe) {
      return """";
    }
  }

    
  public FieldInfo fieldInfo(int fieldNumber) {
    try {
      return (FieldInfo) byNumber.get(fieldNumber);
    }
    catch (IndexOutOfBoundsException ioobe) {
      return null;
    }
  }

  public int size() {
    return byNumber.size();
  }

  public boolean hasVectors() {
    boolean hasVectors = false;
    for (int i = 0; i < size(); i++) {
      if (fieldInfo(i).storeTermVector) {
        hasVectors = true;
        break;
      }
    }
    return hasVectors;
  }

  public void write(Directory d, String name) throws IOException {
    IndexOutput output = d.createOutput(name);
    try {
      write(output);
    } finally {
      output.close();
    }
  }

  public void write(IndexOutput output) throws IOException {
    output.writeVInt(size());
    for (int i = 0; i < size(); i++) {
      FieldInfo fi = fieldInfo(i);
      byte bits = 0x0;
      if (fi.isIndexed) bits |= IS_INDEXED;
      if (fi.storeTermVector) bits |= STORE_TERMVECTOR;
      if (fi.storePositionWithTermVector) bits |= STORE_POSITIONS_WITH_TERMVECTOR;
      if (fi.storeOffsetWithTermVector) bits |= STORE_OFFSET_WITH_TERMVECTOR;
      if (fi.omitNorms) bits |= OMIT_NORMS;
      if (fi.storePayloads) bits |= STORE_PAYLOADS;
      output.writeString(fi.name);
      output.writeByte(bits);
    }
  }

  private void read(IndexInput input) throws IOException {
    int size = input.readVInt();
    for (int i = 0; i < size; i++) {
      String name = input.readString().intern();
      byte bits = input.readByte();
      boolean isIndexed = (bits & IS_INDEXED) != 0;
      boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;
      boolean storePositionsWithTermVector = (bits & STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      boolean storeOffsetWithTermVector = (bits & STORE_OFFSET_WITH_TERMVECTOR) != 0;
      boolean omitNorms = (bits & OMIT_NORMS) != 0;
      boolean storePayloads = (bits & STORE_PAYLOADS) != 0;
      
      addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms, storePayloads);
    }    
  }

}
"
lucene,2.2,org.apache.lucene.document.FieldSelector,1,1,0,18,1,0,17,1,1,2.0,1,0.0,0,0.0,1.0,0,0,0.0,1,1.0,0,"package org.apache.lucene.document;

import java.io.Serializable;



public interface FieldSelector extends Serializable {

  
  FieldSelectorResult accept(String fieldName);
}
"
lucene,2.2,org.apache.lucene.index.CompoundFileWriter,6,1,0,6,39,0,1,5,5,0.6,339,1.0,1,0.0,0.333333333,0,0,54.66666667,4,1.3333,3,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.IndexInput;
import java.util.LinkedList;
import java.util.HashSet;
import java.util.Iterator;
import java.io.IOException;



final class CompoundFileWriter {

    private static final class FileEntry {
        
        String file;

        
        long directoryOffset;

        
        long dataOffset;
    }


    private Directory directory;
    private String fileName;
    private HashSet ids;
    private LinkedList entries;
    private boolean merged = false;


    
    public CompoundFileWriter(Directory dir, String name) {
        if (dir == null)
            throw new NullPointerException(""directory cannot be null"");
        if (name == null)
            throw new NullPointerException(""name cannot be null"");

        directory = dir;
        fileName = name;
        ids = new HashSet();
        entries = new LinkedList();
    }

    
    public Directory getDirectory() {
        return directory;
    }

    
    public String getName() {
        return fileName;
    }

    
    public void addFile(String file) {
        if (merged)
            throw new IllegalStateException(
                ""Can't add extensions after merge has been called"");

        if (file == null)
            throw new NullPointerException(
                ""file cannot be null"");

        if (! ids.add(file))
            throw new IllegalArgumentException(
                ""File "" + file + "" already added"");

        FileEntry entry = new FileEntry();
        entry.file = file;
        entries.add(entry);
    }

    
    public void close() throws IOException {
        if (merged)
            throw new IllegalStateException(
                ""Merge already performed"");

        if (entries.isEmpty())
            throw new IllegalStateException(
                ""No entries to merge have been defined"");

        merged = true;

        
        IndexOutput os = null;
        try {
            os = directory.createOutput(fileName);

            
            os.writeVInt(entries.size());

            
            
            
            Iterator it = entries.iterator();
            while(it.hasNext()) {
                FileEntry fe = (FileEntry) it.next();
                fe.directoryOffset = os.getFilePointer();
                os.writeLong(0);    
                os.writeString(fe.file);
            }

            
            
            byte buffer[] = new byte[16384];
            it = entries.iterator();
            while(it.hasNext()) {
                FileEntry fe = (FileEntry) it.next();
                fe.dataOffset = os.getFilePointer();
                copyFile(fe, os, buffer);
            }

            
            it = entries.iterator();
            while(it.hasNext()) {
                FileEntry fe = (FileEntry) it.next();
                os.seek(fe.directoryOffset);
                os.writeLong(fe.dataOffset);
            }

            
            
            
            
            IndexOutput tmp = os;
            os = null;
            tmp.close();

        } finally {
            if (os != null) try { os.close(); } catch (IOException e) { }
        }
    }

    
    private void copyFile(FileEntry source, IndexOutput os, byte buffer[])
    throws IOException
    {
        IndexInput is = null;
        try {
            long startPtr = os.getFilePointer();

            is = directory.openInput(source.file);
            long length = is.length();
            long remainder = length;
            int chunk = buffer.length;

            while(remainder > 0) {
                int len = (int) Math.min(chunk, remainder);
                is.readBytes(buffer, 0, len);
                os.writeBytes(buffer, len);
                remainder -= len;
            }

            
            if (remainder != 0)
                throw new IOException(
                    ""Non-zero remainder length after copying: "" + remainder
                    + "" (id: "" + source.file + "", length: "" + length
                    + "", buffer size: "" + chunk + "")"");

            
            long endPtr = os.getFilePointer();
            long diff = endPtr - startPtr;
            if (diff != length)
                throw new IOException(
                    ""Difference in the output file offsets "" + diff
                    + "" does not match the original file length "" + length);

        } finally {
            if (is != null) is.close();
        }
    }
}
"
lucene,2.2,org.apache.lucene.search.PrefixFilter,4,2,0,4,13,0,1,4,4,0.0,52,1.0,1,0.25,0.5,0,0,11.75,1,0.75,1,"package org.apache.lucene.search;



import org.apache.lucene.search.Filter;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.index.TermDocs;

import java.util.BitSet;
import java.io.IOException;


public class PrefixFilter extends Filter {
  protected final Term prefix;

  public PrefixFilter(Term prefix) {
    this.prefix = prefix;
  }

  public Term getPrefix() { return prefix; }

  public BitSet bits(IndexReader reader) throws IOException {
    final BitSet bitSet = new BitSet(reader.maxDoc());
    new PrefixGenerator(prefix) {
      public void handleDoc(int doc) {
        bitSet.set(doc);
      }
    }.generate(reader);
    return bitSet;
  }

  
  public String toString () {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""PrefixFilter("");
    buffer.append(prefix.toString());
    buffer.append("")"");
    return buffer.toString();
  }
}




interface IdGenerator {
  public void generate(IndexReader reader) throws IOException;
  public void handleDoc(int doc);
}


abstract class PrefixGenerator implements IdGenerator {
  protected final Term prefix;

  PrefixGenerator(Term prefix) {
    this.prefix = prefix;
  }

  public void generate(IndexReader reader) throws IOException {
    TermEnum enumerator = reader.terms(prefix);
    TermDocs termDocs = reader.termDocs();

    try {

      String prefixText = prefix.text();
      String prefixField = prefix.field();
      do {
        Term term = enumerator.term();
        if (term != null &&
            term.text().startsWith(prefixText) &&
            term.field() == prefixField) 
        {
          termDocs.seek(term);
          while (termDocs.next()) {
            handleDoc(termDocs.doc());
          }
        } else {
          break;
        }
      } while (enumerator.next());
    } finally {
      termDocs.close();
      enumerator.close();
    }
  }
}


"
lucene,2.2,org.apache.lucene.index.TermVectorsWriter,15,1,0,13,54,41,2,11,10,0.804761905,675,0.533333333,5,0.0,0.237037037,0,0,43.0,3,1.2,3,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.util.StringHelper;

import java.io.IOException;
import java.util.Vector;


final class TermVectorsWriter {
  static final byte STORE_POSITIONS_WITH_TERMVECTOR = 0x1;
  static final byte STORE_OFFSET_WITH_TERMVECTOR = 0x2;
  
  static final int FORMAT_VERSION = 2;
  
  static final int FORMAT_SIZE = 4;
  
  static final String TVX_EXTENSION = "".tvx"";
  static final String TVD_EXTENSION = "".tvd"";
  static final String TVF_EXTENSION = "".tvf"";
  
  private IndexOutput tvx = null, tvd = null, tvf = null;
  private Vector fields = null;
  private Vector terms = null;
  private FieldInfos fieldInfos;

  private TVField currentField = null;
  private long currentDocPointer = -1;

  public TermVectorsWriter(Directory directory, String segment,
                           FieldInfos fieldInfos)
    throws IOException {
    
    tvx = directory.createOutput(segment + TVX_EXTENSION);
    tvx.writeInt(FORMAT_VERSION);
    tvd = directory.createOutput(segment + TVD_EXTENSION);
    tvd.writeInt(FORMAT_VERSION);
    tvf = directory.createOutput(segment + TVF_EXTENSION);
    tvf.writeInt(FORMAT_VERSION);

    this.fieldInfos = fieldInfos;
    fields = new Vector(fieldInfos.size());
    terms = new Vector();
  }


  public final void openDocument()
          throws IOException {
    closeDocument();
    currentDocPointer = tvd.getFilePointer();
  }


  public final void closeDocument()
          throws IOException {
    if (isDocumentOpen()) {
      closeField();
      writeDoc();
      fields.clear();
      currentDocPointer = -1;
    }
  }


  public final boolean isDocumentOpen() {
    return currentDocPointer != -1;
  }


  
  public final void openField(String field) throws IOException {
    FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
    openField(fieldInfo.number, fieldInfo.storePositionWithTermVector, fieldInfo.storeOffsetWithTermVector);
  }
  
  private void openField(int fieldNumber, boolean storePositionWithTermVector, 
      boolean storeOffsetWithTermVector) throws IOException{
    if (!isDocumentOpen()) 
      throw new IllegalStateException(""Cannot open field when no document is open."");
    closeField();
    currentField = new TVField(fieldNumber, storePositionWithTermVector, storeOffsetWithTermVector);
  }

  
  public final void closeField()
          throws IOException {
    if (isFieldOpen()) {
      
      
      

      
      writeField();
      fields.add(currentField);
      terms.clear();
      currentField = null;
    }
  }

  
  public final boolean isFieldOpen() {
    return currentField != null;
  }

  
  public final void addTerm(String termText, int freq) {
    addTerm(termText, freq, null, null);
  }
  
  public final void addTerm(String termText, int freq, int [] positions, TermVectorOffsetInfo [] offsets)
  {
    if (!isDocumentOpen()) 
      throw new IllegalStateException(""Cannot add terms when document is not open"");
    if (!isFieldOpen()) 
      throw new IllegalStateException(""Cannot add terms when field is not open"");
    
    addTermInternal(termText, freq, positions, offsets);
  }

  private final void addTermInternal(String termText, int freq, int [] positions, TermVectorOffsetInfo [] offsets) {
    TVTerm term = new TVTerm();
    term.termText = termText;
    term.freq = freq;
    term.positions = positions;
    term.offsets = offsets;
    terms.add(term);
  }

  
  public final void addAllDocVectors(TermFreqVector[] vectors)
      throws IOException {
    openDocument();

    if (vectors != null) {
      for (int i = 0; i < vectors.length; i++) {
        boolean storePositionWithTermVector = false;
        boolean storeOffsetWithTermVector = false;

        try {

          TermPositionVector tpVector = (TermPositionVector) vectors[i];

          if (tpVector.size() > 0 && tpVector.getTermPositions(0) != null)
            storePositionWithTermVector = true;
          if (tpVector.size() > 0 && tpVector.getOffsets(0) != null)
            storeOffsetWithTermVector = true;

          FieldInfo fieldInfo = fieldInfos.fieldInfo(tpVector.getField());
          openField(fieldInfo.number, storePositionWithTermVector, storeOffsetWithTermVector);

          for (int j = 0; j < tpVector.size(); j++)
            addTermInternal(tpVector.getTerms()[j], tpVector.getTermFrequencies()[j], tpVector.getTermPositions(j),
                tpVector.getOffsets(j));

          closeField();

        } catch (ClassCastException ignore) {

          TermFreqVector tfVector = vectors[i];

          FieldInfo fieldInfo = fieldInfos.fieldInfo(tfVector.getField());
          openField(fieldInfo.number, storePositionWithTermVector, storeOffsetWithTermVector);

          for (int j = 0; j < tfVector.size(); j++)
            addTermInternal(tfVector.getTerms()[j], tfVector.getTermFrequencies()[j], null, null);

          closeField();

        }
      }
    }

    closeDocument();
  }
  
  
  final void close() throws IOException {
    try {
      closeDocument();
    } finally {
      
      
      IOException keep = null;
      if (tvx != null)
        try {
          tvx.close();
        } catch (IOException e) {
          if (keep == null) keep = e;
        }
      if (tvd != null)
        try {
          tvd.close();
        } catch (IOException e) {
          if (keep == null) keep = e;
        }
      if (tvf != null)
        try {
          tvf.close();
        } catch (IOException e) {
          if (keep == null) keep = e;
        }
      if (keep != null) throw (IOException) keep.fillInStackTrace();
    }
  }

  

  private void writeField() throws IOException {
    
    currentField.tvfPointer = tvf.getFilePointer();
    
    
    final int size = terms.size();
    tvf.writeVInt(size);
    
    boolean storePositions = currentField.storePositions;
    boolean storeOffsets = currentField.storeOffsets;
    byte bits = 0x0;
    if (storePositions) 
      bits |= STORE_POSITIONS_WITH_TERMVECTOR;
    if (storeOffsets) 
      bits |= STORE_OFFSET_WITH_TERMVECTOR;
    tvf.writeByte(bits);
    
    String lastTermText = """";
    for (int i = 0; i < size; i++) {
      TVTerm term = (TVTerm) terms.elementAt(i);
      int start = StringHelper.stringDifference(lastTermText, term.termText);
      int length = term.termText.length() - start;
      tvf.writeVInt(start);       
      tvf.writeVInt(length);        
      tvf.writeChars(term.termText, start, length);  
      tvf.writeVInt(term.freq);
      lastTermText = term.termText;
      
      if(storePositions){
        if(term.positions == null)
          throw new IllegalStateException(""Trying to write positions that are null!"");
        
        
        int position = 0;
        for (int j = 0; j < term.freq; j++){
          tvf.writeVInt(term.positions[j] - position);
          position = term.positions[j];
        }
      }
      
      if(storeOffsets){
        if(term.offsets == null)
          throw new IllegalStateException(""Trying to write offsets that are null!"");
        
        
        int position = 0;
        for (int j = 0; j < term.freq; j++) {
          tvf.writeVInt(term.offsets[j].getStartOffset() - position);
          tvf.writeVInt(term.offsets[j].getEndOffset() - term.offsets[j].getStartOffset()); 
          position = term.offsets[j].getEndOffset();
        }
      }
    }
  }

  private void writeDoc() throws IOException {
    if (isFieldOpen()) 
      throw new IllegalStateException(""Field is still open while writing document"");
    
    
    tvx.writeLong(currentDocPointer);

    
    final int size = fields.size();

    
    tvd.writeVInt(size);

    
    for (int i = 0; i < size; i++) {
      TVField field = (TVField) fields.elementAt(i);
      tvd.writeVInt(field.number);
    }

    
    long lastFieldPointer = 0;
    for (int i = 0; i < size; i++) {
      TVField field = (TVField) fields.elementAt(i);
      tvd.writeVLong(field.tvfPointer - lastFieldPointer);
      lastFieldPointer = field.tvfPointer;
    }
    
  }


  private static class TVField {
    int number;
    long tvfPointer = 0;
    boolean storePositions = false;
    boolean storeOffsets = false;
    TVField(int number, boolean storePos, boolean storeOff) {
      this.number = number;
      storePositions = storePos;
      storeOffsets = storeOff;
    }
  }

  private static class TVTerm {
    String termText;
    int freq = 0;
    int positions[] = null;
    TermVectorOffsetInfo [] offsets = null;
  }


}
"
lucene,2.2,org.apache.lucene.search.function.FieldScoreQuery,2,3,0,7,12,1,0,7,1,2.0,52,0.0,0,0.947368421,0.833333333,0,0,25.0,5,2.5,0,"package org.apache.lucene.search.function;




public class FieldScoreQuery extends ValueSourceQuery {

  
  public static class Type {
    
    
    public static final Type BYTE = new Type(""byte""); 

    
    public static final Type SHORT = new Type(""short""); 

    
    public static final Type INT = new Type(""int""); 

    
    public static final Type FLOAT = new Type(""float""); 

    private String typeName;
    private Type (String name) {
      this.typeName = name;
    }
    
    public String toString() {
      return getClass().getName()+""::""+typeName;
    }
  }
  
  
  public FieldScoreQuery(String field, Type type) {
    super(getValueSource(field,type));
  }

  
  private static ValueSource getValueSource(String field, Type type) {
    if (type == Type.BYTE) {
      return new ByteFieldSource(field);
    }
    if (type == Type.SHORT) {
      return new ShortFieldSource(field);
    }
    if (type == Type.INT) {
      return new IntFieldSource(field);
    }
    if (type == Type.FLOAT) {
      return new FloatFieldSource(field);
    }
    throw new IllegalArgumentException(type+"" is not a known Field Score Query Type!"");
  }

}
"
lucene,2.2,org.apache.lucene.index.FieldsReader,18,1,0,17,61,69,2,16,0,0.806722689,745,1.0,4,0.0,0.237373737,0,0,40.0,5,1.3333,11,"package org.apache.lucene.index;



import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.document.*;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.AlreadyClosedException;
import org.apache.lucene.store.BufferedIndexInput;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.Reader;
import java.util.zip.DataFormatException;
import java.util.zip.Inflater;


final class FieldsReader {
  private final FieldInfos fieldInfos;

  
  private final IndexInput cloneableFieldsStream;

  
  
  private final IndexInput fieldsStream;

  private final IndexInput indexStream;
  private int size;
  private boolean closed;

  private ThreadLocal fieldsStreamTL = new ThreadLocal();

  FieldsReader(Directory d, String segment, FieldInfos fn) throws IOException {
    this(d, segment, fn, BufferedIndexInput.BUFFER_SIZE);
  }

  FieldsReader(Directory d, String segment, FieldInfos fn, int readBufferSize) throws IOException {
    fieldInfos = fn;

    cloneableFieldsStream = d.openInput(segment + "".fdt"", readBufferSize);
    fieldsStream = (IndexInput)cloneableFieldsStream.clone();
    indexStream = d.openInput(segment + "".fdx"", readBufferSize);
    size = (int) (indexStream.length() / 8);
  }

  
  protected final void ensureOpen() throws AlreadyClosedException {
    if (closed) {
      throw new AlreadyClosedException(""this FieldsReader is closed"");
    }
  }

  
  final void close() throws IOException {
    if (!closed) {
      fieldsStream.close();
      cloneableFieldsStream.close();
      indexStream.close();
      IndexInput localFieldsStream = (IndexInput) fieldsStreamTL.get();
      if (localFieldsStream != null) {
        localFieldsStream.close();
        fieldsStreamTL.set(null);
      }
      closed = true;
    }
  }

  final int size() {
    return size;
  }

  final Document doc(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
    indexStream.seek(n * 8L);
    long position = indexStream.readLong();
    fieldsStream.seek(position);

    Document doc = new Document();
    int numFields = fieldsStream.readVInt();
    for (int i = 0; i < numFields; i++) {
      int fieldNumber = fieldsStream.readVInt();
      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);
      FieldSelectorResult acceptField = fieldSelector == null ? FieldSelectorResult.LOAD : fieldSelector.accept(fi.name);
      
      byte bits = fieldsStream.readByte();
      boolean compressed = (bits & FieldsWriter.FIELD_IS_COMPRESSED) != 0;
      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;
      boolean binary = (bits & FieldsWriter.FIELD_IS_BINARY) != 0;
      
      
      if (acceptField.equals(FieldSelectorResult.LOAD)) {
        addField(doc, fi, binary, compressed, tokenize);
      }
      else if (acceptField.equals(FieldSelectorResult.LOAD_FOR_MERGE)) {
        addFieldForMerge(doc, fi, binary, compressed, tokenize);
      }
      else if (acceptField.equals(FieldSelectorResult.LOAD_AND_BREAK)){
        addField(doc, fi, binary, compressed, tokenize);
        break;
      }
      else if (acceptField.equals(FieldSelectorResult.LAZY_LOAD)) {
        addFieldLazy(doc, fi, binary, compressed, tokenize);
      }
      else if (acceptField.equals(FieldSelectorResult.SIZE)){
        skipField(binary, compressed, addFieldSize(doc, fi, binary, compressed));
      }
      else if (acceptField.equals(FieldSelectorResult.SIZE_AND_BREAK)){
        addFieldSize(doc, fi, binary, compressed);
        break;
      }
      else {
        skipField(binary, compressed);
      }
    }

    return doc;
  }

  
  private void skipField(boolean binary, boolean compressed) throws IOException {
    skipField(binary, compressed, fieldsStream.readVInt());
  }
  
  private void skipField(boolean binary, boolean compressed, int toRead) throws IOException {
    if (binary || compressed) {
      long pointer = fieldsStream.getFilePointer();
      fieldsStream.seek(pointer + toRead);
    } else {
      
      fieldsStream.skipChars(toRead);
    }
  }

  private void addFieldLazy(Document doc, FieldInfo fi, boolean binary, boolean compressed, boolean tokenize) throws IOException {
    if (binary == true) {
      int toRead = fieldsStream.readVInt();
      long pointer = fieldsStream.getFilePointer();
      if (compressed) {
        
        doc.add(new LazyField(fi.name, Field.Store.COMPRESS, toRead, pointer));
      } else {
        
        doc.add(new LazyField(fi.name, Field.Store.YES, toRead, pointer));
      }
      
      fieldsStream.seek(pointer + toRead);
    } else {
      Field.Store store = Field.Store.YES;
      Field.Index index = getIndexType(fi, tokenize);
      Field.TermVector termVector = getTermVectorType(fi);

      Fieldable f;
      if (compressed) {
        store = Field.Store.COMPRESS;
        int toRead = fieldsStream.readVInt();
        long pointer = fieldsStream.getFilePointer();
        f = new LazyField(fi.name, store, toRead, pointer);
        
        fieldsStream.seek(pointer + toRead);
        f.setOmitNorms(fi.omitNorms);
      } else {
        int length = fieldsStream.readVInt();
        long pointer = fieldsStream.getFilePointer();
        
        fieldsStream.skipChars(length);
        f = new LazyField(fi.name, store, index, termVector, length, pointer);
        f.setOmitNorms(fi.omitNorms);
      }
      doc.add(f);
    }

  }

  
  private void addFieldForMerge(Document doc, FieldInfo fi, boolean binary, boolean compressed, boolean tokenize) throws IOException {
    Object data;
      
    if (binary || compressed) {
      int toRead = fieldsStream.readVInt();
      final byte[] b = new byte[toRead];
      fieldsStream.readBytes(b, 0, b.length);
      data = b;
    } else {
      data = fieldsStream.readString();
    }
      
    doc.add(new FieldForMerge(data, fi, binary, compressed, tokenize));
  }
  
  private void addField(Document doc, FieldInfo fi, boolean binary, boolean compressed, boolean tokenize) throws CorruptIndexException, IOException {

    
    if (binary) {
      int toRead = fieldsStream.readVInt();
      final byte[] b = new byte[toRead];
      fieldsStream.readBytes(b, 0, b.length);
      if (compressed)
        doc.add(new Field(fi.name, uncompress(b), Field.Store.COMPRESS));
      else
        doc.add(new Field(fi.name, b, Field.Store.YES));

    } else {
      Field.Store store = Field.Store.YES;
      Field.Index index = getIndexType(fi, tokenize);
      Field.TermVector termVector = getTermVectorType(fi);

      Fieldable f;
      if (compressed) {
        store = Field.Store.COMPRESS;
        int toRead = fieldsStream.readVInt();

        final byte[] b = new byte[toRead];
        fieldsStream.readBytes(b, 0, b.length);
        f = new Field(fi.name,      
                new String(uncompress(b), ""UTF-8""), 
                store,
                index,
                termVector);
        f.setOmitNorms(fi.omitNorms);
      } else {
        f = new Field(fi.name,     
                fieldsStream.readString(), 
                store,
                index,
                termVector);
        f.setOmitNorms(fi.omitNorms);
      }
      doc.add(f);
    }
  }
  
  
  
  
  private int addFieldSize(Document doc, FieldInfo fi, boolean binary, boolean compressed) throws IOException {
    int size = fieldsStream.readVInt(), bytesize = binary || compressed ? size : 2*size;
    byte[] sizebytes = new byte[4];
    sizebytes[0] = (byte) (bytesize>>>24);
    sizebytes[1] = (byte) (bytesize>>>16);
    sizebytes[2] = (byte) (bytesize>>> 8);
    sizebytes[3] = (byte)  bytesize      ;
    doc.add(new Field(fi.name, sizebytes, Field.Store.YES));
    return size;
  }

  private Field.TermVector getTermVectorType(FieldInfo fi) {
    Field.TermVector termVector = null;
    if (fi.storeTermVector) {
      if (fi.storeOffsetWithTermVector) {
        if (fi.storePositionWithTermVector) {
          termVector = Field.TermVector.WITH_POSITIONS_OFFSETS;
        } else {
          termVector = Field.TermVector.WITH_OFFSETS;
        }
      } else if (fi.storePositionWithTermVector) {
        termVector = Field.TermVector.WITH_POSITIONS;
      } else {
        termVector = Field.TermVector.YES;
      }
    } else {
      termVector = Field.TermVector.NO;
    }
    return termVector;
  }

  private Field.Index getIndexType(FieldInfo fi, boolean tokenize) {
    Field.Index index;
    if (fi.isIndexed && tokenize)
      index = Field.Index.TOKENIZED;
    else if (fi.isIndexed && !tokenize)
      index = Field.Index.UN_TOKENIZED;
    else
      index = Field.Index.NO;
    return index;
  }

  
  private class LazyField extends AbstractField implements Fieldable {
    private int toRead;
    private long pointer;

    public LazyField(String name, Field.Store store, int toRead, long pointer) {
      super(name, store, Field.Index.NO, Field.TermVector.NO);
      this.toRead = toRead;
      this.pointer = pointer;
      lazy = true;
    }

    public LazyField(String name, Field.Store store, Field.Index index, Field.TermVector termVector, int toRead, long pointer) {
      super(name, store, index, termVector);
      this.toRead = toRead;
      this.pointer = pointer;
      lazy = true;
    }

    private IndexInput getFieldStream() {
      IndexInput localFieldsStream = (IndexInput) fieldsStreamTL.get();
      if (localFieldsStream == null) {
        localFieldsStream = (IndexInput) cloneableFieldsStream.clone();
        fieldsStreamTL.set(localFieldsStream);
      }
      return localFieldsStream;
    }

    
    public byte[] binaryValue() {
      ensureOpen();
      if (fieldsData == null) {
        final byte[] b = new byte[toRead];
        IndexInput localFieldsStream = getFieldStream();
        
        
        try {
          localFieldsStream.seek(pointer);
          localFieldsStream.readBytes(b, 0, b.length);
          if (isCompressed == true) {
            fieldsData = uncompress(b);
          } else {
            fieldsData = b;
          }
        } catch (IOException e) {
          throw new FieldReaderException(e);
        }
      }
      return fieldsData instanceof byte[] ? (byte[]) fieldsData : null;
    }

    
    public Reader readerValue() {
      ensureOpen();
      return fieldsData instanceof Reader ? (Reader) fieldsData : null;
    }

    
    public TokenStream tokenStreamValue() {
      ensureOpen();
      return fieldsData instanceof TokenStream ? (TokenStream) fieldsData : null;
    }

    
    
    public String stringValue() {
      ensureOpen();
      if (fieldsData == null) {
        IndexInput localFieldsStream = getFieldStream();
        try {
          localFieldsStream.seek(pointer);
          if (isCompressed) {
            final byte[] b = new byte[toRead];
            localFieldsStream.readBytes(b, 0, b.length);
            fieldsData = new String(uncompress(b), ""UTF-8"");
          } else {
            
            char[] chars = new char[toRead];
            localFieldsStream.readChars(chars, 0, toRead);
            fieldsData = new String(chars);
          }
        } catch (IOException e) {
          throw new FieldReaderException(e);
        }
      }
      return fieldsData instanceof String ? (String) fieldsData : null;
    }

    public long getPointer() {
      ensureOpen();
      return pointer;
    }

    public void setPointer(long pointer) {
      ensureOpen();
      this.pointer = pointer;
    }

    public int getToRead() {
      ensureOpen();
      return toRead;
    }

    public void setToRead(int toRead) {
      ensureOpen();
      this.toRead = toRead;
    }
  }

  private final byte[] uncompress(final byte[] input)
          throws CorruptIndexException, IOException {

    Inflater decompressor = new Inflater();
    decompressor.setInput(input);

    
    ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length);

    
    byte[] buf = new byte[1024];
    while (!decompressor.finished()) {
      try {
        int count = decompressor.inflate(buf);
        bos.write(buf, 0, count);
      }
      catch (DataFormatException e) {
        
        CorruptIndexException newException = new CorruptIndexException(""field data are in wrong format: "" + e.toString());
        newException.initCause(e);
        throw newException;
      }
    }
  
    decompressor.end();
    
    
    return bos.toByteArray();
  }
  
  
  
  final static class FieldForMerge extends AbstractField {
    public String stringValue() {
      return (String) this.fieldsData;
    }

    public Reader readerValue() {
      
      return null;
    }

    public byte[] binaryValue() {
      return (byte[]) this.fieldsData;
    }

    public TokenStream tokenStreamValue() {
      
      return null;
    }
    
    public FieldForMerge(Object value, FieldInfo fi, boolean binary, boolean compressed, boolean tokenize) {
      this.isStored = true;  
      this.fieldsData = value;
      this.isCompressed = compressed;
      this.isBinary = binary;
      this.isTokenized = tokenize;

      this.name = fi.name.intern();
      this.isIndexed = fi.isIndexed;
      this.omitNorms = fi.omitNorms;          
      this.storeOffsetWithTermVector = fi.storeOffsetWithTermVector;
      this.storePositionWithTermVector = fi.storePositionWithTermVector;
      this.storeTermVector = fi.storeTermVector;            
    }
     
  }
}
"
lucene,2.2,org.apache.lucene.util.PriorityQueue,12,1,9,12,13,0,12,0,8,0.454545455,275,1.0,0,0.0,0.444444444,0,0,21.66666667,7,2.0833,1,"package org.apache.lucene.util;




public abstract class PriorityQueue {
  private Object[] heap;
  private int size;
  private int maxSize;

  
  protected abstract boolean lessThan(Object a, Object b);

  
  protected final void initialize(int maxSize) {
    size = 0;
    int heapSize = maxSize + 1;
    heap = new Object[heapSize];
    this.maxSize = maxSize;
  }

  
  public final void put(Object element) {
    size++;
    heap[size] = element;
    upHeap();
  }

  
  public boolean insert(Object element){
    if(size < maxSize){
      put(element);
      return true;
    }
    else if(size > 0 && !lessThan(element, top())){
      heap[1] = element;
      adjustTop();
      return true;
    }
    else
      return false;
   }

  
  public final Object top() {
    if (size > 0)
      return heap[1];
    else
      return null;
  }

  
  public final Object pop() {
    if (size > 0) {
      Object result = heap[1];			  
      heap[1] = heap[size];			  
      heap[size] = null;			  
      size--;
      downHeap();				  
      return result;
    } else
      return null;
  }

  
  public final void adjustTop() {
    downHeap();
  }


  
  public final int size() {
    return size;
  }

  
  public final void clear() {
    for (int i = 0; i <= size; i++)
      heap[i] = null;
    size = 0;
  }

  private final void upHeap() {
    int i = size;
    Object node = heap[i];			  
    int j = i >>> 1;
    while (j > 0 && lessThan(node, heap[j])) {
      heap[i] = heap[j];			  
      i = j;
      j = j >>> 1;
    }
    heap[i] = node;				  
  }

  private final void downHeap() {
    int i = 1;
    Object node = heap[i];			  
    int j = i << 1;				  
    int k = j + 1;
    if (k <= size && lessThan(heap[k], heap[j])) {
      j = k;
    }
    while (j <= size && lessThan(heap[j], node)) {
      heap[i] = heap[j];			  
      i = j;
      j = i << 1;
      k = j + 1;
      if (k <= size && lessThan(heap[k], heap[j])) {
	j = k;
      }
    }
    heap[i] = node;				  
  }
}
"
lucene,2.2,org.apache.lucene.search.Query,13,1,15,51,39,72,48,7,12,0.833333333,249,1.0,0,0.0,0.230769231,0,0,18.07692308,9,1.8462,0,"package org.apache.lucene.search;



import java.io.IOException;

import java.util.HashSet;
import java.util.Iterator;
import java.util.Set;

import org.apache.lucene.index.IndexReader;


public abstract class Query implements java.io.Serializable, Cloneable {
  private float boost = 1.0f;                     

  
  public void setBoost(float b) { boost = b; }

  
  public float getBoost() { return boost; }

  
  public abstract String toString(String field);

  
  public String toString() {
    return toString("""");
  }

  
  protected Weight createWeight(Searcher searcher) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  public Weight weight(Searcher searcher)
    throws IOException {
    Query query = searcher.rewrite(this);
    Weight weight = query.createWeight(searcher);
    float sum = weight.sumOfSquaredWeights();
    float norm = getSimilarity(searcher).queryNorm(sum);
    weight.normalize(norm);
    return weight;
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    return this;
  }

  
  public Query combine(Query[] queries) {
    HashSet uniques = new HashSet();
    for (int i = 0; i < queries.length; i++) {
      Query query = queries[i];
      BooleanClause[] clauses = null;
      
      boolean splittable = (query instanceof BooleanQuery);
      if(splittable){
        BooleanQuery bq = (BooleanQuery) query;
        splittable = bq.isCoordDisabled();
        clauses = bq.getClauses();
        for (int j = 0; splittable && j < clauses.length; j++) {
          splittable = (clauses[j].getOccur() == BooleanClause.Occur.SHOULD);
        }
      }
      if(splittable){
        for (int j = 0; j < clauses.length; j++) {
          uniques.add(clauses[j].getQuery());
        }
      } else {
        uniques.add(query);
      }
    }
    
    if(uniques.size() == 1){
        return (Query)uniques.iterator().next();
    }
    Iterator it = uniques.iterator();
    BooleanQuery result = new BooleanQuery(true);
    while (it.hasNext())
      result.add((Query) it.next(), BooleanClause.Occur.SHOULD);
    return result;
  }

  
  public void extractTerms(Set terms) {
    
    throw new UnsupportedOperationException();
  }


  
  public static Query mergeBooleanQueries(Query[] queries) {
    HashSet allClauses = new HashSet();
    for (int i = 0; i < queries.length; i++) {
      BooleanClause[] clauses = ((BooleanQuery)queries[i]).getClauses();
      for (int j = 0; j < clauses.length; j++) {
        allClauses.add(clauses[j]);
      }
    }

    boolean coordDisabled =
      queries.length==0? false : ((BooleanQuery)queries[0]).isCoordDisabled();
    BooleanQuery result = new BooleanQuery(coordDisabled);
    Iterator i = allClauses.iterator();
    while (i.hasNext()) {
      result.add((BooleanClause)i.next());
    }
    return result;
  }

  
  public Similarity getSimilarity(Searcher searcher) {
    return searcher.getSimilarity();
  }

  
  public Object clone() {
    try {
      return (Query)super.clone();
    } catch (CloneNotSupportedException e) {
      throw new RuntimeException(""Clone not supported: "" + e.getMessage());
    }
  }
}
"
lucene,2.2,org.apache.lucene.index.MultipleTermPositions,13,1,0,8,36,58,1,7,13,0.791666667,191,1.0,2,0.0,0.201923077,0,0,13.38461538,1,0.9231,1,"package org.apache.lucene.index;



import org.apache.lucene.util.PriorityQueue;

import java.io.IOException;
import java.util.Arrays;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;


public class MultipleTermPositions implements TermPositions {

  private static final class TermPositionsQueue extends PriorityQueue {
    TermPositionsQueue(List termPositions) throws IOException {
      initialize(termPositions.size());

      Iterator i = termPositions.iterator();
      while (i.hasNext()) {
        TermPositions tp = (TermPositions) i.next();
        if (tp.next())
          put(tp);
      }
    }

    final TermPositions peek() {
      return (TermPositions) top();
    }

    public final boolean lessThan(Object a, Object b) {
      return ((TermPositions) a).doc() < ((TermPositions) b).doc();
    }
  }

  private static final class IntQueue {
    private int _arraySize = 16;
    private int _index = 0;
    private int _lastIndex = 0;
    private int[] _array = new int[_arraySize];

    final void add(int i) {
      if (_lastIndex == _arraySize)
        growArray();

      _array[_lastIndex++] = i;
    }

    final int next() {
      return _array[_index++];
    }

    final void sort() {
      Arrays.sort(_array, _index, _lastIndex);
    }

    final void clear() {
      _index = 0;
      _lastIndex = 0;
    }

    final int size() {
      return (_lastIndex - _index);
    }

    private void growArray() {
      int[] newArray = new int[_arraySize * 2];
      System.arraycopy(_array, 0, newArray, 0, _arraySize);
      _array = newArray;
      _arraySize *= 2;
    }
  }

  private int _doc;
  private int _freq;
  private TermPositionsQueue _termPositionsQueue;
  private IntQueue _posList;

  
  public MultipleTermPositions(IndexReader indexReader, Term[] terms) throws IOException {
    List termPositions = new LinkedList();

    for (int i = 0; i < terms.length; i++)
      termPositions.add(indexReader.termPositions(terms[i]));

    _termPositionsQueue = new TermPositionsQueue(termPositions);
    _posList = new IntQueue();
  }

  public final boolean next() throws IOException {
    if (_termPositionsQueue.size() == 0)
      return false;

    _posList.clear();
    _doc = _termPositionsQueue.peek().doc();

    TermPositions tp;
    do {
      tp = _termPositionsQueue.peek();

      for (int i = 0; i < tp.freq(); i++)
        _posList.add(tp.nextPosition());

      if (tp.next())
        _termPositionsQueue.adjustTop();
      else {
        _termPositionsQueue.pop();
        tp.close();
      }
    } while (_termPositionsQueue.size() > 0 && _termPositionsQueue.peek().doc() == _doc);

    _posList.sort();
    _freq = _posList.size();

    return true;
  }

  public final int nextPosition() {
    return _posList.next();
  }

  public final boolean skipTo(int target) throws IOException {
    while (_termPositionsQueue.peek() != null && target > _termPositionsQueue.peek().doc()) {
      TermPositions tp = (TermPositions) _termPositionsQueue.pop();
      if (tp.skipTo(target))
        _termPositionsQueue.put(tp);
      else
        tp.close();
    }
    return next();
  }

  public final int doc() {
    return _doc;
  }

  public final int freq() {
    return _freq;
  }

  public final void close() throws IOException {
    while (_termPositionsQueue.size() > 0)
      ((TermPositions) _termPositionsQueue.pop()).close();
  }

  
  public void seek(Term arg0) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  public void seek(TermEnum termEnum) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  public int read(int[] arg0, int[] arg1) throws IOException {
    throw new UnsupportedOperationException();
  }
  
  
  
  public int getPayloadLength() {
    throw new UnsupportedOperationException();
  }
   
  
  public byte[] getPayload(byte[] data, int offset) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  
  public boolean isPayloadAvailable() {
    return false;
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.QueryParser,64,1,1,34,151,1520,1,33,40,0.893046107,3329,0.595238095,12,0.0,0.112169312,0,0,50.359375,23,2.4844,7,"
package org.apache.lucene.queryParser;

import java.util.Vector;
import java.io.*;
import java.text.*;
import java.util.*;
import org.apache.lucene.index.Term;
import org.apache.lucene.analysis.*;
import org.apache.lucene.document.*;
import org.apache.lucene.search.*;
import org.apache.lucene.util.Parameter;


public class QueryParser implements QueryParserConstants {

  private static final int CONJ_NONE   = 0;
  private static final int CONJ_AND    = 1;
  private static final int CONJ_OR     = 2;

  private static final int MOD_NONE    = 0;
  private static final int MOD_NOT     = 10;
  private static final int MOD_REQ     = 11;

  
  
  
  public static final Operator AND_OPERATOR = Operator.AND;
  
  public static final Operator OR_OPERATOR = Operator.OR;

  
  private Operator operator = OR_OPERATOR;

  boolean lowercaseExpandedTerms = true;
  boolean useOldRangeQuery= false;
  boolean allowLeadingWildcard = false;

  Analyzer analyzer;
  String field;
  int phraseSlop = 0;
  float fuzzyMinSim = FuzzyQuery.defaultMinSimilarity;
  int fuzzyPrefixLength = FuzzyQuery.defaultPrefixLength;
  Locale locale = Locale.getDefault();

  
  DateTools.Resolution dateResolution = null;
  
  Map fieldToDateResolution = null;

  
  static public final class Operator extends Parameter {
    private Operator(String name) {
      super(name);
    }
    static public final Operator OR = new Operator(""OR"");
    static public final Operator AND = new Operator(""AND"");
  }


  
  public QueryParser(String f, Analyzer a) {
    this(new FastCharStream(new StringReader("""")));
    analyzer = a;
    field = f;
  }

  
  public Query parse(String query) throws ParseException {
    ReInit(new FastCharStream(new StringReader(query)));
    try {
          
      return TopLevelQuery(field);
    }
    catch (ParseException tme) {
      
      throw new ParseException(""Cannot parse '"" +query+ ""': "" + tme.getMessage());
    }
    catch (TokenMgrError tme) {
      throw new ParseException(""Cannot parse '"" +query+ ""': "" + tme.getMessage());
    }
    catch (BooleanQuery.TooManyClauses tmc) {
      throw new ParseException(""Cannot parse '"" +query+ ""': too many boolean clauses"");
    }
  }

   
  public Analyzer getAnalyzer() {
    return analyzer;
  }

  
  public String getField() {
    return field;
  }

   
  public float getFuzzyMinSim() {
      return fuzzyMinSim;
  }

  
  public void setFuzzyMinSim(float fuzzyMinSim) {
      this.fuzzyMinSim = fuzzyMinSim;
  }

   
  public int getFuzzyPrefixLength() {
    return fuzzyPrefixLength;
  }

  
  public void setFuzzyPrefixLength(int fuzzyPrefixLength) {
    this.fuzzyPrefixLength = fuzzyPrefixLength;
  }

  
  public void setPhraseSlop(int phraseSlop) {
    this.phraseSlop = phraseSlop;
  }

  
  public int getPhraseSlop() {
    return phraseSlop;
  }


  
  public void setAllowLeadingWildcard(boolean allowLeadingWildcard) {
    this.allowLeadingWildcard = allowLeadingWildcard;
  }

  
  public boolean getAllowLeadingWildcard() {
    return allowLeadingWildcard;
  }

  
  public void setDefaultOperator(Operator op) {
    this.operator = op;
  }


  
  public Operator getDefaultOperator() {
    return operator;
  }


  
  public void setLowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
    this.lowercaseExpandedTerms = lowercaseExpandedTerms;
  }


  
  public boolean getLowercaseExpandedTerms() {
    return lowercaseExpandedTerms;
  }

  
  public void setUseOldRangeQuery(boolean useOldRangeQuery) {
    this.useOldRangeQuery = useOldRangeQuery;
  }


  
  public boolean getUseOldRangeQuery() {
    return useOldRangeQuery;
  }


  
  public void setLocale(Locale locale) {
    this.locale = locale;
  }

  
  public Locale getLocale() {
    return locale;
  }

  
  public void setDateResolution(DateTools.Resolution dateResolution) {
    this.dateResolution = dateResolution;
  }

  
  public void setDateResolution(String fieldName, DateTools.Resolution dateResolution) {
    if (fieldName == null) {
      throw new IllegalArgumentException(""Field cannot be null."");
    }

    if (fieldToDateResolution == null) {
      
      fieldToDateResolution = new HashMap();
    }

    fieldToDateResolution.put(fieldName, dateResolution);
  }

  
  public DateTools.Resolution getDateResolution(String fieldName) {
    if (fieldName == null) {
      throw new IllegalArgumentException(""Field cannot be null."");
    }

    if (fieldToDateResolution == null) {
      
      return this.dateResolution;
    }

    DateTools.Resolution resolution = (DateTools.Resolution) fieldToDateResolution.get(fieldName);
    if (resolution == null) {
      
      resolution = this.dateResolution;
    }

    return resolution;
  }

  protected void addClause(Vector clauses, int conj, int mods, Query q) {
    boolean required, prohibited;

    
    
    if (clauses.size() > 0 && conj == CONJ_AND) {
      BooleanClause c = (BooleanClause) clauses.elementAt(clauses.size()-1);
      if (!c.isProhibited())
        c.setOccur(BooleanClause.Occur.MUST);
    }

    if (clauses.size() > 0 && operator == AND_OPERATOR && conj == CONJ_OR) {
      
      
      
      
      BooleanClause c = (BooleanClause) clauses.elementAt(clauses.size()-1);
      if (!c.isProhibited())
        c.setOccur(BooleanClause.Occur.SHOULD);
    }

    
    
    if (q == null)
      return;

    if (operator == OR_OPERATOR) {
      
      
      prohibited = (mods == MOD_NOT);
      required = (mods == MOD_REQ);
      if (conj == CONJ_AND && !prohibited) {
        required = true;
      }
    } else {
      
      
      prohibited = (mods == MOD_NOT);
      required   = (!prohibited && conj != CONJ_OR);
    }
    if (required && !prohibited)
      clauses.addElement(new BooleanClause(q, BooleanClause.Occur.MUST));
    else if (!required && !prohibited)
      clauses.addElement(new BooleanClause(q, BooleanClause.Occur.SHOULD));
    else if (!required && prohibited)
      clauses.addElement(new BooleanClause(q, BooleanClause.Occur.MUST_NOT));
    else
      throw new RuntimeException(""Clause cannot be both required and prohibited"");
  }


  
  protected Query getFieldQuery(String field, String queryText)  throws ParseException {
    
    

    TokenStream source = analyzer.tokenStream(field, new StringReader(queryText));
    Vector v = new Vector();
    org.apache.lucene.analysis.Token t;
    int positionCount = 0;
    boolean severalTokensAtSamePosition = false;

    while (true) {
      try {
        t = source.next();
      }
      catch (IOException e) {
        t = null;
      }
      if (t == null)
        break;
      v.addElement(t);
      if (t.getPositionIncrement() != 0)
        positionCount += t.getPositionIncrement();
      else
        severalTokensAtSamePosition = true;
    }
    try {
      source.close();
    }
    catch (IOException e) {
      
    }

    if (v.size() == 0)
      return null;
    else if (v.size() == 1) {
      t = (org.apache.lucene.analysis.Token) v.elementAt(0);
      return new TermQuery(new Term(field, t.termText()));
    } else {
      if (severalTokensAtSamePosition) {
        if (positionCount == 1) {
          
          BooleanQuery q = new BooleanQuery(true);
          for (int i = 0; i < v.size(); i++) {
            t = (org.apache.lucene.analysis.Token) v.elementAt(i);
            TermQuery currentQuery = new TermQuery(
                new Term(field, t.termText()));
            q.add(currentQuery, BooleanClause.Occur.SHOULD);
          }
          return q;
        }
        else {
          
          MultiPhraseQuery mpq = new MultiPhraseQuery();
          mpq.setSlop(phraseSlop);
          List multiTerms = new ArrayList();
          for (int i = 0; i < v.size(); i++) {
            t = (org.apache.lucene.analysis.Token) v.elementAt(i);
            if (t.getPositionIncrement() == 1 && multiTerms.size() > 0) {
              mpq.add((Term[])multiTerms.toArray(new Term[0]));
              multiTerms.clear();
            }
            multiTerms.add(new Term(field, t.termText()));
          }
          mpq.add((Term[])multiTerms.toArray(new Term[0]));
          return mpq;
        }
      }
      else {
        PhraseQuery q = new PhraseQuery();
        q.setSlop(phraseSlop);
        for (int i = 0; i < v.size(); i++) {
          q.add(new Term(field, ((org.apache.lucene.analysis.Token)
              v.elementAt(i)).termText()));

        }
        return q;
      }
    }
  }


  
  protected Query getFieldQuery(String field, String queryText, int slop)
        throws ParseException {
    Query query = getFieldQuery(field, queryText);

    if (query instanceof PhraseQuery) {
      ((PhraseQuery) query).setSlop(slop);
    }
    if (query instanceof MultiPhraseQuery) {
      ((MultiPhraseQuery) query).setSlop(slop);
    }

    return query;
  }


  
  protected Query getRangeQuery(String field,
                                String part1,
                                String part2,
                                boolean inclusive) throws ParseException
  {
    if (lowercaseExpandedTerms) {
      part1 = part1.toLowerCase();
      part2 = part2.toLowerCase();
    }
    try {
      DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT, locale);
      df.setLenient(true);
      Date d1 = df.parse(part1);
      Date d2 = df.parse(part2);
      if (inclusive) {
        
        
        
        Calendar cal = Calendar.getInstance(locale);
        cal.setTime(d2);
        cal.set(Calendar.HOUR_OF_DAY, 23);
        cal.set(Calendar.MINUTE, 59);
        cal.set(Calendar.SECOND, 59);
        cal.set(Calendar.MILLISECOND, 999);
        d2 = cal.getTime();
      }
      DateTools.Resolution resolution = getDateResolution(field);
      if (resolution == null) {
        
        
        
        part1 = DateField.dateToString(d1);
        part2 = DateField.dateToString(d2);
      } else {
        part1 = DateTools.dateToString(d1, resolution);
        part2 = DateTools.dateToString(d2, resolution);
      }
    }
    catch (Exception e) { }

    if(useOldRangeQuery)
    {
            return new RangeQuery(new Term(field, part1),
                          new Term(field, part2),
                          inclusive);
    }
    else
    {
      return new ConstantScoreRangeQuery(field,part1,part2,inclusive,inclusive);
    }
  }

  
  protected Query getBooleanQuery(Vector clauses) throws ParseException {
    return getBooleanQuery(clauses, false);
  }

  
  protected Query getBooleanQuery(Vector clauses, boolean disableCoord)
    throws ParseException
  {
    BooleanQuery query = new BooleanQuery(disableCoord);
    for (int i = 0; i < clauses.size(); i++) {
  query.add((BooleanClause)clauses.elementAt(i));
    }
    return query;
  }

  
  protected Query getWildcardQuery(String field, String termStr) throws ParseException
  {
    if (""*"".equals(field)) {
      if (""*"".equals(termStr)) return new MatchAllDocsQuery();
    }
    if (!allowLeadingWildcard && (termStr.startsWith(""*"") || termStr.startsWith(""?"")))
      throw new ParseException(""'*' or '?' not allowed as first character in WildcardQuery"");
    if (lowercaseExpandedTerms) {
      termStr = termStr.toLowerCase();
    }
    Term t = new Term(field, termStr);
    return new WildcardQuery(t);
  }

  
  protected Query getPrefixQuery(String field, String termStr) throws ParseException
  {
    if (!allowLeadingWildcard && termStr.startsWith(""*""))
      throw new ParseException(""'*' not allowed as first character in PrefixQuery"");
    if (lowercaseExpandedTerms) {
      termStr = termStr.toLowerCase();
    }
    Term t = new Term(field, termStr);
    return new PrefixQuery(t);
  }


   
  protected Query getFuzzyQuery(String field, String termStr, float minSimilarity) throws ParseException
  {
    if (lowercaseExpandedTerms) {
      termStr = termStr.toLowerCase();
    }
    Term t = new Term(field, termStr);
    return new FuzzyQuery(t, minSimilarity, fuzzyPrefixLength);
  }

  
  private String discardEscapeChar(String input) throws ParseException {
    
    char[] output = new char[input.length()];

    
    
    
    int length = 0;

    
    
    boolean lastCharWasEscapeChar = false;

    
    
    int codePointMultiplier = 0;

    
    int codePoint = 0;

    for (int i = 0; i < input.length(); i++) {
      char curChar = input.charAt(i);
      if (codePointMultiplier > 0) {
        codePoint += hexToInt(curChar) * codePointMultiplier;
        codePointMultiplier >>>= 4;
        if (codePointMultiplier == 0) {
          output[length++] = (char)codePoint;
          codePoint = 0;
        }
      } else if (lastCharWasEscapeChar) {
        if (curChar == 'u') {
          
          codePointMultiplier = 16 * 16 * 16;
        } else {
          
          output[length] = curChar;
          length++;
        }
        lastCharWasEscapeChar = false;
      } else {
        if (curChar == '\\') {
          lastCharWasEscapeChar = true;
        } else {
          output[length] = curChar;
          length++;
        }
      }
    }

    if (codePointMultiplier > 0) {
      throw new ParseException(""Truncated unicode escape sequence."");
    }

    if (lastCharWasEscapeChar) {
      throw new ParseException(""Term can not end with escape character."");
    }

    return new String(output, 0, length);
  }

  
  private static final int hexToInt(char c) throws ParseException {
    if ('0' <= c && c <= '9') {
      return c - '0';
    } else if ('a' <= c && c <= 'f'){
      return c - 'a' + 10;
    } else if ('A' <= c && c <= 'F') {
      return c - 'A' + 10;
    } else {
      throw new ParseException(""None-hex character in unicode escape sequence: "" + c);
    }
  }

  
  public static String escape(String s) {
    StringBuffer sb = new StringBuffer();
    for (int i = 0; i < s.length(); i++) {
      char c = s.charAt(i);
      
      if (c == '\\' || c == '+' || c == '-' || c == '!' || c == '(' || c == ')' || c == ':'
        || c == '^' || c == '[' || c == ']' || c == '\""' || c == '{' || c == '}' || c == '~'
        || c == '*' || c == '?' || c == '|' || c == '&') {
        sb.append('\\');
      }
      sb.append(c);
    }
    return sb.toString();
  }

  
  public static void main(String[] args) throws Exception {
    if (args.length == 0) {
      System.out.println(""Usage: java org.apache.lucene.queryParser.QueryParser <input>"");
      System.exit(0);
    }
    QueryParser qp = new QueryParser(""field"",
                           new org.apache.lucene.analysis.SimpleAnalyzer());
    Query q = qp.parse(args[0]);
    System.out.println(q.toString(""field""));
  }



  final public int Conjunction() throws ParseException {
  int ret = CONJ_NONE;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case AND:
    case OR:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case AND:
        jj_consume_token(AND);
            ret = CONJ_AND;
        break;
      case OR:
        jj_consume_token(OR);
              ret = CONJ_OR;
        break;
      default:
        jj_la1[0] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      break;
    default:
      jj_la1[1] = jj_gen;
      ;
    }
    {if (true) return ret;}
    throw new Error(""Missing return statement in function"");
  }

  final public int Modifiers() throws ParseException {
  int ret = MOD_NONE;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case NOT:
    case PLUS:
    case MINUS:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case PLUS:
        jj_consume_token(PLUS);
              ret = MOD_REQ;
        break;
      case MINUS:
        jj_consume_token(MINUS);
                 ret = MOD_NOT;
        break;
      case NOT:
        jj_consume_token(NOT);
               ret = MOD_NOT;
        break;
      default:
        jj_la1[2] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      break;
    default:
      jj_la1[3] = jj_gen;
      ;
    }
    {if (true) return ret;}
    throw new Error(""Missing return statement in function"");
  }


  final public Query TopLevelQuery(String field) throws ParseException {
        Query q;
    q = Query(field);
    jj_consume_token(0);
                {if (true) return q;}
    throw new Error(""Missing return statement in function"");
  }

  final public Query Query(String field) throws ParseException {
  Vector clauses = new Vector();
  Query q, firstQuery=null;
  int conj, mods;
    mods = Modifiers();
    q = Clause(field);
    addClause(clauses, CONJ_NONE, mods, q);
    if (mods == MOD_NONE)
        firstQuery=q;
    label_1:
    while (true) {
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case AND:
      case OR:
      case NOT:
      case PLUS:
      case MINUS:
      case LPAREN:
      case STAR:
      case QUOTED:
      case TERM:
      case PREFIXTERM:
      case WILDTERM:
      case RANGEIN_START:
      case RANGEEX_START:
      case NUMBER:
        ;
        break;
      default:
        jj_la1[4] = jj_gen;
        break label_1;
      }
      conj = Conjunction();
      mods = Modifiers();
      q = Clause(field);
      addClause(clauses, conj, mods, q);
    }
      if (clauses.size() == 1 && firstQuery != null)
        {if (true) return firstQuery;}
      else {
  {if (true) return getBooleanQuery(clauses);}
      }
    throw new Error(""Missing return statement in function"");
  }

  final public Query Clause(String field) throws ParseException {
  Query q;
  Token fieldToken=null, boost=null;
    if (jj_2_1(2)) {
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case TERM:
        fieldToken = jj_consume_token(TERM);
        jj_consume_token(COLON);
                               field=discardEscapeChar(fieldToken.image);
        break;
      case STAR:
        jj_consume_token(STAR);
        jj_consume_token(COLON);
                      field=""*"";
        break;
      default:
        jj_la1[5] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
    } else {
      ;
    }
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case STAR:
    case QUOTED:
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case RANGEIN_START:
    case RANGEEX_START:
    case NUMBER:
      q = Term(field);
      break;
    case LPAREN:
      jj_consume_token(LPAREN);
      q = Query(field);
      jj_consume_token(RPAREN);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[6] = jj_gen;
        ;
      }
      break;
    default:
      jj_la1[7] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
      if (boost != null) {
        float f = (float)1.0;
  try {
    f = Float.valueOf(boost.image).floatValue();
          q.setBoost(f);
  } catch (Exception ignored) { }
      }
      {if (true) return q;}
    throw new Error(""Missing return statement in function"");
  }

  final public Query Term(String field) throws ParseException {
  Token term, boost=null, fuzzySlop=null, goop1, goop2;
  boolean prefix = false;
  boolean wildcard = false;
  boolean fuzzy = false;
  boolean rangein = false;
  Query q;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case STAR:
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case NUMBER:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case TERM:
        term = jj_consume_token(TERM);
        break;
      case STAR:
        term = jj_consume_token(STAR);
                       wildcard=true;
        break;
      case PREFIXTERM:
        term = jj_consume_token(PREFIXTERM);
                             prefix=true;
        break;
      case WILDTERM:
        term = jj_consume_token(WILDTERM);
                           wildcard=true;
        break;
      case NUMBER:
        term = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[8] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                fuzzy=true;
        break;
      default:
        jj_la1[9] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case FUZZY_SLOP:
          fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                                         fuzzy=true;
          break;
        default:
          jj_la1[10] = jj_gen;
          ;
        }
        break;
      default:
        jj_la1[11] = jj_gen;
        ;
      }
       String termImage=discardEscapeChar(term.image);
       if (wildcard) {
       q = getWildcardQuery(field, termImage);
       } else if (prefix) {
         q = getPrefixQuery(field,
           discardEscapeChar(term.image.substring
          (0, term.image.length()-1)));
       } else if (fuzzy) {
          float fms = fuzzyMinSim;
          try {
            fms = Float.valueOf(fuzzySlop.image.substring(1)).floatValue();
          } catch (Exception ignored) { }
         if(fms < 0.0f || fms > 1.0f){
           {if (true) throw new ParseException(""Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !"");}
         }
         q = getFuzzyQuery(field, termImage,fms);
       } else {
         q = getFieldQuery(field, termImage);
       }
      break;
    case RANGEIN_START:
      jj_consume_token(RANGEIN_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop1 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop1 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[12] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_TO:
        jj_consume_token(RANGEIN_TO);
        break;
      default:
        jj_la1[13] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop2 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop2 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[14] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEIN_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[15] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEIN_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          }
          if (goop2.kind == RANGEIN_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
          }
          q = getRangeQuery(field, discardEscapeChar(goop1.image), discardEscapeChar(goop2.image), true);
      break;
    case RANGEEX_START:
      jj_consume_token(RANGEEX_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop1 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop1 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[16] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_TO:
        jj_consume_token(RANGEEX_TO);
        break;
      default:
        jj_la1[17] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop2 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop2 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[18] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEEX_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[19] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEEX_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          }
          if (goop2.kind == RANGEEX_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
          }

          q = getRangeQuery(field, discardEscapeChar(goop1.image), discardEscapeChar(goop2.image), false);
      break;
    case QUOTED:
      term = jj_consume_token(QUOTED);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
        break;
      default:
        jj_la1[20] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[21] = jj_gen;
        ;
      }
         int s = phraseSlop;

         if (fuzzySlop != null) {
           try {
             s = Float.valueOf(fuzzySlop.image.substring(1)).intValue();
           }
           catch (Exception ignored) { }
         }
         q = getFieldQuery(field, discardEscapeChar(term.image.substring(1, term.image.length()-1)), s);
      break;
    default:
      jj_la1[22] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
    if (boost != null) {
      float f = (float) 1.0;
      try {
        f = Float.valueOf(boost.image).floatValue();
      }
      catch (Exception ignored) {
    
      }

      
      if (q != null) {
        q.setBoost(f);
      }
    }
    {if (true) return q;}
    throw new Error(""Missing return statement in function"");
  }

  final private boolean jj_2_1(int xla) {
    jj_la = xla; jj_lastpos = jj_scanpos = token;
    try { return !jj_3_1(); }
    catch(LookaheadSuccess ls) { return true; }
    finally { jj_save(0, xla); }
  }

  final private boolean jj_3_1() {
    Token xsp;
    xsp = jj_scanpos;
    if (jj_3R_2()) {
    jj_scanpos = xsp;
    if (jj_3R_3()) return true;
    }
    return false;
  }

  final private boolean jj_3R_3() {
    if (jj_scan_token(STAR)) return true;
    if (jj_scan_token(COLON)) return true;
    return false;
  }

  final private boolean jj_3R_2() {
    if (jj_scan_token(TERM)) return true;
    if (jj_scan_token(COLON)) return true;
    return false;
  }

  public QueryParserTokenManager token_source;
  public Token token, jj_nt;
  private int jj_ntk;
  private Token jj_scanpos, jj_lastpos;
  private int jj_la;
  public boolean lookingAhead = false;
  private boolean jj_semLA;
  private int jj_gen;
  final private int[] jj_la1 = new int[23];
  static private int[] jj_la1_0;
  static private int[] jj_la1_1;
  static {
      jj_la1_0();
      jj_la1_1();
   }
   private static void jj_la1_0() {
      jj_la1_0 = new int[] {0x180,0x180,0xe00,0xe00,0x1f69f80,0x48000,0x10000,0x1f69000,0x1348000,0x80000,0x80000,0x10000,0x18000000,0x2000000,0x18000000,0x10000,0x80000000,0x20000000,0x80000000,0x10000,0x80000,0x10000,0x1f68000,};
   }
   private static void jj_la1_1() {
      jj_la1_1 = new int[] {0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x1,0x0,0x1,0x0,0x0,0x0,0x0,};
   }
  final private JJCalls[] jj_2_rtns = new JJCalls[1];
  private boolean jj_rescan = false;
  private int jj_gc = 0;

  public QueryParser(CharStream stream) {
    token_source = new QueryParserTokenManager(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 23; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  public void ReInit(CharStream stream) {
    token_source.ReInit(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 23; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  public QueryParser(QueryParserTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 23; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  public void ReInit(QueryParserTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 23; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  final private Token jj_consume_token(int kind) throws ParseException {
    Token oldToken;
    if ((oldToken = token).next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    if (token.kind == kind) {
      jj_gen++;
      if (++jj_gc > 100) {
        jj_gc = 0;
        for (int i = 0; i < jj_2_rtns.length; i++) {
          JJCalls c = jj_2_rtns[i];
          while (c != null) {
            if (c.gen < jj_gen) c.first = null;
            c = c.next;
          }
        }
      }
      return token;
    }
    token = oldToken;
    jj_kind = kind;
    throw generateParseException();
  }

  static private final class LookaheadSuccess extends java.lang.Error { }
  final private LookaheadSuccess jj_ls = new LookaheadSuccess();
  final private boolean jj_scan_token(int kind) {
    if (jj_scanpos == jj_lastpos) {
      jj_la--;
      if (jj_scanpos.next == null) {
        jj_lastpos = jj_scanpos = jj_scanpos.next = token_source.getNextToken();
      } else {
        jj_lastpos = jj_scanpos = jj_scanpos.next;
      }
    } else {
      jj_scanpos = jj_scanpos.next;
    }
    if (jj_rescan) {
      int i = 0; Token tok = token;
      while (tok != null && tok != jj_scanpos) { i++; tok = tok.next; }
      if (tok != null) jj_add_error_token(kind, i);
    }
    if (jj_scanpos.kind != kind) return true;
    if (jj_la == 0 && jj_scanpos == jj_lastpos) throw jj_ls;
    return false;
  }

  final public Token getNextToken() {
    if (token.next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    jj_gen++;
    return token;
  }

  final public Token getToken(int index) {
    Token t = lookingAhead ? jj_scanpos : token;
    for (int i = 0; i < index; i++) {
      if (t.next != null) t = t.next;
      else t = t.next = token_source.getNextToken();
    }
    return t;
  }

  final private int jj_ntk() {
    if ((jj_nt=token.next) == null)
      return (jj_ntk = (token.next=token_source.getNextToken()).kind);
    else
      return (jj_ntk = jj_nt.kind);
  }

  private java.util.Vector jj_expentries = new java.util.Vector();
  private int[] jj_expentry;
  private int jj_kind = -1;
  private int[] jj_lasttokens = new int[100];
  private int jj_endpos;

  private void jj_add_error_token(int kind, int pos) {
    if (pos >= 100) return;
    if (pos == jj_endpos + 1) {
      jj_lasttokens[jj_endpos++] = kind;
    } else if (jj_endpos != 0) {
      jj_expentry = new int[jj_endpos];
      for (int i = 0; i < jj_endpos; i++) {
        jj_expentry[i] = jj_lasttokens[i];
      }
      boolean exists = false;
      for (java.util.Enumeration e = jj_expentries.elements(); e.hasMoreElements();) {
        int[] oldentry = (int[])(e.nextElement());
        if (oldentry.length == jj_expentry.length) {
          exists = true;
          for (int i = 0; i < jj_expentry.length; i++) {
            if (oldentry[i] != jj_expentry[i]) {
              exists = false;
              break;
            }
          }
          if (exists) break;
        }
      }
      if (!exists) jj_expentries.addElement(jj_expentry);
      if (pos != 0) jj_lasttokens[(jj_endpos = pos) - 1] = kind;
    }
  }

  public ParseException generateParseException() {
    jj_expentries.removeAllElements();
    boolean[] la1tokens = new boolean[33];
    for (int i = 0; i < 33; i++) {
      la1tokens[i] = false;
    }
    if (jj_kind >= 0) {
      la1tokens[jj_kind] = true;
      jj_kind = -1;
    }
    for (int i = 0; i < 23; i++) {
      if (jj_la1[i] == jj_gen) {
        for (int j = 0; j < 32; j++) {
          if ((jj_la1_0[i] & (1<<j)) != 0) {
            la1tokens[j] = true;
          }
          if ((jj_la1_1[i] & (1<<j)) != 0) {
            la1tokens[32+j] = true;
          }
        }
      }
    }
    for (int i = 0; i < 33; i++) {
      if (la1tokens[i]) {
        jj_expentry = new int[1];
        jj_expentry[0] = i;
        jj_expentries.addElement(jj_expentry);
      }
    }
    jj_endpos = 0;
    jj_rescan_token();
    jj_add_error_token(0, 0);
    int[][] exptokseq = new int[jj_expentries.size()][];
    for (int i = 0; i < jj_expentries.size(); i++) {
      exptokseq[i] = (int[])jj_expentries.elementAt(i);
    }
    return new ParseException(token, exptokseq, tokenImage);
  }

  final public void enable_tracing() {
  }

  final public void disable_tracing() {
  }

  final private void jj_rescan_token() {
    jj_rescan = true;
    for (int i = 0; i < 1; i++) {
      JJCalls p = jj_2_rtns[i];
      do {
        if (p.gen > jj_gen) {
          jj_la = p.arg; jj_lastpos = jj_scanpos = p.first;
          switch (i) {
            case 0: jj_3_1(); break;
          }
        }
        p = p.next;
      } while (p != null);
    }
    jj_rescan = false;
  }

  final private void jj_save(int index, int xla) {
    JJCalls p = jj_2_rtns[index];
    while (p.gen > jj_gen) {
      if (p.next == null) { p = p.next = new JJCalls(); break; }
      p = p.next;
    }
    p.gen = jj_gen + xla - jj_la; p.first = token; p.arg = xla;
  }

  static final class JJCalls {
    int gen;
    Token first;
    int arg;
    JJCalls next;
  }

}
"
lucene,2.2,org.apache.lucene.analysis.SimpleAnalyzer,2,2,0,4,4,1,1,3,2,2.0,10,0.0,0,0.666666667,0.666666667,0,0,4.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public final class SimpleAnalyzer extends Analyzer {
  public TokenStream tokenStream(String fieldName, Reader reader) {
    return new LowerCaseTokenizer(reader);
  }
}
"
lucene,2.2,org.apache.lucene.search.FieldDocSortedHitQueue,5,2,0,6,21,0,3,3,0,0.375,274,0.0,1,0.733333333,0.5,1,3,53.4,18,5.0,2,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;

import java.text.Collator;
import java.util.Locale;


class FieldDocSortedHitQueue
extends PriorityQueue {

	
	
	volatile SortField[] fields;

	
	
	volatile Collator[] collators;


	
	FieldDocSortedHitQueue (SortField[] fields, int size) {
		this.fields = fields;
		this.collators = hasCollators (fields);
		initialize (size);
	}


	
	synchronized void setFields (SortField[] fields) {
		if (this.fields == null) {
			this.fields = fields;
			this.collators = hasCollators (fields);
		}
	}


	
	SortField[] getFields() {
		return fields;
	}


	
	private Collator[] hasCollators (final SortField[] fields) {
		if (fields == null) return null;
		Collator[] ret = new Collator[fields.length];
		for (int i=0; i<fields.length; ++i) {
			Locale locale = fields[i].getLocale();
			if (locale != null)
				ret[i] = Collator.getInstance (locale);
		}
		return ret;
	}


	
	protected final boolean lessThan (final Object a, final Object b) {
		final FieldDoc docA = (FieldDoc) a;
		final FieldDoc docB = (FieldDoc) b;
		final int n = fields.length;
		int c = 0;
		for (int i=0; i<n && c==0; ++i) {
			final int type = fields[i].getType();
			switch (type) {
				case SortField.SCORE:
					float r1 = ((Float)docA.fields[i]).floatValue();
					float r2 = ((Float)docB.fields[i]).floatValue();
					if (r1 > r2) c = -1;
					if (r1 < r2) c = 1;
					break;
				case SortField.DOC:
				case SortField.INT:
					int i1 = ((Integer)docA.fields[i]).intValue();
					int i2 = ((Integer)docB.fields[i]).intValue();
					if (i1 < i2) c = -1;
					if (i1 > i2) c = 1;
					break;
				case SortField.STRING:
					String s1 = (String) docA.fields[i];
					String s2 = (String) docB.fields[i];
					
					
					
					if (s1 == null) c = (s2==null) ? 0 : -1;
					else if (s2 == null) c = 1;  
					else if (fields[i].getLocale() == null) {
						c = s1.compareTo(s2);
					} else {
						c = collators[i].compare (s1, s2);
					}
					break;
				case SortField.FLOAT:
					float f1 = ((Float)docA.fields[i]).floatValue();
					float f2 = ((Float)docB.fields[i]).floatValue();
					if (f1 < f2) c = -1;
					if (f1 > f2) c = 1;
					break;
				case SortField.CUSTOM:
					c = docA.fields[i].compareTo (docB.fields[i]);
					break;
				case SortField.AUTO:
					
					
					
					
					throw new RuntimeException (""FieldDocSortedHitQueue cannot use an AUTO SortField"");
				default:
					throw new RuntimeException (""invalid SortField type: ""+type);
			}
			if (fields[i].getReverse()) {
				c = -c;
			}
		}

    
    if (c == 0)
      return docA.doc > docB.doc;

    return c > 0;
	}
}
"
lucene,2.2,org.apache.lucene.search.function.FieldCacheSource,8,2,4,8,12,8,4,4,8,0.5,68,1.0,1,0.416666667,0.3125,2,2,7.25,5,1.375,2,"package org.apache.lucene.search.function;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;


public abstract class FieldCacheSource extends ValueSource {
  private String field;
  private FieldCache cache = FieldCache.DEFAULT;

  
  public FieldCacheSource(String field) {
    this.field=field;
  }

  
  public final DocValues getValues(IndexReader reader) throws IOException {
    return getCachedFieldValues(cache, field, reader);
  }

  
  public String description() {
    return field;
  }

  
  public abstract DocValues getCachedFieldValues(FieldCache cache, String field, IndexReader reader) throws IOException;

  
  public final boolean equals(Object o) {
    if (!(o instanceof FieldCacheSource)) {
      return false;
    }
    FieldCacheSource other = (FieldCacheSource) o;
    return 
      this.cache == other.cache &&
      this.field.equals(other.field) && 
      cachedFieldSourceEquals(other);
  }

  
  public final int hashCode() {
    return 
      cache.hashCode() + 
      field.hashCode() +
      cachedFieldSourceHashCode();
  }

  
  public abstract boolean cachedFieldSourceEquals(FieldCacheSource other);

  
  public abstract int cachedFieldSourceHashCode();
}
"
lucene,2.2,org.apache.lucene.search.BooleanQuery,27,2,0,19,64,171,12,11,22,0.769230769,443,1.0,0,0.333333333,0.102564103,2,6,15.22222222,12,1.5926,3,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;
import org.apache.lucene.search.BooleanClause.Occur;

import java.io.IOException;
import java.util.*;


public class BooleanQuery extends Query {

  
  private static int maxClauseCount = 1024;

  
  public static class TooManyClauses extends RuntimeException {
    public TooManyClauses() {}
    public String getMessage() {
      return ""maxClauseCount is set to "" + maxClauseCount;
    }
  }

  
  public static int getMaxClauseCount() { return maxClauseCount; }

  
  public static void setMaxClauseCount(int maxClauseCount) {
    if (maxClauseCount < 1)
      throw new IllegalArgumentException(""maxClauseCount must be >= 1"");
    BooleanQuery.maxClauseCount = maxClauseCount;
  }

  private ArrayList clauses = new ArrayList();
  private boolean disableCoord;

  
  public BooleanQuery() {}

  
  public BooleanQuery(boolean disableCoord) {
    this.disableCoord = disableCoord;
  }

  
  public boolean isCoordDisabled() { return disableCoord; }

  
  
  public Similarity getSimilarity(Searcher searcher) {
    Similarity result = super.getSimilarity(searcher);
    if (disableCoord) {                           
      result = new SimilarityDelegator(result) {
          public float coord(int overlap, int maxOverlap) {
            return 1.0f;
          }
        };
    }
    return result;
  }

  
  public void setMinimumNumberShouldMatch(int min) {
    this.minNrShouldMatch = min;
  }
  protected int minNrShouldMatch = 0;

  
  public int getMinimumNumberShouldMatch() {
    return minNrShouldMatch;
  }

  
  public void add(Query query, BooleanClause.Occur occur) {
    add(new BooleanClause(query, occur));
  }

  
  public void add(BooleanClause clause) {
    if (clauses.size() >= maxClauseCount)
      throw new TooManyClauses();

    clauses.add(clause);
  }

  
  public BooleanClause[] getClauses() {
    return (BooleanClause[])clauses.toArray(new BooleanClause[clauses.size()]);
  }

  
  public List clauses() { return clauses; }

  private class BooleanWeight implements Weight {
    protected Similarity similarity;
    protected Vector weights = new Vector();

    public BooleanWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);
      for (int i = 0 ; i < clauses.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.get(i);
        weights.add(c.getQuery().createWeight(searcher));
      }
    }

    public Query getQuery() { return BooleanQuery.this; }
    public float getValue() { return getBoost(); }

    public float sumOfSquaredWeights() throws IOException {
      float sum = 0.0f;
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.get(i);
        Weight w = (Weight)weights.elementAt(i);
        
        float s = w.sumOfSquaredWeights();         
        if (!c.isProhibited())
          
          sum += s;
      }

      sum *= getBoost() * getBoost();             

      return sum ;
    }


    public void normalize(float norm) {
      norm *= getBoost();                         
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.get(i);
        Weight w = (Weight)weights.elementAt(i);
        
        w.normalize(norm);
      }
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      BooleanScorer2 result = new BooleanScorer2(similarity,
                                                 minNrShouldMatch,
                                                 allowDocsOutOfOrder);

      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.get(i);
        Weight w = (Weight)weights.elementAt(i);
        Scorer subScorer = w.scorer(reader);
        if (subScorer != null)
          result.add(subScorer, c.isRequired(), c.isProhibited());
        else if (c.isRequired())
          return null;
      }

      return result;
    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {
      final int minShouldMatch =
        BooleanQuery.this.getMinimumNumberShouldMatch();
      ComplexExplanation sumExpl = new ComplexExplanation();
      sumExpl.setDescription(""sum of:"");
      int coord = 0;
      int maxCoord = 0;
      float sum = 0.0f;
      boolean fail = false;
      int shouldMatchCount = 0;
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.get(i);
        Weight w = (Weight)weights.elementAt(i);
        Explanation e = w.explain(reader, doc);
        if (!c.isProhibited()) maxCoord++;
        if (e.isMatch()) {
          if (!c.isProhibited()) {
            sumExpl.addDetail(e);
            sum += e.getValue();
            coord++;
          } else {
            Explanation r =
              new Explanation(0.0f, ""match on prohibited clause ("" + c.getQuery().toString() + "")"");
            r.addDetail(e);
            sumExpl.addDetail(r);
            fail = true;
          }
          if (c.getOccur().equals(Occur.SHOULD))
            shouldMatchCount++;
        } else if (c.isRequired()) {
          Explanation r = new Explanation(0.0f, ""no match on required clause ("" + c.getQuery().toString() + "")"");
          r.addDetail(e);
          sumExpl.addDetail(r);
          fail = true;
        }
      }
      if (fail) {
        sumExpl.setMatch(Boolean.FALSE);
        sumExpl.setValue(0.0f);
        sumExpl.setDescription
          (""Failure to meet condition(s) of required/prohibited clause(s)"");
        return sumExpl;
      } else if (shouldMatchCount < minShouldMatch) {
        sumExpl.setMatch(Boolean.FALSE);
        sumExpl.setValue(0.0f);
        sumExpl.setDescription(""Failure to match minimum number ""+
                               ""of optional clauses: "" + minShouldMatch);
        return sumExpl;
      }
      
      sumExpl.setMatch(0 < coord ? Boolean.TRUE : Boolean.FALSE);
      sumExpl.setValue(sum);
      
      float coordFactor = similarity.coord(coord, maxCoord);
      if (coordFactor == 1.0f)                      
        return sumExpl;                             
      else {
        ComplexExplanation result = new ComplexExplanation(sumExpl.isMatch(),
                                                           sum*coordFactor,
                                                           ""product of:"");
        result.addDetail(sumExpl);
        result.addDetail(new Explanation(coordFactor,
                                         ""coord(""+coord+""/""+maxCoord+"")""));
        return result;
      }
    }
  }

  
  private static boolean allowDocsOutOfOrder = false;

  
  public static void setAllowDocsOutOfOrder(boolean allow) {
    allowDocsOutOfOrder = allow;
  }  
  
  
  public static boolean getAllowDocsOutOfOrder() {
    return allowDocsOutOfOrder;
  }  

  
  public static void setUseScorer14(boolean use14) {
    setAllowDocsOutOfOrder(use14);
  }
  
  
  public static boolean getUseScorer14() {
    return getAllowDocsOutOfOrder();
  }

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new BooleanWeight(searcher);
  }

  public Query rewrite(IndexReader reader) throws IOException {
    if (clauses.size() == 1) {                    
      BooleanClause c = (BooleanClause)clauses.get(0);
      if (!c.isProhibited()) {			  

        Query query = c.getQuery().rewrite(reader);    

        if (getBoost() != 1.0f) {                 
          if (query == c.getQuery())                   
            query = (Query)query.clone();         
          query.setBoost(getBoost() * query.getBoost());
        }

        return query;
      }
    }

    BooleanQuery clone = null;                    
    for (int i = 0 ; i < clauses.size(); i++) {
      BooleanClause c = (BooleanClause)clauses.get(i);
      Query query = c.getQuery().rewrite(reader);
      if (query != c.getQuery()) {                     
        if (clone == null)
          clone = (BooleanQuery)this.clone();
        clone.clauses.set(i, new BooleanClause(query, c.getOccur()));
      }
    }
    if (clone != null) {
      return clone;                               
    } else
      return this;                                
  }

  
  public void extractTerms(Set terms) {
      for (Iterator i = clauses.iterator(); i.hasNext();) {
          BooleanClause clause = (BooleanClause) i.next();
          clause.getQuery().extractTerms(terms);
        }
  }

  public Object clone() {
    BooleanQuery clone = (BooleanQuery)super.clone();
    clone.clauses = (ArrayList)this.clauses.clone();
    return clone;
  }

  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    boolean needParens=(getBoost() != 1.0) || (getMinimumNumberShouldMatch()>0) ;
    if (needParens) {
      buffer.append(""("");
    }

    for (int i = 0 ; i < clauses.size(); i++) {
      BooleanClause c = (BooleanClause)clauses.get(i);
      if (c.isProhibited())
        buffer.append(""-"");
      else if (c.isRequired())
        buffer.append(""+"");

      Query subQuery = c.getQuery();
      if (subQuery instanceof BooleanQuery) {	  
        buffer.append(""("");
        buffer.append(c.getQuery().toString(field));
        buffer.append("")"");
      } else
        buffer.append(c.getQuery().toString(field));

      if (i != clauses.size()-1)
        buffer.append("" "");
    }

    if (needParens) {
      buffer.append("")"");
    }

    if (getMinimumNumberShouldMatch()>0) {
      buffer.append('~');
      buffer.append(getMinimumNumberShouldMatch());
    }

    if (getBoost() != 1.0f)
    {
      buffer.append(ToStringUtils.boost(getBoost()));
    }

    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof BooleanQuery))
      return false;
    BooleanQuery other = (BooleanQuery)o;
    return (this.getBoost() == other.getBoost())
        && this.clauses.equals(other.clauses)
        && this.getMinimumNumberShouldMatch() == other.getMinimumNumberShouldMatch();
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ clauses.hashCode()
           + getMinimumNumberShouldMatch();
  }

}
"
lucene,2.2,org.apache.lucene.index.TermInfo,5,1,0,8,6,0,8,0,0,0.125,100,0.0,0,0.0,0.55,0,0,18.2,1,0.4,0,"package org.apache.lucene.index;





final class TermInfo {
  
  int docFreq = 0;

  long freqPointer = 0;
  long proxPointer = 0;
  int skipOffset;

  TermInfo() {}

  TermInfo(int df, long fp, long pp) {
    docFreq = df;
    freqPointer = fp;
    proxPointer = pp;
  }

  TermInfo(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }

  final void set(int docFreq,
                 long freqPointer, long proxPointer, int skipOffset) {
    this.docFreq = docFreq;
    this.freqPointer = freqPointer;
    this.proxPointer = proxPointer;
    this.skipOffset = skipOffset;
  }

  final void set(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }
}
"
lucene,2.2,org.apache.lucene.index.Term,12,1,0,71,21,0,71,0,9,0.136363636,138,0.0,0,0.0,0.291666667,1,1,10.33333333,6,1.3333,1,"package org.apache.lucene.index;





public final class Term implements Comparable, java.io.Serializable {
  String field;
  String text;

  
  public Term(String fld, String txt) {
    this(fld, txt, true);
  }
  Term(String fld, String txt, boolean intern) {
    field = intern ? fld.intern() : fld;	  
    text = txt;					  
  }

  
  public final String field() { return field; }

  
  public final String text() { return text; }
  
  
  public Term createTerm(String text)
  {
      return new Term(field,text,false);
  }

  
  public final boolean equals(Object o) {
    if (o == this)
      return true;
    if (o == null)
      return false;
    if (!(o instanceof Term))
      return false;
    Term other = (Term)o;
    return field == other.field && text.equals(other.text);
  }

  
  public final int hashCode() {
    return field.hashCode() + text.hashCode();
  }

  public int compareTo(Object other) {
    return compareTo((Term)other);
  }

  
  public final int compareTo(Term other) {
    if (field == other.field)			  
      return text.compareTo(other.text);
    else
      return field.compareTo(other.field);
  }

  
  final void set(String fld, String txt) {
    field = fld;
    text = txt;
  }

  public final String toString() { return field + "":"" + text; }

  private void readObject(java.io.ObjectInputStream in)
    throws java.io.IOException, ClassNotFoundException
  {
      in.defaultReadObject();
      field = field.intern();
  }
}
"
lucene,2.2,org.apache.lucene.search.TermQuery,8,2,0,15,22,0,10,6,6,0.142857143,100,1.0,1,0.631578947,0.232142857,2,2,11.375,4,1.375,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Set;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermDocs;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class TermQuery extends Query {
  private Term term;

  private class TermWeight implements Weight {
    private Similarity similarity;
    private float value;
    private float idf;
    private float queryNorm;
    private float queryWeight;

    public TermWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);
      idf = similarity.idf(term, searcher); 
    }

    public String toString() { return ""weight("" + TermQuery.this + "")""; }

    public Query getQuery() { return TermQuery.this; }
    public float getValue() { return value; }

    public float sumOfSquaredWeights() {
      queryWeight = idf * getBoost();             
      return queryWeight * queryWeight;           
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= queryNorm;                   
      value = queryWeight * idf;                  
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      TermDocs termDocs = reader.termDocs(term);

      if (termDocs == null)
        return null;

      return new TermScorer(this, termDocs, similarity,
                            reader.norms(term.field()));
    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {

      ComplexExplanation result = new ComplexExplanation();
      result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");

      Explanation idfExpl =
        new Explanation(idf, ""idf(docFreq="" + reader.docFreq(term) + "")"");

      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

      Explanation boostExpl = new Explanation(getBoost(), ""boost"");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);
      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      
      String field = term.field();
      ComplexExplanation fieldExpl = new ComplexExplanation();
      fieldExpl.setDescription(""fieldWeight(""+term+"" in ""+doc+
                               ""), product of:"");

      Explanation tfExpl = scorer(reader).explain(doc);
      fieldExpl.addDetail(tfExpl);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
      fieldExpl.addDetail(fieldNormExpl);
      
      fieldExpl.setMatch(Boolean.valueOf(tfExpl.isMatch()));
      fieldExpl.setValue(tfExpl.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);
      result.setMatch(fieldExpl.getMatch());
      
      
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }
  }

  
  public TermQuery(Term t) {
    term = t;
  }

  
  public Term getTerm() { return term; }

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new TermWeight(searcher);
  }

  public void extractTerms(Set terms) {
    terms.add(getTerm());
  }

  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    if (!term.field().equals(field)) {
      buffer.append(term.field());
      buffer.append("":"");
    }
    buffer.append(term.text());
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof TermQuery))
      return false;
    TermQuery other = (TermQuery)o;
    return (this.getBoost() == other.getBoost())
      && this.term.equals(other.term);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ term.hashCode();
  }

}
"
lucene,2.2,org.apache.lucene.analysis.CharTokenizer,4,3,2,4,8,4,2,2,2,0.857142857,122,1.0,0,0.571428571,0.583333333,0,0,27.75,1,0.75,2,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.io.Reader;


public abstract class CharTokenizer extends Tokenizer {
  public CharTokenizer(Reader input) {
    super(input);
  }

  private int offset = 0, bufferIndex = 0, dataLen = 0;
  private static final int MAX_WORD_LEN = 255;
  private static final int IO_BUFFER_SIZE = 1024;
  private final char[] buffer = new char[MAX_WORD_LEN];
  private final char[] ioBuffer = new char[IO_BUFFER_SIZE];

  
  protected abstract boolean isTokenChar(char c);

  
  protected char normalize(char c) {
    return c;
  }

  
  public final Token next() throws IOException {
    int length = 0;
    int start = offset;
    while (true) {
      final char c;

      offset++;
      if (bufferIndex >= dataLen) {
        dataLen = input.read(ioBuffer);
        bufferIndex = 0;
      }
      ;
      if (dataLen == -1) {
        if (length > 0)
          break;
        else
          return null;
      } else
        c = ioBuffer[bufferIndex++];

      if (isTokenChar(c)) {               

        if (length == 0)			           
          start = offset - 1;

        buffer[length++] = normalize(c); 

        if (length == MAX_WORD_LEN)		   
          break;

      } else if (length > 0)             
        break;                           

    }

    return new Token(new String(buffer, 0, length), start, start + length);
  }
}
"
lucene,2.2,org.apache.lucene.index.CorruptIndexException,1,4,0,28,2,0,28,0,1,2.0,5,0.0,0,1.0,1.0,0,0,4.0,0,0.0,0,"

package org.apache.lucene.index;

import java.io.IOException;


public class CorruptIndexException extends IOException {
  public CorruptIndexException(String message) {
    super(message);
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.MultiFieldQueryParser,11,2,0,9,31,23,0,9,5,0.55,410,1.0,0,0.869565217,0.313131313,1,5,36.09090909,1,0.8182,2,"package org.apache.lucene.queryParser;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.MultiPhraseQuery;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;

import java.util.Vector;
import java.util.Map;


public class MultiFieldQueryParser extends QueryParser
{
  protected String[] fields;
  protected Map      boosts;

  
  public MultiFieldQueryParser(String[] fields, Analyzer analyzer, Map boosts) {
    this(fields,analyzer);
    this.boosts = boosts;
  }
  
  
  public MultiFieldQueryParser(String[] fields, Analyzer analyzer) {
    super(null, analyzer);
    this.fields = fields;
  }
  
  protected Query getFieldQuery(String field, String queryText, int slop) throws ParseException {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        Query q = getFieldQuery(fields[i], queryText);
        if (q != null) {
          
          if (boosts != null) {
            
            Float boost = (Float)boosts.get(fields[i]);
            if (boost != null) {
              q.setBoost(boost.floatValue());
            }
          }
          if (q instanceof PhraseQuery) {
            ((PhraseQuery) q).setSlop(slop);
          }
          if (q instanceof MultiPhraseQuery) {
            ((MultiPhraseQuery) q).setSlop(slop);
          }
          clauses.add(new BooleanClause(q, BooleanClause.Occur.SHOULD));
        }
      }
      if (clauses.size() == 0)  
        return null;
      return getBooleanQuery(clauses, true);
    }
    return super.getFieldQuery(field, queryText);
  }
  

  protected Query getFieldQuery(String field, String queryText) throws ParseException {
    return getFieldQuery(field, queryText, 0);
  }


  protected Query getFuzzyQuery(String field, String termStr, float minSimilarity) throws ParseException
  {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(getFuzzyQuery(fields[i], termStr, minSimilarity),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getFuzzyQuery(field, termStr, minSimilarity);
  }

  protected Query getPrefixQuery(String field, String termStr) throws ParseException
  {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(getPrefixQuery(fields[i], termStr),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getPrefixQuery(field, termStr);
  }

  protected Query getWildcardQuery(String field, String termStr) throws ParseException {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(getWildcardQuery(fields[i], termStr),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getWildcardQuery(field, termStr);
  }

 
  protected Query getRangeQuery(String field, String part1, String part2, boolean inclusive) throws ParseException {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(getRangeQuery(fields[i], part1, part2, inclusive),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getRangeQuery(field, part1, part2, inclusive);
  }

  
  public static Query parse(String[] queries, String[] fields,
      Analyzer analyzer) throws ParseException
  {
    if (queries.length != fields.length)
      throw new IllegalArgumentException(""queries.length != fields.length"");
    BooleanQuery bQuery = new BooleanQuery();
    for (int i = 0; i < fields.length; i++)
    {
      QueryParser qp = new QueryParser(fields[i], analyzer);
      Query q = qp.parse(queries[i]);
      bQuery.add(q, BooleanClause.Occur.SHOULD);
    }
    return bQuery;
  }

  
  public static Query parse(String query, String[] fields,
      BooleanClause.Occur[] flags, Analyzer analyzer) throws ParseException {
    if (fields.length != flags.length)
      throw new IllegalArgumentException(""fields.length != flags.length"");
    BooleanQuery bQuery = new BooleanQuery();
    for (int i = 0; i < fields.length; i++) {
      QueryParser qp = new QueryParser(fields[i], analyzer);
      Query q = qp.parse(query);
      bQuery.add(q, flags[i]);
    }
    return bQuery;
  }

  
  public static Query parse(String[] queries, String[] fields, BooleanClause.Occur[] flags,
      Analyzer analyzer) throws ParseException
  {
    if (!(queries.length == fields.length && queries.length == flags.length))
      throw new IllegalArgumentException(""queries, fields, and flags array have have different length"");
    BooleanQuery bQuery = new BooleanQuery();
    for (int i = 0; i < fields.length; i++)
    {
      QueryParser qp = new QueryParser(fields[i], analyzer);
      Query q = qp.parse(queries[i]);
      bQuery.add(q, flags[i]);
    }
    return bQuery;
  }

}
"
lucene,2.2,org.apache.lucene.index.SegmentMergeQueue,3,2,0,5,9,3,2,3,0,2.0,47,0.0,0,0.846153846,0.555555556,1,3,14.66666667,4,1.6667,0,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.util.PriorityQueue;

final class SegmentMergeQueue extends PriorityQueue {
  SegmentMergeQueue(int size) {
    initialize(size);
  }

  protected final boolean lessThan(Object a, Object b) {
    SegmentMergeInfo stiA = (SegmentMergeInfo)a;
    SegmentMergeInfo stiB = (SegmentMergeInfo)b;
    int comparison = stiA.term.compareTo(stiB.term);
    if (comparison == 0)
      return stiA.base < stiB.base; 
    else
      return comparison < 0;
  }

  final void close() throws IOException {
    while (top() != null)
      ((SegmentMergeInfo)pop()).close();
  }

}
"
lucene,2.2,org.apache.lucene.store.Directory,18,1,3,36,33,141,32,4,18,0.823529412,177,1.0,1,0.0,0.296296296,0,0,8.777777778,1,0.9444,4,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class Directory {

  
  protected LockFactory lockFactory;

  
  public abstract String[] list()
       throws IOException;

  
  public abstract boolean fileExists(String name)
       throws IOException;

  
  public abstract long fileModified(String name)
       throws IOException;

  
  public abstract void touchFile(String name)
       throws IOException;

  
  public abstract void deleteFile(String name)
       throws IOException;

  
  public abstract void renameFile(String from, String to)
       throws IOException;

  
  public abstract long fileLength(String name)
       throws IOException;


  
  public abstract IndexOutput createOutput(String name) throws IOException;


  
  public abstract IndexInput openInput(String name)
    throws IOException;

  
  public IndexInput openInput(String name, int bufferSize) throws IOException {
    return openInput(name);
  }

  
  public Lock makeLock(String name) {
      return lockFactory.makeLock(name);
  }
  
  public void clearLock(String name) throws IOException {
    if (lockFactory != null) {
      lockFactory.clearLock(name);
    }
  }

  
  public abstract void close()
       throws IOException;

  
  public void setLockFactory(LockFactory lockFactory) {
      this.lockFactory = lockFactory;
      lockFactory.setLockPrefix(this.getLockID());
  }

  
  public LockFactory getLockFactory() {
      return this.lockFactory;
  }

  
  public String getLockID() {
      return this.toString();
  }

  
  public static void copy(Directory src, Directory dest, boolean closeDirSrc) throws IOException {
      final String[] files = src.list();

      if (files == null)
        throw new IOException(""cannot read directory "" + src + "": list() returned null"");

      byte[] buf = new byte[BufferedIndexOutput.BUFFER_SIZE];
      for (int i = 0; i < files.length; i++) {
        IndexOutput os = null;
        IndexInput is = null;
        try {
          
          os = dest.createOutput(files[i]);
          
          is = src.openInput(files[i]);
          
          long len = is.length();
          long readCount = 0;
          while (readCount < len) {
            int toRead = readCount + BufferedIndexOutput.BUFFER_SIZE > len ? (int)(len - readCount) : BufferedIndexOutput.BUFFER_SIZE;
            is.readBytes(buf, 0, toRead);
            os.writeBytes(buf, toRead);
            readCount += toRead;
          }
        } finally {
          
          try {
            if (os != null)
              os.close();
          } finally {
            if (is != null)
              is.close();
          }
        }
      }
      if(closeDirSrc)
        src.close();
  }
}
"
lucene,2.2,org.apache.lucene.analysis.PorterStemmer,27,1,0,1,43,13,1,0,13,0.600961538,1174,1.0,0,0.0,0.25308642,0,0,42.18518519,26,5.7407,1,"package org.apache.lucene.analysis;






import java.io.*;



class PorterStemmer
{
  private char[] b;
  private int i,    
    j, k, k0;
  private boolean dirty = false;
  private static final int INC = 50; 
  private static final int EXTRA = 1;

  public PorterStemmer() {
    b = new char[INC];
    i = 0;
  }

  
  public void reset() { i = 0; dirty = false; }

  
  public void add(char ch) {
    if (b.length <= i + EXTRA) {
      char[] new_b = new char[b.length+INC];
      for (int c = 0; c < b.length; c++)
        new_b[c] = b[c];
      b = new_b;
    }
    b[i++] = ch;
  }

  
  public String toString() { return new String(b,0,i); }

  
  public int getResultLength() { return i; }

  
  public char[] getResultBuffer() { return b; }

  

  private final boolean cons(int i) {
    switch (b[i]) {
    case 'a': case 'e': case 'i': case 'o': case 'u':
      return false;
    case 'y':
      return (i==k0) ? true : !cons(i-1);
    default:
      return true;
    }
  }

  

  private final int m() {
    int n = 0;
    int i = k0;
    while(true) {
      if (i > j)
        return n;
      if (! cons(i))
        break;
      i++;
    }
    i++;
    while(true) {
      while(true) {
        if (i > j)
          return n;
        if (cons(i))
          break;
        i++;
      }
      i++;
      n++;
      while(true) {
        if (i > j)
          return n;
        if (! cons(i))
          break;
        i++;
      }
      i++;
    }
  }

  

  private final boolean vowelinstem() {
    int i;
    for (i = k0; i <= j; i++)
      if (! cons(i))
        return true;
    return false;
  }

  

  private final boolean doublec(int j) {
    if (j < k0+1)
      return false;
    if (b[j] != b[j-1])
      return false;
    return cons(j);
  }

  

  private final boolean cvc(int i) {
    if (i < k0+2 || !cons(i) || cons(i-1) || !cons(i-2))
      return false;
    else {
      int ch = b[i];
      if (ch == 'w' || ch == 'x' || ch == 'y') return false;
    }
    return true;
  }

  private final boolean ends(String s) {
    int l = s.length();
    int o = k-l+1;
    if (o < k0)
      return false;
    for (int i = 0; i < l; i++)
      if (b[o+i] != s.charAt(i))
        return false;
    j = k-l;
    return true;
  }

  

  void setto(String s) {
    int l = s.length();
    int o = j+1;
    for (int i = 0; i < l; i++)
      b[o+i] = s.charAt(i);
    k = j+l;
    dirty = true;
  }

  

  void r(String s) { if (m() > 0) setto(s); }

  

  private final void step1() {
    if (b[k] == 's') {
      if (ends(""sses"")) k -= 2;
      else if (ends(""ies"")) setto(""i"");
      else if (b[k-1] != 's') k--;
    }
    if (ends(""eed"")) {
      if (m() > 0)
        k--;
    }
    else if ((ends(""ed"") || ends(""ing"")) && vowelinstem()) {
      k = j;
      if (ends(""at"")) setto(""ate"");
      else if (ends(""bl"")) setto(""ble"");
      else if (ends(""iz"")) setto(""ize"");
      else if (doublec(k)) {
        int ch = b[k--];
        if (ch == 'l' || ch == 's' || ch == 'z')
          k++;
      }
      else if (m() == 1 && cvc(k))
        setto(""e"");
    }
  }

  

  private final void step2() {
    if (ends(""y"") && vowelinstem()) {
      b[k] = 'i';
      dirty = true;
    }
  }

  

  private final void step3() {
    if (k == k0) return; 
    switch (b[k-1]) {
    case 'a':
      if (ends(""ational"")) { r(""ate""); break; }
      if (ends(""tional"")) { r(""tion""); break; }
      break;
    case 'c':
      if (ends(""enci"")) { r(""ence""); break; }
      if (ends(""anci"")) { r(""ance""); break; }
      break;
    case 'e':
      if (ends(""izer"")) { r(""ize""); break; }
      break;
    case 'l':
      if (ends(""bli"")) { r(""ble""); break; }
      if (ends(""alli"")) { r(""al""); break; }
      if (ends(""entli"")) { r(""ent""); break; }
      if (ends(""eli"")) { r(""e""); break; }
      if (ends(""ousli"")) { r(""ous""); break; }
      break;
    case 'o':
      if (ends(""ization"")) { r(""ize""); break; }
      if (ends(""ation"")) { r(""ate""); break; }
      if (ends(""ator"")) { r(""ate""); break; }
      break;
    case 's':
      if (ends(""alism"")) { r(""al""); break; }
      if (ends(""iveness"")) { r(""ive""); break; }
      if (ends(""fulness"")) { r(""ful""); break; }
      if (ends(""ousness"")) { r(""ous""); break; }
      break;
    case 't':
      if (ends(""aliti"")) { r(""al""); break; }
      if (ends(""iviti"")) { r(""ive""); break; }
      if (ends(""biliti"")) { r(""ble""); break; }
      break;
    case 'g':
      if (ends(""logi"")) { r(""log""); break; }
    }
  }

  

  private final void step4() {
    switch (b[k]) {
    case 'e':
      if (ends(""icate"")) { r(""ic""); break; }
      if (ends(""ative"")) { r(""""); break; }
      if (ends(""alize"")) { r(""al""); break; }
      break;
    case 'i':
      if (ends(""iciti"")) { r(""ic""); break; }
      break;
    case 'l':
      if (ends(""ical"")) { r(""ic""); break; }
      if (ends(""ful"")) { r(""""); break; }
      break;
    case 's':
      if (ends(""ness"")) { r(""""); break; }
      break;
    }
  }

  

  private final void step5() {
    if (k == k0) return; 
    switch (b[k-1]) {
    case 'a':
      if (ends(""al"")) break;
      return;
    case 'c':
      if (ends(""ance"")) break;
      if (ends(""ence"")) break;
      return;
    case 'e':
      if (ends(""er"")) break; return;
    case 'i':
      if (ends(""ic"")) break; return;
    case 'l':
      if (ends(""able"")) break;
      if (ends(""ible"")) break; return;
    case 'n':
      if (ends(""ant"")) break;
      if (ends(""ement"")) break;
      if (ends(""ment"")) break;
      
      if (ends(""ent"")) break;
      return;
    case 'o':
      if (ends(""ion"") && j >= 0 && (b[j] == 's' || b[j] == 't')) break;
      
      if (ends(""ou"")) break;
      return;
      
    case 's':
      if (ends(""ism"")) break;
      return;
    case 't':
      if (ends(""ate"")) break;
      if (ends(""iti"")) break;
      return;
    case 'u':
      if (ends(""ous"")) break;
      return;
    case 'v':
      if (ends(""ive"")) break;
      return;
    case 'z':
      if (ends(""ize"")) break;
      return;
    default:
      return;
    }
    if (m() > 1)
      k = j;
  }

  

  private final void step6() {
    j = k;
    if (b[k] == 'e') {
      int a = m();
      if (a > 1 || a == 1 && !cvc(k-1))
        k--;
    }
    if (b[k] == 'l' && doublec(k) && m() > 1)
      k--;
  }


  
  public String stem(String s) {
    if (stem(s.toCharArray(), s.length()))
      return toString();
    else
      return s;
  }

  
  public boolean stem(char[] word) {
    return stem(word, word.length);
  }

  
  public boolean stem(char[] wordBuffer, int offset, int wordLen) {
    reset();
    if (b.length < wordLen) {
      char[] new_b = new char[wordLen + EXTRA];
      b = new_b;
    }
    for (int j=0; j<wordLen; j++)
      b[j] = wordBuffer[offset+j];
    i = wordLen;
    return stem(0);
  }

  
  public boolean stem(char[] word, int wordLen) {
    return stem(word, 0, wordLen);
  }

  
  public boolean stem() {
    return stem(0);
  }

  public boolean stem(int i0) {
    k = i - 1;
    k0 = i0;
    if (k > k0+1) {
      step1(); step2(); step3(); step4(); step5(); step6();
    }
    
    
    if (i != k+1)
      dirty = true;
    i = k+1;
    return dirty;
  }

  
  public static void main(String[] args) {
    PorterStemmer s = new PorterStemmer();

    for (int i = 0; i < args.length; i++) {
      try {
        InputStream in = new FileInputStream(args[i]);
        byte[] buffer = new byte[1024];
        int bufferLen, offset, ch;

        bufferLen = in.read(buffer);
        offset = 0;
        s.reset();

        while(true) {
          if (offset < bufferLen)
            ch = buffer[offset++];
          else {
            bufferLen = in.read(buffer);
            offset = 0;
            if (bufferLen < 0)
              ch = -1;
            else
              ch = buffer[offset++];
          }

          if (Character.isLetter((char) ch)) {
            s.add(Character.toLowerCase((char) ch));
          }
          else {
             s.stem();
             System.out.print(s.toString());
             s.reset();
             if (ch < 0)
               break;
             else {
               System.out.print((char) ch);
             }
           }
        }

        in.close();
      }
      catch (IOException e) {
        System.out.println(""error reading "" + args[i]);
      }
    }
  }
}

"
lucene,2.2,org.apache.lucene.search.Searcher,23,1,3,40,28,247,29,14,22,0.909090909,131,1.0,1,0.0,0.273913043,0,0,4.652173913,1,0.9565,4,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.CorruptIndexException;
import org.apache.lucene.index.Term;
import org.apache.lucene.document.Document;


public abstract class Searcher implements Searchable {

  
  public final Hits search(Query query) throws IOException {
    return search(query, (Filter)null);
  }

  
  public Hits search(Query query, Filter filter) throws IOException {
    return new Hits(this, query, filter);
  }

  
  public Hits search(Query query, Sort sort)
    throws IOException {
    return new Hits(this, query, null, sort);
  }

  
  public Hits search(Query query, Filter filter, Sort sort)
    throws IOException {
    return new Hits(this, query, filter, sort);
  }

  
  public TopFieldDocs search(Query query, Filter filter, int n,
                             Sort sort) throws IOException {
    return search(createWeight(query), filter, n, sort);
  }

  
  public void search(Query query, HitCollector results)
    throws IOException {
    search(query, (Filter)null, results);
  }

  
  public void search(Query query, Filter filter, HitCollector results)
    throws IOException {
    search(createWeight(query), filter, results);
  }

  
  public TopDocs search(Query query, Filter filter, int n)
    throws IOException {
    return search(createWeight(query), filter, n);
  }

  
  public Explanation explain(Query query, int doc) throws IOException {
    return explain(createWeight(query), doc);
  }

  
  private Similarity similarity = Similarity.getDefault();

  
  public void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
  }

  
  public Similarity getSimilarity() {
    return this.similarity;
  }

  
  protected Weight createWeight(Query query) throws IOException {
      return query.weight(this);
  }

  
  public int[] docFreqs(Term[] terms) throws IOException {
    int[] result = new int[terms.length];
    for (int i = 0; i < terms.length; i++) {
      result[i] = docFreq(terms[i]);
    }
    return result;
  }

  
  abstract public void search(Weight weight, Filter filter, HitCollector results) throws IOException;
  abstract public void close() throws IOException;
  abstract public int docFreq(Term term) throws IOException;
  abstract public int maxDoc() throws IOException;
  abstract public TopDocs search(Weight weight, Filter filter, int n) throws IOException;
  abstract public Document doc(int i) throws CorruptIndexException, IOException;
  abstract public Query rewrite(Query query) throws IOException;
  abstract public Explanation explain(Weight weight, int doc) throws IOException;
  abstract public TopFieldDocs search(Weight weight, Filter filter, int n, Sort sort) throws IOException;
  
}
"
lucene,2.2,org.apache.lucene.search.payloads.BoostingTermQuery,3,4,0,5,7,3,1,5,2,2.0,38,0.0,0,0.923076923,0.5,1,1,11.66666667,4,1.6667,4,"package org.apache.lucene.search.payloads;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;
import org.apache.lucene.search.*;
import org.apache.lucene.search.spans.SpanScorer;
import org.apache.lucene.search.spans.SpanTermQuery;
import org.apache.lucene.search.spans.SpanWeight;
import org.apache.lucene.search.spans.TermSpans;

import java.io.IOException;




public class BoostingTermQuery extends SpanTermQuery{


  public BoostingTermQuery(Term term) {
    super(term);
  }


  protected Weight createWeight(Searcher searcher) throws IOException {
    return new BoostingTermWeight(this, searcher);
  }

  protected class BoostingTermWeight extends SpanWeight implements Weight {


    public BoostingTermWeight(BoostingTermQuery query, Searcher searcher) throws IOException {
      super(query, searcher);
    }




    public Scorer scorer(IndexReader reader) throws IOException {
      return new BoostingSpanScorer((TermSpans)query.getSpans(reader), this, similarity,
              reader.norms(query.getField()));
    }

    class BoostingSpanScorer extends SpanScorer {

      
      byte[] payload = new byte[256];
      private TermPositions positions;
      protected float payloadScore;
      private int payloadsSeen;

      public BoostingSpanScorer(TermSpans spans, Weight weight,
                                Similarity similarity, byte[] norms) throws IOException {
        super(spans, weight, similarity, norms);
        positions = spans.getPositions();

      }

      
      

      protected boolean setFreqCurrentDoc() throws IOException {
        if (!more) {
          return false;
        }
        doc = spans.doc();
        freq = 0.0f;
        payloadScore = 0;
        payloadsSeen = 0;
        Similarity similarity1 = getSimilarity();
        while (more && doc == spans.doc()) {
          int matchLength = spans.end() - spans.start();

          freq += similarity1.sloppyFreq(matchLength);
          processPayload(similarity1);

          more = spans.next();
        }
        return more || (freq != 0);
      }


      protected void processPayload(Similarity similarity) throws IOException {
        if (positions.isPayloadAvailable()) {
          payload = positions.getPayload(payload, 0);
          payloadScore += similarity.scorePayload(payload, 0, positions.getPayloadLength());
          payloadsSeen++;

        } else {
          
        }

      }

      public float score() throws IOException {

        return super.score() * (payloadsSeen > 0 ? (payloadScore / payloadsSeen) : 1);
      }


      public Explanation explain(final int doc) throws IOException {
        Explanation result = new Explanation();
        Explanation nonPayloadExpl = super.explain(doc);
        result.addDetail(nonPayloadExpl);
        
        
        Explanation payloadBoost = new Explanation();
        result.addDetail(payloadBoost);


        float avgPayloadScore = payloadScore / payloadsSeen;
        payloadBoost.setValue(avgPayloadScore);
        
        payloadBoost.setDescription(""scorePayload(...)"");
        result.setValue(nonPayloadExpl.getValue() * avgPayloadScore);
        result.setDescription(""btq, product of:"");
        return result;
      }
    }

  }


  public boolean equals(Object o) {
    if (!(o instanceof BoostingTermQuery))
      return false;
    BoostingTermQuery other = (BoostingTermQuery) o;
    return (this.getBoost() == other.getBoost())
            && this.term.equals(other.term);
  }
}
"
lucene,2.2,org.apache.lucene.analysis.Analyzer,3,1,6,13,4,3,12,1,3,2.0,8,0.0,0,0.0,0.666666667,0,0,1.666666667,1,0.6667,1,"package org.apache.lucene.analysis;



import java.io.Reader;


public abstract class Analyzer {
  
  public abstract TokenStream tokenStream(String fieldName, Reader reader);


  
  public int getPositionIncrementGap(String fieldName)
  {
    return 0;
  }
}

"
lucene,2.2,org.apache.lucene.store.SimpleFSLockFactory,6,2,0,4,17,3,1,3,4,0.2,102,1.0,0,0.571428571,0.611111111,0,0,15.83333333,2,0.6667,3,"package org.apache.lucene.store;



import java.io.File;
import java.io.IOException;



public class SimpleFSLockFactory extends LockFactory {

  

  private File lockDir;

  
  SimpleFSLockFactory() throws IOException {
    this((File) null);
  }

  
  public SimpleFSLockFactory(File lockDir) throws IOException {
    setLockDir(lockDir);
  }

  
  public SimpleFSLockFactory(String lockDirName) throws IOException {
    lockDir = new File(lockDirName);
    setLockDir(lockDir);
  }

  
  void setLockDir(File lockDir) throws IOException {
    this.lockDir = lockDir;
  }

  public Lock makeLock(String lockName) {
    if (lockPrefix != null) {
      lockName = lockPrefix + ""-"" + lockName;
    }
    return new SimpleFSLock(lockDir, lockName);
  }

  public void clearLock(String lockName) throws IOException {
    if (lockDir.exists()) {
      if (lockPrefix != null) {
        lockName = lockPrefix + ""-"" + lockName;
      }
      File lockFile = new File(lockDir, lockName);
      if (lockFile.exists() && !lockFile.delete()) {
        throw new IOException(""Cannot delete "" + lockFile);
      }
    }
  }
};

class SimpleFSLock extends Lock {

  File lockFile;
  File lockDir;

  public SimpleFSLock(File lockDir, String lockFileName) {
    this.lockDir = lockDir;
    lockFile = new File(lockDir, lockFileName);
  }

  public boolean obtain() throws IOException {

    
    if (!lockDir.exists()) {
      if (!lockDir.mkdirs())
        throw new IOException(""Cannot create directory: "" +
                              lockDir.getAbsolutePath());
    } else if (!lockDir.isDirectory()) {
      throw new IOException(""Found regular file where directory expected: "" + 
                            lockDir.getAbsolutePath());
    }
    return lockFile.createNewFile();
  }

  public void release() {
    lockFile.delete();
  }

  public boolean isLocked() {
    return lockFile.exists();
  }

  public String toString() {
    return ""SimpleFSLock@"" + lockFile;
  }
}
"
lucene,2.2,org.apache.lucene.search.DisjunctionSumScorer,12,2,1,7,37,0,2,5,9,0.454545455,357,1.0,1,0.444444444,0.416666667,1,3,28.08333333,1,0.8333,0,"package org.apache.lucene.search;



import java.util.List;
import java.util.Iterator;
import java.io.IOException;

import org.apache.lucene.util.ScorerDocQueue;


class DisjunctionSumScorer extends Scorer {
   
  private final int nrScorers;
  
  
  protected final List subScorers;
  
  
  private final int minimumNrMatchers;
  
  
  private ScorerDocQueue scorerDocQueue = null;
  private int queueSize = -1; 
  
  
  private int currentDoc = -1;

  
  protected int nrMatchers = -1;

  private float currentScore = Float.NaN;
  
  
  public DisjunctionSumScorer( List subScorers, int minimumNrMatchers) {
    super(null);
    
    nrScorers = subScorers.size();

    if (minimumNrMatchers <= 0) {
      throw new IllegalArgumentException(""Minimum nr of matchers must be positive"");
    }
    if (nrScorers <= 1) {
      throw new IllegalArgumentException(""There must be at least 2 subScorers"");
    }

    this.minimumNrMatchers = minimumNrMatchers;
    this.subScorers = subScorers;
  }
  
  
  public DisjunctionSumScorer(List subScorers) {
    this(subScorers, 1);
  }

  
  private void initScorerDocQueue() throws IOException {
    Iterator si = subScorers.iterator();
    scorerDocQueue = new ScorerDocQueue(nrScorers);
    queueSize = 0;
    while (si.hasNext()) {
      Scorer se = (Scorer) si.next();
      if (se.next()) { 
        if (scorerDocQueue.insert(se)) {
          queueSize++;
        }
      }
    }
  }

  
  public void score(HitCollector hc) throws IOException {
    while (next()) {
      hc.collect(currentDoc, currentScore);
    }
  }

  
  protected boolean score(HitCollector hc, int max) throws IOException {
    while (currentDoc < max) {
      hc.collect(currentDoc, currentScore);
      if (!next()) {
        return false;
      }
    }
    return true;
  }

  public boolean next() throws IOException {
    if (scorerDocQueue == null) {
      initScorerDocQueue();
    }
    return (scorerDocQueue.size() >= minimumNrMatchers)
          && advanceAfterCurrent();
  }


  
  protected boolean advanceAfterCurrent() throws IOException {
    do { 
      currentDoc = scorerDocQueue.topDoc();
      currentScore = scorerDocQueue.topScore();
      nrMatchers = 1;
      do { 
        if (! scorerDocQueue.topNextAndAdjustElsePop()) {
          if (--queueSize == 0) {
            break; 
          }
        }
        if (scorerDocQueue.topDoc() != currentDoc) {
          break; 
        }
        currentScore += scorerDocQueue.topScore();
        nrMatchers++;
      } while (true);
      
      if (nrMatchers >= minimumNrMatchers) {
        return true;
      } else if (queueSize < minimumNrMatchers) {
        return false;
      }
    } while (true);
  }
  
  
  public float score() throws IOException { return currentScore; }
   
  public int doc() { return currentDoc; }

  
  public int nrMatchers() {
    return nrMatchers;
  }

  
  public boolean skipTo(int target) throws IOException {
    if (scorerDocQueue == null) {
      initScorerDocQueue();
    }
    if (queueSize < minimumNrMatchers) {
      return false;
    }
    if (target <= currentDoc) {
      return true;
    }
    do {
      if (scorerDocQueue.topDoc() >= target) {
        return advanceAfterCurrent();
      } else if (! scorerDocQueue.topSkipToAndAdjustElsePop(target)) {
        if (--queueSize < minimumNrMatchers) {
          return false;
        }
      }
    } while (true);
  }

  
  public Explanation explain(int doc) throws IOException {
    Explanation res = new Explanation();
    Iterator ssi = subScorers.iterator();
    float sumScore = 0.0f;
    int nrMatches = 0;
    while (ssi.hasNext()) {
      Explanation es = ((Scorer) ssi.next()).explain(doc);
      if (es.getValue() > 0.0f) { 
        sumScore += es.getValue();
        nrMatches++;
      }
      res.addDetail(es);
    }
    if (nrMatchers >= minimumNrMatchers) {
      res.setValue(sumScore);
      res.setDescription(""sum over at least "" + minimumNrMatchers
                         + "" of "" + subScorers.size() + "":"");
    } else {
      res.setValue(0.0f);
      res.setDescription(nrMatches + "" match(es) but at least ""
                         + minimumNrMatchers + "" of ""
                         + subScorers.size() + "" needed"");
    }
    return res;
  }
}
"
lucene,2.2,org.apache.lucene.index.TermBuffer,11,1,0,4,25,0,1,3,6,0.52,241,1.0,1,0.0,0.242857143,0,0,20.45454545,3,1.4545,0,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.store.IndexInput;

final class TermBuffer implements Cloneable {
  private static final char[] NO_CHARS = new char[0];

  private String field;
  private char[] text = NO_CHARS;
  private int textLength;
  private Term term;                            

  public final int compareTo(TermBuffer other) {
    if (field == other.field)			  
      return compareChars(text, textLength, other.text, other.textLength);
    else
      return field.compareTo(other.field);
  }

  private static final int compareChars(char[] v1, int len1,
                                        char[] v2, int len2) {
    int end = Math.min(len1, len2);
    for (int k = 0; k < end; k++) {
      char c1 = v1[k];
      char c2 = v2[k];
      if (c1 != c2) {
        return c1 - c2;
      }
    }
    return len1 - len2;
  }

  private final void setTextLength(int newLength) {
    if (text.length < newLength) {
      char[] newText = new char[newLength];
      System.arraycopy(text, 0, newText, 0, textLength);
      text = newText;
    }
    textLength = newLength;
  }

  public final void read(IndexInput input, FieldInfos fieldInfos)
    throws IOException {
    this.term = null;                           
    int start = input.readVInt();
    int length = input.readVInt();
    int totalLength = start + length;
    setTextLength(totalLength);
    input.readChars(this.text, start, length);
    this.field = fieldInfos.fieldName(input.readVInt());
  }

  public final void set(Term term) {
    if (term == null) {
      reset();
      return;
    }

    
    setTextLength(term.text().length());
    term.text().getChars(0, term.text().length(), text, 0);

    this.field = term.field();
    this.term = term;
  }

  public final void set(TermBuffer other) {
    setTextLength(other.textLength);
    System.arraycopy(other.text, 0, text, 0, textLength);

    this.field = other.field;
    this.term = other.term;
  }

  public void reset() {
    this.field = null;
    this.textLength = 0;
    this.term = null;
  }

  public Term toTerm() {
    if (field == null)                            
      return null;

    if (term == null)
      term = new Term(field, new String(text, 0, textLength), false);

    return term;
  }

  protected Object clone() {
    TermBuffer clone = null;
    try {
      clone = (TermBuffer)super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.text = new char[text.length];
    System.arraycopy(text, 0, clone.text, 0, textLength);

    return clone;
  }
}
"
lucene,2.2,org.apache.lucene.store.BufferedIndexOutput,10,2,1,2,12,17,1,1,8,0.555555556,185,0.75,0,0.608695652,0.36,1,3,17.1,1,0.9,0,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class BufferedIndexOutput extends IndexOutput {
  static final int BUFFER_SIZE = 16384;

  private final byte[] buffer = new byte[BUFFER_SIZE];
  private long bufferStart = 0;           
  private int bufferPosition = 0;         

  
  public void writeByte(byte b) throws IOException {
    if (bufferPosition >= BUFFER_SIZE)
      flush();
    buffer[bufferPosition++] = b;
  }

  
  public void writeBytes(byte[] b, int offset, int length) throws IOException {
    int bytesLeft = BUFFER_SIZE - bufferPosition;
    
    if (bytesLeft >= length) {
      
      System.arraycopy(b, offset, buffer, bufferPosition, length);
      bufferPosition += length;
      
      if (BUFFER_SIZE - bufferPosition == 0)
        flush();
    } else {
      
      if (length > BUFFER_SIZE) {
        
        if (bufferPosition > 0)
          flush();
        
        flushBuffer(b, offset, length);
        bufferStart += length;
      } else {
        
        int pos = 0; 
        int pieceLength;
        while (pos < length) {
          pieceLength = (length - pos < bytesLeft) ? length - pos : bytesLeft;
          System.arraycopy(b, pos + offset, buffer, bufferPosition, pieceLength);
          pos += pieceLength;
          bufferPosition += pieceLength;
          
          bytesLeft = BUFFER_SIZE - bufferPosition;
          if (bytesLeft == 0) {
            flush();
            bytesLeft = BUFFER_SIZE;
          }
        }
      }
    }
  }

  
  public void flush() throws IOException {
    flushBuffer(buffer, bufferPosition);
    bufferStart += bufferPosition;
    bufferPosition = 0;
  }

  
  private void flushBuffer(byte[] b, int len) throws IOException {
    flushBuffer(b, 0, len);
  }

  
  protected abstract void flushBuffer(byte[] b, int offset, int len) throws IOException;
  
  
  public void close() throws IOException {
    flush();
  }

  
  public long getFilePointer() {
    return bufferStart + bufferPosition;
  }

  
  public void seek(long pos) throws IOException {
    flush();
    bufferStart = pos;
  }

  
  public abstract long length() throws IOException;


}
"
lucene,2.2,org.apache.lucene.index.TermVectorOffsetInfo,9,1,0,7,10,2,7,0,8,0.666666667,83,0.666666667,1,0.0,0.5,1,1,7.888888889,5,1.1111,0,"package org.apache.lucene.index;




public class TermVectorOffsetInfo {
  
  public static final TermVectorOffsetInfo[] EMPTY_OFFSET_INFO = new TermVectorOffsetInfo[0];
  private int startOffset;
  private int endOffset;

  public TermVectorOffsetInfo() {
  }

  public TermVectorOffsetInfo(int startOffset, int endOffset) {
    this.endOffset = endOffset;
    this.startOffset = startOffset;
  }

  
  public int getEndOffset() {
    return endOffset;
  }

  public void setEndOffset(int endOffset) {
    this.endOffset = endOffset;
  }

  
  public int getStartOffset() {
    return startOffset;
  }

  public void setStartOffset(int startOffset) {
    this.startOffset = startOffset;
  }

  
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof TermVectorOffsetInfo)) return false;

    final TermVectorOffsetInfo termVectorOffsetInfo = (TermVectorOffsetInfo) o;

    if (endOffset != termVectorOffsetInfo.endOffset) return false;
    if (startOffset != termVectorOffsetInfo.startOffset) return false;

    return true;
  }

  public int hashCode() {
    int result;
    result = startOffset;
    result = 29 * result + endOffset;
    return result;
  }
}
"
lucene,2.2,org.apache.lucene.search.function.IntFieldSource,7,3,0,7,22,9,2,6,6,0.777777778,122,0.333333333,1,0.705882353,0.333333333,2,3,16.0,6,1.7143,1,"package org.apache.lucene.search.function;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;
import org.apache.lucene.search.function.DocValues;

import java.io.IOException;


public class IntFieldSource extends FieldCacheSource {
  private FieldCache.IntParser parser;

  
  public IntFieldSource(String field) {
    this(field, null);
  }

  
  public IntFieldSource(String field, FieldCache.IntParser parser) {
    super(field);
    this.parser = parser;
  }

  
  public String description() {
    return ""int("" + super.description() + ')';
  }

  
  public DocValues getCachedFieldValues (FieldCache cache, String field, IndexReader reader) throws IOException {
    final int[] arr = (parser==null) ?  
      cache.getInts(reader, field) : 
      cache.getInts(reader, field, parser);
    return new DocValues(reader.maxDoc()) {
      
      public float floatVal(int doc) { 
        return (float) arr[doc]; 
      }
      
      public  int intVal(int doc) { 
        return arr[doc]; 
      }
      
      public String toString(int doc) { 
        return  description() + '=' + intVal(doc);  
      }
      
      Object getInnerArray() {
        return arr;
      }
    };
  }

  
  public boolean cachedFieldSourceEquals(FieldCacheSource o) {
    if (o.getClass() !=  IntFieldSource.class) {
      return false;
    }
    IntFieldSource other = (IntFieldSource)o;
    return this.parser==null ? 
      other.parser==null :
      this.parser.getClass() == other.parser.getClass();
  }

  
  public int cachedFieldSourceHashCode() {
    return parser==null ? 
      Integer.class.hashCode() : parser.getClass().hashCode();
  }

}
"
lucene,2.2,org.apache.lucene.index.MultiLevelSkipListWriter,6,1,1,3,16,0,1,2,0,0.466666667,178,1.0,1,0.0,0.611111111,0,0,28.16666667,3,1.3333,0,"package org.apache.lucene.index;



import java.io.IOException;

import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.RAMOutputStream;


abstract class MultiLevelSkipListWriter {
  
  private int numberOfSkipLevels;
  
  
  private int skipInterval;
  
  
  private RAMOutputStream[] skipBuffer;

  protected MultiLevelSkipListWriter(int skipInterval, int maxSkipLevels, int df) {
    this.skipInterval = skipInterval;
    
    
    numberOfSkipLevels = df == 0 ? 0 : (int) Math.floor(Math.log(df) / Math.log(skipInterval));
    
    
    if (numberOfSkipLevels > maxSkipLevels) {
      numberOfSkipLevels = maxSkipLevels;
    }
  }
  
  protected void init() {
    skipBuffer = new RAMOutputStream[numberOfSkipLevels];
    for (int i = 0; i < numberOfSkipLevels; i++) {
      skipBuffer[i] = new RAMOutputStream();
    }
  }

  protected void resetSkip() {
    
    if (skipBuffer == null) {
      init();
    } else {
      for (int i = 0; i < skipBuffer.length; i++) {
        skipBuffer[i].reset();
      }
    }      
  }

  
  protected abstract void writeSkipData(int level, IndexOutput skipBuffer) throws IOException;
  
  
  void bufferSkip(int df) throws IOException {
    int numLevels;
   
    
    for (numLevels = 0; (df % skipInterval) == 0 && numLevels < numberOfSkipLevels; df /= skipInterval) {
      numLevels++;
    }
    
    long childPointer = 0;
    
    for (int level = 0; level < numLevels; level++) {
      writeSkipData(level, skipBuffer[level]);
      
      long newChildPointer = skipBuffer[level].getFilePointer();
      
      if (level != 0) {
        
        skipBuffer[level].writeVLong(childPointer);
      }
      
      
      childPointer = newChildPointer;
    }
  }

  
  long writeSkip(IndexOutput output) throws IOException {
    long skipPointer = output.getFilePointer();
    if (skipBuffer == null || skipBuffer.length == 0) return skipPointer;
    
    for (int level = numberOfSkipLevels - 1; level > 0; level--) {
      long length = skipBuffer[level].getFilePointer();
      if (length > 0) {
        output.writeVLong(length);
        skipBuffer[level].writeTo(output);
      }
    }
    skipBuffer[0].writeTo(output);
    
    return skipPointer;
  }

}
"
lucene,2.2,org.apache.lucene.index.IndexDeletionPolicy,2,1,0,5,2,1,5,0,2,2.0,2,0.0,0,0.0,1.0,0,0,0.0,1,1.0,1,"package org.apache.lucene.index;



import java.util.List;
import java.io.IOException;



public interface IndexDeletionPolicy {

  
  public void onInit(List commits) throws IOException;

  
  public void onCommit(List commits) throws IOException;
}
"
lucene,2.2,org.apache.lucene.analysis.LetterTokenizer,2,4,1,2,4,1,1,1,1,2.0,9,0.0,0,0.875,0.666666667,1,1,3.5,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public class LetterTokenizer extends CharTokenizer {
  
  public LetterTokenizer(Reader in) {
    super(in);
  }

  
  protected boolean isTokenChar(char c) {
    return Character.isLetter(c);
  }
}
"
lucene,2.2,org.apache.lucene.search.MatchAllDocsQuery,6,2,0,7,14,15,3,5,5,2.0,57,0.0,0,0.705882353,0.333333333,2,3,8.5,3,1.1667,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Explanation;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.Scorer;
import org.apache.lucene.search.Searcher;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.search.Weight;
import org.apache.lucene.util.ToStringUtils;

import java.util.Set;


public class MatchAllDocsQuery extends Query {

  public MatchAllDocsQuery() {
  }

  private class MatchAllScorer extends Scorer {

    final IndexReader reader;
    int id;
    final int maxId;
    final float score;

    MatchAllScorer(IndexReader reader, Similarity similarity, Weight w) {
      super(similarity);
      this.reader = reader;
      id = -1;
      maxId = reader.maxDoc() - 1;
      score = w.getValue();
    }

    public Explanation explain(int doc) {
      return null; 
    }

    public int doc() {
      return id;
    }

    public boolean next() {
      while (id < maxId) {
        id++;
        if (!reader.isDeleted(id)) {
          return true;
        }
      }
      return false;
    }

    public float score() {
      return score;
    }

    public boolean skipTo(int target) {
      id = target - 1;
      return next();
    }

  }

  private class MatchAllDocsWeight implements Weight {
    private Similarity similarity;
    private float queryWeight;
    private float queryNorm;

    public MatchAllDocsWeight(Searcher searcher) {
      this.similarity = searcher.getSimilarity();
    }

    public String toString() {
      return ""weight("" + MatchAllDocsQuery.this + "")"";
    }

    public Query getQuery() {
      return MatchAllDocsQuery.this;
    }

    public float getValue() {
      return queryWeight;
    }

    public float sumOfSquaredWeights() {
      queryWeight = getBoost();
      return queryWeight * queryWeight;
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= this.queryNorm;
    }

    public Scorer scorer(IndexReader reader) {
      return new MatchAllScorer(reader, similarity, this);
    }

    public Explanation explain(IndexReader reader, int doc) {
      
      Explanation queryExpl = new ComplexExplanation
        (true, getValue(), ""MatchAllDocsQuery, product of:"");
      if (getBoost() != 1.0f) {
        queryExpl.addDetail(new Explanation(getBoost(),""boost""));
      }
      queryExpl.addDetail(new Explanation(queryNorm,""queryNorm""));

      return queryExpl;
    }
  }

  protected Weight createWeight(Searcher searcher) {
    return new MatchAllDocsWeight(searcher);
  }

  public void extractTerms(Set terms) {
  }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""MatchAllDocsQuery"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  public boolean equals(Object o) {
    if (!(o instanceof MatchAllDocsQuery))
      return false;
    MatchAllDocsQuery other = (MatchAllDocsQuery) o;
    return this.getBoost() == other.getBoost();
  }

  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ 0x1AA71190;
  }
}
"
lucene,2.2,org.apache.lucene.search.BooleanClause,10,1,0,6,18,0,5,2,10,0.333333333,104,1.0,2,0.0,0.375,1,1,9.2,4,1.4,0,"package org.apache.lucene.search;

import org.apache.lucene.util.Parameter;




public class BooleanClause implements java.io.Serializable {
  
  
  public static final class Occur extends Parameter implements java.io.Serializable {
    
    private Occur(String name) {
      
      super(name);
    }

    public String toString() {
      if (this == MUST) return ""+"";
      if (this == MUST_NOT) return ""-"";
      return """";
    }

    
    public static final Occur MUST = new Occur(""MUST"");
    
    public static final Occur SHOULD = new Occur(""SHOULD"");
    
    public static final Occur MUST_NOT = new Occur(""MUST_NOT"");
    
  }

  
  private Query query;

  private Occur occur;


   
  public BooleanClause(Query query, Occur occur) {
    this.query = query;
    this.occur = occur;
    
  }

  public Occur getOccur() {
    return occur;
  }

  public void setOccur(Occur occur) {
    this.occur = occur;

  }

  public Query getQuery() {
    return query;
  }

  public void setQuery(Query query) {
    this.query = query;
  }
  
  public boolean isProhibited() {
    return Occur.MUST_NOT.equals(occur);
  }

  public boolean isRequired() {
    return Occur.MUST.equals(occur);
  }



  
  public boolean equals(Object o) {
    if (!(o instanceof BooleanClause))
      return false;
    BooleanClause other = (BooleanClause)o;
    return this.query.equals(other.query)
      && this.occur.equals(other.occur);
  }

  
  public int hashCode() {
    return query.hashCode() ^ (Occur.MUST.equals(occur)?1:0) ^ (Occur.MUST_NOT.equals(occur)?2:0);
  }


  public String toString() {
    return occur.toString() + query.toString();
  }
}
"
lucene,2.2,org.apache.lucene.index.IndexCommitPoint,2,1,0,2,2,1,2,0,2,2.0,2,0.0,0,0.0,1.0,0,0,0.0,1,1.0,2,"package org.apache.lucene.index;





public interface IndexCommitPoint {

  
  public String getSegmentsFileName();
  
  
  public void delete();
}
"
lucene,2.2,org.apache.lucene.util.ToStringUtils,2,1,0,17,7,1,17,0,2,2.0,21,0.0,0,0.0,0.5,0,0,9.5,2,1.0,0,"package org.apache.lucene.util;



public class ToStringUtils {
   
  public static String boost(float boost) {
    if (boost != 1.0f) {
      return ""^"" + Float.toString(boost);
    } else return """";
  }

}
"
lucene,2.2,org.apache.lucene.search.WildcardQuery,4,3,0,8,12,4,1,7,3,0.666666667,55,1.0,0,0.857142857,0.5,1,1,12.5,2,1.0,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import java.io.IOException;


public class WildcardQuery extends MultiTermQuery {
  private boolean termContainsWildcard;
    
  public WildcardQuery(Term term) {
    super(term);
    this.termContainsWildcard = (term.text().indexOf('*') != -1) || (term.text().indexOf('?') != -1);
  }

  protected FilteredTermEnum getEnum(IndexReader reader) throws IOException {
    return new WildcardTermEnum(reader, getTerm());
  }

  public boolean equals(Object o) {
    if (o instanceof WildcardQuery)
      return super.equals(o);

    return false;
  }
  
  public Query rewrite(IndexReader reader) throws IOException {
      if (this.termContainsWildcard) {
          return super.rewrite(reader);
      }
      
      return new TermQuery(getTerm());
  }
}
"
lucene,2.2,org.apache.lucene.index.SegmentTermVector,8,1,1,3,15,0,2,1,7,0.571428571,133,1.0,0,0.0,0.35,0,0,15.25,4,1.75,1,"package org.apache.lucene.index;



import java.util.*;


class SegmentTermVector implements TermFreqVector {
  private String field;
  private String terms[];
  private int termFreqs[];
  
  SegmentTermVector(String field, String terms[], int termFreqs[]) {
    this.field = field;
    this.terms = terms;
    this.termFreqs = termFreqs;
  }

  
  public String getField() {
    return field;
  }

  public String toString() {
    StringBuffer sb = new StringBuffer();
    sb.append('{');
    sb.append(field).append("": "");
    if(terms != null){
      for (int i=0; i<terms.length; i++) {
        if (i>0) sb.append("", "");
        sb.append(terms[i]).append('/').append(termFreqs[i]);
      }
    }
    sb.append('}');
    
    return sb.toString();
  }

  public int size() {
    return terms == null ? 0 : terms.length;
  }

  public String [] getTerms() {
    return terms;
  }

  public int[] getTermFrequencies() {
    return termFreqs;
  }

  public int indexOf(String termText) {
    if(terms == null)
      return -1;
    int res = Arrays.binarySearch(terms, termText);
    return res >= 0 ? res : -1;
  }

  public int[] indexesOf(String [] termNumbers, int start, int len) {
    
    
    
    
    
    int res[] = new int[len];

    for (int i=0; i < len; i++) {
      res[i] = indexOf(termNumbers[start+ i]);
    }
    return res;
  }
}
"
lucene,2.2,org.apache.lucene.search.function.ValueSource,6,1,3,8,7,15,6,2,6,2.0,12,0.0,0,0.0,0.444444444,1,1,1.0,1,0.8333,1,"package org.apache.lucene.search.function;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.function.DocValues;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;
import java.io.Serializable;


public abstract class ValueSource implements Serializable {

  
  public abstract DocValues getValues(IndexReader reader) throws IOException;

  
  public abstract String description();

  
  public String toString() {
    return description();
  }

  
  public abstract boolean equals(Object o);

  
  public abstract int hashCode();
  
}
"
lucene,2.2,org.apache.lucene.document.DateField,8,1,0,1,25,22,1,0,6,0.428571429,126,1.0,0,0.0,0.178571429,0,0,14.625,5,1.375,0,"package org.apache.lucene.document;



import org.apache.lucene.search.PrefixQuery;
import org.apache.lucene.search.RangeQuery;

import java.util.Date;   


public class DateField {
  
  private DateField() {}

  
  private static int DATE_LEN = Long.toString(1000L*365*24*60*60*1000,
					       Character.MAX_RADIX).length();

  public static String MIN_DATE_STRING() {
    return timeToString(0);
  }

  public static String MAX_DATE_STRING() {
    char[] buffer = new char[DATE_LEN];
    char c = Character.forDigit(Character.MAX_RADIX-1, Character.MAX_RADIX);
    for (int i = 0 ; i < DATE_LEN; i++)
      buffer[i] = c;
    return new String(buffer);
  }

  
  public static String dateToString(Date date) {
    return timeToString(date.getTime());
  }
  
  public static String timeToString(long time) {
    if (time < 0)
      throw new RuntimeException(""time '"" + time + ""' is too early, must be >= 0"");

    String s = Long.toString(time, Character.MAX_RADIX);

    if (s.length() > DATE_LEN)
      throw new RuntimeException(""time '"" + time + ""' is too late, length of string "" +
          ""representation must be <= "" + DATE_LEN);

    
    if (s.length() < DATE_LEN) {
      StringBuffer sb = new StringBuffer(s);
      while (sb.length() < DATE_LEN)
        sb.insert(0, 0);
      s = sb.toString();
    }

    return s;
  }

  
  public static long stringToTime(String s) {
    return Long.parseLong(s, Character.MAX_RADIX);
  }
  
  public static Date stringToDate(String s) {
    return new Date(stringToTime(s));
  }
}
"
lucene,2.2,org.apache.lucene.search.FieldDoc,2,2,0,4,3,1,3,1,2,1.0,16,0.0,0,0.0,0.875,0,0,6.5,0,0.0,1,"package org.apache.lucene.search;





public class FieldDoc
extends ScoreDoc {

	
	public Comparable[] fields;

	
	public FieldDoc (int doc, float score) {
		super (doc, score);
	}

	
	public FieldDoc (int doc, float score, Comparable[] fields) {
		super (doc, score);
		this.fields = fields;
	}
}"
lucene,2.2,org.apache.lucene.queryParser.TokenMgrError,6,3,0,2,19,15,2,0,4,1.12,184,0.0,0,0.8125,0.5,1,1,28.83333333,14,2.8333,3,"
package org.apache.lucene.queryParser;

public class TokenMgrError extends Error
{
   

   
   static final int LEXICAL_ERROR = 0;

   
   static final int STATIC_LEXER_ERROR = 1;

   
   static final int INVALID_LEXICAL_STATE = 2;

   
   static final int LOOP_DETECTED = 3;

   
   int errorCode;

   
   protected static final String addEscapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

   
   protected static String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar) {
      return(""Lexical error at line "" +
           errorLine + "", column "" +
           errorColumn + "".  Encountered: "" +
           (EOFSeen ? ""<EOF> "" : (""\"""" + addEscapes(String.valueOf(curChar)) + ""\"""") + "" ("" + (int)curChar + ""), "") +
           ""after : \"""" + addEscapes(errorAfter) + ""\"""");
   }

   
   public String getMessage() {
      return super.getMessage();
   }

   

   public TokenMgrError() {
   }

   public TokenMgrError(String message, int reason) {
      super(message);
      errorCode = reason;
   }

   public TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason) {
      this(LexicalError(EOFSeen, lexState, errorLine, errorColumn, errorAfter, curChar), reason);
   }
}
"
lucene,2.2,org.apache.lucene.index.SegmentMerger,16,1,0,25,99,0,3,24,0,0.691666667,1172,0.9375,8,0.0,0.2,0,0,71.25,1,0.8125,8,"package org.apache.lucene.index;



import java.util.Vector;
import java.util.Iterator;
import java.util.Collection;
import java.io.IOException;

import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.document.FieldSelectorResult;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;


final class SegmentMerger {
  
  
  static final byte[] NORMS_HEADER = new byte[]{'N','R','M',-1}; 
  
  private Directory directory;
  private String segment;
  private int termIndexInterval = IndexWriter.DEFAULT_TERM_INDEX_INTERVAL;

  private Vector readers = new Vector();
  private FieldInfos fieldInfos;
  
  private int mergedDocs;

  
  SegmentMerger(Directory dir, String name) {
    directory = dir;
    segment = name;
  }

  SegmentMerger(IndexWriter writer, String name) {
    directory = writer.getDirectory();
    segment = name;
    termIndexInterval = writer.getTermIndexInterval();
  }

  
  final void add(IndexReader reader) {
    readers.addElement(reader);
  }

  
  final IndexReader segmentReader(int i) {
    return (IndexReader) readers.elementAt(i);
  }

  
  final int merge() throws CorruptIndexException, IOException {
    int value;
    
    mergedDocs = mergeFields();
    mergeTerms();
    mergeNorms();

    if (fieldInfos.hasVectors())
      mergeVectors();

    return mergedDocs;
  }
  
  
  final void closeReaders() throws IOException {
    for (int i = 0; i < readers.size(); i++) {  
      IndexReader reader = (IndexReader) readers.elementAt(i);
      reader.close();
    }
  }

  final Vector createCompoundFile(String fileName)
          throws IOException {
    CompoundFileWriter cfsWriter =
            new CompoundFileWriter(directory, fileName);

    Vector files =
      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + 1);    
    
    
    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {
      files.add(segment + ""."" + IndexFileNames.COMPOUND_EXTENSIONS[i]);
    }

    
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        files.add(segment + ""."" + IndexFileNames.NORMS_EXTENSION);
        break;
      }
    }

    
    if (fieldInfos.hasVectors()) {
      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {
        files.add(segment + ""."" + IndexFileNames.VECTOR_EXTENSIONS[i]);
      }
    }

    
    Iterator it = files.iterator();
    while (it.hasNext()) {
      cfsWriter.addFile((String) it.next());
    }
    
    
    cfsWriter.close();
   
    return files;
  }

  private void addIndexed(IndexReader reader, FieldInfos fieldInfos, Collection names, boolean storeTermVectors, boolean storePositionWithTermVector,
                         boolean storeOffsetWithTermVector, boolean storePayloads) throws IOException {
    Iterator i = names.iterator();
    while (i.hasNext()) {
      String field = (String)i.next();
      fieldInfos.add(field, true, storeTermVectors, storePositionWithTermVector, storeOffsetWithTermVector, !reader.hasNorms(field), storePayloads);
    }
  }

  
  private final int mergeFields() throws CorruptIndexException, IOException {
    fieldInfos = new FieldInfos();		  
    int docCount = 0;
    for (int i = 0; i < readers.size(); i++) {
      IndexReader reader = (IndexReader) readers.elementAt(i);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true, false);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION), true, true, false, false);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true, false);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR), true, false, false, false);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.STORES_PAYLOADS), false, false, false, true);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.INDEXED), false, false, false, false);
      fieldInfos.add(reader.getFieldNames(IndexReader.FieldOption.UNINDEXED), false);
    }
    fieldInfos.write(directory, segment + "".fnm"");

    FieldsWriter fieldsWriter = 
            new FieldsWriter(directory, segment, fieldInfos);
    
    
    
    FieldSelector fieldSelectorMerge = new FieldSelector() {
      public FieldSelectorResult accept(String fieldName) {
        return FieldSelectorResult.LOAD_FOR_MERGE;
      }        
    };
    
    try {
      for (int i = 0; i < readers.size(); i++) {
        IndexReader reader = (IndexReader) readers.elementAt(i);
        int maxDoc = reader.maxDoc();
        for (int j = 0; j < maxDoc; j++)
          if (!reader.isDeleted(j)) {               
            fieldsWriter.addDocument(reader.document(j, fieldSelectorMerge));
            docCount++;
          }
      }
    } finally {
      fieldsWriter.close();
    }
    return docCount;
  }

  
  private final void mergeVectors() throws IOException {
    TermVectorsWriter termVectorsWriter = 
      new TermVectorsWriter(directory, segment, fieldInfos);

    try {
      for (int r = 0; r < readers.size(); r++) {
        IndexReader reader = (IndexReader) readers.elementAt(r);
        int maxDoc = reader.maxDoc();
        for (int docNum = 0; docNum < maxDoc; docNum++) {
          
          if (reader.isDeleted(docNum)) 
            continue;
          termVectorsWriter.addAllDocVectors(reader.getTermFreqVectors(docNum));
        }
      }
    } finally {
      termVectorsWriter.close();
    }
  }

  private IndexOutput freqOutput = null;
  private IndexOutput proxOutput = null;
  private TermInfosWriter termInfosWriter = null;
  private int skipInterval;
  private int maxSkipLevels;
  private SegmentMergeQueue queue = null;
  private DefaultSkipListWriter skipListWriter = null;

  private final void mergeTerms() throws CorruptIndexException, IOException {
    try {
      freqOutput = directory.createOutput(segment + "".frq"");
      proxOutput = directory.createOutput(segment + "".prx"");
      termInfosWriter =
              new TermInfosWriter(directory, segment, fieldInfos,
                                  termIndexInterval);
      skipInterval = termInfosWriter.skipInterval;
      maxSkipLevels = termInfosWriter.maxSkipLevels;
      skipListWriter = new DefaultSkipListWriter(skipInterval, maxSkipLevels, mergedDocs, freqOutput, proxOutput);
      queue = new SegmentMergeQueue(readers.size());

      mergeTermInfos();

    } finally {
      if (freqOutput != null) freqOutput.close();
      if (proxOutput != null) proxOutput.close();
      if (termInfosWriter != null) termInfosWriter.close();
      if (queue != null) queue.close();
    }
  }

  private final void mergeTermInfos() throws CorruptIndexException, IOException {
    int base = 0;
    for (int i = 0; i < readers.size(); i++) {
      IndexReader reader = (IndexReader) readers.elementAt(i);
      TermEnum termEnum = reader.terms();
      SegmentMergeInfo smi = new SegmentMergeInfo(base, termEnum, reader);
      base += reader.numDocs();
      if (smi.next())
        queue.put(smi);				  
      else
        smi.close();
    }

    SegmentMergeInfo[] match = new SegmentMergeInfo[readers.size()];

    while (queue.size() > 0) {
      int matchSize = 0;			  
      match[matchSize++] = (SegmentMergeInfo) queue.pop();
      Term term = match[0].term;
      SegmentMergeInfo top = (SegmentMergeInfo) queue.top();

      while (top != null && term.compareTo(top.term) == 0) {
        match[matchSize++] = (SegmentMergeInfo) queue.pop();
        top = (SegmentMergeInfo) queue.top();
      }

      mergeTermInfo(match, matchSize);		  

      while (matchSize > 0) {
        SegmentMergeInfo smi = match[--matchSize];
        if (smi.next())
          queue.put(smi);			  
        else
          smi.close();				  
      }
    }
  }

  private final TermInfo termInfo = new TermInfo(); 

  
  private final void mergeTermInfo(SegmentMergeInfo[] smis, int n)
          throws CorruptIndexException, IOException {
    long freqPointer = freqOutput.getFilePointer();
    long proxPointer = proxOutput.getFilePointer();

    int df = appendPostings(smis, n);		  

    long skipPointer = skipListWriter.writeSkip(freqOutput);

    if (df > 0) {
      
      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));
      termInfosWriter.add(smis[0].term, termInfo);
    }
  }
  
  private byte[] payloadBuffer = null;

  
  private final int appendPostings(SegmentMergeInfo[] smis, int n)
          throws CorruptIndexException, IOException {
    int lastDoc = 0;
    int df = 0;					  
    skipListWriter.resetSkip();
    boolean storePayloads = fieldInfos.fieldInfo(smis[0].term.field).storePayloads;
    int lastPayloadLength = -1;   
    for (int i = 0; i < n; i++) {
      SegmentMergeInfo smi = smis[i];
      TermPositions postings = smi.getPositions();
      int base = smi.base;
      int[] docMap = smi.getDocMap();
      postings.seek(smi.termEnum);
      while (postings.next()) {
        int doc = postings.doc();
        if (docMap != null)
          doc = docMap[doc];                      
        doc += base;                              

        if (doc < 0 || (df > 0 && doc <= lastDoc))
          throw new CorruptIndexException(""docs out of order ("" + doc +
              "" <= "" + lastDoc + "" )"");

        df++;

        if ((df % skipInterval) == 0) {
          skipListWriter.setSkipData(lastDoc, storePayloads, lastPayloadLength);
          skipListWriter.bufferSkip(df);
        }

        int docCode = (doc - lastDoc) << 1;	  
        lastDoc = doc;

        int freq = postings.freq();
        if (freq == 1) {
          freqOutput.writeVInt(docCode | 1);	  
        } else {
          freqOutput.writeVInt(docCode);	  
          freqOutput.writeVInt(freq);		  
        }
        
        
        int lastPosition = 0;			  
        for (int j = 0; j < freq; j++) {
          int position = postings.nextPosition();
          int delta = position - lastPosition;
          if (storePayloads) {
            int payloadLength = postings.getPayloadLength();
            if (payloadLength == lastPayloadLength) {
              proxOutput.writeVInt(delta * 2);
            } else {
              proxOutput.writeVInt(delta * 2 + 1);
              proxOutput.writeVInt(payloadLength);
              lastPayloadLength = payloadLength;
            }
            if (payloadLength > 0) {
              if (payloadBuffer == null || payloadBuffer.length < payloadLength) {
                payloadBuffer = new byte[payloadLength];
              }
              postings.getPayload(payloadBuffer, 0);
              proxOutput.writeBytes(payloadBuffer, 0, payloadLength);
            }
          } else {
            proxOutput.writeVInt(delta);
          }
          lastPosition = position;
        }
      }
    }
    return df;
  }

  private void mergeNorms() throws IOException {
    byte[] normBuffer = null;
    IndexOutput output = null;
    try {
      for (int i = 0; i < fieldInfos.size(); i++) {
        FieldInfo fi = fieldInfos.fieldInfo(i);
        if (fi.isIndexed && !fi.omitNorms) {
          if (output == null) { 
            output = directory.createOutput(segment + ""."" + IndexFileNames.NORMS_EXTENSION);
            output.writeBytes(NORMS_HEADER,NORMS_HEADER.length);
          }
          for (int j = 0; j < readers.size(); j++) {
            IndexReader reader = (IndexReader) readers.elementAt(j);
            int maxDoc = reader.maxDoc();
            if (normBuffer == null || normBuffer.length < maxDoc) {
              
              normBuffer = new byte[maxDoc];
            }
            reader.norms(fi.name, normBuffer, 0);
            if (!reader.hasDeletions()) {
              
              output.writeBytes(normBuffer, maxDoc);
            } else {
              
              
              for (int k = 0; k < maxDoc; k++) {
                if (!reader.isDeleted(k)) {
                  output.writeByte(normBuffer[k]);
                }
              }
            }
          }
        }
      }
    } finally {
      if (output != null) { 
        output.close();
      }
    }
  }

}
"
lucene,2.2,org.apache.lucene.document.FieldSelectorResult,4,1,0,7,6,0,7,0,2,0.875,83,0.125,7,0.0,0.555555556,1,1,17.75,5,1.5,0,"package org.apache.lucene.document;

import java.io.Serializable;




public final class FieldSelectorResult implements Serializable {

    
  public transient static final FieldSelectorResult LOAD = new FieldSelectorResult(0);
    
  public transient static final FieldSelectorResult LAZY_LOAD = new FieldSelectorResult(1);
    
  public transient static final FieldSelectorResult NO_LOAD = new FieldSelectorResult(2);
    
  public transient static final FieldSelectorResult LOAD_AND_BREAK = new FieldSelectorResult(3);
    
  public transient static final FieldSelectorResult LOAD_FOR_MERGE = new FieldSelectorResult(4);

     
  public transient static final FieldSelectorResult SIZE = new FieldSelectorResult(5);

           
  public transient static final FieldSelectorResult SIZE_AND_BREAK = new FieldSelectorResult(6);



  private int id;

  private FieldSelectorResult(int id) {
    this.id = id;
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    final FieldSelectorResult that = (FieldSelectorResult) o;

    if (id != that.id) return false;

    return true;
  }

  public int hashCode() {
    return id;
  }
}
"
lucene,2.2,org.apache.lucene.search.SortComparatorSource,1,1,0,6,1,0,4,2,1,2.0,1,0.0,0,0.0,1.0,0,0,0.0,1,1.0,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import java.io.IOException;
import java.io.Serializable;


public interface SortComparatorSource
extends Serializable {

  
  ScoreDocComparator newComparator (IndexReader reader, String fieldname)
  throws IOException;
}
"
lucene,2.2,org.apache.lucene.search.ReqOptSumScorer,6,2,0,4,15,0,1,3,6,0.466666667,113,1.0,2,0.615384615,0.5,1,3,17.33333333,1,0.8333,0,"package org.apache.lucene.search;


import java.io.IOException;


public class ReqOptSumScorer extends Scorer {
  
  private Scorer reqScorer;
  private Scorer optScorer;

  
  public ReqOptSumScorer(
      Scorer reqScorer,
      Scorer optScorer)
  {
    super(null); 
    this.reqScorer = reqScorer;
    this.optScorer = optScorer;
  }

  private boolean firstTimeOptScorer = true;

  public boolean next() throws IOException {
    return reqScorer.next();
  }

  public boolean skipTo(int target) throws IOException {
    return reqScorer.skipTo(target);
  }

  public int doc() {
    return reqScorer.doc();
  }

  
  public float score() throws IOException {
    int curDoc = reqScorer.doc();
    float reqScore = reqScorer.score();
    if (firstTimeOptScorer) {
      firstTimeOptScorer = false;
      if (! optScorer.skipTo(curDoc)) {
        optScorer = null;
        return reqScore;
      }
    } else if (optScorer == null) {
      return reqScore;
    } else if ((optScorer.doc() < curDoc) && (! optScorer.skipTo(curDoc))) {
      optScorer = null;
      return reqScore;
    }
    
    return (optScorer.doc() == curDoc)
       ? reqScore + optScorer.score()
       : reqScore;
  }

  
  public Explanation explain(int doc) throws IOException {
    Explanation res = new Explanation();
    res.setDescription(""required, optional"");
    res.addDetail(reqScorer.explain(doc));
    res.addDetail(optScorer.explain(doc));
    return res;
  }
}

"
lucene,2.2,org.apache.lucene.search.DisjunctionMaxScorer,11,2,0,4,25,0,1,3,7,0.625,447,1.0,0,0.444444444,0.287878788,1,3,39.27272727,6,1.5455,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.ArrayList;


class DisjunctionMaxScorer extends Scorer {

    
    private ArrayList subScorers = new ArrayList();

    
    private float tieBreakerMultiplier;

    private boolean more = false;          
    private boolean firstTime = true;      

    
    public DisjunctionMaxScorer(float tieBreakerMultiplier, Similarity similarity) {
        super(similarity);
        this.tieBreakerMultiplier = tieBreakerMultiplier;
    }

    
    public void add(Scorer scorer) throws IOException {
        if (scorer.next()) {       
            subScorers.add(scorer);
            more = true;
        }
    }

    
    public boolean next() throws IOException {
        if (!more) return false;
        if (firstTime) {
            heapify();
            firstTime = false;
            return true;   
        }
        
        int lastdoc = ((Scorer) subScorers.get(0)).doc();
        do {
            if (((Scorer) subScorers.get(0)).next())
                heapAdjust(0);
            else {
                heapRemoveRoot();
                if (subScorers.isEmpty()) return (more = false);
            }
        } while ( ((Scorer) subScorers.get(0)).doc()==lastdoc );
        return true;
    }

    
    public int doc() {
        return ((Scorer) subScorers.get(0)).doc();
    }

    
    public float score() throws IOException {
        int doc = ((Scorer) subScorers.get(0)).doc();
        float[] sum = {((Scorer) subScorers.get(0)).score()}, max = {sum[0]};
        int size = subScorers.size();
        scoreAll(1, size, doc, sum, max);
        scoreAll(2, size, doc, sum, max);
        return max[0] + (sum[0] - max[0])*tieBreakerMultiplier;
    }

    
    private void scoreAll(int root, int size, int doc, float[] sum, float[] max) throws IOException {
        if (root<size && ((Scorer) subScorers.get(root)).doc() == doc) {
            float sub = ((Scorer) subScorers.get(root)).score();
            sum[0] += sub;
            max[0] = Math.max(max[0], sub);
            scoreAll((root<<1)+1, size, doc, sum, max);
            scoreAll((root<<1)+2, size, doc, sum, max);
        }
    }

    
    public boolean skipTo(int target) throws IOException {
        if (firstTime) {
          if (!more) return false;
          heapify();
          firstTime = false;
        }

        while (subScorers.size()>0 && ((Scorer)subScorers.get(0)).doc()<target) {
            if (((Scorer)subScorers.get(0)).skipTo(target))
                heapAdjust(0);
            else
                heapRemoveRoot();
        }
        if ((subScorers.size()==0))
            return (more = false);
        return true;
    }

    
    public Explanation explain(int doc) throws IOException {
        throw new UnsupportedOperationException();
    }

    
    private void heapify() {
        int size = subScorers.size();
        for (int i=(size>>1)-1; i>=0; i--)
            heapAdjust(i);
    }

    
    private void heapAdjust(int root) {
        Scorer scorer=(Scorer)subScorers.get(root);
        int doc=scorer.doc();
        int i=root, size=subScorers.size();
        while (i<=(size>>1)-1) {
            int lchild=(i<<1)+1;
            Scorer lscorer=(Scorer)subScorers.get(lchild);
            int ldoc=lscorer.doc();
            int rdoc=Integer.MAX_VALUE, rchild=(i<<1)+2;
            Scorer rscorer=null;
            if (rchild<size) {
                rscorer=(Scorer)subScorers.get(rchild);
                rdoc=rscorer.doc();
            }
            if (ldoc<doc) {
                if (rdoc<ldoc) {
                    subScorers.set(i, rscorer);
                    subScorers.set(rchild, scorer);
                    i=rchild;
                } else {
                    subScorers.set(i, lscorer);
                    subScorers.set(lchild, scorer);
                    i=lchild;
                }
            } else if (rdoc<doc) {
                subScorers.set(i, rscorer);
                subScorers.set(rchild, scorer);
                i=rchild;
            } else return;
        }
    }

    
    private void heapRemoveRoot() {
        int size=subScorers.size();
        if (size==1)
            subScorers.remove(0);
        else {
            subScorers.set(0, subScorers.get(size-1));
            subScorers.remove(size-1);
            heapAdjust(0);
        }
    }

}
"
lucene,2.2,org.apache.lucene.document.NumberTools,4,1,0,0,18,0,0,0,3,1.166666667,130,0.5,0,0.0,0.333333333,0,0,30.0,6,2.5,0,"package org.apache.lucene.document;





public class NumberTools {

    private static final int RADIX = 36;

    private static final char NEGATIVE_PREFIX = '-';

    
    private static final char POSITIVE_PREFIX = '0';

    
    
    public static final String MIN_STRING_VALUE = NEGATIVE_PREFIX
            + ""0000000000000"";

    
    public static final String MAX_STRING_VALUE = POSITIVE_PREFIX
            + ""1y2p0ij32e8e7"";

    
    public static final int STR_SIZE = MIN_STRING_VALUE.length();

    
    public static String longToString(long l) {

        if (l == Long.MIN_VALUE) {
            
            return MIN_STRING_VALUE;
        }

        StringBuffer buf = new StringBuffer(STR_SIZE);

        if (l < 0) {
            buf.append(NEGATIVE_PREFIX);
            l = Long.MAX_VALUE + l + 1;
        } else {
            buf.append(POSITIVE_PREFIX);
        }
        String num = Long.toString(l, RADIX);

        int padLen = STR_SIZE - num.length() - buf.length();
        while (padLen-- > 0) {
            buf.append('0');
        }
        buf.append(num);

        return buf.toString();
    }

    
    public static long stringToLong(String str) {
        if (str == null) {
            throw new NullPointerException(""string cannot be null"");
        }
        if (str.length() != STR_SIZE) {
            throw new NumberFormatException(""string is the wrong size"");
        }

        if (str.equals(MIN_STRING_VALUE)) {
            return Long.MIN_VALUE;
        }

        char prefix = str.charAt(0);
        long l = Long.parseLong(str.substring(1), RADIX);

        if (prefix == POSITIVE_PREFIX) {
            
        } else if (prefix == NEGATIVE_PREFIX) {
            l = l - Long.MAX_VALUE - 1;
        } else {
            throw new NumberFormatException(
                    ""string does not begin with the correct prefix"");
        }

        return l;
    }
}"
lucene,2.2,org.apache.lucene.search.SimilarityDelegator,7,2,1,2,14,0,1,1,7,0.0,47,1.0,1,0.714285714,0.428571429,1,2,5.571428571,1,0.8571,1,"package org.apache.lucene.search;




public class SimilarityDelegator extends Similarity {

  private Similarity delegee;

  
  public SimilarityDelegator(Similarity delegee) {
    this.delegee = delegee;
  }

  public float lengthNorm(String fieldName, int numTerms) {
    return delegee.lengthNorm(fieldName, numTerms);
  }
  
  public float queryNorm(float sumOfSquaredWeights) {
    return delegee.queryNorm(sumOfSquaredWeights);
  }

  public float tf(float freq) {
    return delegee.tf(freq);
  }
    
  public float sloppyFreq(int distance) {
    return delegee.sloppyFreq(distance);
  }
    
  public float idf(int docFreq, int numDocs) {
    return delegee.idf(docFreq, numDocs);
  }
    
  public float coord(int overlap, int maxOverlap) {
    return delegee.coord(overlap, maxOverlap);
  }

}
"
lucene,2.2,org.apache.lucene.store.SingleInstanceLockFactory,3,2,0,4,8,0,1,3,3,0.0,43,1.0,0,0.666666667,0.833333333,0,0,13.0,1,0.6667,1,"package org.apache.lucene.store;



import java.io.IOException;
import java.util.HashSet;
import java.util.Enumeration;



public class SingleInstanceLockFactory extends LockFactory {

  private HashSet locks = new HashSet();

  public Lock makeLock(String lockName) {
    
    
    
    return new SingleInstanceLock(locks, lockName);
  }

  public void clearLock(String lockName) throws IOException {
    synchronized(locks) {
      if (locks.contains(lockName)) {
        locks.remove(lockName);
      }
    }
  }
};

class SingleInstanceLock extends Lock {

  String lockName;
  private HashSet locks;

  public SingleInstanceLock(HashSet locks, String lockName) {
    this.locks = locks;
    this.lockName = lockName;
  }

  public boolean obtain() throws IOException {
    synchronized(locks) {
      return locks.add(lockName);
    }
  }

  public void release() {
    synchronized(locks) {
      locks.remove(lockName);
    }
  }

  public boolean isLocked() {
    synchronized(locks) {
      return locks.contains(lockName);
    }
  }

  public String toString() {
      return ""SingleInstanceLock: "" + lockName;
  }
}
"
lucene,2.2,org.apache.lucene.search.SortField,15,1,0,9,22,0,8,1,14,0.852040816,297,0.285714286,3,0.0,0.380952381,0,0,17.86666667,7,0.8,3,"package org.apache.lucene.search;



import java.io.Serializable;
import java.util.Locale;


public class SortField
implements Serializable {

  
  public static final int SCORE = 0;

  
  public static final int DOC = 1;

  
  public static final int AUTO = 2;

  
  public static final int STRING = 3;

  
  public static final int INT = 4;

  
  public static final int FLOAT = 5;

  
  public static final int CUSTOM = 9;

  
  
  


  
  public static final SortField FIELD_SCORE = new SortField (null, SCORE);

  
  public static final SortField FIELD_DOC = new SortField (null, DOC);


  private String field;
  private int type = AUTO;  
  private Locale locale;    
  boolean reverse = false;  
  private SortComparatorSource factory;

  
  public SortField (String field) {
    this.field = field.intern();
  }

  
  public SortField (String field, boolean reverse) {
    this.field = field.intern();
    this.reverse = reverse;
  }

  
  public SortField (String field, int type) {
    this.field = (field != null) ? field.intern() : field;
    this.type = type;
  }

  
  public SortField (String field, int type, boolean reverse) {
    this.field = (field != null) ? field.intern() : field;
    this.type = type;
    this.reverse = reverse;
  }

  
  public SortField (String field, Locale locale) {
    this.field = field.intern();
    this.type = STRING;
    this.locale = locale;
  }

  
  public SortField (String field, Locale locale, boolean reverse) {
    this.field = field.intern();
    this.type = STRING;
    this.locale = locale;
    this.reverse = reverse;
  }

  
  public SortField (String field, SortComparatorSource comparator) {
    this.field = (field != null) ? field.intern() : field;
    this.type = CUSTOM;
    this.factory = comparator;
  }

  
  public SortField (String field, SortComparatorSource comparator, boolean reverse) {
    this.field = (field != null) ? field.intern() : field;
    this.type = CUSTOM;
    this.reverse = reverse;
    this.factory = comparator;
  }

  
  public String getField() {
    return field;
  }

  
  public int getType() {
    return type;
  }

  
  public Locale getLocale() {
    return locale;
  }

  
  public boolean getReverse() {
    return reverse;
  }

  public SortComparatorSource getFactory() {
    return factory;
  }

  public String toString() {
    StringBuffer buffer = new StringBuffer();
    switch (type) {
      case SCORE: buffer.append(""<score>"");
                  break;

      case DOC: buffer.append(""<doc>"");
                break;

      case CUSTOM: buffer.append (""<custom:\"""" + field + ""\"": ""
                                               + factory + "">"");
                break;

      default: buffer.append(""\"""" + field + ""\"""");
               break;
    }

    if (locale != null) buffer.append (""(""+locale+"")"");
    if (reverse) buffer.append('!');

    return buffer.toString();
  }
}
"
lucene,2.2,org.apache.lucene.search.Similarity,17,1,2,49,26,124,47,4,16,0.875,94,1.0,1,0.0,0.175,0,0,4.411764706,1,0.8824,3,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.Term;
import org.apache.lucene.util.SmallFloat;

import java.io.IOException;
import java.io.Serializable;
import java.util.Collection;
import java.util.Iterator;


public abstract class Similarity implements Serializable {
  
  private static Similarity defaultImpl = new DefaultSimilarity();

  
  public static void setDefault(Similarity similarity) {
    Similarity.defaultImpl = similarity;
  }

  
  public static Similarity getDefault() {
    return Similarity.defaultImpl;
  }

  
  private static final float[] NORM_TABLE = new float[256];

  static {
    for (int i = 0; i < 256; i++)
      NORM_TABLE[i] = SmallFloat.byte315ToFloat((byte)i);
  }

  
  public static float decodeNorm(byte b) {
    return NORM_TABLE[b & 0xFF];  
  }

  
  public static float[] getNormDecoder() {
    return NORM_TABLE;
  }

  
  public abstract float lengthNorm(String fieldName, int numTokens);

  
  public abstract float queryNorm(float sumOfSquaredWeights);

  
  public static byte encodeNorm(float f) {
    return SmallFloat.floatToByte315(f);
  }


  
  public float tf(int freq) {
    return tf((float)freq);
  }

  
  public abstract float sloppyFreq(int distance);

  
  public abstract float tf(float freq);

  
  public float idf(Term term, Searcher searcher) throws IOException {
    return idf(searcher.docFreq(term), searcher.maxDoc());
  }

  
  public float idf(Collection terms, Searcher searcher) throws IOException {
    float idf = 0.0f;
    Iterator i = terms.iterator();
    while (i.hasNext()) {
      idf += idf((Term)i.next(), searcher);
    }
    return idf;
  }

  
  public abstract float idf(int docFreq, int numDocs);

  
  public abstract float coord(int overlap, int maxOverlap);


  
  
  public float scorePayload(byte [] payload, int offset, int length)
  {
    
    return 1;
  }
}
"
lucene,2.2,org.apache.lucene.search.FuzzyTermEnum,14,3,0,5,29,53,1,4,6,0.692307692,514,1.0,1,0.541666667,0.333333333,1,4,34.92857143,14,2.2857,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;

import java.io.IOException;


public final class FuzzyTermEnum extends FilteredTermEnum {

  
  private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19;

  
  private int[][] d;

  private float similarity;
  private boolean endEnum = false;

  private Term searchTerm = null;
  private final String field;
  private final String text;
  private final String prefix;

  private final float minimumSimilarity;
  private final float scale_factor;
  private final int[] maxDistances = new int[TYPICAL_LONGEST_WORD_IN_INDEX];

  
  public FuzzyTermEnum(IndexReader reader, Term term) throws IOException {
    this(reader, term, FuzzyQuery.defaultMinSimilarity, FuzzyQuery.defaultPrefixLength);
  }
    
  
  public FuzzyTermEnum(IndexReader reader, Term term, float minSimilarity) throws IOException {
    this(reader, term, minSimilarity, FuzzyQuery.defaultPrefixLength);
  }
    
  
  public FuzzyTermEnum(IndexReader reader, Term term, final float minSimilarity, final int prefixLength) throws IOException {
    super();
    
    if (minSimilarity >= 1.0f)
      throw new IllegalArgumentException(""minimumSimilarity cannot be greater than or equal to 1"");
    else if (minSimilarity < 0.0f)
      throw new IllegalArgumentException(""minimumSimilarity cannot be less than 0"");
    if(prefixLength < 0)
      throw new IllegalArgumentException(""prefixLength cannot be less than 0"");

    this.minimumSimilarity = minSimilarity;
    this.scale_factor = 1.0f / (1.0f - minimumSimilarity);
    this.searchTerm = term;
    this.field = searchTerm.field();

    
    
    final int fullSearchTermLength = searchTerm.text().length();
    final int realPrefixLength = prefixLength > fullSearchTermLength ? fullSearchTermLength : prefixLength;

    this.text = searchTerm.text().substring(realPrefixLength);
    this.prefix = searchTerm.text().substring(0, realPrefixLength);

    initializeMaxDistances();
    this.d = initDistanceArray();

    setEnum(reader.terms(new Term(searchTerm.field(), prefix)));
  }

  
  protected final boolean termCompare(Term term) {
    if (field == term.field() && term.text().startsWith(prefix)) {
        final String target = term.text().substring(prefix.length());
        this.similarity = similarity(target);
        return (similarity > minimumSimilarity);
    }
    endEnum = true;
    return false;
  }
  
  public final float difference() {
    return (float)((similarity - minimumSimilarity) * scale_factor);
  }
  
  public final boolean endEnum() {
    return endEnum;
  }
  
  
  
  
  private static final int min(int a, int b, int c) {
    final int t = (a < b) ? a : b;
    return (t < c) ? t : c;
  }

  private final int[][] initDistanceArray(){
    return new int[this.text.length() + 1][TYPICAL_LONGEST_WORD_IN_INDEX];
  }

  
  private synchronized final float similarity(final String target) {
    final int m = target.length();
    final int n = text.length();
    if (n == 0)  {
      
      
      return prefix.length() == 0 ? 0.0f : 1.0f - ((float) m / prefix.length());
    }
    if (m == 0) {
      return prefix.length() == 0 ? 0.0f : 1.0f - ((float) n / prefix.length());
    }

    final int maxDistance = getMaxDistance(m);

    if (maxDistance < Math.abs(m-n)) {
      
      
      
      
      
      
      
      return 0.0f;
    }

    
    if (d[0].length <= m) {
      growDistanceArray(m);
    }

    
    for (int i = 0; i <= n; i++) d[i][0] = i;
    for (int j = 0; j <= m; j++) d[0][j] = j;
    
    
    for (int i = 1; i <= n; i++) {
      int bestPossibleEditDistance = m;
      final char s_i = text.charAt(i - 1);
      for (int j = 1; j <= m; j++) {
        if (s_i != target.charAt(j-1)) {
            d[i][j] = min(d[i-1][j], d[i][j-1], d[i-1][j-1])+1;
        }
        else {
          d[i][j] = min(d[i-1][j]+1, d[i][j-1]+1, d[i-1][j-1]);
        }
        bestPossibleEditDistance = Math.min(bestPossibleEditDistance, d[i][j]);
      }

      
      
      

      if (i > maxDistance && bestPossibleEditDistance > maxDistance) {  
        
        
        return 0.0f;
      }
    }

    
    
    
    
    
    return 1.0f - ((float)d[n][m] / (float) (prefix.length() + Math.min(n, m)));
  }

  
  private void growDistanceArray(int m) {
    for (int i = 0; i < d.length; i++) {
      d[i] = new int[m+1];
    }
  }

  
  private final int getMaxDistance(int m) {
    return (m < maxDistances.length) ? maxDistances[m] : calculateMaxDistance(m);
  }

  private void initializeMaxDistances() {
    for (int i = 0; i < maxDistances.length; i++) {
      maxDistances[i] = calculateMaxDistance(i);
    }
  }
  
  private int calculateMaxDistance(int m) {
    return (int) ((1-minimumSimilarity) * (Math.min(text.length(), m) + prefix.length()));
  }

  public void close() throws IOException {
    super.close();  
  }
  
}
"
lucene,2.2,org.apache.lucene.store.Lock,6,1,4,15,17,13,14,1,5,0.9,89,0.5,0,0.0,0.6,0,0,13.5,1,0.6667,2,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class Lock {
  public static long LOCK_POLL_INTERVAL = 1000;

  
  public abstract boolean obtain() throws IOException;

  
  protected Throwable failureReason;

  
  public boolean obtain(long lockWaitTimeout) throws LockObtainFailedException, IOException {
    failureReason = null;
    boolean locked = obtain();
    int maxSleepCount = (int)(lockWaitTimeout / LOCK_POLL_INTERVAL);
    int sleepCount = 0;
    while (!locked) {
      if (sleepCount++ == maxSleepCount) {
        String reason = ""Lock obtain timed out: "" + this.toString();
        if (failureReason != null) {
          reason += "": "" + failureReason;
        }
        LockObtainFailedException e = new LockObtainFailedException(reason);
        if (failureReason != null) {
          e.initCause(failureReason);
        }
        throw e;
      }
      try {
        Thread.sleep(LOCK_POLL_INTERVAL);
      } catch (InterruptedException e) {
        throw new IOException(e.toString());
      }
      locked = obtain();
    }
    return locked;
  }

  
  public abstract void release();

  
  public abstract boolean isLocked();


  
  public abstract static class With {
    private Lock lock;
    private long lockWaitTimeout;


    
    public With(Lock lock, long lockWaitTimeout) {
      this.lock = lock;
      this.lockWaitTimeout = lockWaitTimeout;
    }

    
    protected abstract Object doBody() throws IOException;

    
    public Object run() throws LockObtainFailedException, IOException {
      boolean locked = false;
      try {
         locked = lock.obtain(lockWaitTimeout);
         return doBody();
      } finally {
        if (locked)
	      lock.release();
      }
    }
  }

}
"
lucene,2.2,org.apache.lucene.search.spans.SpanFirstQuery,13,3,0,6,30,0,1,6,11,0.416666667,176,1.0,1,0.571428571,0.192307692,2,2,12.38461538,6,1.3077,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class SpanFirstQuery extends SpanQuery {
  private SpanQuery match;
  private int end;

  
  public SpanFirstQuery(SpanQuery match, int end) {
    this.match = match;
    this.end = end;
  }

  
  public SpanQuery getMatch() { return match; }

  
  public int getEnd() { return end; }

  public String getField() { return match.getField(); }

  
  public Collection getTerms() { return match.getTerms(); }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanFirst("");
    buffer.append(match.toString(field));
    buffer.append("", "");
    buffer.append(end);
    buffer.append("")"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }
  
  public void extractTerms(Set terms) {
	    match.extractTerms(terms);
  }  

  public Spans getSpans(final IndexReader reader) throws IOException {
    return new Spans() {
        private Spans spans = match.getSpans(reader);

        public boolean next() throws IOException {
          while (spans.next()) {                  
            if (end() <= end)
              return true;
          }
          return false;
        }

        public boolean skipTo(int target) throws IOException {
          if (!spans.skipTo(target))
            return false;

          if (spans.end() <= end)                 
            return true;

          return next();                          
        }

        public int doc() { return spans.doc(); }
        public int start() { return spans.start(); }
        public int end() { return spans.end(); }

        public String toString() {
          return ""spans("" + SpanFirstQuery.this.toString() + "")"";
        }

      };
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanFirstQuery clone = null;

    SpanQuery rewritten = (SpanQuery) match.rewrite(reader);
    if (rewritten != match) {
      clone = (SpanFirstQuery) this.clone();
      clone.match = rewritten;
    }

    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof SpanFirstQuery)) return false;

    SpanFirstQuery other = (SpanFirstQuery)o;
    return this.end == other.end
         && this.match.equals(other.match)
         && this.getBoost() == other.getBoost();
  }

  public int hashCode() {
    int h = match.hashCode();
    h ^= (h << 8) | (h >>> 25);  
    h ^= Float.floatToRawIntBits(getBoost()) ^ end;
    return h;
  }


}
"
lucene,2.2,org.apache.lucene.search.TopDocs,3,1,1,14,4,0,13,1,2,0.666666667,25,0.333333333,1,0.0,0.583333333,0,0,6.333333333,1,0.6667,1,"package org.apache.lucene.search;




public class TopDocs implements java.io.Serializable {
  
  public int totalHits;
  
  public ScoreDoc[] scoreDocs;
  
  private float maxScore;
  
  
  public float getMaxScore() {
      return maxScore;
  }
  
  
  public void setMaxScore(float maxScore) {
      this.maxScore=maxScore;
  }
  
  
  TopDocs(int totalHits, ScoreDoc[] scoreDocs, float maxScore) {
    this.totalHits = totalHits;
    this.scoreDocs = scoreDocs;
    this.maxScore = maxScore;
  }
}
"
lucene,2.2,org.apache.lucene.search.TopFieldDocCollector,3,3,0,11,13,1,1,10,3,2.0,70,0.0,0,0.666666667,0.533333333,1,3,22.33333333,2,1.3333,2,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;


public class TopFieldDocCollector extends TopDocCollector {

  
  public TopFieldDocCollector(IndexReader reader, Sort sort, int numHits)
    throws IOException {
    super(numHits, new FieldSortedHitQueue(reader, sort.fields, numHits));
  }

  
  public void collect(int doc, float score) {
    if (score > 0.0f) {
      totalHits++;
      hq.insert(new FieldDoc(doc, score));
    }
  }

  
  public TopDocs topDocs() {
    FieldSortedHitQueue fshq = (FieldSortedHitQueue)hq;
    ScoreDoc[] scoreDocs = new ScoreDoc[fshq.size()];
    for (int i = fshq.size()-1; i >= 0; i--)      
      scoreDocs[i] = fshq.fillFields ((FieldDoc) fshq.pop());

    return new TopFieldDocs(totalHits, scoreDocs,
                            fshq.getFields(), fshq.getMaxScore());
  }
}
"
lucene,2.2,org.apache.lucene.analysis.Tokenizer,3,2,3,4,5,1,3,1,1,0.5,17,1.0,0,0.75,0.666666667,0,0,4.333333333,1,0.3333,3,"package org.apache.lucene.analysis;



import java.io.Reader;
import java.io.IOException;



public abstract class Tokenizer extends TokenStream {
  
  protected Reader input;

  
  protected Tokenizer() {}

  
  protected Tokenizer(Reader input) {
    this.input = input;
  }

  
  public void close() throws IOException {
    input.close();
  }
}

"
lucene,2.2,org.apache.lucene.LucenePackage,3,1,0,0,8,3,0,0,1,1.0,27,0.0,0,0.0,0.333333333,0,0,7.666666667,2,1.0,0,"package org.apache.lucene;




public final class LucenePackage {

  private LucenePackage() {}                      

  
  public static Package get() {
    return LucenePackage.class.getPackage();
  }
}
"
lucene,2.2,org.apache.lucene.search.ComplexExplanation,6,2,0,10,18,9,9,1,5,0.2,65,1.0,0,0.733333333,0.333333333,1,1,9.666666667,3,1.1667,1,"package org.apache.lucene.search;



import java.util.ArrayList;


public class ComplexExplanation extends Explanation {
  private Boolean match;
  
  public ComplexExplanation() {
    super();
  }

  public ComplexExplanation(boolean match, float value, String description) {
    
    
    super(value, description);
    this.match = Boolean.valueOf(match);
  }

  
  public Boolean getMatch() { return match; }
  
  public void setMatch(Boolean match) { this.match = match; }
  
  public boolean isMatch() {
    Boolean m = getMatch();
    return (null != m ? m.booleanValue() : super.isMatch());
  }

  protected String getSummary() {
    if (null == getMatch())
      return super.getSummary();
    
    return getValue() + "" = ""
      + (isMatch() ? ""(MATCH) "" : ""(NON-MATCH) "")
      + getDescription();
  }
  
}
"
lucene,2.2,org.apache.lucene.search.Hit,8,1,0,4,19,2,1,3,6,0.178571429,116,1.0,2,0.0,0.34375,0,0,13.0,2,1.0,2,"

package org.apache.lucene.search;

import java.io.IOException;

import org.apache.lucene.document.Document;
import org.apache.lucene.index.CorruptIndexException;


public class Hit implements java.io.Serializable {

  private Document doc = null;

  private boolean resolved = false;

  private Hits hits = null;
  private int hitNumber;

  
  Hit(Hits hits, int hitNumber) {
    this.hits = hits;
    this.hitNumber = hitNumber;
  }

  
  public Document getDocument() throws CorruptIndexException, IOException {
    if (!resolved) fetchTheHit();
    return doc;
  }

  
  public float getScore() throws IOException {
    return hits.score(hitNumber);
  }

  
  public int getId() throws IOException {
    return hits.id(hitNumber);
  }

  private void fetchTheHit() throws CorruptIndexException, IOException {
    doc = hits.doc(hitNumber);
    resolved = true;
  }

  

  
  public float getBoost() throws CorruptIndexException, IOException {
    return getDocument().getBoost();
  }

  
  public String get(String name) throws CorruptIndexException, IOException {
    return getDocument().get(name);
  }

  
  public String toString() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""Hit<"");
    buffer.append(hits.toString());
    buffer.append("" ["");
    buffer.append(hitNumber);
    buffer.append(""] "");
    if (resolved) {
        buffer.append(""resolved"");
    } else {
        buffer.append(""unresolved"");
    }
    buffer.append("">"");
    return buffer.toString();
  }


}
"
lucene,2.2,org.apache.lucene.util.Parameter,6,1,5,5,18,5,5,0,1,0.6,88,0.5,0,0.0,0.7,0,0,13.33333333,1,0.5,0,"package org.apache.lucene.util;



import java.io.ObjectStreamException;
import java.io.Serializable;
import java.io.StreamCorruptedException;
import java.util.HashMap;
import java.util.Map;


public abstract class Parameter implements Serializable
{
  static Map allParameters = new HashMap();
  
  private String name;
  
  private Parameter() {
    
  }
  
  protected Parameter(String name) {
    
    this.name = name;
    String key = makeKey(name);
    
    if(allParameters.containsKey(key))
      throw new IllegalArgumentException(""Parameter name "" + key + "" already used!"");
    
    allParameters.put(key, this);
  }
  
  private String makeKey(String name){
    return getClass() + "" "" + name;
  }
  
  public String toString() {
    return name;
  }
  
  
  protected Object readResolve() throws ObjectStreamException {
    Object par = allParameters.get(makeKey(name));
    
    if(par == null)
      throw new StreamCorruptedException(""Unknown parameter value: "" + name);
      
    return par;
  }
  
 }
"
lucene,2.2,org.apache.lucene.search.spans.NearSpansUnordered,19,1,0,6,48,71,3,6,7,0.75,468,1.0,5,0.0,0.210526316,0,0,23.10526316,3,1.3158,1,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.List;
import java.util.ArrayList;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.PriorityQueue;

class NearSpansUnordered implements Spans {
  private SpanNearQuery query;

  private List ordered = new ArrayList();         
  private int slop;                               

  private SpansCell first;                        
  private SpansCell last;                         

  private int totalLength;                        

  private CellQueue queue;                        
  private SpansCell max;                          

  private boolean more = true;                    
  private boolean firstTime = true;               

  private class CellQueue extends PriorityQueue {
    public CellQueue(int size) {
      initialize(size);
    }
    
    protected final boolean lessThan(Object o1, Object o2) {
      SpansCell spans1 = (SpansCell)o1;
      SpansCell spans2 = (SpansCell)o2;
      if (spans1.doc() == spans2.doc()) {
        return NearSpansOrdered.docSpansOrdered(spans1, spans2);
      } else {
        return spans1.doc() < spans2.doc();
      }
    }
  }


  
  private class SpansCell implements Spans {
    private Spans spans;
    private SpansCell next;
    private int length = -1;
    private int index;

    public SpansCell(Spans spans, int index) {
      this.spans = spans;
      this.index = index;
    }

    public boolean next() throws IOException {
      return adjust(spans.next());
    }

    public boolean skipTo(int target) throws IOException {
      return adjust(spans.skipTo(target));
    }
    
    private boolean adjust(boolean condition) {
      if (length != -1) {
        totalLength -= length;  
      }
      if (condition) {
        length = end() - start(); 
        totalLength += length; 

        if (max == null || doc() > max.doc()
            || (doc() == max.doc()) && (end() > max.end())) {
          max = this;
        }
      }
      more = condition;
      return condition;
    }

    public int doc() { return spans.doc(); }
    public int start() { return spans.start(); }
    public int end() { return spans.end(); }

    public String toString() { return spans.toString() + ""#"" + index; }
  }


  public NearSpansUnordered(SpanNearQuery query, IndexReader reader)
    throws IOException {
    this.query = query;
    this.slop = query.getSlop();

    SpanQuery[] clauses = query.getClauses();
    queue = new CellQueue(clauses.length);
    for (int i = 0; i < clauses.length; i++) {
      SpansCell cell =
        new SpansCell(clauses[i].getSpans(reader), i);
      ordered.add(cell);
    }
  }

  public boolean next() throws IOException {
    if (firstTime) {
      initList(true);
      listToQueue(); 
      firstTime = false;
    } else if (more) {
      if (min().next()) { 
        queue.adjustTop(); 
      } else {
        more = false;
      }
    }

    while (more) {

      boolean queueStale = false;

      if (min().doc() != max.doc()) {             
        queueToList();
        queueStale = true;
      }

      

      while (more && first.doc() < last.doc()) {
        more = first.skipTo(last.doc());          
        firstToLast();                            
        queueStale = true;
      }

      if (!more) return false;

      

      if (queueStale) {                           
        listToQueue();
        queueStale = false;
      }

      if (atMatch()) {
        return true;
      }
      
      more = min().next();
      if (more) {
        queue.adjustTop();                      
      }
    }
    return false;                                 
  }

  public boolean skipTo(int target) throws IOException {
    if (firstTime) {                              
      initList(false);
      for (SpansCell cell = first; more && cell!=null; cell=cell.next) {
        more = cell.skipTo(target);               
      }
      if (more) {
        listToQueue();
      }
      firstTime = false;
    } else {                                      
      while (more && min().doc() < target) {      
        if (min().skipTo(target)) {
          queue.adjustTop();
        } else {
          more = false;
        }
      }
    }
    return more && (atMatch() ||  next());
  }

  private SpansCell min() { return (SpansCell)queue.top(); }

  public int doc() { return min().doc(); }
  public int start() { return min().start(); }
  public int end() { return max.end(); }


  public String toString() {
    return getClass().getName() + ""(""+query.toString()+"")@""+
      (firstTime?""START"":(more?(doc()+"":""+start()+""-""+end()):""END""));
  }

  private void initList(boolean next) throws IOException {
    for (int i = 0; more && i < ordered.size(); i++) {
      SpansCell cell = (SpansCell)ordered.get(i);
      if (next)
        more = cell.next();                       
      if (more) {
        addToList(cell);                          
      }
    }
  }

  private void addToList(SpansCell cell) {
    if (last != null) {			  
      last.next = cell;
    } else
      first = cell;
    last = cell;
    cell.next = null;
  }

  private void firstToLast() {
    last.next = first;			  
    last = first;
    first = first.next;
    last.next = null;
  }

  private void queueToList() {
    last = first = null;
    while (queue.top() != null) {
      addToList((SpansCell)queue.pop());
    }
  }
  
  private void listToQueue() {
    queue.clear(); 
    for (SpansCell cell = first; cell != null; cell = cell.next) {
      queue.put(cell);                      
    }
  }

  private boolean atMatch() {
    return (min().doc() == max.doc())
        && ((max.end() - min().start() - totalLength) <= slop);
  }
}
"
lucene,2.2,org.apache.lucene.document.Fieldable,18,1,0,10,18,153,9,1,18,2.0,18,0.0,0,0.0,0.37037037,0,0,0.0,1,1.0,2,"package org.apache.lucene.document;



import java.io.Reader;
import java.io.Serializable;

import org.apache.lucene.analysis.TokenStream;


public interface Fieldable extends Serializable {
  
  void setBoost(float boost);

  
  float getBoost();

  
  String name();

  
  public String stringValue();
  
  
  public Reader readerValue();
  
  
  public byte[] binaryValue();
  
  
  public TokenStream tokenStreamValue();

  
  boolean  isStored();

  
  boolean  isIndexed();

  
  boolean  isTokenized();

  
  boolean  isCompressed();

  
  boolean isTermVectorStored();

  
  boolean isStoreOffsetWithTermVector();

  
  boolean isStorePositionWithTermVector();

  
  boolean  isBinary();

  
  boolean getOmitNorms();

  
  void setOmitNorms(boolean omitNorms);

  
  boolean isLazy();
}
"
lucene,2.2,org.apache.lucene.search.Hits,11,1,0,13,28,19,3,12,5,0.64,338,1.0,6,0.0,0.324675325,0,0,28.81818182,4,1.1818,2,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Vector;
import java.util.Iterator;

import org.apache.lucene.document.Document;
import org.apache.lucene.index.CorruptIndexException;


public final class Hits {
  private Weight weight;
  private Searcher searcher;
  private Filter filter = null;
  private Sort sort = null;

  private int length;				  
  private Vector hitDocs = new Vector();	  

  private HitDoc first;         
  private HitDoc last;          
  private int numDocs = 0;      
  private int maxDocs = 200;    

  Hits(Searcher s, Query q, Filter f) throws IOException {
    weight = q.weight(s);
    searcher = s;
    filter = f;
    getMoreDocs(50); 
  }

  Hits(Searcher s, Query q, Filter f, Sort o) throws IOException {
    weight = q.weight(s);
    searcher = s;
    filter = f;
    sort = o;
    getMoreDocs(50); 
  }

  
  private final void getMoreDocs(int min) throws IOException {
    if (hitDocs.size() > min) {
      min = hitDocs.size();
    }

    int n = min * 2;	
    TopDocs topDocs = (sort == null) ? searcher.search(weight, filter, n) : searcher.search(weight, filter, n, sort);
    length = topDocs.totalHits;
    ScoreDoc[] scoreDocs = topDocs.scoreDocs;

    float scoreNorm = 1.0f;
    
    if (length > 0 && topDocs.getMaxScore() > 1.0f) {
      scoreNorm = 1.0f / topDocs.getMaxScore();
    }

    int end = scoreDocs.length < length ? scoreDocs.length : length;
    for (int i = hitDocs.size(); i < end; i++) {
      hitDocs.addElement(new HitDoc(scoreDocs[i].score * scoreNorm,
                                    scoreDocs[i].doc));
    }
  }

  
  public final int length() {
    return length;
  }

  
  public final Document doc(int n) throws CorruptIndexException, IOException {
    HitDoc hitDoc = hitDoc(n);

    
    remove(hitDoc);               
    addToFront(hitDoc);           
    if (numDocs > maxDocs) {      
      HitDoc oldLast = last;
      remove(last);             
      oldLast.doc = null;       
    }

    if (hitDoc.doc == null) {
      hitDoc.doc = searcher.doc(hitDoc.id);  
    }

    return hitDoc.doc;
  }

  
  public final float score(int n) throws IOException {
    return hitDoc(n).score;
  }

  
  public final int id(int n) throws IOException {
    return hitDoc(n).id;
  }

  
  public Iterator iterator() {
    return new HitIterator(this);
  }

  private final HitDoc hitDoc(int n) throws IOException {
    if (n >= length) {
      throw new IndexOutOfBoundsException(""Not a valid hit number: "" + n);
    }

    if (n >= hitDocs.size()) {
      getMoreDocs(n);
    }

    return (HitDoc) hitDocs.elementAt(n);
  }

  private final void addToFront(HitDoc hitDoc) {  
    if (first == null) {
      last = hitDoc;
    } else {
      first.prev = hitDoc;
    }

    hitDoc.next = first;
    first = hitDoc;
    hitDoc.prev = null;

    numDocs++;
  }

  private final void remove(HitDoc hitDoc) {	  
    if (hitDoc.doc == null) {     
      return;					  
    }

    if (hitDoc.next == null) {
      last = hitDoc.prev;
    } else {
      hitDoc.next.prev = hitDoc.prev;
    }

    if (hitDoc.prev == null) {
      first = hitDoc.next;
    } else {
      hitDoc.prev.next = hitDoc.next;
    }

    numDocs--;
  }
}

final class HitDoc {
  float score;
  int id;
  Document doc = null;

  HitDoc next;  
  HitDoc prev;  

  HitDoc(float s, int i) {
    score = s;
    id = i;
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.Token,3,1,0,4,4,3,4,0,3,1.4375,23,0.0,2,0.0,0.5,0,0,4.0,2,1.0,1,"
package org.apache.lucene.queryParser;



public class Token {

  
  public int kind;

  
  public int beginLine, beginColumn, endLine, endColumn;

  
  public String image;

  
  public Token next;

  
  public Token specialToken;

  
  public String toString()
  {
     return image;
  }

  
  public static final Token newToken(int ofKind)
  {
     switch(ofKind)
     {
       default : return new Token();
     }
  }

}
"
lucene,2.2,org.apache.lucene.search.spans.SpanTermQuery,9,3,1,8,27,0,1,7,9,0.0,116,1.0,1,0.666666667,0.259259259,2,2,11.77777778,4,1.3333,0,"package org.apache.lucene.search.spans;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Set;


public class SpanTermQuery extends SpanQuery {
  protected Term term;

  
  public SpanTermQuery(Term term) { this.term = term; }

  
  public Term getTerm() { return term; }

  public String getField() { return term.field(); }
  
  
  public Collection getTerms() {
    Collection terms = new ArrayList();
    terms.add(term);
    return terms;
  }
  public void extractTerms(Set terms) {
	  terms.add(term);
  }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    if (term.field().equals(field))
      buffer.append(term.text());
    else
      buffer.append(term.toString());
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof SpanTermQuery))
      return false;
    SpanTermQuery other = (SpanTermQuery)o;
    return (this.getBoost() == other.getBoost())
      && this.term.equals(other.term);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ term.hashCode() ^ 0xD23FE494;
  }

  public Spans getSpans(final IndexReader reader) throws IOException {
    return new TermSpans(reader.termPositions(term), term);
  }

}
"
lucene,2.2,org.apache.lucene.util.StringHelper,2,1,0,2,5,1,2,0,1,2.0,36,0.0,0,0.0,0.5,0,0,17.0,4,2.0,0,"package org.apache.lucene.util;





public abstract class StringHelper {

  
  public static final int stringDifference(String s1, String s2) {
    int len1 = s1.length();
    int len2 = s2.length();
    int len = len1 < len2 ? len1 : len2;
    for (int i = 0; i < len; i++) {
      if (s1.charAt(i) != s2.charAt(i)) {
	      return i;
      }
    }
    return len;
  }


  private StringHelper() {
  }
}
"
lucene,2.2,org.apache.lucene.store.RAMInputStream,8,2,0,3,13,0,1,2,7,0.5,204,0.875,1,0.666666667,0.3,1,4,23.5,2,1.0,3,"package org.apache.lucene.store;

import java.io.IOException;





class RAMInputStream extends IndexInput implements Cloneable {
  static final int BUFFER_SIZE = RAMOutputStream.BUFFER_SIZE;

  private RAMFile file;
  private long length;

  private byte[] currentBuffer;
  private int currentBufferIndex;
  
  private int bufferPosition;
  private long bufferStart;
  private int bufferLength;

  public RAMInputStream(RAMFile f) {
    file = f;
    length = file.length;

    
    
    currentBufferIndex = -1;
    currentBuffer = null;
  }

  public void close() {
    
  }

  public long length() {
    return length;
  }

  public byte readByte() throws IOException {
    if (bufferPosition >= bufferLength) {
      currentBufferIndex++;
      switchCurrentBuffer();
    }
    return currentBuffer[bufferPosition++];
  }

  public void readBytes(byte[] b, int offset, int len) throws IOException {
    while (len > 0) {
      if (bufferPosition >= bufferLength) {
        currentBufferIndex++;
        switchCurrentBuffer();
      }

      int remainInBuffer = bufferLength - bufferPosition;
      int bytesToCopy = len < remainInBuffer ? len : remainInBuffer;
      System.arraycopy(currentBuffer, bufferPosition, b, offset, bytesToCopy);
      offset += bytesToCopy;
      len -= bytesToCopy;
      bufferPosition += bytesToCopy;
    }
  }

  private final void switchCurrentBuffer() throws IOException {
    if (currentBufferIndex >= file.buffers.size()) {
      
      throw new IOException(""Read past EOF"");
    } else {
      currentBuffer = (byte[]) file.buffers.get(currentBufferIndex);
      bufferPosition = 0;
      bufferStart = BUFFER_SIZE * currentBufferIndex;
      bufferLength = (int) (length - bufferStart);
      if (bufferLength > BUFFER_SIZE) {
        bufferLength = BUFFER_SIZE;
      }
    }
  }

  public long getFilePointer() {
    return currentBufferIndex < 0 ? 0 : bufferStart + bufferPosition;
  }

  public void seek(long pos) throws IOException {
    long bufferStart = currentBufferIndex * BUFFER_SIZE;
    if (pos < bufferStart || pos >= bufferStart + BUFFER_SIZE) {
      currentBufferIndex = (int) (pos / BUFFER_SIZE);
      switchCurrentBuffer();
    }
    bufferPosition = (int) (pos % BUFFER_SIZE);
  }
}
"
lucene,2.2,org.apache.lucene.search.CachingWrapperFilter,5,2,1,3,16,0,1,2,5,0.5,102,1.0,1,0.2,0.4,1,1,19.0,2,1.0,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import java.util.BitSet;
import java.util.WeakHashMap;
import java.util.Map;
import java.io.IOException;


public class CachingWrapperFilter extends Filter {
  protected Filter filter;

  
  protected transient Map cache;

  
  public CachingWrapperFilter(Filter filter) {
    this.filter = filter;
  }

  public BitSet bits(IndexReader reader) throws IOException {
    if (cache == null) {
      cache = new WeakHashMap();
    }

    synchronized (cache) {  
      BitSet cached = (BitSet) cache.get(reader);
      if (cached != null) {
        return cached;
      }
    }

    final BitSet bits = filter.bits(reader);

    synchronized (cache) {  
      cache.put(reader, bits);
    }

    return bits;
  }

  public String toString() {
    return ""CachingWrapperFilter(""+filter+"")"";
  }

  public boolean equals(Object o) {
    if (!(o instanceof CachingWrapperFilter)) return false;
    return this.filter.equals(((CachingWrapperFilter)o).filter);
  }

  public int hashCode() {
    return filter.hashCode() ^ 0x1117BF25;  
  }
}
"
lucene,2.2,org.apache.lucene.index.TermPositionVector,2,1,0,4,2,1,2,2,2,2.0,2,0.0,0,0.0,1.0,0,0,0.0,1,1.0,0,"package org.apache.lucene.index;




public interface TermPositionVector extends TermFreqVector {
  
    
    public int[] getTermPositions(int index);
  
     
    public TermVectorOffsetInfo [] getOffsets(int index);
}"
lucene,2.2,org.apache.lucene.store.RAMFile,8,1,0,3,12,6,3,1,0,0.80952381,115,0.333333333,1,0.0,0.375,0,0,12.625,2,0.875,2,"package org.apache.lucene.store;



import java.util.ArrayList;
import java.io.Serializable;

class RAMFile implements Serializable {

  private static final long serialVersionUID = 1l;

  
  ArrayList buffers = new ArrayList();
  long length;
  RAMDirectory directory;
  long sizeInBytes;                  

  
  private long lastModified = System.currentTimeMillis();

  
  RAMFile() {}
  
  RAMFile(RAMDirectory directory) {
    this.directory = directory;
  }

  
  synchronized long getLength() {
    return length;
  }

  synchronized void setLength(long length) {
    this.length = length;
  }

  
  synchronized long getLastModified() {
    return lastModified;
  }

  synchronized void setLastModified(long lastModified) {
    this.lastModified = lastModified;
  }

  
  final byte[] addBuffer(int size) {
    byte[] buffer = new byte[size];
    if (directory!=null)
      synchronized (directory) {             
        buffers.add(buffer);
        directory.sizeInBytes += size;
        sizeInBytes += size;
      }
    else
      buffers.add(buffer);
    return buffer;
  }

  
  long getSizeInBytes() {
    synchronized (directory) {
      return sizeInBytes;
    }
  }
  
}
"
lucene,2.2,org.apache.lucene.analysis.StopFilter,7,3,0,5,13,15,2,3,7,0.333333333,106,1.0,0,0.571428571,0.514285714,0,0,13.85714286,3,0.7143,4,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.util.HashSet;
import java.util.Set;



public final class StopFilter extends TokenFilter {

  private final Set stopWords;
  private final boolean ignoreCase;

    
    public StopFilter(TokenStream input, String [] stopWords)
    {
        this(input, stopWords, false);
    }

  
  public StopFilter(TokenStream in, String[] stopWords, boolean ignoreCase) {
    super(in);
    this.ignoreCase = ignoreCase;
    this.stopWords = makeStopSet(stopWords, ignoreCase);
  }


    
    public StopFilter(TokenStream input, Set stopWords, boolean ignoreCase)
    {
        super(input);
        this.ignoreCase = ignoreCase;
        this.stopWords = stopWords;
    }

  
  public StopFilter(TokenStream in, Set stopWords) {
    this(in, stopWords, false);
  }

  
  public static final Set makeStopSet(String[] stopWords) {
    return makeStopSet(stopWords, false);
  }
    
      
  public static final Set makeStopSet(String[] stopWords, boolean ignoreCase) {
    HashSet stopTable = new HashSet(stopWords.length);
    for (int i = 0; i < stopWords.length; i++)
      stopTable.add(ignoreCase ? stopWords[i].toLowerCase() : stopWords[i]);
    return stopTable;
  }    

  
  public final Token next() throws IOException {
    
    for (Token token = input.next(); token != null; token = input.next())
    {
        String termText = ignoreCase ? token.termText.toLowerCase() : token.termText;
        if (!stopWords.contains(termText))
          return token;
    }
    
    return null;
  }
}
"
lucene,2.2,org.apache.lucene.util.ScorerDocQueue,16,1,0,3,24,0,2,2,12,0.383333333,361,1.0,2,0.0,0.328125,0,0,21.3125,7,1.75,0,"package org.apache.lucene.util;





import java.io.IOException;
import org.apache.lucene.search.Scorer;


public class ScorerDocQueue {  
  private final HeapedScorerDoc[] heap;
  private final int maxSize;
  private int size;
  
  private class HeapedScorerDoc {
    Scorer scorer;
    int doc;
    
    HeapedScorerDoc(Scorer s) { this(s, s.doc()); }
    
    HeapedScorerDoc(Scorer scorer, int doc) {
      this.scorer = scorer;
      this.doc = doc;
    }
    
    void adjust() { doc = scorer.doc(); }
  }
  
  private HeapedScorerDoc topHSD; 

  
  public ScorerDocQueue(int maxSize) {
    
    size = 0;
    int heapSize = maxSize + 1;
    heap = new HeapedScorerDoc[heapSize];
    this.maxSize = maxSize;
    topHSD = heap[1]; 
  }

  
  public final void put(Scorer scorer) {
    size++;
    heap[size] = new HeapedScorerDoc(scorer);
    upHeap();
  }

  
  public boolean insert(Scorer scorer){
    if (size < maxSize) {
      put(scorer);
      return true;
    } else {
      int docNr = scorer.doc();
      if ((size > 0) && (! (docNr < topHSD.doc))) { 
        heap[1] = new HeapedScorerDoc(scorer, docNr);
        downHeap();
        return true;
      } else {
        return false;
      }
    }
   }

  
  public final Scorer top() {
    
    return topHSD.scorer;
  }

  
  public final int topDoc() {
    
    return topHSD.doc;
  }
  
  public final float topScore() throws IOException {
    
    return topHSD.scorer.score();
  }

  public final boolean topNextAndAdjustElsePop() throws IOException {
    return checkAdjustElsePop( topHSD.scorer.next());
  }

  public final boolean topSkipToAndAdjustElsePop(int target) throws IOException {
    return checkAdjustElsePop( topHSD.scorer.skipTo(target));
  }
  
  private boolean checkAdjustElsePop(boolean cond) {
    if (cond) { 
      topHSD.doc = topHSD.scorer.doc();
    } else { 
      heap[1] = heap[size]; 
      heap[size] = null;
      size--;
    }
    downHeap();
    return cond;
  }

  
  public final Scorer pop() {
    
    Scorer result = topHSD.scorer;
    popNoResult();
    return result;
  }
  
  
  private final void popNoResult() {
    heap[1] = heap[size]; 
    heap[size] = null;
    size--;
    downHeap();	
  }

  
  public final void adjustTop() {
    
    topHSD.adjust();
    downHeap();
  }

  
  public final int size() {
    return size;
  }

  
  public final void clear() {
    for (int i = 0; i <= size; i++) {
      heap[i] = null;
    }
    size = 0;
  }

  private final void upHeap() {
    int i = size;
    HeapedScorerDoc node = heap[i];		  
    int j = i >>> 1;
    while ((j > 0) && (node.doc < heap[j].doc)) {
      heap[i] = heap[j];			  
      i = j;
      j = j >>> 1;
    }
    heap[i] = node;				  
    topHSD = heap[1];
  }

  private final void downHeap() {
    int i = 1;
    HeapedScorerDoc node = heap[i];	          
    int j = i << 1;				  
    int k = j + 1;
    if ((k <= size) && (heap[k].doc < heap[j].doc)) {
      j = k;
    }
    while ((j <= size) && (heap[j].doc < node.doc)) {
      heap[i] = heap[j];			  
      i = j;
      j = i << 1;
      k = j + 1;
      if (k <= size && (heap[k].doc < heap[j].doc)) {
	j = k;
      }
    }
    heap[i] = node;				  
    topHSD = heap[1];
  }
}
"
lucene,2.2,org.apache.lucene.search.DefaultSimilarity,7,2,0,3,10,21,3,1,7,2.0,54,0.0,0,0.714285714,0.5,1,2,6.714285714,1,0.8571,0,"package org.apache.lucene.search;




public class DefaultSimilarity extends Similarity {
  
  public float lengthNorm(String fieldName, int numTerms) {
    return (float)(1.0 / Math.sqrt(numTerms));
  }
  
  
  public float queryNorm(float sumOfSquaredWeights) {
    return (float)(1.0 / Math.sqrt(sumOfSquaredWeights));
  }

  
  public float tf(float freq) {
    return (float)Math.sqrt(freq);
  }
    
  
  public float sloppyFreq(int distance) {
    return 1.0f / (distance + 1);
  }
    
  
  public float idf(int docFreq, int numDocs) {
    return (float)(Math.log(numDocs/(double)(docFreq+1)) + 1.0);
  }
    
  
  public float coord(int overlap, int maxOverlap) {
    return overlap / (float)maxOverlap;
  }
}
"
lucene,2.2,org.apache.lucene.search.ConstantScoreRangeQuery,10,2,0,6,24,0,1,5,10,0.444444444,313,1.0,0,0.571428571,0.3,2,3,29.8,13,3.1,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;



public class ConstantScoreRangeQuery extends Query
{
  private final String fieldName;
  private final String lowerVal;
  private final String upperVal;
  private final boolean includeLower;
  private final boolean includeUpper;


  public ConstantScoreRangeQuery(String fieldName, String lowerVal, String upperVal, boolean includeLower, boolean includeUpper)
  {
    
    
    if (lowerVal==null) {
      includeLower=true;
    } else if (includeLower && lowerVal.equals("""")) {
      lowerVal=null;
    }
    if (upperVal==null) {
      includeUpper=true;
    }


    this.fieldName = fieldName.intern();  
    this.lowerVal = lowerVal;
    this.upperVal = upperVal;
    this.includeLower = includeLower;
    this.includeUpper = includeUpper;
  }

  
  public String getField() { return fieldName; }
  
  public String getLowerVal() { return lowerVal; }
  
  public String getUpperVal() { return upperVal; }
  
  public boolean includesLower() { return includeLower; }
  
  public boolean includesUpper() { return includeUpper; }

  public Query rewrite(IndexReader reader) throws IOException {
    
    RangeFilter rangeFilt = new RangeFilter(fieldName,
            lowerVal!=null?lowerVal:"""",
            upperVal, lowerVal==""""?false:includeLower, upperVal==null?false:includeUpper);
    Query q = new ConstantScoreQuery(rangeFilt);
    q.setBoost(getBoost());
    return q;
  }

    
    public String toString(String field)
    {
        StringBuffer buffer = new StringBuffer();
        if (!getField().equals(field))
        {
            buffer.append(getField());
            buffer.append("":"");
        }
        buffer.append(includeLower ? '[' : '{');
        buffer.append(lowerVal != null ? lowerVal : ""*"");
        buffer.append("" TO "");
        buffer.append(upperVal != null ? upperVal : ""*"");
        buffer.append(includeUpper ? ']' : '}');
        if (getBoost() != 1.0f)
        {
            buffer.append(""^"");
            buffer.append(Float.toString(getBoost()));
        }
        return buffer.toString();
    }

    
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof ConstantScoreRangeQuery)) return false;
        ConstantScoreRangeQuery other = (ConstantScoreRangeQuery) o;

        if (this.fieldName != other.fieldName  
            || this.includeLower != other.includeLower
            || this.includeUpper != other.includeUpper
           ) { return false; }
        if (this.lowerVal != null ? !this.lowerVal.equals(other.lowerVal) : other.lowerVal != null) return false;
        if (this.upperVal != null ? !this.upperVal.equals(other.upperVal) : other.upperVal != null) return false;
        return this.getBoost() == other.getBoost();
    }

    
    public int hashCode() {
      int h = Float.floatToIntBits(getBoost()) ^ fieldName.hashCode();
      
      h ^= lowerVal != null ? lowerVal.hashCode() : 0x965a965a;
      
      
      h ^= (h << 17) | (h >>> 16);  
      h ^= (upperVal != null ? (upperVal.hashCode()) : 0x5a695a69);
      h ^= (includeLower ? 0x665599aa : 0)
         ^ (includeUpper ? 0x99aa5566 : 0);
      return h;
    }
}
"
lucene,2.2,org.apache.lucene.analysis.TokenFilter,2,2,7,8,4,0,7,1,1,0.0,13,1.0,1,0.75,0.75,0,0,5.0,1,0.5,2,"package org.apache.lucene.analysis;



import java.io.IOException;


public abstract class TokenFilter extends TokenStream {
  
  protected TokenStream input;

  
  protected TokenFilter(TokenStream input) {
    this.input = input;
  }

  
  public void close() throws IOException {
    input.close();
  }

}
"
lucene,2.2,org.apache.lucene.search.PhraseQueue,2,2,0,5,4,1,3,2,0,2.0,51,0.0,0,0.916666667,0.666666667,1,3,24.5,6,3.0,0,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;

final class PhraseQueue extends PriorityQueue {
  PhraseQueue(int size) {
    initialize(size);
  }

  protected final boolean lessThan(Object o1, Object o2) {
    PhrasePositions pp1 = (PhrasePositions)o1;
    PhrasePositions pp2 = (PhrasePositions)o2;
    if (pp1.doc == pp2.doc) 
      if (pp1.position == pp2.position)
        
        
        return pp1.offset < pp2.offset;
      else
        return pp1.position < pp2.position;
    else
      return pp1.doc < pp2.doc;
  }
}
"
lucene,2.2,org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy,3,1,0,4,7,3,2,2,3,2.0,28,0.0,0,0.0,0.833333333,0,0,8.333333333,2,1.0,1,"package org.apache.lucene.index;



import java.util.List;



public final class KeepOnlyLastCommitDeletionPolicy implements IndexDeletionPolicy {

  
  public void onInit(List commits) {
    
    onCommit(commits);
  }

  
  public void onCommit(List commits) {
    
    
    int size = commits.size();
    for(int i=0;i<size-1;i++) {
      ((IndexCommitPoint) commits.get(i)).delete();
    }
  }
}
"
lucene,2.2,org.apache.lucene.analysis.standard.StandardAnalyzer,7,2,0,8,15,0,0,8,6,0.5,67,0.5,0,0.666666667,0.333333333,0,0,8.285714286,1,0.1429,6,"package org.apache.lucene.analysis.standard;



import org.apache.lucene.analysis.*;

import java.io.File;
import java.io.IOException;
import java.io.Reader;
import java.util.Set;


public class StandardAnalyzer extends Analyzer {
  private Set stopSet;

  
  public static final String[] STOP_WORDS = StopAnalyzer.ENGLISH_STOP_WORDS;

  
  public StandardAnalyzer() {
    this(STOP_WORDS);
  }

  
  public StandardAnalyzer(Set stopWords) {
    stopSet = stopWords;
  }

  
  public StandardAnalyzer(String[] stopWords) {
    stopSet = StopFilter.makeStopSet(stopWords);
  }

  
  public StandardAnalyzer(File stopwords) throws IOException {
    stopSet = WordlistLoader.getWordSet(stopwords);
  }

  
  public StandardAnalyzer(Reader stopwords) throws IOException {
    stopSet = WordlistLoader.getWordSet(stopwords);
  }

  
  public TokenStream tokenStream(String fieldName, Reader reader) {
    TokenStream result = new StandardTokenizer(reader);
    result = new StandardFilter(result);
    result = new LowerCaseFilter(result);
    result = new StopFilter(result, stopSet);
    return result;
  }
}
"
lucene,2.2,org.apache.lucene.store.RAMOutputStream,13,2,0,4,25,0,2,2,10,0.523809524,292,0.857142857,1,0.56,0.208791209,1,3,20.92307692,2,1.0,4,"package org.apache.lucene.store;



import java.io.IOException;



public class RAMOutputStream extends IndexOutput {
  static final int BUFFER_SIZE = 1024;

  private RAMFile file;

  private byte[] currentBuffer;
  private int currentBufferIndex;
  
  private int bufferPosition;
  private long bufferStart;
  private int bufferLength;

  
  public RAMOutputStream() {
    this(new RAMFile());
  }

  RAMOutputStream(RAMFile f) {
    file = f;

    
    
    currentBufferIndex = -1;
    currentBuffer = null;
  }

  
  public void writeTo(IndexOutput out) throws IOException {
    flush();
    final long end = file.length;
    long pos = 0;
    int buffer = 0;
    while (pos < end) {
      int length = BUFFER_SIZE;
      long nextPos = pos + length;
      if (nextPos > end) {                        
        length = (int)(end - pos);
      }
      out.writeBytes((byte[])file.buffers.get(buffer++), length);
      pos = nextPos;
    }
  }

  
  public void reset() {
    try {
      seek(0);
    } catch (IOException e) {                     
      throw new RuntimeException(e.toString());
    }

    file.setLength(0);
  }

  public void close() throws IOException {
    flush();
  }

  public void seek(long pos) throws IOException {
    
    
    setFileLength();
    if (pos < bufferStart || pos >= bufferStart + bufferLength) {
      currentBufferIndex = (int) (pos / BUFFER_SIZE);
      switchCurrentBuffer();
    }

    bufferPosition = (int) (pos % BUFFER_SIZE);
  }

  public long length() {
    return file.length;
  }

  public void writeByte(byte b) throws IOException {
    if (bufferPosition == bufferLength) {
      currentBufferIndex++;
      switchCurrentBuffer();
    }
    currentBuffer[bufferPosition++] = b;
  }

  public void writeBytes(byte[] b, int offset, int len) throws IOException {
    while (len > 0) {
      if (bufferPosition ==  bufferLength) {
        currentBufferIndex++;
        switchCurrentBuffer();
      }

      int remainInBuffer = currentBuffer.length - bufferPosition;
      int bytesToCopy = len < remainInBuffer ? len : remainInBuffer;
      System.arraycopy(b, offset, currentBuffer, bufferPosition, bytesToCopy);
      offset += bytesToCopy;
      len -= bytesToCopy;
      bufferPosition += bytesToCopy;
    }
  }

  private final void switchCurrentBuffer() throws IOException {
    if (currentBufferIndex == file.buffers.size()) {
      currentBuffer = file.addBuffer(BUFFER_SIZE);
    } else {
      currentBuffer = (byte[]) file.buffers.get(currentBufferIndex);
    }
    bufferPosition = 0;
    bufferStart = BUFFER_SIZE * currentBufferIndex;
    bufferLength = currentBuffer.length;
  }

  private void setFileLength() {
    long pointer = bufferStart + bufferPosition;
    if (pointer > file.length) {
      file.setLength(pointer);
    }
  }

  public void flush() throws IOException {
    file.setLastModified(System.currentTimeMillis());
    setFileLength();
  }

  public long getFilePointer() {
    return currentBufferIndex < 0 ? 0 : bufferStart + bufferPosition;
  }
}
"
lucene,2.2,org.apache.lucene.store.AlreadyClosedException,1,5,0,4,2,0,4,0,1,2.0,5,0.0,0,1.0,1.0,0,0,4.0,0,0.0,0,"package org.apache.lucene.store;




public class AlreadyClosedException extends IllegalStateException {
  public AlreadyClosedException(String message) {
    super(message);
  }
}
"
lucene,2.2,org.apache.lucene.search.spans.Spans,5,1,0,20,5,10,20,0,5,2.0,5,0.0,0,0.0,0.6,0,0,0.0,1,1.0,0,"package org.apache.lucene.search.spans;



import java.io.IOException;


public interface Spans {
  
  boolean next() throws IOException;

  
  boolean skipTo(int target) throws IOException;

  
  int doc();

  
  int start();

  
  int end();

}
"
lucene,2.2,org.apache.lucene.index.SegmentMergeInfo,5,1,0,7,14,0,3,4,0,0.75,108,0.333333333,4,0.0,0.4,0,0,19.4,5,1.6,0,"package org.apache.lucene.index;



import java.io.IOException;

final class SegmentMergeInfo {
  Term term;
  int base;
  TermEnum termEnum;
  IndexReader reader;
  private TermPositions postings;  
  private int[] docMap;  

  SegmentMergeInfo(int b, TermEnum te, IndexReader r)
    throws IOException {
    base = b;
    reader = r;
    termEnum = te;
    term = te.term();
  }

  
  int[] getDocMap() {
    if (docMap == null) {
    
    if (reader.hasDeletions()) {
      int maxDoc = reader.maxDoc();
      docMap = new int[maxDoc];
      int j = 0;
      for (int i = 0; i < maxDoc; i++) {
        if (reader.isDeleted(i))
          docMap[i] = -1;
        else
          docMap[i] = j++;
      }
    }
  }
    return docMap;
  }

  TermPositions getPositions() throws IOException {
    if (postings == null) {
      postings = reader.termPositions();
    }
    return postings;
  }

  final boolean next() throws IOException {
    if (termEnum.next()) {
      term = termEnum.term();
      return true;
    } else {
      term = null;
      return false;
    }
  }

  final void close() throws IOException {
    termEnum.close();
    if (postings != null) {
    postings.close();
  }
}
}

"
lucene,2.2,org.apache.lucene.index.SegmentTermDocs,12,1,1,13,33,12,2,12,8,0.690909091,377,0.866666667,4,0.0,0.21875,0,0,29.16666667,1,0.9167,0,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.util.BitVector;
import org.apache.lucene.store.IndexInput;

class SegmentTermDocs implements TermDocs {
  protected SegmentReader parent;
  protected IndexInput freqStream;
  protected int count;
  protected int df;
  protected BitVector deletedDocs;
  int doc = 0;
  int freq;

  private int skipInterval;
  private int maxSkipLevels;
  private DefaultSkipListReader skipListReader;
  
  private long freqBasePointer;
  private long proxBasePointer;

  private long skipPointer;
  private boolean haveSkipped;
  
  protected boolean currentFieldStoresPayloads;

  protected SegmentTermDocs(SegmentReader parent) {
    this.parent = parent;
    this.freqStream = (IndexInput) parent.freqStream.clone();
    this.deletedDocs = parent.deletedDocs;
    this.skipInterval = parent.tis.getSkipInterval();
    this.maxSkipLevels = parent.tis.getMaxSkipLevels();
  }

  public void seek(Term term) throws IOException {
    TermInfo ti = parent.tis.get(term);
    seek(ti, term);
  }

  public void seek(TermEnum termEnum) throws IOException {
    TermInfo ti;
    Term term;
    
    
    if (termEnum instanceof SegmentTermEnum && ((SegmentTermEnum) termEnum).fieldInfos == parent.fieldInfos) {        
      SegmentTermEnum segmentTermEnum = ((SegmentTermEnum) termEnum);
      term = segmentTermEnum.term();
      ti = segmentTermEnum.termInfo();
    } else  {                                         
      term = termEnum.term();
      ti = parent.tis.get(term);        
    }
    
    seek(ti, term);
  }

  void seek(TermInfo ti, Term term) throws IOException {
    count = 0;
    FieldInfo fi = parent.fieldInfos.fieldInfo(term.field);
    currentFieldStoresPayloads = (fi != null) ? fi.storePayloads : false;
    if (ti == null) {
      df = 0;
    } else {
      df = ti.docFreq;
      doc = 0;
      freqBasePointer = ti.freqPointer;
      proxBasePointer = ti.proxPointer;
      skipPointer = freqBasePointer + ti.skipOffset;
      freqStream.seek(freqBasePointer);
      haveSkipped = false;
    }
  }

  public void close() throws IOException {
    freqStream.close();
    if (skipListReader != null)
      skipListReader.close();
  }

  public final int doc() { return doc; }
  public final int freq() { return freq; }

  protected void skippingDoc() throws IOException {
  }

  public boolean next() throws IOException {
    while (true) {
      if (count == df)
        return false;

      int docCode = freqStream.readVInt();
      doc += docCode >>> 1;       
      if ((docCode & 1) != 0)       
        freq = 1;         
      else
        freq = freqStream.readVInt();     

      count++;

      if (deletedDocs == null || !deletedDocs.get(doc))
        break;
      skippingDoc();
    }
    return true;
  }

  
  public int read(final int[] docs, final int[] freqs)
          throws IOException {
    final int length = docs.length;
    int i = 0;
    while (i < length && count < df) {

      
      final int docCode = freqStream.readVInt();
      doc += docCode >>> 1;       
      if ((docCode & 1) != 0)       
        freq = 1;         
      else
        freq = freqStream.readVInt();     
      count++;

      if (deletedDocs == null || !deletedDocs.get(doc)) {
        docs[i] = doc;
        freqs[i] = freq;
        ++i;
      }
    }
    return i;
  }

  
  protected void skipProx(long proxPointer, int payloadLength) throws IOException {}

  
  public boolean skipTo(int target) throws IOException {
    if (df >= skipInterval) {                      
      if (skipListReader == null)
        skipListReader = new DefaultSkipListReader((IndexInput) freqStream.clone(), maxSkipLevels, skipInterval); 

      if (!haveSkipped) {                          
        skipListReader.init(skipPointer, freqBasePointer, proxBasePointer, df, currentFieldStoresPayloads);
        haveSkipped = true;
      }

      int newCount = skipListReader.skipTo(target); 
      if (newCount > count) {
        freqStream.seek(skipListReader.getFreqPointer());
        skipProx(skipListReader.getProxPointer(), skipListReader.getPayloadLength());

        doc = skipListReader.getDoc();
        count = newCount;
      }      
    }

    
    do {
      if (!next())
        return false;
    } while (target > doc);
    return true;
  }
}
"
lucene,2.2,org.apache.lucene.index.CompoundFileReader,16,2,0,9,40,70,2,7,16,0.72,273,1.0,2,0.548387097,0.5,1,5,15.75,1,0.875,2,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.BufferedIndexInput;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.Lock;

import java.util.HashMap;
import java.io.IOException;



class CompoundFileReader extends Directory {

    private int readBufferSize;

    private static final class FileEntry {
        long offset;
        long length;
    }


    
    private Directory directory;
    private String fileName;

    private IndexInput stream;
    private HashMap entries = new HashMap();


  public CompoundFileReader(Directory dir, String name) throws IOException {
    this(dir, name, BufferedIndexInput.BUFFER_SIZE);
  }

  public CompoundFileReader(Directory dir, String name, int readBufferSize)
    throws IOException
    {
        directory = dir;
        fileName = name;
        this.readBufferSize = readBufferSize;

        boolean success = false;

        try {
            stream = dir.openInput(name, readBufferSize);

            
            int count = stream.readVInt();
            FileEntry entry = null;
            for (int i=0; i<count; i++) {
                long offset = stream.readLong();
                String id = stream.readString();

                if (entry != null) {
                    
                    entry.length = offset - entry.offset;
                }

                entry = new FileEntry();
                entry.offset = offset;
                entries.put(id, entry);
            }

            
            if (entry != null) {
                entry.length = stream.length() - entry.offset;
            }

            success = true;

        } finally {
            if (! success && (stream != null)) {
                try {
                    stream.close();
                } catch (IOException e) { }
            }
        }
    }

    public Directory getDirectory() {
        return directory;
    }

    public String getName() {
        return fileName;
    }

    public synchronized void close() throws IOException {
        if (stream == null)
            throw new IOException(""Already closed"");

        entries.clear();
        stream.close();
        stream = null;
    }

    public synchronized IndexInput openInput(String id)
    throws IOException
    {
      
      return openInput(id, readBufferSize);
    }

    public synchronized IndexInput openInput(String id, int readBufferSize)
    throws IOException
    {
        if (stream == null)
            throw new IOException(""Stream closed"");

        FileEntry entry = (FileEntry) entries.get(id);
        if (entry == null)
            throw new IOException(""No sub-file with id "" + id + "" found"");

        return new CSIndexInput(stream, entry.offset, entry.length, readBufferSize);
    }

    
    public String[] list() {
        String res[] = new String[entries.size()];
        return (String[]) entries.keySet().toArray(res);
    }

    
    public boolean fileExists(String name) {
        return entries.containsKey(name);
    }

    
    public long fileModified(String name) throws IOException {
        return directory.fileModified(fileName);
    }

    
    public void touchFile(String name) throws IOException {
        directory.touchFile(fileName);
    }

    
    public void deleteFile(String name)
    {
        throw new UnsupportedOperationException();
    }

    
    public void renameFile(String from, String to)
    {
        throw new UnsupportedOperationException();
    }

    
    public long fileLength(String name)
    throws IOException
    {
        FileEntry e = (FileEntry) entries.get(name);
        if (e == null)
            throw new IOException(""File "" + name + "" does not exist"");
        return e.length;
    }

    
    public IndexOutput createOutput(String name)
    {
        throw new UnsupportedOperationException();
    }

    
    public Lock makeLock(String name)
    {
        throw new UnsupportedOperationException();
    }

    
    static final class CSIndexInput extends BufferedIndexInput {

        IndexInput base;
        long fileOffset;
        long length;

        CSIndexInput(final IndexInput base, final long fileOffset, final long length)
        {
            this(base, fileOffset, length, BufferedIndexInput.BUFFER_SIZE);
        }

        CSIndexInput(final IndexInput base, final long fileOffset, final long length, int readBufferSize)
        {
            super(readBufferSize);
            this.base = base;
            this.fileOffset = fileOffset;
            this.length = length;
        }

        
        protected void readInternal(byte[] b, int offset, int len)
        throws IOException
        {
            synchronized (base) {
              long start = getFilePointer();
              if(start + len > length)
                throw new IOException(""read past EOF"");
              base.seek(fileOffset + start);
              base.readBytes(b, offset, len);
            }
        }

        
        protected void seekInternal(long pos) {}

        
        public void close() {}

        public long length() {
          return length;
        }


    }
    
}
"
lucene,2.2,org.apache.lucene.search.PhraseQuery,15,2,0,9,43,0,3,7,11,0.589285714,303,1.0,0,0.461538462,0.191666667,2,3,18.93333333,6,1.8,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Set;
import java.util.Vector;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class PhraseQuery extends Query {
  private String field;
  private Vector terms = new Vector();
  private Vector positions = new Vector();
  private int slop = 0;

  
  public PhraseQuery() {}

  
  public void setSlop(int s) { slop = s; }
  
  public int getSlop() { return slop; }

  
  public void add(Term term) {
    int position = 0;
    if(positions.size() > 0)
        position = ((Integer) positions.lastElement()).intValue() + 1;

    add(term, position);
  }

  
  public void add(Term term, int position) {
      if (terms.size() == 0)
          field = term.field();
      else if (term.field() != field)
          throw new IllegalArgumentException(""All phrase terms must be in the same field: "" + term);

      terms.addElement(term);
      positions.addElement(new Integer(position));
  }

  
  public Term[] getTerms() {
    return (Term[])terms.toArray(new Term[0]);
  }

  
  public int[] getPositions() {
      int[] result = new int[positions.size()];
      for(int i = 0; i < positions.size(); i++)
          result[i] = ((Integer) positions.elementAt(i)).intValue();
      return result;
  }

  private class PhraseWeight implements Weight {
    private Similarity similarity;
    private float value;
    private float idf;
    private float queryNorm;
    private float queryWeight;

    public PhraseWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);

      idf = similarity.idf(terms, searcher);
    }

    public String toString() { return ""weight("" + PhraseQuery.this + "")""; }

    public Query getQuery() { return PhraseQuery.this; }
    public float getValue() { return value; }

    public float sumOfSquaredWeights() {
      queryWeight = idf * getBoost();             
      return queryWeight * queryWeight;           
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= queryNorm;                   
      value = queryWeight * idf;                  
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      if (terms.size() == 0)			  
        return null;

      TermPositions[] tps = new TermPositions[terms.size()];
      for (int i = 0; i < terms.size(); i++) {
        TermPositions p = reader.termPositions((Term)terms.elementAt(i));
        if (p == null)
          return null;
        tps[i] = p;
      }

      if (slop == 0)				  
        return new ExactPhraseScorer(this, tps, getPositions(), similarity,
                                     reader.norms(field));
      else
        return
          new SloppyPhraseScorer(this, tps, getPositions(), similarity, slop,
                                 reader.norms(field));

    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {

      Explanation result = new Explanation();
      result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");

      StringBuffer docFreqs = new StringBuffer();
      StringBuffer query = new StringBuffer();
      query.append('\""');
      for (int i = 0; i < terms.size(); i++) {
        if (i != 0) {
          docFreqs.append("" "");
          query.append("" "");
        }

        Term term = (Term)terms.elementAt(i);

        docFreqs.append(term.text());
        docFreqs.append(""="");
        docFreqs.append(reader.docFreq(term));

        query.append(term.text());
      }
      query.append('\""');

      Explanation idfExpl =
        new Explanation(idf, ""idf("" + field + "": "" + docFreqs + "")"");

      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

      Explanation boostExpl = new Explanation(getBoost(), ""boost"");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);
      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      
      Explanation fieldExpl = new Explanation();
      fieldExpl.setDescription(""fieldWeight(""+field+"":""+query+"" in ""+doc+
                               ""), product of:"");

      Explanation tfExpl = scorer(reader).explain(doc);
      fieldExpl.addDetail(tfExpl);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setValue(tfExpl.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);

      
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }
  }

  protected Weight createWeight(Searcher searcher) throws IOException {
    if (terms.size() == 1) {			  
      Term term = (Term)terms.elementAt(0);
      Query termQuery = new TermQuery(term);
      termQuery.setBoost(getBoost());
      return termQuery.createWeight(searcher);
    }
    return new PhraseWeight(searcher);
  }

  
  public void extractTerms(Set queryTerms) {
    queryTerms.addAll(terms);
  }

  
  public String toString(String f) {
    StringBuffer buffer = new StringBuffer();
    if (!field.equals(f)) {
      buffer.append(field);
      buffer.append("":"");
    }

    buffer.append(""\"""");
    for (int i = 0; i < terms.size(); i++) {
      buffer.append(((Term)terms.elementAt(i)).text());
      if (i != terms.size()-1)
  buffer.append("" "");
    }
    buffer.append(""\"""");

    if (slop != 0) {
      buffer.append(""~"");
      buffer.append(slop);
    }

    buffer.append(ToStringUtils.boost(getBoost()));

    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof PhraseQuery))
      return false;
    PhraseQuery other = (PhraseQuery)o;
    return (this.getBoost() == other.getBoost())
      && (this.slop == other.slop)
      &&  this.terms.equals(other.terms)
      && this.positions.equals(other.positions);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost())
      ^ slop
      ^ terms.hashCode()
      ^ positions.hashCode();
  }

}
"
lucene,2.2,org.apache.lucene.analysis.WhitespaceAnalyzer,2,2,0,3,4,1,0,3,2,2.0,10,0.0,0,0.666666667,0.666666667,0,0,4.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public final class WhitespaceAnalyzer extends Analyzer {
  public TokenStream tokenStream(String fieldName, Reader reader) {
    return new WhitespaceTokenizer(reader);
  }
}
"
lucene,2.2,org.apache.lucene.search.QueryTermVector,10,1,0,4,37,0,0,4,9,0.388888889,280,1.0,0,0.0,0.34,0,0,26.8,5,1.6,1,"package org.apache.lucene.search;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.Token;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.index.TermFreqVector;

import java.io.IOException;
import java.io.StringReader;
import java.util.*;


public class QueryTermVector implements TermFreqVector {
  private String [] terms = new String[0];
  private int [] termFreqs = new int[0];

  public String getField() { return null;  }

   
  public QueryTermVector(String [] queryTerms) {

    processTerms(queryTerms);
  }

  public QueryTermVector(String queryString, Analyzer analyzer) {    
    if (analyzer != null)
    {
      TokenStream stream = analyzer.tokenStream("""", new StringReader(queryString));
      if (stream != null)
      {
        Token next = null;
        List terms = new ArrayList();
        try {
          while ((next = stream.next()) != null)
          {
            terms.add(next.termText());
          }
          processTerms((String[])terms.toArray(new String[terms.size()]));
        } catch (IOException e) {
        }
      }
    }                                                              
  }
  
  private void processTerms(String[] queryTerms) {
    if (queryTerms != null) {
      Arrays.sort(queryTerms);
      Map tmpSet = new HashMap(queryTerms.length);
      
      List tmpList = new ArrayList(queryTerms.length);
      List tmpFreqs = new ArrayList(queryTerms.length);
      int j = 0;
      for (int i = 0; i < queryTerms.length; i++) {
        String term = queryTerms[i];
        Integer position = (Integer)tmpSet.get(term);
        if (position == null) {
          tmpSet.put(term, new Integer(j++));
          tmpList.add(term);
          tmpFreqs.add(new Integer(1));
        }       
        else {
          Integer integer = (Integer)tmpFreqs.get(position.intValue());
          tmpFreqs.set(position.intValue(), new Integer(integer.intValue() + 1));          
        }
      }
      terms = (String[])tmpList.toArray(terms);
      
      termFreqs = new int[tmpFreqs.size()];
      int i = 0;
      for (Iterator iter = tmpFreqs.iterator(); iter.hasNext();) {
        Integer integer = (Integer) iter.next();
        termFreqs[i++] = integer.intValue();
      }
    }
  }
  
  public final String toString() {
        StringBuffer sb = new StringBuffer();
        sb.append('{');
        for (int i=0; i<terms.length; i++) {
            if (i>0) sb.append("", "");
            sb.append(terms[i]).append('/').append(termFreqs[i]);
        }
        sb.append('}');
        return sb.toString();
    }
  

  public int size() {
    return terms.length;
  }

  public String[] getTerms() {
    return terms;
  }

  public int[] getTermFrequencies() {
    return termFreqs;
  }

  public int indexOf(String term) {
    int res = Arrays.binarySearch(terms, term);
        return res >= 0 ? res : -1;
  }

  public int[] indexesOf(String[] terms, int start, int len) {
    int res[] = new int[len];

    for (int i=0; i < len; i++) {
        res[i] = indexOf(terms[i]);
    }
    return res;                  
  }

}
"
lucene,2.2,org.apache.lucene.analysis.standard.TokenMgrError,6,3,0,1,19,15,1,0,4,1.12,184,0.0,0,0.8125,0.5,1,1,28.83333333,14,2.8333,0,"
package org.apache.lucene.analysis.standard;

public class TokenMgrError extends Error
{
   

   
   static final int LEXICAL_ERROR = 0;

   
   static final int STATIC_LEXER_ERROR = 1;

   
   static final int INVALID_LEXICAL_STATE = 2;

   
   static final int LOOP_DETECTED = 3;

   
   int errorCode;

   
   protected static final String addEscapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

   
   protected static String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar) {
      return(""Lexical error at line "" +
           errorLine + "", column "" +
           errorColumn + "".  Encountered: "" +
           (EOFSeen ? ""<EOF> "" : (""\"""" + addEscapes(String.valueOf(curChar)) + ""\"""") + "" ("" + (int)curChar + ""), "") +
           ""after : \"""" + addEscapes(errorAfter) + ""\"""");
   }

   
   public String getMessage() {
      return super.getMessage();
   }

   

   public TokenMgrError() {
   }

   public TokenMgrError(String message, int reason) {
      super(message);
      errorCode = reason;
   }

   public TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason) {
      this(LexicalError(EOFSeen, lexState, errorLine, errorColumn, errorAfter, curChar), reason);
   }
}
"
lucene,2.2,org.apache.lucene.index.FieldsWriter,4,1,0,8,39,0,2,6,0,0.888888889,235,0.5,3,0.0,0.375,0,0,56.25,2,1.0,7,"package org.apache.lucene.index;



import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.util.Iterator;
import java.util.zip.Deflater;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Fieldable;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;

final class FieldsWriter
{
  static final byte FIELD_IS_TOKENIZED = 0x1;
  static final byte FIELD_IS_BINARY = 0x2;
  static final byte FIELD_IS_COMPRESSED = 0x4;
  
    private FieldInfos fieldInfos;

    private IndexOutput fieldsStream;

    private IndexOutput indexStream;

    FieldsWriter(Directory d, String segment, FieldInfos fn) throws IOException {
        fieldInfos = fn;
        fieldsStream = d.createOutput(segment + "".fdt"");
        indexStream = d.createOutput(segment + "".fdx"");
    }

    final void close() throws IOException {
        fieldsStream.close();
        indexStream.close();
    }

    final void addDocument(Document doc) throws IOException {
        indexStream.writeLong(fieldsStream.getFilePointer());

        int storedCount = 0;
        Iterator fieldIterator = doc.getFields().iterator();
        while (fieldIterator.hasNext()) {
            Fieldable field = (Fieldable) fieldIterator.next();
            if (field.isStored())
                storedCount++;
        }
        fieldsStream.writeVInt(storedCount);

        fieldIterator = doc.getFields().iterator();
        while (fieldIterator.hasNext()) {
            Fieldable field = (Fieldable) fieldIterator.next();
            
            
            
            boolean disableCompression = (field instanceof FieldsReader.FieldForMerge);
            if (field.isStored()) {
                fieldsStream.writeVInt(fieldInfos.fieldNumber(field.name()));

                byte bits = 0;
                if (field.isTokenized())
                    bits |= FieldsWriter.FIELD_IS_TOKENIZED;
                if (field.isBinary())
                    bits |= FieldsWriter.FIELD_IS_BINARY;
                if (field.isCompressed())
                    bits |= FieldsWriter.FIELD_IS_COMPRESSED;
                
                fieldsStream.writeByte(bits);
                
                if (field.isCompressed()) {
                  
                  byte[] data = null;
                  
                  if (disableCompression) {
                      
                      
                      data = field.binaryValue();
                  } else {
                      
                      if (field.isBinary()) {
                        data = compress(field.binaryValue());
                      }
                      else {
                        data = compress(field.stringValue().getBytes(""UTF-8""));
                      }
                  }
                  final int len = data.length;
                  fieldsStream.writeVInt(len);
                  fieldsStream.writeBytes(data, len);
                }
                else {
                  
                  if (field.isBinary()) {
                    byte[] data = field.binaryValue();
                    final int len = data.length;
                    fieldsStream.writeVInt(len);
                    fieldsStream.writeBytes(data, len);
                  }
                  else {
                    fieldsStream.writeString(field.stringValue());
                  }
                }
            }
        }
    }

    private final byte[] compress (byte[] input) {

      
      Deflater compressor = new Deflater();
      compressor.setLevel(Deflater.BEST_COMPRESSION);

      
      compressor.setInput(input);
      compressor.finish();

      
      ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length);

      
      byte[] buf = new byte[1024];
      while (!compressor.finished()) {
        int count = compressor.deflate(buf);
        bos.write(buf, 0, count);
      }
      
      compressor.end();

      
      return bos.toByteArray();
    }
}
"
lucene,2.2,org.apache.lucene.index.SegmentTermPositions,15,2,0,6,27,7,1,6,7,0.612244898,287,1.0,1,0.44,0.2,1,3,17.66666667,3,1.0667,1,"package org.apache.lucene.index;



import org.apache.lucene.store.IndexInput;

import java.io.IOException;

final class SegmentTermPositions
extends SegmentTermDocs implements TermPositions {
  private IndexInput proxStream;
  private int proxCount;
  private int position;
  
  
  private int payloadLength;
  
  
  private boolean needToLoadPayload;
  
  
  
  private long lazySkipPointer = 0;
  private int lazySkipProxCount = 0;
  
  SegmentTermPositions(SegmentReader p) {
    super(p);
    this.proxStream = null;  
  }

  final void seek(TermInfo ti, Term term) throws IOException {
    super.seek(ti, term);
    if (ti != null)
      lazySkipPointer = ti.proxPointer;
    
    lazySkipProxCount = 0;
    proxCount = 0;
    payloadLength = 0;
    needToLoadPayload = false;
  }

  public final void close() throws IOException {
    super.close();
    if (proxStream != null) proxStream.close();
  }

  public final int nextPosition() throws IOException {
    
    lazySkip();
    proxCount--;
    return position += readDeltaPosition();
  }

  private final int readDeltaPosition() throws IOException {
    int delta = proxStream.readVInt();
    if (currentFieldStoresPayloads) {
      
      
      
      
      if ((delta & 1) != 0) {
        payloadLength = proxStream.readVInt();
      } 
      delta >>>= 1;
      needToLoadPayload = true;
    } else {
      payloadLength = 0;
      needToLoadPayload = false;
    }
    return delta;
  }
  
  protected final void skippingDoc() throws IOException {
    
    lazySkipProxCount += freq;
  }

  public final boolean next() throws IOException {
    
    
    lazySkipProxCount += proxCount;
    
    if (super.next()) {               
      proxCount = freq;               
      position = 0;               
      return true;
    }
    return false;
  }

  public final int read(final int[] docs, final int[] freqs) {
    throw new UnsupportedOperationException(""TermPositions does not support processing multiple documents in one call. Use TermDocs instead."");
  }


  
  protected void skipProx(long proxPointer, int payloadLength) throws IOException {
    
    lazySkipPointer = proxPointer;
    lazySkipProxCount = 0;
    proxCount = 0;
    this.payloadLength = payloadLength;
    needToLoadPayload = false;
  }

  private void skipPositions(int n) throws IOException {
    for (int f = n; f > 0; f--) {        
      readDeltaPosition();
      skipPayload();
    }      
  }
  
  private void skipPayload() throws IOException {
    if (needToLoadPayload && payloadLength > 0) {
      proxStream.seek(proxStream.getFilePointer() + payloadLength);
    }
    needToLoadPayload = false;
  }

  
  
  
  
  
  
  
  
  
  
  private void lazySkip() throws IOException {
    if (proxStream == null) {
      
      proxStream = (IndexInput)parent.proxStream.clone();
    }
    
    
    
    skipPayload();
      
    if (lazySkipPointer != 0) {
      proxStream.seek(lazySkipPointer);
      lazySkipPointer = 0;
    }
     
    if (lazySkipProxCount != 0) {
      skipPositions(lazySkipProxCount);
      lazySkipProxCount = 0;
    }
  }
  
  public int getPayloadLength() {
    return payloadLength;
  }

  public byte[] getPayload(byte[] data, int offset) throws IOException {
    if (!needToLoadPayload) {
      throw new IOException(""Payload cannot be loaded more than once for the same term position."");
    }

    
    byte[] retArray;
    int retOffset;
    if (data == null || data.length - offset < payloadLength) {
      
      
      retArray = new byte[payloadLength];
      retOffset = 0;
    } else {
      retArray = data;
      retOffset = offset;
    }
    proxStream.readBytes(retArray, retOffset, payloadLength);
    needToLoadPayload = false;
    return retArray;
  }

  
  public boolean isPayloadAvailable() {
    return needToLoadPayload && payloadLength > 0;
  }

}
"
lucene,2.2,org.apache.lucene.store.IndexInput,15,1,5,31,18,103,31,0,15,0.928571429,256,1.0,0,0.0,0.28,0,0,16.0,1,0.9333,1,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class IndexInput implements Cloneable {
  private char[] chars;                           

  
  public abstract byte readByte() throws IOException;

  
  public abstract void readBytes(byte[] b, int offset, int len)
    throws IOException;

  
  public int readInt() throws IOException {
    return ((readByte() & 0xFF) << 24) | ((readByte() & 0xFF) << 16)
         | ((readByte() & 0xFF) <<  8) |  (readByte() & 0xFF);
  }

  
  public int readVInt() throws IOException {
    byte b = readByte();
    int i = b & 0x7F;
    for (int shift = 7; (b & 0x80) != 0; shift += 7) {
      b = readByte();
      i |= (b & 0x7F) << shift;
    }
    return i;
  }

  
  public long readLong() throws IOException {
    return (((long)readInt()) << 32) | (readInt() & 0xFFFFFFFFL);
  }

  
  public long readVLong() throws IOException {
    byte b = readByte();
    long i = b & 0x7F;
    for (int shift = 7; (b & 0x80) != 0; shift += 7) {
      b = readByte();
      i |= (b & 0x7FL) << shift;
    }
    return i;
  }

  
  public String readString() throws IOException {
    int length = readVInt();
    if (chars == null || length > chars.length)
      chars = new char[length];
    readChars(chars, 0, length);
    return new String(chars, 0, length);
  }

  
  public void readChars(char[] buffer, int start, int length)
       throws IOException {
    final int end = start + length;
    for (int i = start; i < end; i++) {
      byte b = readByte();
      if ((b & 0x80) == 0)
	buffer[i] = (char)(b & 0x7F);
      else if ((b & 0xE0) != 0xE0) {
	buffer[i] = (char)(((b & 0x1F) << 6)
		 | (readByte() & 0x3F));
      } else
	buffer[i] = (char)(((b & 0x0F) << 12)
		| ((readByte() & 0x3F) << 6)
	        |  (readByte() & 0x3F));
    }
  }

  
  public void skipChars(int length) throws IOException{
    for (int i = 0; i < length; i++) {
      byte b = readByte();
      if ((b & 0x80) == 0){
        
      }
      else if ((b & 0xE0) != 0xE0) {
        readByte();
      } else{      
        
        readByte();
        readByte();
      }
    }
  }
  

  
  public abstract void close() throws IOException;

  
  public abstract long getFilePointer();

  
  public abstract void seek(long pos) throws IOException;

  
  public abstract long length();

  
  public Object clone() {
    IndexInput clone = null;
    try {
      clone = (IndexInput)super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.chars = null;

    return clone;
  }

}
"
lucene,2.2,org.apache.lucene.analysis.TokenStream,4,1,2,24,5,6,23,1,4,2.0,9,0.0,0,0.0,1.0,0,0,1.25,1,0.75,4,"package org.apache.lucene.analysis;



import java.io.IOException;



public abstract class TokenStream {
  
  public abstract Token next() throws IOException;

  
  public void reset() throws IOException {}
  
  
  public void close() throws IOException {}
}
"
lucene,2.2,org.apache.lucene.search.ExactPhraseScorer,2,3,0,8,9,1,2,6,0,2.0,64,0.0,0,0.952380952,0.583333333,1,1,31.0,1,0.5,0,"package org.apache.lucene.search;



import java.io.IOException;
import org.apache.lucene.index.*;

final class ExactPhraseScorer extends PhraseScorer {

  ExactPhraseScorer(Weight weight, TermPositions[] tps, int[] offsets, Similarity similarity,
                    byte[] norms) {
    super(weight, tps, offsets, similarity, norms);
  }

  protected final float phraseFreq() throws IOException {
    
    pq.clear();
    for (PhrasePositions pp = first; pp != null; pp = pp.next) {
      pp.firstPosition();
      pq.put(pp);				  
    }
    pqToList();					  

    
    
    int freq = 0;
    do {					  
      while (first.position < last.position) {	  
	    do {
	      if (!first.nextPosition())
	        return (float)freq;
	    } while (first.position < last.position);
	      firstToLast();
      }
      freq++;					  
    } while (last.nextPosition());
  
    return (float)freq;
  }
}
"
lucene,2.2,org.apache.lucene.search.RangeFilter,7,2,0,6,30,1,1,5,7,0.0,373,1.0,0,0.142857143,0.314285714,1,1,51.57142857,12,3.5714,3,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermDocs;
import org.apache.lucene.index.TermEnum;

import java.io.IOException;
import java.util.BitSet;


public class RangeFilter extends Filter {
    
    private String fieldName;
    private String lowerTerm;
    private String upperTerm;
    private boolean includeLower;
    private boolean includeUpper;

    
    public RangeFilter(String fieldName, String lowerTerm, String upperTerm,
                       boolean includeLower, boolean includeUpper) {
        this.fieldName = fieldName;
        this.lowerTerm = lowerTerm;
        this.upperTerm = upperTerm;
        this.includeLower = includeLower;
        this.includeUpper = includeUpper;
        
        if (null == lowerTerm && null == upperTerm) {
            throw new IllegalArgumentException
                (""At least one value must be non-null"");
        }
        if (includeLower && null == lowerTerm) {
            throw new IllegalArgumentException
                (""The lower bound must be non-null to be inclusive"");
        }
        if (includeUpper && null == upperTerm) {
            throw new IllegalArgumentException
                (""The upper bound must be non-null to be inclusive"");
        }
    }
    
    
    public static RangeFilter Less(String fieldName, String upperTerm) {
        return new RangeFilter(fieldName, null, upperTerm, false, true);
    }

    
    public static RangeFilter More(String fieldName, String lowerTerm) {
        return new RangeFilter(fieldName, lowerTerm, null, true, false);
    }
    
    
    public BitSet bits(IndexReader reader) throws IOException {
        BitSet bits = new BitSet(reader.maxDoc());
        TermEnum enumerator =
            (null != lowerTerm
             ? reader.terms(new Term(fieldName, lowerTerm))
             : reader.terms(new Term(fieldName,"""")));
        
        try {
            
            if (enumerator.term() == null) {
                return bits;
            }
            
            boolean checkLower = false;
            if (!includeLower) 
                checkLower = true;
        
            TermDocs termDocs = reader.termDocs();
            try {
                
                do {
                    Term term = enumerator.term();
                    if (term != null && term.field().equals(fieldName)) {
                        if (!checkLower || null==lowerTerm || term.text().compareTo(lowerTerm) > 0) {
                            checkLower = false;
                            if (upperTerm != null) {
                                int compare = upperTerm.compareTo(term.text());
                                
                                if ((compare < 0) ||
                                    (!includeUpper && compare==0)) {
                                    break;
                                }
                            }
                            
                            
                            termDocs.seek(enumerator.term());
                            while (termDocs.next()) {
                                bits.set(termDocs.doc());
                            }
                        }
                    } else {
                        break;
                    }
                }
                while (enumerator.next());
                
            } finally {
                termDocs.close();
            }
        } finally {
            enumerator.close();
        }

        return bits;
    }
    
    public String toString() {
        StringBuffer buffer = new StringBuffer();
        buffer.append(fieldName);
        buffer.append("":"");
        buffer.append(includeLower ? ""["" : ""{"");
        if (null != lowerTerm) {
            buffer.append(lowerTerm);
        }
        buffer.append(""-"");
        if (null != upperTerm) {
            buffer.append(upperTerm);
        }
        buffer.append(includeUpper ? ""]"" : ""}"");
        return buffer.toString();
    }

    
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof RangeFilter)) return false;
        RangeFilter other = (RangeFilter) o;

        if (!this.fieldName.equals(other.fieldName)
            || this.includeLower != other.includeLower
            || this.includeUpper != other.includeUpper
           ) { return false; }
        if (this.lowerTerm != null ? !this.lowerTerm.equals(other.lowerTerm) : other.lowerTerm != null) return false;
        if (this.upperTerm != null ? !this.upperTerm.equals(other.upperTerm) : other.upperTerm != null) return false;
        return true;
    }

    
    public int hashCode() {
      int h = fieldName.hashCode();
      h ^= lowerTerm != null ? lowerTerm.hashCode() : 0xB6ECE882;
      h = (h << 1) | (h >>> 31);  
      h ^= (upperTerm != null ? (upperTerm.hashCode()) : 0x91BEC2C2);
      h ^= (includeLower ? 0xD484B933 : 0)
         ^ (includeUpper ? 0x6AE423AC : 0);
      return h;
    }
}
"
lucene,2.2,org.apache.lucene.search.function.ReverseOrdFieldSource,7,2,0,6,21,0,1,6,5,0.666666667,99,0.333333333,0,0.5,0.375,2,2,12.71428571,3,1.0,2,"

package org.apache.lucene.search.function;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;

import java.io.IOException;



public class ReverseOrdFieldSource extends ValueSource {
  public String field;

  
  public ReverseOrdFieldSource(String field) {
    this.field = field;
  }

  
  public String description() {
    return ""rord(""+field+')';
  }

  
  public DocValues getValues(IndexReader reader) throws IOException {
    final FieldCache.StringIndex sindex = FieldCache.DEFAULT.getStringIndex(reader, field);

    final int arr[] = sindex.order;
    final int end = sindex.lookup.length;

    return new DocValues(arr.length) {
      
      public float floatVal(int doc) {
        return (float)(end - arr[doc]);
      }
      
      public int intVal(int doc) {
        return end - arr[doc];
      }
      
      public String strVal(int doc) {
        
        return Integer.toString(intVal(doc));
      }
      
      public String toString(int doc) {
        return description() + '=' + strVal(doc);
      }
      
      Object getInnerArray() {
        return arr;
      }
    };
  }

  
  public boolean equals(Object o) {
    if (o.getClass() !=  ReverseOrdFieldSource.class) return false;
    ReverseOrdFieldSource other = (ReverseOrdFieldSource)o;
    return this.field.equals(other.field); 
  }

  private static final int hcode = ReverseOrdFieldSource.class.hashCode();
  
  
  public int hashCode() {
    return hcode + field.hashCode();
  }
}
"
lucene,2.2,org.apache.lucene.search.ReqExclScorer,7,2,0,4,16,0,1,3,6,0.333333333,179,1.0,2,0.571428571,0.476190476,1,3,24.14285714,1,0.8571,0,"package org.apache.lucene.search;



import java.io.IOException;



public class ReqExclScorer extends Scorer {
  private Scorer reqScorer, exclScorer;

  
  public ReqExclScorer(
      Scorer reqScorer,
      Scorer exclScorer) {
    super(null); 
    this.reqScorer = reqScorer;
    this.exclScorer = exclScorer;
  }

  private boolean firstTime = true;
  
  public boolean next() throws IOException {
    if (firstTime) {
      if (! exclScorer.next()) {
        exclScorer = null; 
      }
      firstTime = false;
    }
    if (reqScorer == null) {
      return false;
    }
    if (! reqScorer.next()) {
      reqScorer = null; 
      return false;
    }
    if (exclScorer == null) {
      return true; 
    }
    return toNonExcluded();
  }
  
  
  private boolean toNonExcluded() throws IOException {
    int exclDoc = exclScorer.doc();
    do {  
      int reqDoc = reqScorer.doc(); 
      if (reqDoc < exclDoc) {
        return true; 
      } else if (reqDoc > exclDoc) {
        if (! exclScorer.skipTo(reqDoc)) {
          exclScorer = null; 
          return true;
        }
        exclDoc = exclScorer.doc();
        if (exclDoc > reqDoc) {
          return true; 
        }
      }
    } while (reqScorer.next());
    reqScorer = null; 
    return false;
  }

  public int doc() {
    return reqScorer.doc(); 
  }

  
  public float score() throws IOException {
    return reqScorer.score(); 
  }
  
  
  public boolean skipTo(int target) throws IOException {
    if (firstTime) {
      firstTime = false;
      if (! exclScorer.skipTo(target)) {
        exclScorer = null; 
      }
    }
    if (reqScorer == null) {
      return false;
    }
    if (exclScorer == null) {
      return reqScorer.skipTo(target);
    }
    if (! reqScorer.skipTo(target)) {
      reqScorer = null;
      return false;
    }
    return toNonExcluded();
  }

  public Explanation explain(int doc) throws IOException {
    Explanation res = new Explanation();
    if (exclScorer.skipTo(doc) && (exclScorer.doc() == doc)) {
      res.setDescription(""excluded"");
    } else {
      res.setDescription(""not excluded"");
      res.addDetail(reqScorer.explain(doc));
    }
    return res;
  }
}
"
lucene,2.2,org.apache.lucene.analysis.PorterStemFilter,2,3,0,4,6,0,0,4,2,0.0,35,1.0,1,0.8,0.75,0,0,16.0,1,0.5,1,"package org.apache.lucene.analysis;



import java.io.IOException;


public final class PorterStemFilter extends TokenFilter {
  private PorterStemmer stemmer;

  public PorterStemFilter(TokenStream in) {
    super(in);
    stemmer = new PorterStemmer();
  }

  
  public final Token next() throws IOException {
    Token token = input.next();
    if (token == null)
      return null;
    else {
      String s = stemmer.stem(token.termText);
      if (s != token.termText) 
  	    token.termText = s;
      return token;
    }
  }
}
"
lucene,2.2,org.apache.lucene.index.IndexModifier,26,1,0,10,55,0,0,10,22,0.344,705,1.0,4,0.0,0.184615385,0,0,25.73076923,2,1.1538,5,"package org.apache.lucene.index;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.LockObtainFailedException;

import java.io.File;
import java.io.IOException;
import java.io.PrintStream;


public class IndexModifier {

  protected IndexWriter indexWriter = null;
  protected IndexReader indexReader = null;

  protected Directory directory = null;
  protected Analyzer analyzer = null;
  protected boolean open = false;

  
  protected PrintStream infoStream = null;
  protected boolean useCompoundFile = true;
  protected int maxBufferedDocs = IndexWriter.DEFAULT_MAX_BUFFERED_DOCS;
  protected int maxFieldLength = IndexWriter.DEFAULT_MAX_FIELD_LENGTH;
  protected int mergeFactor = IndexWriter.DEFAULT_MERGE_FACTOR;

  
  public IndexModifier(Directory directory, Analyzer analyzer, boolean create) throws CorruptIndexException, LockObtainFailedException, IOException {
    init(directory, analyzer, create);
  }

  
  public IndexModifier(String dirName, Analyzer analyzer, boolean create) throws CorruptIndexException, LockObtainFailedException, IOException {
    Directory dir = FSDirectory.getDirectory(dirName);
    init(dir, analyzer, create);
  }

  
  public IndexModifier(File file, Analyzer analyzer, boolean create) throws CorruptIndexException, LockObtainFailedException, IOException {
    Directory dir = FSDirectory.getDirectory(file);
    init(dir, analyzer, create);
  }

  
  protected void init(Directory directory, Analyzer analyzer, boolean create) throws CorruptIndexException, LockObtainFailedException, IOException {
    this.directory = directory;
    synchronized(this.directory) {
      this.analyzer = analyzer;
      indexWriter = new IndexWriter(directory, analyzer, create);
      open = true;
    }
  }

  
  protected void assureOpen() {
    if (!open) {
      throw new IllegalStateException(""Index is closed"");
    }
  }

  
  protected void createIndexWriter() throws CorruptIndexException, LockObtainFailedException, IOException {
    if (indexWriter == null) {
      if (indexReader != null) {
        indexReader.close();
        indexReader = null;
      }
      indexWriter = new IndexWriter(directory, analyzer, false);
      indexWriter.setInfoStream(infoStream);
      indexWriter.setUseCompoundFile(useCompoundFile);
      indexWriter.setMaxBufferedDocs(maxBufferedDocs);
      indexWriter.setMaxFieldLength(maxFieldLength);
      indexWriter.setMergeFactor(mergeFactor);
    }
  }

  
  protected void createIndexReader() throws CorruptIndexException, IOException {
    if (indexReader == null) {
      if (indexWriter != null) {
        indexWriter.close();
        indexWriter = null;
      }
      indexReader = IndexReader.open(directory);
    }
  }

  
  public void flush() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.close();
        indexWriter = null;
        createIndexWriter();
      } else {
        indexReader.close();
        indexReader = null;
        createIndexReader();
      }
    }
  }

  
  public void addDocument(Document doc, Analyzer docAnalyzer) throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      if (docAnalyzer != null)
        indexWriter.addDocument(doc, docAnalyzer);
      else
        indexWriter.addDocument(doc);
    }
  }

  
  public void addDocument(Document doc) throws CorruptIndexException, LockObtainFailedException, IOException {
    addDocument(doc, null);
  }

  
  public int deleteDocuments(Term term) throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexReader();
      return indexReader.deleteDocuments(term);
    }
  }

  
  public void deleteDocument(int docNum) throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexReader();
      indexReader.deleteDocument(docNum);
    }
  }


  
  public int docCount() {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        return indexWriter.docCount();
      } else {
        return indexReader.numDocs();
      }
    }
  }

  
  public void optimize() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      indexWriter.optimize();
    }
  }

  
  public void setInfoStream(PrintStream infoStream) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setInfoStream(infoStream);
      }
      this.infoStream = infoStream;
    }
  }

  
  public PrintStream getInfoStream() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getInfoStream();
    }
  }

  
  public void setUseCompoundFile(boolean useCompoundFile) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setUseCompoundFile(useCompoundFile);
      }
      this.useCompoundFile = useCompoundFile;
    }
  }

  
  public boolean getUseCompoundFile() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getUseCompoundFile();
    }
  }

  
  public void setMaxFieldLength(int maxFieldLength) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setMaxFieldLength(maxFieldLength);
      }
      this.maxFieldLength = maxFieldLength;
    }
  }

  
  public int getMaxFieldLength() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getMaxFieldLength();
    }
  }

  
  public void setMaxBufferedDocs(int maxBufferedDocs) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setMaxBufferedDocs(maxBufferedDocs);
      }
      this.maxBufferedDocs = maxBufferedDocs;
    }
  }

  
  public int getMaxBufferedDocs() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getMaxBufferedDocs();
    }
  }

  
  public void setMergeFactor(int mergeFactor) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setMergeFactor(mergeFactor);
      }
      this.mergeFactor = mergeFactor;
    }
  }

  
  public int getMergeFactor() throws CorruptIndexException, LockObtainFailedException, IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getMergeFactor();
    }
  }

  
  public void close() throws CorruptIndexException, IOException {
    synchronized(directory) {
      if (!open)
        throw new IllegalStateException(""Index is closed already"");
      if (indexWriter != null) {
        indexWriter.close();
        indexWriter = null;
      } else {
        indexReader.close();
        indexReader = null;
      }
      open = false;
    }
  }

  public String toString() {
    return ""Index@"" + directory;
  }

  
  
}
"
lucene,2.2,org.apache.lucene.index.SegmentTermEnum,13,2,0,10,38,0,3,7,4,0.766666667,367,0.533333333,6,0.294117647,0.211538462,1,2,26.07692308,1,0.9231,3,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.store.IndexInput;

final class SegmentTermEnum extends TermEnum implements Cloneable {
  private IndexInput input;
  FieldInfos fieldInfos;
  long size;
  long position = -1;

  private TermBuffer termBuffer = new TermBuffer();
  private TermBuffer prevBuffer = new TermBuffer();
  private TermBuffer scratch;                     

  private TermInfo termInfo = new TermInfo();

  private int format;
  private boolean isIndex = false;
  long indexPointer = 0;
  int indexInterval;
  int skipInterval;
  int maxSkipLevels;
  private int formatM1SkipInterval;

  SegmentTermEnum(IndexInput i, FieldInfos fis, boolean isi)
          throws CorruptIndexException, IOException {
    input = i;
    fieldInfos = fis;
    isIndex = isi;
    maxSkipLevels = 1; 
    
    int firstInt = input.readInt();
    if (firstInt >= 0) {
      
      format = 0;
      size = firstInt;

      
      indexInterval = 128;
      skipInterval = Integer.MAX_VALUE; 
    } else {
      
      format = firstInt;

      
      if (format < TermInfosWriter.FORMAT)
        throw new CorruptIndexException(""Unknown format version:"" + format);

      size = input.readLong();                    
      
      if(format == -1){
        if (!isIndex) {
          indexInterval = input.readInt();
          formatM1SkipInterval = input.readInt();
        }
        
        
        skipInterval = Integer.MAX_VALUE;
      } else {
        indexInterval = input.readInt();
        skipInterval = input.readInt();
        if (format == -3) {
          
          maxSkipLevels = input.readInt();
        }
      }
    }

  }

  protected Object clone() {
    SegmentTermEnum clone = null;
    try {
      clone = (SegmentTermEnum) super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.input = (IndexInput) input.clone();
    clone.termInfo = new TermInfo(termInfo);

    clone.termBuffer = (TermBuffer)termBuffer.clone();
    clone.prevBuffer = (TermBuffer)prevBuffer.clone();
    clone.scratch = null;

    return clone;
  }

  final void seek(long pointer, int p, Term t, TermInfo ti)
          throws IOException {
    input.seek(pointer);
    position = p;
    termBuffer.set(t);
    prevBuffer.reset();
    termInfo.set(ti);
  }

  
  public final boolean next() throws IOException {
    if (position++ >= size - 1) {
      termBuffer.reset();
      return false;
    }

    prevBuffer.set(termBuffer);
    termBuffer.read(input, fieldInfos);

    termInfo.docFreq = input.readVInt();	  
    termInfo.freqPointer += input.readVLong();	  
    termInfo.proxPointer += input.readVLong();	  
    
    if(format == -1){
    
    
      if (!isIndex) {
        if (termInfo.docFreq > formatM1SkipInterval) {
          termInfo.skipOffset = input.readVInt(); 
        }
      }
    }
    else{
      if (termInfo.docFreq >= skipInterval) 
        termInfo.skipOffset = input.readVInt();
    }
    
    if (isIndex)
      indexPointer += input.readVLong();	  

    return true;
  }

  
  final void scanTo(Term term) throws IOException {
    if (scratch == null)
      scratch = new TermBuffer();
    scratch.set(term);
    while (scratch.compareTo(termBuffer) > 0 && next()) {}
  }

  
  public final Term term() {
    return termBuffer.toTerm();
  }

  
  final Term prev() {
    return prevBuffer.toTerm();
  }

  
  final TermInfo termInfo() {
    return new TermInfo(termInfo);
  }

  
  final void termInfo(TermInfo ti) {
    ti.set(termInfo);
  }

  
  public final int docFreq() {
    return termInfo.docFreq;
  }

  
  final long freqPointer() {
    return termInfo.freqPointer;
  }

  
  final long proxPointer() {
    return termInfo.proxPointer;
  }

  
  public final void close() throws IOException {
    input.close();
  }
}
"
lucene,2.2,org.apache.lucene.analysis.standard.ParseException,5,4,0,2,18,0,1,1,4,0.55,380,0.4,1,0.866666667,0.4,1,1,74.0,14,4.8,0,"
package org.apache.lucene.analysis.standard;

  


public class ParseException extends java.io.IOException {

  
  public ParseException(Token currentTokenVal,
                        int[][] expectedTokenSequencesVal,
                        String[] tokenImageVal
                       )
  {
    super("""");
    specialConstructor = true;
    currentToken = currentTokenVal;
    expectedTokenSequences = expectedTokenSequencesVal;
    tokenImage = tokenImageVal;
  }

  

  public ParseException() {
    super();
    specialConstructor = false;
  }

  public ParseException(String message) {
    super(message);
    specialConstructor = false;
  }

  
  protected boolean specialConstructor;

  
  public Token currentToken;

  
  public int[][] expectedTokenSequences;

  
  public String[] tokenImage;

  
  public String getMessage() {
    if (!specialConstructor) {
      return super.getMessage();
    }
    String expected = """";
    int maxSize = 0;
    for (int i = 0; i < expectedTokenSequences.length; i++) {
      if (maxSize < expectedTokenSequences[i].length) {
        maxSize = expectedTokenSequences[i].length;
      }
      for (int j = 0; j < expectedTokenSequences[i].length; j++) {
        expected += tokenImage[expectedTokenSequences[i][j]] + "" "";
      }
      if (expectedTokenSequences[i][expectedTokenSequences[i].length - 1] != 0) {
        expected += ""..."";
      }
      expected += eol + ""    "";
    }
    String retval = ""Encountered \"""";
    Token tok = currentToken.next;
    for (int i = 0; i < maxSize; i++) {
      if (i != 0) retval += "" "";
      if (tok.kind == 0) {
        retval += tokenImage[0];
        break;
      }
      retval += add_escapes(tok.image);
      tok = tok.next; 
    }
    retval += ""\"" at line "" + currentToken.next.beginLine + "", column "" + currentToken.next.beginColumn + ""."" + eol;
    if (expectedTokenSequences.length == 1) {
      retval += ""Was expecting:"" + eol + ""    "";
    } else {
      retval += ""Was expecting one of:"" + eol + ""    "";
    }
    retval += expected;
    return retval;
  }

  
  protected String eol = System.getProperty(""line.separator"", ""\n"");
 
  
  protected String add_escapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

}
"
lucene,2.2,org.apache.lucene.index.SegmentTermPositionVector,4,2,0,4,5,0,1,3,3,0.666666667,65,0.666666667,1,0.777777778,0.476190476,0,0,14.5,4,2.0,0,"package org.apache.lucene.index;



class SegmentTermPositionVector extends SegmentTermVector implements TermPositionVector {
  protected int[][] positions;
  protected TermVectorOffsetInfo[][] offsets;
  public static final int[] EMPTY_TERM_POS = new int[0];
  
  public SegmentTermPositionVector(String field, String terms[], int termFreqs[], int[][] positions, TermVectorOffsetInfo[][] offsets) {
    super(field, terms, termFreqs);
    this.offsets = offsets;
    this.positions = positions;
  }

  
  public TermVectorOffsetInfo[] getOffsets(int index) {
    TermVectorOffsetInfo[] result = TermVectorOffsetInfo.EMPTY_OFFSET_INFO;
    if(offsets == null)
      return null;
    if (index >=0 && index < offsets.length)
    {
      result = offsets[index];
    }
    return result;
  }
  
  
  public int[] getTermPositions(int index) {
    int[] result = EMPTY_TERM_POS;
    if(positions == null)
      return null;
    if (index >=0 && index < positions.length)
    {
      result = positions[index];
    }
    
    return result;
  }
}"
lucene,2.2,org.apache.lucene.search.function.CustomScoreQuery,17,2,0,9,43,48,2,8,13,0.5625,263,1.0,2,0.444444444,0.135746606,2,4,14.29411765,7,1.6471,1,"package org.apache.lucene.search.function;



import java.io.IOException;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.ComplexExplanation;
import org.apache.lucene.search.Explanation;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.Scorer;
import org.apache.lucene.search.Searcher;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.search.Weight;
import org.apache.lucene.util.ToStringUtils;


public class CustomScoreQuery extends Query {

  private Query subQuery;
  private ValueSourceQuery valSrcQuery; 
  private boolean strict = false; 
  
  
  public CustomScoreQuery(Query subQuery) {
    this(subQuery,null);
  }

  
  public CustomScoreQuery(Query subQuery, ValueSourceQuery valSrcQuery) {
    super();
    this.subQuery = subQuery;
    this.valSrcQuery = valSrcQuery;
    if (subQuery == null) throw new IllegalArgumentException(""<subqyery> must not be null!"");
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    subQuery = subQuery.rewrite(reader);
    if (valSrcQuery!=null) {
      valSrcQuery = (ValueSourceQuery) valSrcQuery.rewrite(reader);
    }
    return this;
  }

  
  public void extractTerms(Set terms) {
    subQuery.extractTerms(terms);
    if (valSrcQuery!=null) {
      valSrcQuery.extractTerms(terms);
    }
  }

  
  public Object clone() {
    CustomScoreQuery clone = (CustomScoreQuery)super.clone();
    clone.subQuery = (Query) subQuery.clone();
    if (valSrcQuery!=null) {
      clone.valSrcQuery = (ValueSourceQuery) valSrcQuery.clone();
    }
    return clone;
  }

  
  public String toString(String field) {
    StringBuffer sb = new StringBuffer(name()).append(""("");
    sb.append(subQuery.toString(field));
    if (valSrcQuery!=null) {
      sb.append("", "").append(valSrcQuery.toString(field));
    }
    sb.append("")"");
    sb.append(strict?"" STRICT"" : """");
    return sb.toString() + ToStringUtils.boost(getBoost());
  }

  
  public boolean equals(Object o) {
    if (getClass() != o.getClass()) {
      return false;
    }
    CustomScoreQuery other = (CustomScoreQuery)o;
    return this.getBoost() == other.getBoost()
           && this.subQuery.equals(other.subQuery)
           && (this.valSrcQuery==null ? other.valSrcQuery==null 
               : this.valSrcQuery.equals(other.valSrcQuery));
  }

  
  public int hashCode() {
    int valSrcHash = valSrcQuery==null ? 0 : valSrcQuery.hashCode();
    return (getClass().hashCode() + subQuery.hashCode() + valSrcHash) ^ Float.floatToIntBits(getBoost());
  }  
  
  
  public float customScore(int doc, float subQueryScore, float valSrcScore) {
    return valSrcScore * subQueryScore;
  }

  
  public Explanation customExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpl) {
    float valSrcScore = valSrcExpl==null ? 1 : valSrcExpl.getValue();
    Explanation exp = new Explanation( valSrcScore * subQueryExpl.getValue(), ""custom score: product of:"");
    exp.addDetail(subQueryExpl);
    if (valSrcExpl != null) {
      exp.addDetail(valSrcExpl);
    }
    return exp;
  }
  
  
  private class CustomWeight implements Weight {
    Searcher searcher;
    Weight subQueryWeight;
    Weight valSrcWeight; 
    boolean qStrict;

    public CustomWeight(Searcher searcher) throws IOException {
      this.searcher = searcher;
      this.subQueryWeight = subQuery.weight(searcher); 
      if (valSrcQuery!=null) {
        this.valSrcWeight = valSrcQuery.createWeight(searcher);
      }
      this.qStrict = strict;
    }

    
    public Query getQuery() {
      return CustomScoreQuery.this;
    }

    
    public float getValue() {
      return getBoost();
    }

    
    public float sumOfSquaredWeights() throws IOException {
      float sum = subQueryWeight.sumOfSquaredWeights();
      if (valSrcWeight!=null) {
        if (qStrict) {
          valSrcWeight.sumOfSquaredWeights(); 
        } else {
          sum += valSrcWeight.sumOfSquaredWeights();
        }
      }
      sum *= getBoost() * getBoost(); 
      return sum ;
    }

    
    public void normalize(float norm) {
      norm *= getBoost(); 
      subQueryWeight.normalize(norm);
      if (valSrcWeight!=null) {
        if (qStrict) {
          valSrcWeight.normalize(1); 
        } else {
          valSrcWeight.normalize(norm);
        }
      }
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      Scorer subQueryScorer = subQueryWeight.scorer(reader);
      Scorer valSrcScorer = (valSrcWeight==null ? null : valSrcWeight.scorer(reader));
      return new CustomScorer(getSimilarity(searcher), reader, this, subQueryScorer, valSrcScorer);
    }

    
    public Explanation explain(IndexReader reader, int doc) throws IOException {
      return scorer(reader).explain(doc);
    }
  }


  
  
  
  private class CustomScorer extends Scorer {
    private final CustomWeight weight;
    private final float qWeight;
    private Scorer subQueryScorer;
    private Scorer valSrcScorer; 
    private IndexReader reader;

    
    private CustomScorer(Similarity similarity, IndexReader reader, CustomWeight w,
        Scorer subQueryScorer, Scorer valSrcScorer) throws IOException {
      super(similarity);
      this.weight = w;
      this.qWeight = w.getValue();
      this.subQueryScorer = subQueryScorer;
      this.valSrcScorer = valSrcScorer;
      this.reader = reader;
    }

    
    public boolean next() throws IOException {
      boolean hasNext = subQueryScorer.next();
      if (valSrcScorer!=null && hasNext) {
        valSrcScorer.skipTo(subQueryScorer.doc());
      }
      return hasNext;
    }

    
    public int doc() {
      return subQueryScorer.doc();
    }

    
    public float score() throws IOException {
      float valSrcScore = (valSrcScorer==null ? 1 : valSrcScorer.score());
      return qWeight * customScore(subQueryScorer.doc(), subQueryScorer.score(), valSrcScore);
    }

    
    public boolean skipTo(int target) throws IOException {
      boolean hasNext = subQueryScorer.skipTo(target);
      if (valSrcScorer!=null && hasNext) {
        valSrcScorer.skipTo(subQueryScorer.doc());
      }
      return hasNext;
    }

    
    public Explanation explain(int doc) throws IOException {
      Explanation subQueryExpl = weight.subQueryWeight.explain(reader,doc);
      if (!subQueryExpl.isMatch()) {
        return subQueryExpl;
      }
      
      Explanation valSrcExpl = valSrcScorer==null ? null : valSrcScorer.explain(doc);
      Explanation customExp = customExplain(doc,subQueryExpl,valSrcExpl);
      float sc = qWeight * customExp.getValue();
      Explanation res = new ComplexExplanation(
        true, sc, CustomScoreQuery.this.toString() + "", product of:"");
      res.addDetail(customExp);
      res.addDetail(new Explanation(qWeight, ""queryBoost"")); 
      return res;
    }
  }

  
  protected Weight createWeight(Searcher searcher) throws IOException {
    return new CustomWeight(searcher);
  }

  
  public boolean isStrict() {
    return strict;
  }

  
  public void setStrict(boolean strict) {
    this.strict = strict;
  }

  
  public String name() {
    return ""custom"";
  }

}
"
lucene,2.2,org.apache.lucene.search.HitQueue,2,2,0,6,4,1,4,2,0,2.0,39,0.0,0,0.916666667,0.666666667,1,3,18.5,4,2.0,0,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;

final class HitQueue extends PriorityQueue {
  HitQueue(int size) {
    initialize(size);
  }

  protected final boolean lessThan(Object a, Object b) {
    ScoreDoc hitA = (ScoreDoc)a;
    ScoreDoc hitB = (ScoreDoc)b;
    if (hitA.score == hitB.score)
      return hitA.doc > hitB.doc; 
    else
      return hitA.score < hitB.score;
  }
}
"
lucene,2.2,org.apache.lucene.store.LockFactory,5,1,4,8,6,4,7,1,5,0.5,19,1.0,0,0.0,0.8,0,0,2.6,1,0.8,1,"package org.apache.lucene.store;



import java.io.IOException;



public abstract class LockFactory {

  protected String lockPrefix = """";

  
  public void setLockPrefix(String lockPrefix) {
    this.lockPrefix = lockPrefix;
  }

  
  public String getLockPrefix() {
    return this.lockPrefix;
  }

  
  public abstract Lock makeLock(String lockName);

  
  abstract public void clearLock(String lockName) throws IOException;
}
"
lucene,2.2,org.apache.lucene.search.NonMatchingScorer,6,2,0,4,10,15,1,3,6,2.0,31,0.0,0,0.615384615,0.666666667,1,3,4.166666667,1,0.8333,0,"package org.apache.lucene.search;


 
import java.io.IOException;


class NonMatchingScorer extends Scorer {
  public NonMatchingScorer() { super(null); } 
  
  public int doc() { throw new UnsupportedOperationException(); }

  public boolean next() throws IOException { return false; }

  public float score() { throw new UnsupportedOperationException(); }

  public boolean skipTo(int target) { return false; }

  public Explanation explain(int doc) {
    Explanation e = new Explanation();
    e.setDescription(""No document matches."");
    return e;
  }
}
 

"
lucene,2.2,org.apache.lucene.index.StaleReaderException,1,4,0,2,2,0,2,0,1,2.0,5,0.0,0,1.0,1.0,0,0,4.0,0,0.0,0,"

package org.apache.lucene.index;

import java.io.IOException;


public class StaleReaderException extends IOException {
  public StaleReaderException(String message) {
    super(message);
  }
}
"
lucene,2.2,org.apache.lucene.search.TopFieldDocs,1,2,0,14,2,0,11,3,0,2.0,11,0.0,1,1.0,1.0,0,0,9.0,0,0.0,1,"package org.apache.lucene.search;





public class TopFieldDocs
extends TopDocs {

	
	public SortField[] fields;
        
	
	TopFieldDocs (int totalHits, ScoreDoc[] scoreDocs, SortField[] fields, float maxScore) {
	  super (totalHits, scoreDocs, maxScore);
	  this.fields = fields;
	}
}"
lucene,2.2,org.apache.lucene.search.spans.SpanWeight,7,1,1,13,46,0,2,12,7,0.69047619,357,1.0,2,0.0,0.30952381,0,0,49.0,1,0.8571,0,"package org.apache.lucene.search.spans;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.*;

import java.io.IOException;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Set;


public class SpanWeight implements Weight {
  protected Similarity similarity;
  protected float value;
  protected float idf;
  protected float queryNorm;
  protected float queryWeight;

  protected Set terms;
  protected SpanQuery query;

  public SpanWeight(SpanQuery query, Searcher searcher)
    throws IOException {
    this.similarity = query.getSimilarity(searcher);
    this.query = query;
    terms=new HashSet();
    query.extractTerms(terms);

    idf = this.query.getSimilarity(searcher).idf(terms, searcher);
  }

  public Query getQuery() { return query; }
  public float getValue() { return value; }

  public float sumOfSquaredWeights() throws IOException {
    queryWeight = idf * query.getBoost();         
    return queryWeight * queryWeight;             
  }

  public void normalize(float queryNorm) {
    this.queryNorm = queryNorm;
    queryWeight *= queryNorm;                     
    value = queryWeight * idf;                    
  }

  public Scorer scorer(IndexReader reader) throws IOException {
    return new SpanScorer(query.getSpans(reader), this,
                          similarity,
                          reader.norms(query.getField()));
  }

  public Explanation explain(IndexReader reader, int doc)
    throws IOException {

    ComplexExplanation result = new ComplexExplanation();
    result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");
    String field = ((SpanQuery)getQuery()).getField();

    StringBuffer docFreqs = new StringBuffer();
    Iterator i = terms.iterator();
    while (i.hasNext()) {
      Term term = (Term)i.next();
      docFreqs.append(term.text());
      docFreqs.append(""="");
      docFreqs.append(reader.docFreq(term));

      if (i.hasNext()) {
        docFreqs.append("" "");
      }
    }

    Explanation idfExpl =
      new Explanation(idf, ""idf("" + field + "": "" + docFreqs + "")"");

    
    Explanation queryExpl = new Explanation();
    queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

    Explanation boostExpl = new Explanation(getQuery().getBoost(), ""boost"");
    if (getQuery().getBoost() != 1.0f)
      queryExpl.addDetail(boostExpl);
    queryExpl.addDetail(idfExpl);

    Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
    queryExpl.addDetail(queryNormExpl);

    queryExpl.setValue(boostExpl.getValue() *
                       idfExpl.getValue() *
                       queryNormExpl.getValue());

    result.addDetail(queryExpl);

    
    ComplexExplanation fieldExpl = new ComplexExplanation();
    fieldExpl.setDescription(""fieldWeight(""+field+"":""+query.toString(field)+
                             "" in ""+doc+""), product of:"");

    Explanation tfExpl = scorer(reader).explain(doc);
    fieldExpl.addDetail(tfExpl);
    fieldExpl.addDetail(idfExpl);

    Explanation fieldNormExpl = new Explanation();
    byte[] fieldNorms = reader.norms(field);
    float fieldNorm =
      fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
    fieldNormExpl.setValue(fieldNorm);
    fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
    fieldExpl.addDetail(fieldNormExpl);

    fieldExpl.setMatch(Boolean.valueOf(tfExpl.isMatch()));
    fieldExpl.setValue(tfExpl.getValue() *
                       idfExpl.getValue() *
                       fieldNormExpl.getValue());

    result.addDetail(fieldExpl);
    result.setMatch(fieldExpl.getMatch());

    
    result.setValue(queryExpl.getValue() * fieldExpl.getValue());

    if (queryExpl.getValue() == 1.0f)
      return fieldExpl;

    return result;
  }
}
"
lucene,2.2,org.apache.lucene.index.DefaultSkipListWriter,4,2,0,3,10,0,1,2,0,0.484848485,176,1.0,2,0.625,0.625,1,1,40.25,1,0.75,0,"package org.apache.lucene.index;



import java.io.IOException;
import java.util.Arrays;

import org.apache.lucene.store.IndexOutput;



class DefaultSkipListWriter extends MultiLevelSkipListWriter {
  private int[] lastSkipDoc;
  private int[] lastSkipPayloadLength;
  private long[] lastSkipFreqPointer;
  private long[] lastSkipProxPointer;
  
  private IndexOutput freqOutput;
  private IndexOutput proxOutput;

  private int curDoc;
  private boolean curStorePayloads;
  private int curPayloadLength;
  private long curFreqPointer;
  private long curProxPointer;
  
  DefaultSkipListWriter(int skipInterval, int numberOfSkipLevels, int docCount, IndexOutput freqOutput, IndexOutput proxOutput) {
    super(skipInterval, numberOfSkipLevels, docCount);
    this.freqOutput = freqOutput;
    this.proxOutput = proxOutput;
    
    lastSkipDoc = new int[numberOfSkipLevels];
    lastSkipPayloadLength = new int[numberOfSkipLevels];
    lastSkipFreqPointer = new long[numberOfSkipLevels];
    lastSkipProxPointer = new long[numberOfSkipLevels];
  }

  
  void setSkipData(int doc, boolean storePayloads, int payloadLength) {
    this.curDoc = doc;
    this.curStorePayloads = storePayloads;
    this.curPayloadLength = payloadLength;
    this.curFreqPointer = freqOutput.getFilePointer();
    this.curProxPointer = proxOutput.getFilePointer();
  }
  
  protected void resetSkip() {
    super.resetSkip();
    Arrays.fill(lastSkipDoc, 0);
    Arrays.fill(lastSkipPayloadLength, -1);  
    Arrays.fill(lastSkipFreqPointer, freqOutput.getFilePointer());
    Arrays.fill(lastSkipProxPointer, proxOutput.getFilePointer());
  }
  
  protected void writeSkipData(int level, IndexOutput skipBuffer) throws IOException {
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    if (curStorePayloads) {
      int delta = curDoc - lastSkipDoc[level];
      if (curPayloadLength == lastSkipPayloadLength[level]) {
        
        
        skipBuffer.writeVInt(delta * 2);
      } else {
        
        
        skipBuffer.writeVInt(delta * 2 + 1);
        skipBuffer.writeVInt(curPayloadLength);
        lastSkipPayloadLength[level] = curPayloadLength;
      }
    } else {
      
      skipBuffer.writeVInt(curDoc - lastSkipDoc[level]);
    }
    skipBuffer.writeVInt((int) (curFreqPointer - lastSkipFreqPointer[level]));
    skipBuffer.writeVInt((int) (curProxPointer - lastSkipProxPointer[level]));

    lastSkipDoc[level] = curDoc;
    
    
    lastSkipFreqPointer[level] = curFreqPointer;
    lastSkipProxPointer[level] = curProxPointer;
  }

}
"
lucene,2.2,org.apache.lucene.analysis.standard.StandardTokenizerConstants,1,1,0,3,1,0,3,0,0,2.0,87,0.0,0,0.0,0.0,0,0,68.0,0,0.0,0,"
package org.apache.lucene.analysis.standard;

public interface StandardTokenizerConstants {

  int EOF = 0;
  int ALPHANUM = 1;
  int APOSTROPHE = 2;
  int ACRONYM = 3;
  int COMPANY = 4;
  int EMAIL = 5;
  int HOST = 6;
  int NUM = 7;
  int P = 8;
  int HAS_DIGIT = 9;
  int ALPHA = 10;
  int LETTER = 11;
  int CJ = 12;
  int KOREAN = 13;
  int DIGIT = 14;
  int NOISE = 15;

  int DEFAULT = 0;

  String[] tokenImage = {
    ""<EOF>"",
    ""<ALPHANUM>"",
    ""<APOSTROPHE>"",
    ""<ACRONYM>"",
    ""<COMPANY>"",
    ""<EMAIL>"",
    ""<HOST>"",
    ""<NUM>"",
    ""<P>"",
    ""<HAS_DIGIT>"",
    ""<ALPHA>"",
    ""<LETTER>"",
    ""<CJ>"",
    ""<KOREAN>"",
    ""<DIGIT>"",
    ""<NOISE>"",
  };

}
"
lucene,2.2,org.apache.lucene.queryParser.QueryParserTokenManager,36,1,0,5,52,282,1,4,7,0.720300752,3060,0.210526316,1,0.0,0.405714286,0,0,83.47222222,112,7.6389,4,"
package org.apache.lucene.queryParser;
import java.util.Vector;
import java.io.*;
import java.text.*;
import java.util.*;
import org.apache.lucene.index.Term;
import org.apache.lucene.analysis.*;
import org.apache.lucene.document.*;
import org.apache.lucene.search.*;
import org.apache.lucene.util.Parameter;

public class QueryParserTokenManager implements QueryParserConstants
{
  public  java.io.PrintStream debugStream = System.out;
  public  void setDebugStream(java.io.PrintStream ds) { debugStream = ds; }
private final int jjStopStringLiteralDfa_3(int pos, long active0)
{
   switch (pos)
   {
      default :
         return -1;
   }
}
private final int jjStartNfa_3(int pos, long active0)
{
   return jjMoveNfa_3(jjStopStringLiteralDfa_3(pos, active0), pos + 1);
}
private final int jjStopAtPos(int pos, int kind)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   return pos + 1;
}
private final int jjStartNfaWithStates_3(int pos, int kind, int state)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) { return pos + 1; }
   return jjMoveNfa_3(state, pos + 1);
}
private final int jjMoveStringLiteralDfa0_3()
{
   switch(curChar)
   {
      case 40:
         return jjStopAtPos(0, 12);
      case 41:
         return jjStopAtPos(0, 13);
      case 42:
         return jjStartNfaWithStates_3(0, 15, 36);
      case 43:
         return jjStopAtPos(0, 10);
      case 45:
         return jjStopAtPos(0, 11);
      case 58:
         return jjStopAtPos(0, 14);
      case 91:
         return jjStopAtPos(0, 22);
      case 94:
         return jjStopAtPos(0, 16);
      case 123:
         return jjStopAtPos(0, 23);
      default :
         return jjMoveNfa_3(0, 0);
   }
}
private final void jjCheckNAdd(int state)
{
   if (jjrounds[state] != jjround)
   {
      jjstateSet[jjnewStateCnt++] = state;
      jjrounds[state] = jjround;
   }
}
private final void jjAddStates(int start, int end)
{
   do {
      jjstateSet[jjnewStateCnt++] = jjnextStates[start];
   } while (start++ != end);
}
private final void jjCheckNAddTwoStates(int state1, int state2)
{
   jjCheckNAdd(state1);
   jjCheckNAdd(state2);
}
private final void jjCheckNAddStates(int start, int end)
{
   do {
      jjCheckNAdd(jjnextStates[start]);
   } while (start++ != end);
}
private final void jjCheckNAddStates(int start)
{
   jjCheckNAdd(jjnextStates[start]);
   jjCheckNAdd(jjnextStates[start + 1]);
}
static final long[] jjbitVec0 = {
   0xfffffffffffffffeL, 0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffffffL
};
static final long[] jjbitVec2 = {
   0x0L, 0x0L, 0xffffffffffffffffL, 0xffffffffffffffffL
};
private final int jjMoveNfa_3(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 36;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 36:
               case 25:
                  if ((0xfbfffcf8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 0:
                  if ((0xfbffd4f8ffffd9ffL & l) != 0L)
                  {
                     if (kind > 21)
                        kind = 21;
                     jjCheckNAddTwoStates(25, 26);
                  }
                  else if ((0x100002600L & l) != 0L)
                  {
                     if (kind > 6)
                        kind = 6;
                  }
                  else if (curChar == 34)
                     jjCheckNAddTwoStates(15, 17);
                  else if (curChar == 33)
                  {
                     if (kind > 9)
                        kind = 9;
                  }
                  if ((0x7bffd0f8ffffd9ffL & l) != 0L)
                  {
                     if (kind > 18)
                        kind = 18;
                     jjCheckNAddStates(0, 4);
                  }
                  else if (curChar == 42)
                  {
                     if (kind > 20)
                        kind = 20;
                  }
                  if (curChar == 38)
                     jjstateSet[jjnewStateCnt++] = 4;
                  break;
               case 4:
                  if (curChar == 38 && kind > 7)
                     kind = 7;
                  break;
               case 5:
                  if (curChar == 38)
                     jjstateSet[jjnewStateCnt++] = 4;
                  break;
               case 13:
                  if (curChar == 33 && kind > 9)
                     kind = 9;
                  break;
               case 14:
                  if (curChar == 34)
                     jjCheckNAddTwoStates(15, 17);
                  break;
               case 15:
                  if ((0xfffffffbffffffffL & l) != 0L)
                     jjCheckNAddStates(5, 7);
                  break;
               case 16:
                  if (curChar == 34)
                     jjCheckNAddStates(5, 7);
                  break;
               case 18:
                  if (curChar == 34 && kind > 17)
                     kind = 17;
                  break;
               case 20:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 19)
                     kind = 19;
                  jjAddStates(8, 9);
                  break;
               case 21:
                  if (curChar == 46)
                     jjCheckNAdd(22);
                  break;
               case 22:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 19)
                     kind = 19;
                  jjCheckNAdd(22);
                  break;
               case 23:
                  if (curChar == 42 && kind > 20)
                     kind = 20;
                  break;
               case 24:
                  if ((0xfbffd4f8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 27:
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 28:
                  if ((0x7bffd0f8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddStates(0, 4);
                  break;
               case 29:
                  if ((0x7bfff8f8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 31:
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 32:
                  if ((0x7bfff8f8ffffd9ffL & l) != 0L)
                     jjCheckNAddStates(10, 12);
                  break;
               case 34:
                  jjCheckNAddStates(10, 12);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 36:
                  if ((0x97ffffff87ffffffL & l) != 0L)
                  {
                     if (kind > 21)
                        kind = 21;
                     jjCheckNAddTwoStates(25, 26);
                  }
                  else if (curChar == 92)
                     jjCheckNAddTwoStates(27, 27);
                  break;
               case 0:
                  if ((0x97ffffff87ffffffL & l) != 0L)
                  {
                     if (kind > 18)
                        kind = 18;
                     jjCheckNAddStates(0, 4);
                  }
                  else if (curChar == 92)
                     jjCheckNAddStates(13, 15);
                  else if (curChar == 126)
                  {
                     if (kind > 19)
                        kind = 19;
                     jjstateSet[jjnewStateCnt++] = 20;
                  }
                  if ((0x97ffffff87ffffffL & l) != 0L)
                  {
                     if (kind > 21)
                        kind = 21;
                     jjCheckNAddTwoStates(25, 26);
                  }
                  if (curChar == 78)
                     jjstateSet[jjnewStateCnt++] = 11;
                  else if (curChar == 124)
                     jjstateSet[jjnewStateCnt++] = 8;
                  else if (curChar == 79)
                     jjstateSet[jjnewStateCnt++] = 6;
                  else if (curChar == 65)
                     jjstateSet[jjnewStateCnt++] = 2;
                  break;
               case 1:
                  if (curChar == 68 && kind > 7)
                     kind = 7;
                  break;
               case 2:
                  if (curChar == 78)
                     jjstateSet[jjnewStateCnt++] = 1;
                  break;
               case 3:
                  if (curChar == 65)
                     jjstateSet[jjnewStateCnt++] = 2;
                  break;
               case 6:
                  if (curChar == 82 && kind > 8)
                     kind = 8;
                  break;
               case 7:
                  if (curChar == 79)
                     jjstateSet[jjnewStateCnt++] = 6;
                  break;
               case 8:
                  if (curChar == 124 && kind > 8)
                     kind = 8;
                  break;
               case 9:
                  if (curChar == 124)
                     jjstateSet[jjnewStateCnt++] = 8;
                  break;
               case 10:
                  if (curChar == 84 && kind > 9)
                     kind = 9;
                  break;
               case 11:
                  if (curChar == 79)
                     jjstateSet[jjnewStateCnt++] = 10;
                  break;
               case 12:
                  if (curChar == 78)
                     jjstateSet[jjnewStateCnt++] = 11;
                  break;
               case 15:
                  jjAddStates(5, 7);
                  break;
               case 17:
                  if (curChar == 92)
                     jjstateSet[jjnewStateCnt++] = 16;
                  break;
               case 19:
                  if (curChar != 126)
                     break;
                  if (kind > 19)
                     kind = 19;
                  jjstateSet[jjnewStateCnt++] = 20;
                  break;
               case 24:
                  if ((0x97ffffff87ffffffL & l) == 0L)
                     break;
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 25:
                  if ((0x97ffffff87ffffffL & l) == 0L)
                     break;
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 26:
                  if (curChar == 92)
                     jjCheckNAddTwoStates(27, 27);
                  break;
               case 27:
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 28:
                  if ((0x97ffffff87ffffffL & l) == 0L)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddStates(0, 4);
                  break;
               case 29:
                  if ((0x97ffffff87ffffffL & l) == 0L)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 30:
                  if (curChar == 92)
                     jjCheckNAddTwoStates(31, 31);
                  break;
               case 31:
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 32:
                  if ((0x97ffffff87ffffffL & l) != 0L)
                     jjCheckNAddStates(10, 12);
                  break;
               case 33:
                  if (curChar == 92)
                     jjCheckNAddTwoStates(34, 34);
                  break;
               case 34:
                  jjCheckNAddStates(10, 12);
                  break;
               case 35:
                  if (curChar == 92)
                     jjCheckNAddStates(13, 15);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 36:
               case 25:
               case 27:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 0:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 21)
                        kind = 21;
                     jjCheckNAddTwoStates(25, 26);
                  }
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 18)
                        kind = 18;
                     jjCheckNAddStates(0, 4);
                  }
                  break;
               case 15:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjAddStates(5, 7);
                  break;
               case 24:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 21)
                     kind = 21;
                  jjCheckNAddTwoStates(25, 26);
                  break;
               case 28:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddStates(0, 4);
                  break;
               case 29:
               case 31:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 32:
               case 34:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(10, 12);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 36 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
private final int jjStopStringLiteralDfa_1(int pos, long active0)
{
   switch (pos)
   {
      case 0:
         if ((active0 & 0x20000000L) != 0L)
         {
            jjmatchedKind = 32;
            return 6;
         }
         return -1;
      default :
         return -1;
   }
}
private final int jjStartNfa_1(int pos, long active0)
{
   return jjMoveNfa_1(jjStopStringLiteralDfa_1(pos, active0), pos + 1);
}
private final int jjStartNfaWithStates_1(int pos, int kind, int state)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) { return pos + 1; }
   return jjMoveNfa_1(state, pos + 1);
}
private final int jjMoveStringLiteralDfa0_1()
{
   switch(curChar)
   {
      case 84:
         return jjMoveStringLiteralDfa1_1(0x20000000L);
      case 125:
         return jjStopAtPos(0, 30);
      default :
         return jjMoveNfa_1(0, 0);
   }
}
private final int jjMoveStringLiteralDfa1_1(long active0)
{
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) {
      jjStopStringLiteralDfa_1(0, active0);
      return 1;
   }
   switch(curChar)
   {
      case 79:
         if ((active0 & 0x20000000L) != 0L)
            return jjStartNfaWithStates_1(1, 29, 6);
         break;
      default :
         break;
   }
   return jjStartNfa_1(0, active0);
}
private final int jjMoveNfa_1(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 7;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0xfffffffeffffffffL & l) != 0L)
                  {
                     if (kind > 32)
                        kind = 32;
                     jjCheckNAdd(6);
                  }
                  if ((0x100002600L & l) != 0L)
                  {
                     if (kind > 6)
                        kind = 6;
                  }
                  else if (curChar == 34)
                     jjCheckNAddTwoStates(2, 4);
                  break;
               case 1:
                  if (curChar == 34)
                     jjCheckNAddTwoStates(2, 4);
                  break;
               case 2:
                  if ((0xfffffffbffffffffL & l) != 0L)
                     jjCheckNAddStates(16, 18);
                  break;
               case 3:
                  if (curChar == 34)
                     jjCheckNAddStates(16, 18);
                  break;
               case 5:
                  if (curChar == 34 && kind > 31)
                     kind = 31;
                  break;
               case 6:
                  if ((0xfffffffeffffffffL & l) == 0L)
                     break;
                  if (kind > 32)
                     kind = 32;
                  jjCheckNAdd(6);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 6:
                  if ((0xdfffffffffffffffL & l) == 0L)
                     break;
                  if (kind > 32)
                     kind = 32;
                  jjCheckNAdd(6);
                  break;
               case 2:
                  jjAddStates(16, 18);
                  break;
               case 4:
                  if (curChar == 92)
                     jjstateSet[jjnewStateCnt++] = 3;
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 6:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 32)
                     kind = 32;
                  jjCheckNAdd(6);
                  break;
               case 2:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjAddStates(16, 18);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 7 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
private final int jjMoveStringLiteralDfa0_0()
{
   return jjMoveNfa_0(0, 0);
}
private final int jjMoveNfa_0(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 3;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 24)
                     kind = 24;
                  jjAddStates(19, 20);
                  break;
               case 1:
                  if (curChar == 46)
                     jjCheckNAdd(2);
                  break;
               case 2:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 24)
                     kind = 24;
                  jjCheckNAdd(2);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 3 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
private final int jjStopStringLiteralDfa_2(int pos, long active0)
{
   switch (pos)
   {
      case 0:
         if ((active0 & 0x2000000L) != 0L)
         {
            jjmatchedKind = 28;
            return 6;
         }
         return -1;
      default :
         return -1;
   }
}
private final int jjStartNfa_2(int pos, long active0)
{
   return jjMoveNfa_2(jjStopStringLiteralDfa_2(pos, active0), pos + 1);
}
private final int jjStartNfaWithStates_2(int pos, int kind, int state)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) { return pos + 1; }
   return jjMoveNfa_2(state, pos + 1);
}
private final int jjMoveStringLiteralDfa0_2()
{
   switch(curChar)
   {
      case 84:
         return jjMoveStringLiteralDfa1_2(0x2000000L);
      case 93:
         return jjStopAtPos(0, 26);
      default :
         return jjMoveNfa_2(0, 0);
   }
}
private final int jjMoveStringLiteralDfa1_2(long active0)
{
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) {
      jjStopStringLiteralDfa_2(0, active0);
      return 1;
   }
   switch(curChar)
   {
      case 79:
         if ((active0 & 0x2000000L) != 0L)
            return jjStartNfaWithStates_2(1, 25, 6);
         break;
      default :
         break;
   }
   return jjStartNfa_2(0, active0);
}
private final int jjMoveNfa_2(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 7;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0xfffffffeffffffffL & l) != 0L)
                  {
                     if (kind > 28)
                        kind = 28;
                     jjCheckNAdd(6);
                  }
                  if ((0x100002600L & l) != 0L)
                  {
                     if (kind > 6)
                        kind = 6;
                  }
                  else if (curChar == 34)
                     jjCheckNAddTwoStates(2, 4);
                  break;
               case 1:
                  if (curChar == 34)
                     jjCheckNAddTwoStates(2, 4);
                  break;
               case 2:
                  if ((0xfffffffbffffffffL & l) != 0L)
                     jjCheckNAddStates(16, 18);
                  break;
               case 3:
                  if (curChar == 34)
                     jjCheckNAddStates(16, 18);
                  break;
               case 5:
                  if (curChar == 34 && kind > 27)
                     kind = 27;
                  break;
               case 6:
                  if ((0xfffffffeffffffffL & l) == 0L)
                     break;
                  if (kind > 28)
                     kind = 28;
                  jjCheckNAdd(6);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 6:
                  if ((0xffffffffdfffffffL & l) == 0L)
                     break;
                  if (kind > 28)
                     kind = 28;
                  jjCheckNAdd(6);
                  break;
               case 2:
                  jjAddStates(16, 18);
                  break;
               case 4:
                  if (curChar == 92)
                     jjstateSet[jjnewStateCnt++] = 3;
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 6:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 28)
                     kind = 28;
                  jjCheckNAdd(6);
                  break;
               case 2:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjAddStates(16, 18);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 7 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
static final int[] jjnextStates = {
   29, 32, 23, 33, 30, 15, 17, 18, 20, 21, 32, 23, 33, 31, 34, 27, 
   2, 4, 5, 0, 1, 
};
private static final boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 0:
         return ((jjbitVec2[i2] & l2) != 0L);
      default : 
         if ((jjbitVec0[i1] & l1) != 0L)
            return true;
         return false;
   }
}
public static final String[] jjstrLiteralImages = {
"""", null, null, null, null, null, null, null, null, null, ""\53"", ""\55"", ""\50"", 
""\51"", ""\72"", ""\52"", ""\136"", null, null, null, null, null, ""\133"", ""\173"", null, 
""\124\117"", ""\135"", null, null, ""\124\117"", ""\175"", null, null, };
public static final String[] lexStateNames = {
   ""Boost"", 
   ""RangeEx"", 
   ""RangeIn"", 
   ""DEFAULT"", 
};
public static final int[] jjnewLexState = {
   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 2, 1, 3, 
   -1, 3, -1, -1, -1, 3, -1, -1, 
};
static final long[] jjtoToken = {
   0x1ffffff81L, 
};
static final long[] jjtoSkip = {
   0x40L, 
};
protected CharStream input_stream;
private final int[] jjrounds = new int[36];
private final int[] jjstateSet = new int[72];
protected char curChar;
public QueryParserTokenManager(CharStream stream)
{
   input_stream = stream;
}
public QueryParserTokenManager(CharStream stream, int lexState)
{
   this(stream);
   SwitchTo(lexState);
}
public void ReInit(CharStream stream)
{
   jjmatchedPos = jjnewStateCnt = 0;
   curLexState = defaultLexState;
   input_stream = stream;
   ReInitRounds();
}
private final void ReInitRounds()
{
   int i;
   jjround = 0x80000001;
   for (i = 36; i-- > 0;)
      jjrounds[i] = 0x80000000;
}
public void ReInit(CharStream stream, int lexState)
{
   ReInit(stream);
   SwitchTo(lexState);
}
public void SwitchTo(int lexState)
{
   if (lexState >= 4 || lexState < 0)
      throw new TokenMgrError(""Error: Ignoring invalid lexical state : "" + lexState + "". State unchanged."", TokenMgrError.INVALID_LEXICAL_STATE);
   else
      curLexState = lexState;
}

protected Token jjFillToken()
{
   Token t = Token.newToken(jjmatchedKind);
   t.kind = jjmatchedKind;
   String im = jjstrLiteralImages[jjmatchedKind];
   t.image = (im == null) ? input_stream.GetImage() : im;
   t.beginLine = input_stream.getBeginLine();
   t.beginColumn = input_stream.getBeginColumn();
   t.endLine = input_stream.getEndLine();
   t.endColumn = input_stream.getEndColumn();
   return t;
}

int curLexState = 3;
int defaultLexState = 3;
int jjnewStateCnt;
int jjround;
int jjmatchedPos;
int jjmatchedKind;

public Token getNextToken() 
{
  int kind;
  Token specialToken = null;
  Token matchedToken;
  int curPos = 0;

  EOFLoop :
  for (;;)
  {   
   try   
   {     
      curChar = input_stream.BeginToken();
   }     
   catch(java.io.IOException e)
   {        
      jjmatchedKind = 0;
      matchedToken = jjFillToken();
      return matchedToken;
   }

   switch(curLexState)
   {
     case 0:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_0();
       break;
     case 1:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_1();
       break;
     case 2:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_2();
       break;
     case 3:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_3();
       break;
   }
     if (jjmatchedKind != 0x7fffffff)
     {
        if (jjmatchedPos + 1 < curPos)
           input_stream.backup(curPos - jjmatchedPos - 1);
        if ((jjtoToken[jjmatchedKind >> 6] & (1L << (jjmatchedKind & 077))) != 0L)
        {
           matchedToken = jjFillToken();
       if (jjnewLexState[jjmatchedKind] != -1)
         curLexState = jjnewLexState[jjmatchedKind];
           return matchedToken;
        }
        else
        {
         if (jjnewLexState[jjmatchedKind] != -1)
           curLexState = jjnewLexState[jjmatchedKind];
           continue EOFLoop;
        }
     }
     int error_line = input_stream.getEndLine();
     int error_column = input_stream.getEndColumn();
     String error_after = null;
     boolean EOFSeen = false;
     try { input_stream.readChar(); input_stream.backup(1); }
     catch (java.io.IOException e1) {
        EOFSeen = true;
        error_after = curPos <= 1 ? """" : input_stream.GetImage();
        if (curChar == '\n' || curChar == '\r') {
           error_line++;
           error_column = 0;
        }
        else
           error_column++;
     }
     if (!EOFSeen) {
        input_stream.backup(1);
        error_after = curPos <= 1 ? """" : input_stream.GetImage();
     }
     throw new TokenMgrError(EOFSeen, curLexState, error_line, error_column, error_after, curChar, TokenMgrError.LEXICAL_ERROR);
  }
}

}
"
lucene,2.2,org.apache.lucene.search.SortComparator,3,1,0,7,7,3,4,5,2,2.0,21,0.0,0,0.0,0.666666667,0,0,6.0,1,0.6667,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;


public abstract class SortComparator
implements SortComparatorSource {

  
  public ScoreDocComparator newComparator (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final Comparable[] cachedValues = FieldCache.DEFAULT.getCustom (reader, field, SortComparator.this);
    
    return new ScoreDocComparator() {

      public int compare (ScoreDoc i, ScoreDoc j) {
        return cachedValues[i.doc].compareTo (cachedValues[j.doc]);
      }

      public Comparable sortValue (ScoreDoc i) {
        return cachedValues[i.doc];
      }

      public int sortType(){
        return SortField.CUSTOM;
      }
    };
  }

  
  protected abstract Comparable getComparable (String termtext);

}
"
lucene,2.2,org.apache.lucene.search.function.ValueSourceQuery,7,2,1,11,20,9,5,7,6,0.5,74,0.0,1,0.666666667,0.265306122,2,3,9.428571429,4,1.2857,1,"package org.apache.lucene.search.function;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.*;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;
import java.util.Set;


public class ValueSourceQuery extends Query {
  ValueSource valSrc;

  
  public ValueSourceQuery(ValueSource valSrc) {
    this.valSrc=valSrc;
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    return this;
  }

  
  public void extractTerms(Set terms) {
    
  }

  private class ValueSourceWeight implements Weight {
    Searcher searcher;
    float queryNorm;
    float queryWeight;

    public ValueSourceWeight(Searcher searcher) {
      this.searcher = searcher;
    }

    
    public Query getQuery() {
      return ValueSourceQuery.this;
    }

    
    public float getValue() {
      return queryWeight;
    }

    
    public float sumOfSquaredWeights() throws IOException {
      queryWeight = getBoost();
      return queryWeight * queryWeight;
    }

    
    public void normalize(float norm) {
      this.queryNorm = norm;
      queryWeight *= this.queryNorm;
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      return new ValueSourceScorer(getSimilarity(searcher), reader, this);
    }

    
    public Explanation explain(IndexReader reader, int doc) throws IOException {
      return scorer(reader).explain(doc);
    }
  }

  
  private class ValueSourceScorer extends Scorer {
    private final IndexReader reader;
    private final ValueSourceWeight weight;
    private final int maxDoc;
    private final float qWeight;
    private int doc=-1;
    private final DocValues vals;

    
    private ValueSourceScorer(Similarity similarity, IndexReader reader, ValueSourceWeight w) throws IOException {
      super(similarity);
      this.weight = w;
      this.qWeight = w.getValue();
      this.reader = reader;
      this.maxDoc = reader.maxDoc();
      
      vals = valSrc.getValues(reader);
    }

    
    public boolean next() throws IOException {
      for(;;) {
        ++doc;
        if (doc>=maxDoc) {
          return false;
        }
        if (reader.isDeleted(doc)) {
          continue;
        }
        return true;
      }
    }

    
    public int doc() {
      return doc;
    }

    
    public float score() throws IOException {
      return qWeight * vals.floatVal(doc);
    }

    
    public boolean skipTo(int target) throws IOException {
      doc=target-1;
      return next();
    }

    
    public Explanation explain(int doc) throws IOException {
      float sc = qWeight * vals.floatVal(doc);

      Explanation result = new ComplexExplanation(
        true, sc, ValueSourceQuery.this.toString() + "", product of:"");

      result.addDetail(vals.explain(doc));
      result.addDetail(new Explanation(getBoost(), ""boost""));
      result.addDetail(new Explanation(weight.queryNorm,""queryNorm""));
      return result;
    }
  }

  
  protected Weight createWeight(Searcher searcher) {
    return new ValueSourceQuery.ValueSourceWeight(searcher);
  }

  
  public String toString(String field) {
    return valSrc.toString() + ToStringUtils.boost(getBoost());
  }

  
  public boolean equals(Object o) {
    if (getClass() != o.getClass()) {
      return false;
    }
    ValueSourceQuery other = (ValueSourceQuery)o;
    return this.getBoost() == other.getBoost()
           && this.valSrc.equals(other.valSrc);
  }

  
  public int hashCode() {
    return (getClass().hashCode() + valSrc.hashCode()) ^ Float.floatToIntBits(getBoost());
  }

}
"
lucene,2.2,org.apache.lucene.index.TermEnum,6,1,5,33,8,15,32,1,6,2.0,21,0.0,0,0.0,0.583333333,0,0,2.5,1,0.8333,0,"package org.apache.lucene.index;



import java.io.IOException;



public abstract class TermEnum {
  
  public abstract boolean next() throws IOException;

  
  public abstract Term term();

  
  public abstract int docFreq();

  
  public abstract void close() throws IOException;
  

  
  
  public boolean skipTo(Term target) throws IOException {
     do {
        if (!next())
  	        return false;
     } while (target.compareTo(term()) > 0);
     return true;
  }
}
"
lucene,2.2,org.apache.lucene.index.ParallelReader,27,2,0,16,84,193,3,16,21,0.824175824,558,1.0,0,0.697674419,0.168350168,1,9,19.40740741,2,1.037,5,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.document.FieldSelectorResult;
import org.apache.lucene.document.Fieldable;

import java.io.IOException;
import java.util.*;



public class ParallelReader extends IndexReader {
  private List readers = new ArrayList();
  private SortedMap fieldToReader = new TreeMap();
  private Map readerToFields = new HashMap();
  private List storedFieldReaders = new ArrayList();

  private int maxDoc;
  private int numDocs;
  private boolean hasDeletions;

 
  public ParallelReader() throws IOException { super(null); }

 
  public void add(IndexReader reader) throws IOException {
    ensureOpen();
    add(reader, false);
  }

 
  public void add(IndexReader reader, boolean ignoreStoredFields)
    throws IOException {

    ensureOpen();
    if (readers.size() == 0) {
      this.maxDoc = reader.maxDoc();
      this.numDocs = reader.numDocs();
      this.hasDeletions = reader.hasDeletions();
    }

    if (reader.maxDoc() != maxDoc)                
      throw new IllegalArgumentException
        (""All readers must have same maxDoc: ""+maxDoc+""!=""+reader.maxDoc());
    if (reader.numDocs() != numDocs)
      throw new IllegalArgumentException
        (""All readers must have same numDocs: ""+numDocs+""!=""+reader.numDocs());

    Collection fields = reader.getFieldNames(IndexReader.FieldOption.ALL);
    readerToFields.put(reader, fields);
    Iterator i = fields.iterator();
    while (i.hasNext()) {                         
      String field = (String)i.next();
      if (fieldToReader.get(field) == null)
        fieldToReader.put(field, reader);
    }

    if (!ignoreStoredFields)
      storedFieldReaders.add(reader);             
    readers.add(reader);
  }

  public int numDocs() {
    
    return numDocs;
  }

  public int maxDoc() {
    
    return maxDoc;
  }

  public boolean hasDeletions() {
    
    return hasDeletions;
  }

  
  public boolean isDeleted(int n) {
    
    if (readers.size() > 0)
      return ((IndexReader)readers.get(0)).isDeleted(n);
    return false;
  }

  
  protected void doDelete(int n) throws CorruptIndexException, IOException {
    for (int i = 0; i < readers.size(); i++) {
      ((IndexReader)readers.get(i)).deleteDocument(n);
    }
    hasDeletions = true;
  }

  
  protected void doUndeleteAll() throws CorruptIndexException, IOException {
    for (int i = 0; i < readers.size(); i++) {
      ((IndexReader)readers.get(i)).undeleteAll();
    }
    hasDeletions = false;
  }

  
  public Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
    ensureOpen();
    Document result = new Document();
    for (int i = 0; i < storedFieldReaders.size(); i++) {
      IndexReader reader = (IndexReader)storedFieldReaders.get(i);

      boolean include = (fieldSelector==null);
      if (!include) {
        Iterator it = ((Collection) readerToFields.get(reader)).iterator();
        while (it.hasNext())
          if (fieldSelector.accept((String)it.next())!=FieldSelectorResult.NO_LOAD) {
            include = true;
            break;
          }
      }
      if (include) {
        Iterator fieldIterator = reader.document(n, fieldSelector).getFields().iterator();
        while (fieldIterator.hasNext()) {
          result.add((Fieldable)fieldIterator.next());
        }
      }
    }
    return result;
  }

  
  public TermFreqVector[] getTermFreqVectors(int n) throws IOException {
    ensureOpen();
    ArrayList results = new ArrayList();
    Iterator i = fieldToReader.entrySet().iterator();
    while (i.hasNext()) {
      Map.Entry e = (Map.Entry)i.next();
      String field = (String)e.getKey();
      IndexReader reader = (IndexReader)e.getValue();
      TermFreqVector vector = reader.getTermFreqVector(n, field);
      if (vector != null)
        results.add(vector);
    }
    return (TermFreqVector[])
      results.toArray(new TermFreqVector[results.size()]);
  }

  public TermFreqVector getTermFreqVector(int n, String field)
    throws IOException {
    ensureOpen();
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    return reader==null ? null : reader.getTermFreqVector(n, field);
  }

  public boolean hasNorms(String field) throws IOException {
    ensureOpen();
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    return reader==null ? false : reader.hasNorms(field);
  }

  public byte[] norms(String field) throws IOException {
    ensureOpen();
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    return reader==null ? null : reader.norms(field);
  }

  public void norms(String field, byte[] result, int offset)
    throws IOException {
    ensureOpen();
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    if (reader!=null)
      reader.norms(field, result, offset);
  }

  protected void doSetNorm(int n, String field, byte value)
    throws CorruptIndexException, IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    if (reader!=null)
      reader.doSetNorm(n, field, value);
  }

  public TermEnum terms() throws IOException {
    ensureOpen();
    return new ParallelTermEnum();
  }

  public TermEnum terms(Term term) throws IOException {
    ensureOpen();
    return new ParallelTermEnum(term);
  }

  public int docFreq(Term term) throws IOException {
    ensureOpen();
    IndexReader reader = ((IndexReader)fieldToReader.get(term.field()));
    return reader==null ? 0 : reader.docFreq(term);
  }

  public TermDocs termDocs(Term term) throws IOException {
    ensureOpen();
    return new ParallelTermDocs(term);
  }

  public TermDocs termDocs() throws IOException {
    ensureOpen();
    return new ParallelTermDocs();
  }

  public TermPositions termPositions(Term term) throws IOException {
    ensureOpen();
    return new ParallelTermPositions(term);
  }

  public TermPositions termPositions() throws IOException {
    ensureOpen();
    return new ParallelTermPositions();
  }

  protected void doCommit() throws IOException {
    for (int i = 0; i < readers.size(); i++)
      ((IndexReader)readers.get(i)).commit();
  }

  protected synchronized void doClose() throws IOException {
    for (int i = 0; i < readers.size(); i++)
      ((IndexReader)readers.get(i)).close();
  }


  public Collection getFieldNames (IndexReader.FieldOption fieldNames) {
    ensureOpen();
    Set fieldSet = new HashSet();
    for (int i = 0; i < readers.size(); i++) {
      IndexReader reader = ((IndexReader)readers.get(i));
      Collection names = reader.getFieldNames(fieldNames);
      fieldSet.addAll(names);
    }
    return fieldSet;
  }

  private class ParallelTermEnum extends TermEnum {
    private String field;
    private Iterator fieldIterator;
    private TermEnum termEnum;

    public ParallelTermEnum() throws IOException {
      field = (String)fieldToReader.firstKey();
      if (field != null)
        termEnum = ((IndexReader)fieldToReader.get(field)).terms();
    }

    public ParallelTermEnum(Term term) throws IOException {
      field = term.field();
      IndexReader reader = ((IndexReader)fieldToReader.get(field));
      if (reader!=null)
        termEnum = reader.terms(term);
    }

    public boolean next() throws IOException {
      if (termEnum==null)
        return false;

      
      if (termEnum.next() && termEnum.term().field()==field)
        return true;                              

      termEnum.close();                           

      
      if (fieldIterator==null) {
        fieldIterator = fieldToReader.tailMap(field).keySet().iterator();
        fieldIterator.next();                     
      }
      while (fieldIterator.hasNext()) {
        field = (String) fieldIterator.next();
        termEnum = ((IndexReader)fieldToReader.get(field)).terms(new Term(field, """"));
        Term term = termEnum.term();
        if (term!=null && term.field()==field)
          return true;
        else
          termEnum.close();
      }
 
      return false;                               
    }

    public Term term() {
      if (termEnum==null)
        return null;

      return termEnum.term();
    }

    public int docFreq() {
      if (termEnum==null)
        return 0;

      return termEnum.docFreq();
    }

    public void close() throws IOException {
      if (termEnum!=null)
        termEnum.close();
    }

  }

  
  private class ParallelTermDocs implements TermDocs {
    protected TermDocs termDocs;

    public ParallelTermDocs() {}
    public ParallelTermDocs(Term term) throws IOException { seek(term); }

    public int doc() { return termDocs.doc(); }
    public int freq() { return termDocs.freq(); }

    public void seek(Term term) throws IOException {
      IndexReader reader = ((IndexReader)fieldToReader.get(term.field()));
      termDocs = reader!=null ? reader.termDocs(term) : null;
    }

    public void seek(TermEnum termEnum) throws IOException {
      seek(termEnum.term());
    }

    public boolean next() throws IOException {
      if (termDocs==null)
        return false;

      return termDocs.next();
    }

    public int read(final int[] docs, final int[] freqs) throws IOException {
      if (termDocs==null)
        return 0;

      return termDocs.read(docs, freqs);
    }

    public boolean skipTo(int target) throws IOException {
      if (termDocs==null)
        return false;

      return termDocs.skipTo(target);
    }

    public void close() throws IOException {
      if (termDocs!=null)
        termDocs.close();
    }

  }

  private class ParallelTermPositions
    extends ParallelTermDocs implements TermPositions {

    public ParallelTermPositions() {}
    public ParallelTermPositions(Term term) throws IOException { seek(term); }

    public void seek(Term term) throws IOException {
      IndexReader reader = ((IndexReader)fieldToReader.get(term.field()));
      termDocs = reader!=null ? reader.termPositions(term) : null;
    }

    public int nextPosition() throws IOException {
      
      return ((TermPositions)termDocs).nextPosition();
    }

    public int getPayloadLength() {
      return ((TermPositions)termDocs).getPayloadLength();
    }

    public byte[] getPayload(byte[] data, int offset) throws IOException {
      return ((TermPositions)termDocs).getPayload(data, offset);
    }


    
    public boolean isPayloadAvailable() {
      return ((TermPositions) termDocs).isPayloadAvailable();
    }
  }

}


"
lucene,2.2,org.apache.lucene.search.TermScorer,9,2,0,10,31,0,1,9,7,0.545454545,409,1.0,2,0.5,0.285714286,1,3,43.22222222,2,1.0,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.TermDocs;


final class TermScorer extends Scorer {
  private Weight weight;
  private TermDocs termDocs;
  private byte[] norms;
  private float weightValue;
  private int doc;

  private final int[] docs = new int[32];         
  private final int[] freqs = new int[32];        
  private int pointer;
  private int pointerMax;

  private static final int SCORE_CACHE_SIZE = 32;
  private float[] scoreCache = new float[SCORE_CACHE_SIZE];

  
  TermScorer(Weight weight, TermDocs td, Similarity similarity,
             byte[] norms) {
    super(similarity);
    this.weight = weight;
    this.termDocs = td;
    this.norms = norms;
    this.weightValue = weight.getValue();

    for (int i = 0; i < SCORE_CACHE_SIZE; i++)
      scoreCache[i] = getSimilarity().tf(i) * weightValue;
  }

  public void score(HitCollector hc) throws IOException {
    next();
    score(hc, Integer.MAX_VALUE);
  }

  protected boolean score(HitCollector c, int end) throws IOException {
    Similarity similarity = getSimilarity();      
    float[] normDecoder = Similarity.getNormDecoder();
    while (doc < end) {                           
      int f = freqs[pointer];
      float score =                               
        f < SCORE_CACHE_SIZE                      
         ? scoreCache[f]                          
         : similarity.tf(f)*weightValue;          

      score *= normDecoder[norms[doc] & 0xFF];    

      c.collect(doc, score);                      

      if (++pointer >= pointerMax) {
        pointerMax = termDocs.read(docs, freqs);  
        if (pointerMax != 0) {
          pointer = 0;
        } else {
          termDocs.close();                       
          doc = Integer.MAX_VALUE;                
          return false;
        }
      } 
      doc = docs[pointer];
    }
    return true;
  }

  
  public int doc() { return doc; }

  
  public boolean next() throws IOException {
    pointer++;
    if (pointer >= pointerMax) {
      pointerMax = termDocs.read(docs, freqs);    
      if (pointerMax != 0) {
        pointer = 0;
      } else {
        termDocs.close();                         
        doc = Integer.MAX_VALUE;                  
        return false;
      }
    } 
    doc = docs[pointer];
    return true;
  }

  public float score() {
    int f = freqs[pointer];
    float raw =                                   
      f < SCORE_CACHE_SIZE                        
      ? scoreCache[f]                             
      : getSimilarity().tf(f)*weightValue;        

    return raw * Similarity.decodeNorm(norms[doc]); 
  }

  
  public boolean skipTo(int target) throws IOException {
    
    for (pointer++; pointer < pointerMax; pointer++) {
      if (docs[pointer] >= target) {
        doc = docs[pointer];
        return true;
      }
    }

    
    boolean result = termDocs.skipTo(target);
    if (result) {
      pointerMax = 1;
      pointer = 0;
      docs[pointer] = doc = termDocs.doc();
      freqs[pointer] = termDocs.freq();
    } else {
      doc = Integer.MAX_VALUE;
    }
    return result;
  }

  
  public Explanation explain(int doc) throws IOException {
    TermQuery query = (TermQuery)weight.getQuery();
    Explanation tfExplanation = new Explanation();
    int tf = 0;
    while (pointer < pointerMax) {
      if (docs[pointer] == doc)
        tf = freqs[pointer];
      pointer++;
    }
    if (tf == 0) {
        if (termDocs.skipTo(doc))
        {
            if (termDocs.doc() == doc)
            {
                tf = termDocs.freq();
            }
        }
    }
    termDocs.close();
    tfExplanation.setValue(getSimilarity().tf(tf));
    tfExplanation.setDescription(""tf(termFreq(""+query.getTerm()+"")=""+tf+"")"");
    
    return tfExplanation;
  }

  
  public String toString() { return ""scorer("" + weight + "")""; }
}
"
lucene,2.2,org.apache.lucene.search.function.ShortFieldSource,7,3,0,7,22,9,2,6,6,0.777777778,122,0.333333333,1,0.705882353,0.333333333,2,3,16.0,6,1.7143,1,"package org.apache.lucene.search.function;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;
import org.apache.lucene.search.function.DocValues;

import java.io.IOException;


public class ShortFieldSource extends FieldCacheSource {
  private FieldCache.ShortParser parser;

  
  public ShortFieldSource(String field) {
    this(field, null);
  }

  
  public ShortFieldSource(String field, FieldCache.ShortParser parser) {
    super(field);
    this.parser = parser;
  }

  
  public String description() {
    return ""short("" + super.description() + ')';
  }

  
  public DocValues getCachedFieldValues (FieldCache cache, String field, IndexReader reader) throws IOException {
    final short[] arr = (parser==null) ?  
      cache.getShorts(reader, field) : 
      cache.getShorts(reader, field, parser);
    return new DocValues(reader.maxDoc()) {
      
      public float floatVal(int doc) { 
        return (float) arr[doc]; 
      }
      
      public  int intVal(int doc) { 
        return arr[doc]; 
      }
      
      public String toString(int doc) { 
        return  description() + '=' + intVal(doc);  
      }
      
      Object getInnerArray() {
        return arr;
      }
    };
  }

  
  public boolean cachedFieldSourceEquals(FieldCacheSource o) {
    if (o.getClass() !=  ShortFieldSource.class) {
      return false;
    }
    ShortFieldSource other = (ShortFieldSource)o;
    return this.parser==null ? 
      other.parser==null :
      this.parser.getClass() == other.parser.getClass();
  }

  
  public int cachedFieldSourceHashCode() {
    return parser==null ? 
      Short.class.hashCode() : parser.getClass().hashCode();
  }

}
"
lucene,2.2,org.apache.lucene.search.FilteredQuery,9,2,0,9,26,0,2,8,8,0.3125,143,0.0,2,0.6,0.222222222,2,4,14.66666667,5,1.3333,2,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;
import java.util.BitSet;
import java.util.Set;



public class FilteredQuery
extends Query {

  Query query;
  Filter filter;

  
  public FilteredQuery (Query query, Filter filter) {
    this.query = query;
    this.filter = filter;
  }



  
  protected Weight createWeight (final Searcher searcher) throws IOException {
    final Weight weight = query.createWeight (searcher);
    final Similarity similarity = query.getSimilarity(searcher);
    return new Weight() {
      private float value;
        
      
      public float getValue() { return value; }
      public float sumOfSquaredWeights() throws IOException { 
        return weight.sumOfSquaredWeights() * getBoost() * getBoost(); 
      }
      public void normalize (float v) { 
        weight.normalize(v);
        value = weight.getValue() * getBoost();
      }
      public Explanation explain (IndexReader ir, int i) throws IOException {
        Explanation inner = weight.explain (ir, i);
        if (getBoost()!=1) {
          Explanation preBoost = inner;
          inner = new Explanation(inner.getValue()*getBoost(),""product of:"");
          inner.addDetail(new Explanation(getBoost(),""boost""));
          inner.addDetail(preBoost);
        }
        Filter f = FilteredQuery.this.filter;
        BitSet matches = f.bits(ir);
        if (matches.get(i))
          return inner;
        Explanation result = new Explanation
          (0.0f, ""failure to match filter: "" + f.toString());
        result.addDetail(inner);
        return result;
      }

      
      public Query getQuery() { return FilteredQuery.this; }

      
       public Scorer scorer (IndexReader indexReader) throws IOException {
        final Scorer scorer = weight.scorer (indexReader);
        final BitSet bitset = filter.bits (indexReader);
        return new Scorer (similarity) {

          public boolean next() throws IOException {
            do {
              if (! scorer.next()) {
                return false;
              }
            } while (! bitset.get(scorer.doc()));
            
            return true;
          }
          public int doc() { return scorer.doc(); }

          public boolean skipTo(int i) throws IOException {
            if (! scorer.skipTo(i)) {
              return false;
            }
            while (! bitset.get(scorer.doc())) {
              int nextFiltered = bitset.nextSetBit(scorer.doc() + 1);
              if (nextFiltered == -1) {
                return false;
              } else if (! scorer.skipTo(nextFiltered)) {
                return false;
              }
            }
            return true;
           }

          public float score() throws IOException { return getBoost() * scorer.score(); }

          
          public Explanation explain (int i) throws IOException {
            Explanation exp = scorer.explain (i);
            exp.setValue(getBoost() * exp.getValue());
            
            if (bitset.get(i))
              exp.setDescription (""allowed by filter: ""+exp.getDescription());
            else
              exp.setDescription (""removed by filter: ""+exp.getDescription());
            return exp;
          }
        };
      }
    };
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    Query rewritten = query.rewrite(reader);
    if (rewritten != query) {
      FilteredQuery clone = (FilteredQuery)this.clone();
      clone.query = rewritten;
      return clone;
    } else {
      return this;
    }
  }

  public Query getQuery() {
    return query;
  }

  public Filter getFilter() {
    return filter;
  }

  
  public void extractTerms(Set terms) {
      getQuery().extractTerms(terms);
  }

  
  public String toString (String s) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""filtered("");
    buffer.append(query.toString(s));
    buffer.append("")->"");
    buffer.append(filter);
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (o instanceof FilteredQuery) {
      FilteredQuery fq = (FilteredQuery) o;
      return (query.equals(fq.query) && filter.equals(fq.filter) && getBoost()==fq.getBoost());
    }
    return false;
  }

  
  public int hashCode() {
    return query.hashCode() ^ filter.hashCode() + Float.floatToRawIntBits(getBoost());
  }
}
"
lucene,2.2,org.apache.lucene.search.function.FloatFieldSource,7,3,0,7,22,9,2,6,6,0.777777778,122,0.333333333,1,0.705882353,0.333333333,2,3,16.0,6,1.7143,2,"package org.apache.lucene.search.function;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;
import org.apache.lucene.search.function.DocValues;

import java.io.IOException;


public class FloatFieldSource extends FieldCacheSource {
  private FieldCache.FloatParser parser;

  
  public FloatFieldSource(String field) {
    this(field, null);
  }

  
  public FloatFieldSource(String field, FieldCache.FloatParser parser) {
    super(field);
    this.parser = parser;
  }

  
  public String description() {
    return ""float("" + super.description() + ')';
  }

  
  public DocValues getCachedFieldValues (FieldCache cache, String field, IndexReader reader) throws IOException {
    final float[] arr = (parser==null) ?
      cache.getFloats(reader, field) :
      cache.getFloats(reader, field, parser);
    return new DocValues(reader.maxDoc()) {
      
      public float floatVal(int doc) {
        return arr[doc];      
      }
      
      public String toString(int doc) { 
        return  description() + '=' + arr[doc];  
      }
      
      Object getInnerArray() {
        return arr;
      }
    };
  }

  
  public boolean cachedFieldSourceEquals(FieldCacheSource o) {
    if (o.getClass() !=  FloatFieldSource.class) {
      return false;
    }
    FloatFieldSource other = (FloatFieldSource)o;
    return this.parser==null ? 
      other.parser==null :
      this.parser.getClass() == other.parser.getClass();
  }

  
  public int cachedFieldSourceHashCode() {
    return parser==null ? 
      Float.class.hashCode() : parser.getClass().hashCode();
  }
}"
lucene,2.2,org.apache.lucene.search.FilterManager,5,1,0,5,18,4,4,3,4,0.821428571,112,1.0,2,0.0,0.35,0,0,20.0,2,1.2,1,"package org.apache.lucene.search;



import java.util.Comparator;
import java.util.Date;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.TreeSet;


public class FilterManager {

  protected static FilterManager manager;
  
  
  protected static final int  DEFAULT_CACHE_CLEAN_SIZE = 100;
  
  protected static final long DEFAULT_CACHE_SLEEP_TIME = 1000 * 60 * 10;

  
  protected Map           cache;
  
  protected int           cacheCleanSize;
  
  protected long          cleanSleepTime;
  
  protected FilterCleaner filterCleaner;

  public synchronized static FilterManager getInstance() {
    if (manager == null) {
      manager = new FilterManager();
    }
    return manager;
  }

  
  protected FilterManager() {
    cache            = new HashMap();
    cacheCleanSize   = DEFAULT_CACHE_CLEAN_SIZE; 
    cleanSleepTime   = DEFAULT_CACHE_SLEEP_TIME; 

    filterCleaner   = new FilterCleaner();
    Thread fcThread = new Thread(filterCleaner);
    
    fcThread.setDaemon(true);
    fcThread.start();
  }
  
  
  public void setCacheSize(int cacheCleanSize) {
    this.cacheCleanSize = cacheCleanSize;
  }

  
  public void setCleanThreadSleepTime(long cleanSleepTime) {
    this.cleanSleepTime  = cleanSleepTime;
  }

  
  public Filter getFilter(Filter filter) {
    synchronized(cache) {
      FilterItem fi = null;
      fi = (FilterItem)cache.get(new Integer(filter.hashCode()));
      if (fi != null) {
        fi.timestamp = new Date().getTime();
        return fi.filter;
      }
      cache.put(new Integer(filter.hashCode()), new FilterItem(filter));
      return filter;
    }
  }

  
  protected class FilterItem {
    public Filter filter;
    public long   timestamp;

    public FilterItem (Filter filter) {        
      this.filter = filter;
      this.timestamp = new Date().getTime();
    }
  }


  
  protected class FilterCleaner implements Runnable  {

    private boolean running = true;
    private TreeSet sortedFilterItems;

    public FilterCleaner() {
      sortedFilterItems = new TreeSet(new Comparator() {
        public int compare(Object a, Object b) {
          if( a instanceof Map.Entry && b instanceof Map.Entry) {
            FilterItem fia = (FilterItem) ((Map.Entry)a).getValue();
            FilterItem fib = (FilterItem) ((Map.Entry)b).getValue();
            if ( fia.timestamp == fib.timestamp ) {
              return 0;
            }
            
            if ( fia.timestamp < fib.timestamp ) {
              return -1;
            }
            
            return 1;
          } else {
            throw new ClassCastException(""Objects are not Map.Entry"");
          }
        }
      });
    }

    public void run () {
      while (running) {

        
        
        if (cache.size() > cacheCleanSize) {
          
          sortedFilterItems.clear();
          synchronized (cache) {
            sortedFilterItems.addAll(cache.entrySet());
            Iterator it = sortedFilterItems.iterator();
            int numToDelete = (int) ((cache.size() - cacheCleanSize) * 1.5);
            int counter = 0;
            
            while (it.hasNext() && counter++ < numToDelete) {
              Map.Entry entry = (Map.Entry)it.next();
              cache.remove(entry.getKey());
            }
          }
          
          sortedFilterItems.clear();
        }
        
        try {
          Thread.sleep(cleanSleepTime);
        } catch (InterruptedException e) {
          
        }
      }
    }
  }
}
"
lucene,2.2,org.apache.lucene.search.FilteredTermEnum,9,2,2,7,14,8,5,2,6,0.5,103,1.0,2,0.384615385,0.407407407,1,2,10.22222222,2,1.0,0,"package org.apache.lucene.search;



import java.io.IOException;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;


public abstract class FilteredTermEnum extends TermEnum {
    private Term currentTerm = null;
    private TermEnum actualEnum = null;
    
    public FilteredTermEnum() {}

    
    protected abstract boolean termCompare(Term term);
    
    
    public abstract float difference();

    
    protected abstract boolean endEnum();
    
    protected void setEnum(TermEnum actualEnum) throws IOException {
        this.actualEnum = actualEnum;
        
        Term term = actualEnum.term();
        if (term != null && termCompare(term)) 
            currentTerm = term;
        else next();
    }
    
    
    public int docFreq() {
        if (actualEnum == null) return -1;
        return actualEnum.docFreq();
    }
    
    
    public boolean next() throws IOException {
        if (actualEnum == null) return false; 
        currentTerm = null;
        while (currentTerm == null) {
            if (endEnum()) return false;
            if (actualEnum.next()) {
                Term term = actualEnum.term();
                if (termCompare(term)) {
                    currentTerm = term;
                    return true;
                }
            }
            else return false;
        }
        currentTerm = null;
        return false;
    }
    
    
    public Term term() {
        return currentTerm;
    }
    
    
    public void close() throws IOException {
        actualEnum.close();
        currentTerm = null;
        actualEnum = null;
    }
}
"
lucene,2.2,org.apache.lucene.index.TermDocs,8,1,0,27,8,28,25,2,8,2.0,8,0.0,0,0.0,0.3,0,0,0.0,1,1.0,0,"package org.apache.lucene.index;



import java.io.IOException;



public interface TermDocs {
  
  void seek(Term term) throws IOException;

  
  void seek(TermEnum termEnum) throws IOException;

  
  int doc();

  
  int freq();

  
  boolean next() throws IOException;

  
  int read(int[] docs, int[] freqs) throws IOException;

  
  boolean skipTo(int target) throws IOException;

  
  void close() throws IOException;
}


"
lucene,2.2,org.apache.lucene.index.SegmentReader,45,2,0,31,137,732,6,28,20,0.899793388,1253,0.590909091,10,0.582524272,0.131118881,1,8,26.35555556,28,1.7556,11,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.search.DefaultSimilarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.BufferedIndexInput;
import org.apache.lucene.util.BitVector;

import java.io.IOException;
import java.util.*;


class SegmentReader extends IndexReader {
  private String segment;
  private SegmentInfo si;

  FieldInfos fieldInfos;
  private FieldsReader fieldsReader;

  TermInfosReader tis;
  TermVectorsReader termVectorsReaderOrig = null;
  ThreadLocal termVectorsLocal = new ThreadLocal();

  BitVector deletedDocs = null;
  private boolean deletedDocsDirty = false;
  private boolean normsDirty = false;
  private boolean undeleteAll = false;

  private boolean rollbackDeletedDocsDirty = false;
  private boolean rollbackNormsDirty = false;
  private boolean rollbackUndeleteAll = false;

  IndexInput freqStream;
  IndexInput proxStream;

  
  private IndexInput singleNormStream;

  
  CompoundFileReader cfsReader = null;

  private class Norm {
    public Norm(IndexInput in, int number, long normSeek)
    {
      this.in = in;
      this.number = number;
      this.normSeek = normSeek;
    }

    private IndexInput in;
    private byte[] bytes;
    private boolean dirty;
    private int number;
    private long normSeek;
    private boolean rollbackDirty;

    private void reWrite(SegmentInfo si) throws IOException {
      
      si.advanceNormGen(this.number);
      IndexOutput out = directory().createOutput(si.getNormFileName(this.number));
      try {
        out.writeBytes(bytes, maxDoc());
      } finally {
        out.close();
      }
      this.dirty = false;
    }

    
    public void close() throws IOException {
      if (in != null && in != singleNormStream) {
        in.close();
      }
      in = null;
    }
  }

  private Hashtable norms = new Hashtable();

  
  private static Class IMPL;
  static {
    try {
      String name =
        System.getProperty(""org.apache.lucene.SegmentReader.class"",
                           SegmentReader.class.getName());
      IMPL = Class.forName(name);
    } catch (ClassNotFoundException e) {
      throw new RuntimeException(""cannot load SegmentReader class: "" + e, e);
    } catch (SecurityException se) {
      try {
        IMPL = Class.forName(SegmentReader.class.getName());
      } catch (ClassNotFoundException e) {
        throw new RuntimeException(""cannot load default SegmentReader class: "" + e, e);
      }
    }
  }

  protected SegmentReader() { super(null); }

  
  public static SegmentReader get(SegmentInfo si) throws CorruptIndexException, IOException {
    return get(si.dir, si, null, false, false, BufferedIndexInput.BUFFER_SIZE);
  }

  
  public static SegmentReader get(SegmentInfo si, int readBufferSize) throws CorruptIndexException, IOException {
    return get(si.dir, si, null, false, false, readBufferSize);
  }

  
  public static SegmentReader get(SegmentInfos sis, SegmentInfo si,
                                  boolean closeDir) throws CorruptIndexException, IOException {
    return get(si.dir, si, sis, closeDir, true, BufferedIndexInput.BUFFER_SIZE);
  }

  
  public static SegmentReader get(Directory dir, SegmentInfo si,
                                  SegmentInfos sis,
                                  boolean closeDir, boolean ownDir,
                                  int readBufferSize)
    throws CorruptIndexException, IOException {
    SegmentReader instance;
    try {
      instance = (SegmentReader)IMPL.newInstance();
    } catch (Exception e) {
      throw new RuntimeException(""cannot load SegmentReader class: "" + e, e);
    }
    instance.init(dir, sis, closeDir, ownDir);
    instance.initialize(si, readBufferSize);
    return instance;
  }

  private void initialize(SegmentInfo si, int readBufferSize) throws CorruptIndexException, IOException {
    segment = si.name;
    this.si = si;

    boolean success = false;

    try {
      
      Directory cfsDir = directory();
      if (si.getUseCompoundFile()) {
        cfsReader = new CompoundFileReader(directory(), segment + "".cfs"", readBufferSize);
        cfsDir = cfsReader;
      }

      
      fieldInfos = new FieldInfos(cfsDir, segment + "".fnm"");
      fieldsReader = new FieldsReader(cfsDir, segment, fieldInfos, readBufferSize);

      
      if (fieldsReader.size() != si.docCount) {
        throw new CorruptIndexException(""doc counts differ for segment "" + si.name + "": fieldsReader shows "" + fieldsReader.size() + "" but segmentInfo shows "" + si.docCount);
      }

      tis = new TermInfosReader(cfsDir, segment, fieldInfos, readBufferSize);
      
      
      if (hasDeletions(si)) {
        deletedDocs = new BitVector(directory(), si.getDelFileName());

        
        if (deletedDocs.count() > maxDoc()) {
          throw new CorruptIndexException(""number of deletes ("" + deletedDocs.count() + "") exceeds max doc ("" + maxDoc() + "") for segment "" + si.name);
        }
      }

      
      
      freqStream = cfsDir.openInput(segment + "".frq"", readBufferSize);
      proxStream = cfsDir.openInput(segment + "".prx"", readBufferSize);
      openNorms(cfsDir, readBufferSize);

      if (fieldInfos.hasVectors()) { 
        termVectorsReaderOrig = new TermVectorsReader(cfsDir, segment, fieldInfos, readBufferSize);
      }
      success = true;
    } finally {

      
      
      
      
      
      if (!success) {
        doClose();
      }
    }
  }

  protected void doCommit() throws IOException {
    if (deletedDocsDirty) {               
      si.advanceDelGen();

      
      
      
      deletedDocs.write(directory(), si.getDelFileName());
    }
    if (undeleteAll && si.hasDeletions()) {
      si.clearDelGen();
    }
    if (normsDirty) {               
      si.setNumFields(fieldInfos.size());
      Enumeration values = norms.elements();
      while (values.hasMoreElements()) {
        Norm norm = (Norm) values.nextElement();
        if (norm.dirty) {
          norm.reWrite(si);
        }
      }
    }
    deletedDocsDirty = false;
    normsDirty = false;
    undeleteAll = false;
  }

  protected void doClose() throws IOException {
    if (fieldsReader != null) {
      fieldsReader.close();
    }
    if (tis != null) {
      tis.close();
    }

    if (freqStream != null)
      freqStream.close();
    if (proxStream != null)
      proxStream.close();

    closeNorms();

    if (termVectorsReaderOrig != null)
      termVectorsReaderOrig.close();

    if (cfsReader != null)
      cfsReader.close();
  }

  static boolean hasDeletions(SegmentInfo si) throws IOException {
    
    return si.hasDeletions();
  }

  public boolean hasDeletions() {
    
    return deletedDocs != null;
  }

  static boolean usesCompoundFile(SegmentInfo si) throws IOException {
    return si.getUseCompoundFile();
  }

  static boolean hasSeparateNorms(SegmentInfo si) throws IOException {
    return si.hasSeparateNorms();
  }

  protected void doDelete(int docNum) {
    if (deletedDocs == null)
      deletedDocs = new BitVector(maxDoc());
    deletedDocsDirty = true;
    undeleteAll = false;
    deletedDocs.set(docNum);
  }

  protected void doUndeleteAll() {
      deletedDocs = null;
      deletedDocsDirty = false;
      undeleteAll = true;
  }

  Vector files() throws IOException {
    return new Vector(si.files());
  }

  public TermEnum terms() {
    ensureOpen();
    return tis.terms();
  }

  public TermEnum terms(Term t) throws IOException {
    ensureOpen();
    return tis.terms(t);
  }

  
  public synchronized Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
    ensureOpen();
    if (isDeleted(n))
      throw new IllegalArgumentException
              (""attempt to access a deleted document"");
    return fieldsReader.doc(n, fieldSelector);
  }

  public synchronized boolean isDeleted(int n) {
    return (deletedDocs != null && deletedDocs.get(n));
  }

  public TermDocs termDocs() throws IOException {
    ensureOpen();
    return new SegmentTermDocs(this);
  }

  public TermPositions termPositions() throws IOException {
    ensureOpen();
    return new SegmentTermPositions(this);
  }

  public int docFreq(Term t) throws IOException {
    ensureOpen();
    TermInfo ti = tis.get(t);
    if (ti != null)
      return ti.docFreq;
    else
      return 0;
  }

  public int numDocs() {
    
    int n = maxDoc();
    if (deletedDocs != null)
      n -= deletedDocs.count();
    return n;
  }

  public int maxDoc() {
    
    return si.docCount;
  }

  
  public Collection getFieldNames(IndexReader.FieldOption fieldOption) {
    ensureOpen();

    Set fieldSet = new HashSet();
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fieldOption == IndexReader.FieldOption.ALL) {
        fieldSet.add(fi.name);
      }
      else if (!fi.isIndexed && fieldOption == IndexReader.FieldOption.UNINDEXED) {
        fieldSet.add(fi.name);
      }
      else if (fi.storePayloads && fieldOption == IndexReader.FieldOption.STORES_PAYLOADS) {
        fieldSet.add(fi.name);
      }
      else if (fi.isIndexed && fieldOption == IndexReader.FieldOption.INDEXED) {
        fieldSet.add(fi.name);
      }
      else if (fi.isIndexed && fi.storeTermVector == false && fieldOption == IndexReader.FieldOption.INDEXED_NO_TERMVECTOR) {
        fieldSet.add(fi.name);
      }
      else if (fi.storeTermVector == true &&
               fi.storePositionWithTermVector == false &&
               fi.storeOffsetWithTermVector == false &&
               fieldOption == IndexReader.FieldOption.TERMVECTOR) {
        fieldSet.add(fi.name);
      }
      else if (fi.isIndexed && fi.storeTermVector && fieldOption == IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR) {
        fieldSet.add(fi.name);
      }
      else if (fi.storePositionWithTermVector && fi.storeOffsetWithTermVector == false && fieldOption == IndexReader.FieldOption.TERMVECTOR_WITH_POSITION) {
        fieldSet.add(fi.name);
      }
      else if (fi.storeOffsetWithTermVector && fi.storePositionWithTermVector == false && fieldOption == IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET) {
        fieldSet.add(fi.name);
      }
      else if ((fi.storeOffsetWithTermVector && fi.storePositionWithTermVector) &&
                fieldOption == IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET) {
        fieldSet.add(fi.name);
      }
    }
    return fieldSet;
  }


  public synchronized boolean hasNorms(String field) {
    ensureOpen();
    return norms.containsKey(field);
  }

  static byte[] createFakeNorms(int size) {
    byte[] ones = new byte[size];
    Arrays.fill(ones, DefaultSimilarity.encodeNorm(1.0f));
    return ones;
  }

  private byte[] ones;
  private byte[] fakeNorms() {
    if (ones==null) ones=createFakeNorms(maxDoc());
    return ones;
  }

  
  protected synchronized byte[] getNorms(String field) throws IOException {
    Norm norm = (Norm) norms.get(field);
    if (norm == null) return null;  
    if (norm.bytes == null) {                     
      byte[] bytes = new byte[maxDoc()];
      norms(field, bytes, 0);
      norm.bytes = bytes;                         
      
      
      norm.close();
    }
    return norm.bytes;
  }

  
  public synchronized byte[] norms(String field) throws IOException {
    ensureOpen();
    byte[] bytes = getNorms(field);
    if (bytes==null) bytes=fakeNorms();
    return bytes;
  }

  protected void doSetNorm(int doc, String field, byte value)
          throws IOException {
    Norm norm = (Norm) norms.get(field);
    if (norm == null)                             
      return;

    norm.dirty = true;                            
    normsDirty = true;

    norms(field)[doc] = value;                    
  }

  
  public synchronized void norms(String field, byte[] bytes, int offset)
    throws IOException {

    ensureOpen();
    Norm norm = (Norm) norms.get(field);
    if (norm == null) {
      System.arraycopy(fakeNorms(), 0, bytes, offset, maxDoc());
      return;
    }

    if (norm.bytes != null) {                     
      System.arraycopy(norm.bytes, 0, bytes, offset, maxDoc());
      return;
    }

    
    
    norm.in.seek(norm.normSeek);
    norm.in.readBytes(bytes, offset, maxDoc());
  }


  private void openNorms(Directory cfsDir, int readBufferSize) throws IOException {
    long nextNormSeek = SegmentMerger.NORMS_HEADER.length; 
    int maxDoc = maxDoc();
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        Directory d = directory();
        String fileName = si.getNormFileName(fi.number);
        if (!si.hasSeparateNorms(fi.number)) {
          d = cfsDir;
        }
        
        
        boolean singleNormFile = fileName.endsWith(""."" + IndexFileNames.NORMS_EXTENSION);
        IndexInput normInput = null;
        long normSeek;

        if (singleNormFile) {
          normSeek = nextNormSeek;
          if (singleNormStream==null) {
            singleNormStream = d.openInput(fileName, readBufferSize);
          }
          
          
          
          normInput = singleNormStream;
        } else {
          normSeek = 0;
          normInput = d.openInput(fileName);
        }

        norms.put(fi.name, new Norm(normInput, fi.number, normSeek));
        nextNormSeek += maxDoc; 
      }
    }
  }

  private void closeNorms() throws IOException {
    synchronized (norms) {
      Enumeration enumerator = norms.elements();
      while (enumerator.hasMoreElements()) {
        Norm norm = (Norm) enumerator.nextElement();
        norm.close();
      }
      if (singleNormStream != null) {
        singleNormStream.close();
        singleNormStream = null;
      }
    }
  }
  
  
  private TermVectorsReader getTermVectorsReader() {
    TermVectorsReader tvReader = (TermVectorsReader)termVectorsLocal.get();
    if (tvReader == null) {
      tvReader = (TermVectorsReader)termVectorsReaderOrig.clone();
      termVectorsLocal.set(tvReader);
    }
    return tvReader;
  }
  
  
  public TermFreqVector getTermFreqVector(int docNumber, String field) throws IOException {
    
    ensureOpen();
    FieldInfo fi = fieldInfos.fieldInfo(field);
    if (fi == null || !fi.storeTermVector || termVectorsReaderOrig == null) 
      return null;
    
    TermVectorsReader termVectorsReader = getTermVectorsReader();
    if (termVectorsReader == null)
      return null;
    
    return termVectorsReader.get(docNumber, field);
  }


  
  public TermFreqVector[] getTermFreqVectors(int docNumber) throws IOException {
    ensureOpen();
    if (termVectorsReaderOrig == null)
      return null;
    
    TermVectorsReader termVectorsReader = getTermVectorsReader();
    if (termVectorsReader == null)
      return null;
    
    return termVectorsReader.get(docNumber);
  }
  
  
  FieldInfos fieldInfos() {
    return fieldInfos;
  }
  
  
  String getSegmentName() {
    return segment;
  }

  void setSegmentInfo(SegmentInfo info) {
    si = info;
  }

  void startCommit() {
    super.startCommit();
    rollbackDeletedDocsDirty = deletedDocsDirty;
    rollbackNormsDirty = normsDirty;
    rollbackUndeleteAll = undeleteAll;
    Enumeration values = norms.elements();
    while (values.hasMoreElements()) {
      Norm norm = (Norm) values.nextElement();
      norm.rollbackDirty = norm.dirty;
    }
  }

  void rollbackCommit() {
    super.rollbackCommit();
    deletedDocsDirty = rollbackDeletedDocsDirty;
    normsDirty = rollbackNormsDirty;
    undeleteAll = rollbackUndeleteAll;
    Enumeration values = norms.elements();
    while (values.hasMoreElements()) {
      Norm norm = (Norm) values.nextElement();
      norm.dirty = norm.rollbackDirty;
    }
  }
}
"
lucene,2.2,org.apache.lucene.search.FieldSortedHitQueue,14,2,0,17,47,73,2,16,4,0.826923077,361,0.75,3,0.47826087,0.256410256,1,3,24.5,7,1.3571,5,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.PriorityQueue;

import java.io.IOException;
import java.util.Locale;
import java.text.Collator;


public class FieldSortedHitQueue
extends PriorityQueue {

  
  public FieldSortedHitQueue (IndexReader reader, SortField[] fields, int size)
  throws IOException {
    final int n = fields.length;
    comparators = new ScoreDocComparator[n];
    this.fields = new SortField[n];
    for (int i=0; i<n; ++i) {
      String fieldname = fields[i].getField();
      comparators[i] = getCachedComparator (reader, fieldname, fields[i].getType(), fields[i].getLocale(), fields[i].getFactory());
      
      if (comparators[i].sortType() == SortField.STRING) {
    	  this.fields[i] = new SortField (fieldname, fields[i].getLocale(), fields[i].getReverse());
      } else {
    	  this.fields[i] = new SortField (fieldname, comparators[i].sortType(), fields[i].getReverse());
      }
    }
    initialize (size);
  }


  
  protected ScoreDocComparator[] comparators;

  
  protected SortField[] fields;

  
  protected float maxscore = Float.NEGATIVE_INFINITY;

  
  public float getMaxScore() {
    return maxscore;
  }

  
  
  
  public boolean insert(FieldDoc fdoc) {
    maxscore = Math.max(maxscore,fdoc.score);
    return super.insert(fdoc);
  }

  
  
  
  public boolean insert(Object fdoc) {
    return insert((FieldDoc)fdoc);
  }

  
  protected boolean lessThan (final Object a, final Object b) {
    final ScoreDoc docA = (ScoreDoc) a;
    final ScoreDoc docB = (ScoreDoc) b;

    
    final int n = comparators.length;
    int c = 0;
    for (int i=0; i<n && c==0; ++i) {
      c = (fields[i].reverse) ? comparators[i].compare (docB, docA)
                              : comparators[i].compare (docA, docB);
    }
    
    if (c == 0)
      return docA.doc > docB.doc;
    return c > 0;
  }


  
  FieldDoc fillFields (final FieldDoc doc) {
    final int n = comparators.length;
    final Comparable[] fields = new Comparable[n];
    for (int i=0; i<n; ++i)
      fields[i] = comparators[i].sortValue(doc);
    doc.fields = fields;
    
    return doc;
  }


  
  SortField[] getFields() {
    return fields;
  }
  
  static ScoreDocComparator getCachedComparator (IndexReader reader, String field, int type, Locale locale, SortComparatorSource factory)
  throws IOException {
    if (type == SortField.DOC) return ScoreDocComparator.INDEXORDER;
    if (type == SortField.SCORE) return ScoreDocComparator.RELEVANCE;
    FieldCacheImpl.Entry entry = (factory != null)
      ? new FieldCacheImpl.Entry (field, factory)
      : new FieldCacheImpl.Entry (field, type, locale);
    return (ScoreDocComparator)Comparators.get(reader, entry);
  }

  
  static final FieldCacheImpl.Cache Comparators = new FieldCacheImpl.Cache() {

    protected Object createValue(IndexReader reader, Object entryKey)
        throws IOException {
      FieldCacheImpl.Entry entry = (FieldCacheImpl.Entry) entryKey;
      String fieldname = entry.field;
      int type = entry.type;
      Locale locale = entry.locale;
      SortComparatorSource factory = (SortComparatorSource) entry.custom;
      ScoreDocComparator comparator;
      switch (type) {
        case SortField.AUTO:
          comparator = comparatorAuto (reader, fieldname);
          break;
        case SortField.INT:
          comparator = comparatorInt (reader, fieldname);
          break;
        case SortField.FLOAT:
          comparator = comparatorFloat (reader, fieldname);
          break;
        case SortField.STRING:
          if (locale != null) comparator = comparatorStringLocale (reader, fieldname, locale);
          else comparator = comparatorString (reader, fieldname);
          break;
        case SortField.CUSTOM:
          comparator = factory.newComparator (reader, fieldname);
          break;
        default:
          throw new RuntimeException (""unknown field type: ""+type);
      }
      return comparator;
    }
  };

  
  static ScoreDocComparator comparatorInt (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final int[] fieldOrder = FieldCache.DEFAULT.getInts (reader, field);
    return new ScoreDocComparator() {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        final int fi = fieldOrder[i.doc];
        final int fj = fieldOrder[j.doc];
        if (fi < fj) return -1;
        if (fi > fj) return 1;
        return 0;
      }

      public Comparable sortValue (final ScoreDoc i) {
        return new Integer (fieldOrder[i.doc]);
      }

      public int sortType() {
        return SortField.INT;
      }
    };
  }

  
  static ScoreDocComparator comparatorFloat (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final float[] fieldOrder = FieldCache.DEFAULT.getFloats (reader, field);
    return new ScoreDocComparator () {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        final float fi = fieldOrder[i.doc];
        final float fj = fieldOrder[j.doc];
        if (fi < fj) return -1;
        if (fi > fj) return 1;
        return 0;
      }

      public Comparable sortValue (final ScoreDoc i) {
        return new Float (fieldOrder[i.doc]);
      }

      public int sortType() {
        return SortField.FLOAT;
      }
    };
  }

  
  static ScoreDocComparator comparatorString (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final FieldCache.StringIndex index = FieldCache.DEFAULT.getStringIndex (reader, field);
    return new ScoreDocComparator () {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        final int fi = index.order[i.doc];
        final int fj = index.order[j.doc];
        if (fi < fj) return -1;
        if (fi > fj) return 1;
        return 0;
      }

      public Comparable sortValue (final ScoreDoc i) {
        return index.lookup[index.order[i.doc]];
      }

      public int sortType() {
        return SortField.STRING;
      }
    };
  }

  
  static ScoreDocComparator comparatorStringLocale (final IndexReader reader, final String fieldname, final Locale locale)
  throws IOException {
    final Collator collator = Collator.getInstance (locale);
    final String field = fieldname.intern();
    final String[] index = FieldCache.DEFAULT.getStrings (reader, field);
    return new ScoreDocComparator() {

    	public final int compare(final ScoreDoc i, final ScoreDoc j) {
			String is = index[i.doc];
			String js = index[j.doc];
			if (is == js) {
				return 0;
			} else if (is == null) {
				return -1;
			} else if (js == null) {
				return 1;
			} else {
				return collator.compare(is, js);
			}
		}

      public Comparable sortValue (final ScoreDoc i) {
        return index[i.doc];
      }

      public int sortType() {
        return SortField.STRING;
      }
    };
  }

  
  static ScoreDocComparator comparatorAuto (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    Object lookupArray = FieldCache.DEFAULT.getAuto (reader, field);
    if (lookupArray instanceof FieldCache.StringIndex) {
      return comparatorString (reader, field);
    } else if (lookupArray instanceof int[]) {
      return comparatorInt (reader, field);
    } else if (lookupArray instanceof float[]) {
      return comparatorFloat (reader, field);
    } else if (lookupArray instanceof String[]) {
      return comparatorString (reader, field);
    } else {
      throw new RuntimeException (""unknown data type in field '""+field+""'"");
    }
  }
}
"
lucene,2.2,org.apache.lucene.analysis.PerFieldAnalyzerWrapper,5,2,0,2,15,0,0,2,5,0.125,73,1.0,1,0.333333333,0.55,0,0,13.2,2,1.2,0,"package org.apache.lucene.analysis;



import java.io.Reader;
import java.util.Map;
import java.util.HashMap;


public class PerFieldAnalyzerWrapper extends Analyzer {
  private Analyzer defaultAnalyzer;
  private Map analyzerMap = new HashMap();


  
  public PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer) {
    this.defaultAnalyzer = defaultAnalyzer;
  }

  
  public void addAnalyzer(String fieldName, Analyzer analyzer) {
    analyzerMap.put(fieldName, analyzer);
  }

  public TokenStream tokenStream(String fieldName, Reader reader) {
    Analyzer analyzer = (Analyzer) analyzerMap.get(fieldName);
    if (analyzer == null) {
      analyzer = defaultAnalyzer;
    }

    return analyzer.tokenStream(fieldName, reader);
  }
  
  
  public int getPositionIncrementGap(String fieldName) {
    Analyzer analyzer = (Analyzer) analyzerMap.get(fieldName);
    if (analyzer == null)
      analyzer = defaultAnalyzer;
    return analyzer.getPositionIncrementGap(fieldName);
  }
  
  public String toString() {
    return ""PerFieldAnalyzerWrapper("" + analyzerMap + "", default="" + defaultAnalyzer + "")"";
  }
}
"
lucene,2.2,org.apache.lucene.search.HitCollector,2,1,6,22,3,1,22,0,2,2.0,5,0.0,0,0.0,0.666666667,0,0,1.5,1,0.5,0,"package org.apache.lucene.search;




public abstract class HitCollector {
  
  public abstract void collect(int doc, float score);
}
"
lucene,2.2,org.apache.lucene.analysis.WhitespaceTokenizer,2,4,0,2,4,1,1,1,1,2.0,13,0.0,0,0.875,0.666666667,1,1,5.5,2,1.0,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public class WhitespaceTokenizer extends CharTokenizer {
  
  public WhitespaceTokenizer(Reader in) {
    super(in);
  }

  
  protected boolean isTokenChar(char c) {
    return !Character.isWhitespace(c);
  }
}
"
lucene,2.2,org.apache.lucene.search.spans.SpanNotQuery,13,3,0,6,31,0,1,6,11,0.375,218,1.0,2,0.571428571,0.208791209,2,2,15.61538462,6,1.3077,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class SpanNotQuery extends SpanQuery {
  private SpanQuery include;
  private SpanQuery exclude;

  
  public SpanNotQuery(SpanQuery include, SpanQuery exclude) {
    this.include = include;
    this.exclude = exclude;

    if (!include.getField().equals(exclude.getField()))
      throw new IllegalArgumentException(""Clauses must have same field."");
  }

  
  public SpanQuery getInclude() { return include; }

  
  public SpanQuery getExclude() { return exclude; }

  public String getField() { return include.getField(); }

  
  public Collection getTerms() { return include.getTerms(); }
  
  public void extractTerms(Set terms) { include.extractTerms(terms); }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanNot("");
    buffer.append(include.toString(field));
    buffer.append("", "");
    buffer.append(exclude.toString(field));
    buffer.append("")"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }


  public Spans getSpans(final IndexReader reader) throws IOException {
    return new Spans() {
        private Spans includeSpans = include.getSpans(reader);
        private boolean moreInclude = true;

        private Spans excludeSpans = exclude.getSpans(reader);
        private boolean moreExclude = excludeSpans.next();

        public boolean next() throws IOException {
          if (moreInclude)                        
            moreInclude = includeSpans.next();

          while (moreInclude && moreExclude) {

            if (includeSpans.doc() > excludeSpans.doc()) 
              moreExclude = excludeSpans.skipTo(includeSpans.doc());

            while (moreExclude                    
                   && includeSpans.doc() == excludeSpans.doc()
                   && excludeSpans.end() <= includeSpans.start()) {
              moreExclude = excludeSpans.next();  
            }

            if (!moreExclude                      
                || includeSpans.doc() != excludeSpans.doc()
                || includeSpans.end() <= excludeSpans.start())
              break;                              

            moreInclude = includeSpans.next();    
          }
          return moreInclude;
        }

        public boolean skipTo(int target) throws IOException {
          if (moreInclude)                        
            moreInclude = includeSpans.skipTo(target);

          if (!moreInclude)
            return false;

          if (moreExclude                         
              && includeSpans.doc() > excludeSpans.doc())
            moreExclude = excludeSpans.skipTo(includeSpans.doc());

          while (moreExclude                      
                 && includeSpans.doc() == excludeSpans.doc()
                 && excludeSpans.end() <= includeSpans.start()) {
            moreExclude = excludeSpans.next();    
          }

          if (!moreExclude                      
                || includeSpans.doc() != excludeSpans.doc()
                || includeSpans.end() <= excludeSpans.start())
            return true;                          

          return next();                          
        }

        public int doc() { return includeSpans.doc(); }
        public int start() { return includeSpans.start(); }
        public int end() { return includeSpans.end(); }

        public String toString() {
          return ""spans("" + SpanNotQuery.this.toString() + "")"";
        }

      };
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanNotQuery clone = null;

    SpanQuery rewrittenInclude = (SpanQuery) include.rewrite(reader);
    if (rewrittenInclude != include) {
      clone = (SpanNotQuery) this.clone();
      clone.include = rewrittenInclude;
    }
    SpanQuery rewrittenExclude = (SpanQuery) exclude.rewrite(reader);
    if (rewrittenExclude != exclude) {
      if (clone == null) clone = (SpanNotQuery) this.clone();
      clone.exclude = rewrittenExclude;
    }

    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

    
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof SpanNotQuery)) return false;

    SpanNotQuery other = (SpanNotQuery)o;
    return this.include.equals(other.include)
            && this.exclude.equals(other.exclude)
            && this.getBoost() == other.getBoost();
  }

  public int hashCode() {
    int h = include.hashCode();
    h = (h<<1) | (h >>> 31);  
    h ^= exclude.hashCode();
    h = (h<<1) | (h >>> 31);  
    h ^= Float.floatToRawIntBits(getBoost());
    return h;
  }

}
"
lucene,2.2,org.apache.lucene.analysis.standard.StandardFilter,3,3,0,5,17,1,1,4,2,0.5,98,1.0,0,0.8,0.75,0,0,31.0,1,0.3333,1,"package org.apache.lucene.analysis.standard;



import org.apache.lucene.analysis.*;



public final class StandardFilter extends TokenFilter
  implements StandardTokenizerConstants  {


  
  public StandardFilter(TokenStream in) {
    super(in);
  }

  private static final String APOSTROPHE_TYPE = tokenImage[APOSTROPHE];
  private static final String ACRONYM_TYPE = tokenImage[ACRONYM];
  
  
  public final org.apache.lucene.analysis.Token next() throws java.io.IOException {
    org.apache.lucene.analysis.Token t = input.next();

    if (t == null)
      return null;

    String text = t.termText();
    String type = t.type();

    if (type == APOSTROPHE_TYPE &&		  
	(text.endsWith(""'s"") || text.endsWith(""'S""))) {
      return new org.apache.lucene.analysis.Token
	(text.substring(0,text.length()-2),
	 t.startOffset(), t.endOffset(), type);

    } else if (type == ACRONYM_TYPE) {		  
      StringBuffer trimmed = new StringBuffer();
      for (int i = 0; i < text.length(); i++) {
	char c = text.charAt(i);
	if (c != '.')
	  trimmed.append(c);
      }
      return new org.apache.lucene.analysis.Token
	(trimmed.toString(), t.startOffset(), t.endOffset(), type);

    } else {
      return t;
    }
  }
}
"
lucene,2.2,org.apache.lucene.search.ConstantScoreQuery,8,2,0,8,19,8,3,6,7,0.428571429,93,1.0,1,0.631578947,0.25,2,3,10.5,5,1.5,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;
import java.util.BitSet;
import java.util.Set;


public class ConstantScoreQuery extends Query {
  protected final Filter filter;

  public ConstantScoreQuery(Filter filter) {
    this.filter=filter;
  }

  
  public Filter getFilter() {
    return filter;
  }

  public Query rewrite(IndexReader reader) throws IOException {
    return this;
  }

  public void extractTerms(Set terms) {
    
    
  }

  protected class ConstantWeight implements Weight {
    private Similarity similarity;
    private float queryNorm;
    private float queryWeight;

    public ConstantWeight(Searcher searcher) {
      this.similarity = getSimilarity(searcher);
    }

    public Query getQuery() {
      return ConstantScoreQuery.this;
    }

    public float getValue() {
      return queryWeight;
    }

    public float sumOfSquaredWeights() throws IOException {
      queryWeight = getBoost();
      return queryWeight * queryWeight;
    }

    public void normalize(float norm) {
      this.queryNorm = norm;
      queryWeight *= this.queryNorm;
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      return new ConstantScorer(similarity, reader, this);
    }

    public Explanation explain(IndexReader reader, int doc) throws IOException {

      ConstantScorer cs = (ConstantScorer)scorer(reader);
      boolean exists = cs.bits.get(doc);

      ComplexExplanation result = new ComplexExplanation();

      if (exists) {
        result.setDescription(""ConstantScoreQuery("" + filter
        + ""), product of:"");
        result.setValue(queryWeight);
        result.setMatch(Boolean.TRUE);
        result.addDetail(new Explanation(getBoost(), ""boost""));
        result.addDetail(new Explanation(queryNorm,""queryNorm""));
      } else {
        result.setDescription(""ConstantScoreQuery("" + filter
        + "") doesn't match id "" + doc);
        result.setValue(0);
        result.setMatch(Boolean.FALSE);
      }
      return result;
    }
  }

  protected class ConstantScorer extends Scorer {
    final BitSet bits;
    final float theScore;
    int doc=-1;

    public ConstantScorer(Similarity similarity, IndexReader reader, Weight w) throws IOException {
      super(similarity);
      theScore = w.getValue();
      bits = filter.bits(reader);
    }

    public boolean next() throws IOException {
      doc = bits.nextSetBit(doc+1);
      return doc >= 0;
    }

    public int doc() {
      return doc;
    }

    public float score() throws IOException {
      return theScore;
    }

    public boolean skipTo(int target) throws IOException {
      doc = bits.nextSetBit(target);  
      return doc >= 0;
    }

    public Explanation explain(int doc) throws IOException {
      throw new UnsupportedOperationException();
    }
  }


  protected Weight createWeight(Searcher searcher) {
    return new ConstantScoreQuery.ConstantWeight(searcher);
  }


  
  public String toString(String field)
  {
    return ""ConstantScore("" + filter.toString()
      + (getBoost()==1.0 ? "")"" : ""^"" + getBoost());
  }

  
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof ConstantScoreQuery)) return false;
    ConstantScoreQuery other = (ConstantScoreQuery)o;
    return this.getBoost()==other.getBoost() && filter.equals(other.filter);
  }

  
  public int hashCode() {
    
    return filter.hashCode() + Float.floatToIntBits(getBoost());
  }

}


"
lucene,2.2,org.apache.lucene.search.RemoteSearchable,13,4,0,14,31,0,0,14,13,0.0,120,1.0,1,0.6,0.205128205,0,0,8.153846154,1,0.9231,0,"package org.apache.lucene.search;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.CorruptIndexException;

import java.io.IOException;
import java.rmi.Naming;
import java.rmi.RMISecurityManager;
import java.rmi.RemoteException;
import java.rmi.server.UnicastRemoteObject;


public class RemoteSearchable
  extends UnicastRemoteObject
  implements Searchable {
  
  private Searchable local;
  
  
  public RemoteSearchable(Searchable local) throws RemoteException {
    super();
    this.local = local;
  }


  public void search(Weight weight, Filter filter, HitCollector results)
    throws IOException {
    local.search(weight, filter, results);
  }

  public void close() throws IOException {
    local.close();
  }

  public int docFreq(Term term) throws IOException {
    return local.docFreq(term);
  }


  public int[] docFreqs(Term[] terms) throws IOException {
    return local.docFreqs(terms);
  }

  public int maxDoc() throws IOException {
    return local.maxDoc();
  }

  public TopDocs search(Weight weight, Filter filter, int n) throws IOException {
    return local.search(weight, filter, n);
  }


  public TopFieldDocs search (Weight weight, Filter filter, int n, Sort sort)
  throws IOException {
    return local.search (weight, filter, n, sort);
  }

  public Document doc(int i) throws CorruptIndexException, IOException {
    return local.doc(i);
  }

  public Document doc(int i, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
	    return local.doc(i, fieldSelector);
  }
  
  public Query rewrite(Query original) throws IOException {
    return local.rewrite(original);
  }

  public Explanation explain(Weight weight, int doc) throws IOException {
    return local.explain(weight, doc);
  }

  /** Exports a searcher for the index in args[0] named
   * ""
  public static void main(String args[]) throws Exception {
    String indexName = null;
    
    if (args != null && args.length == 1)
      indexName = args[0];
    
    if (indexName == null) {
      System.out.println(""Usage: org.apache.lucene.search.RemoteSearchable <index>"");
      return;
    }
    
    
    if (System.getSecurityManager() == null) {
      System.setSecurityManager(new RMISecurityManager());
    }
    
    Searchable local = new IndexSearcher(indexName);
    RemoteSearchable impl = new RemoteSearchable(local);
      
    
    Naming.rebind(""
  }

}
"
lucene,2.2,org.apache.lucene.index.FilterIndexReader,24,2,0,11,50,0,0,11,19,0.0,171,1.0,1,0.722891566,0.199074074,1,8,6.083333333,1,0.9583,2,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;

import java.io.IOException;
import java.util.Collection;


public class FilterIndexReader extends IndexReader {

  
  public static class FilterTermDocs implements TermDocs {
    protected TermDocs in;

    public FilterTermDocs(TermDocs in) { this.in = in; }

    public void seek(Term term) throws IOException { in.seek(term); }
    public void seek(TermEnum termEnum) throws IOException { in.seek(termEnum); }
    public int doc() { return in.doc(); }
    public int freq() { return in.freq(); }
    public boolean next() throws IOException { return in.next(); }
    public int read(int[] docs, int[] freqs) throws IOException {
      return in.read(docs, freqs);
    }
    public boolean skipTo(int i) throws IOException { return in.skipTo(i); }
    public void close() throws IOException { in.close(); }
  }

  
  public static class FilterTermPositions
          extends FilterTermDocs implements TermPositions {

    public FilterTermPositions(TermPositions in) { super(in); }

    public int nextPosition() throws IOException {
      return ((TermPositions) this.in).nextPosition();
    }
    
    public int getPayloadLength() {
      return ((TermPositions) this.in).getPayloadLength();
    }

    public byte[] getPayload(byte[] data, int offset) throws IOException {
      return ((TermPositions) this.in).getPayload(data, offset);
    }


    
    public boolean isPayloadAvailable() {
      return ((TermPositions)this.in).isPayloadAvailable();
    }
  }

  
  public static class FilterTermEnum extends TermEnum {
    protected TermEnum in;

    public FilterTermEnum(TermEnum in) { this.in = in; }

    public boolean next() throws IOException { return in.next(); }
    public Term term() { return in.term(); }
    public int docFreq() { return in.docFreq(); }
    public void close() throws IOException { in.close(); }
  }

  protected IndexReader in;

  
  public FilterIndexReader(IndexReader in) {
    super(in.directory());
    this.in = in;
  }

  public TermFreqVector[] getTermFreqVectors(int docNumber)
          throws IOException {
    ensureOpen();
    return in.getTermFreqVectors(docNumber);
  }

  public TermFreqVector getTermFreqVector(int docNumber, String field)
          throws IOException {
    ensureOpen();
    return in.getTermFreqVector(docNumber, field);
  }

  public int numDocs() {
    
    return in.numDocs();
  }

  public int maxDoc() {
    
    return in.maxDoc();
  }

  public Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
    ensureOpen();
    return in.document(n, fieldSelector);
  }

  public boolean isDeleted(int n) {
    
    return in.isDeleted(n);
  }

  public boolean hasDeletions() {
    
    return in.hasDeletions();
  }

  protected void doUndeleteAll() throws CorruptIndexException, IOException {in.undeleteAll();}

  public boolean hasNorms(String field) throws IOException {
    ensureOpen();
    return in.hasNorms(field);
  }

  public byte[] norms(String f) throws IOException {
    ensureOpen();
    return in.norms(f);
  }

  public void norms(String f, byte[] bytes, int offset) throws IOException {
    ensureOpen();
    in.norms(f, bytes, offset);
  }

  protected void doSetNorm(int d, String f, byte b) throws CorruptIndexException, IOException {
    in.setNorm(d, f, b);
  }

  public TermEnum terms() throws IOException {
    ensureOpen();
    return in.terms();
  }

  public TermEnum terms(Term t) throws IOException {
    ensureOpen();
    return in.terms(t);
  }

  public int docFreq(Term t) throws IOException {
    ensureOpen();
    return in.docFreq(t);
  }

  public TermDocs termDocs() throws IOException {
    ensureOpen();
    return in.termDocs();
  }

  public TermPositions termPositions() throws IOException {
    ensureOpen();
    return in.termPositions();
  }

  protected void doDelete(int n) throws  CorruptIndexException, IOException { in.deleteDocument(n); }
  protected void doCommit() throws IOException { in.commit(); }
  protected void doClose() throws IOException { in.close(); }


  public Collection getFieldNames(IndexReader.FieldOption fieldNames) {
    ensureOpen();
    return in.getFieldNames(fieldNames);
  }

  public long getVersion() {
    ensureOpen();
    return in.getVersion();
  }

  public boolean isCurrent() throws CorruptIndexException, IOException {
    ensureOpen();
    return in.isCurrent();
  }
}
"
lucene,2.2,org.apache.lucene.document.DateTools,8,1,0,2,27,18,1,1,6,0.428571429,567,1.0,0,0.0,0.314285714,0,0,68.875,8,2.5,1,"package org.apache.lucene.document;



import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Date;
import java.util.TimeZone;


public class DateTools {
  
  private final static TimeZone GMT = TimeZone.getTimeZone(""GMT"");

  private static final SimpleDateFormat YEAR_FORMAT = new SimpleDateFormat(""yyyy"");
  private static final SimpleDateFormat MONTH_FORMAT = new SimpleDateFormat(""yyyyMM"");
  private static final SimpleDateFormat DAY_FORMAT = new SimpleDateFormat(""yyyyMMdd"");
  private static final SimpleDateFormat HOUR_FORMAT = new SimpleDateFormat(""yyyyMMddHH"");
  private static final SimpleDateFormat MINUTE_FORMAT = new SimpleDateFormat(""yyyyMMddHHmm"");
  private static final SimpleDateFormat SECOND_FORMAT = new SimpleDateFormat(""yyyyMMddHHmmss"");
  private static final SimpleDateFormat MILLISECOND_FORMAT = new SimpleDateFormat(""yyyyMMddHHmmssSSS"");
  static {
    
    
    YEAR_FORMAT.setTimeZone(GMT);
    MONTH_FORMAT.setTimeZone(GMT);
    DAY_FORMAT.setTimeZone(GMT);
    HOUR_FORMAT.setTimeZone(GMT);
    MINUTE_FORMAT.setTimeZone(GMT);
    SECOND_FORMAT.setTimeZone(GMT);
    MILLISECOND_FORMAT.setTimeZone(GMT);
  }

  
  private DateTools() {}

  
  public static String dateToString(Date date, Resolution resolution) {
    return timeToString(date.getTime(), resolution);
  }

  
  public static String timeToString(long time, Resolution resolution) {
    Calendar cal = Calendar.getInstance(GMT);

    
    
    
    cal.setTime(new Date(round(time, resolution)));

    String result;
    if (resolution == Resolution.YEAR) {
      synchronized (YEAR_FORMAT) {
        result = YEAR_FORMAT.format(cal.getTime());
      }
    } else if (resolution == Resolution.MONTH) {
      synchronized (MONTH_FORMAT) {
        result = MONTH_FORMAT.format(cal.getTime());
      }
    } else if (resolution == Resolution.DAY) {
      synchronized (DAY_FORMAT) {
        result = DAY_FORMAT.format(cal.getTime());
      }
    } else if (resolution == Resolution.HOUR) {
      synchronized (HOUR_FORMAT) {
        result = HOUR_FORMAT.format(cal.getTime());
      }
    } else if (resolution == Resolution.MINUTE) {
      synchronized (MINUTE_FORMAT) {
        result = MINUTE_FORMAT.format(cal.getTime());
      }
    } else if (resolution == Resolution.SECOND) {
      synchronized (SECOND_FORMAT) {
        result = SECOND_FORMAT.format(cal.getTime());
      }
    } else if (resolution == Resolution.MILLISECOND) {
      synchronized (MILLISECOND_FORMAT) {
        result = MILLISECOND_FORMAT.format(cal.getTime());
      }
    } else {
      throw new IllegalArgumentException(""unknown resolution "" + resolution);
    }
    return result;
  }
  
  
  public static long stringToTime(String dateString) throws ParseException {
    return stringToDate(dateString).getTime();
  }

  
  public static Date stringToDate(String dateString) throws ParseException {
    Date date;
    if (dateString.length() == 4) {
      synchronized (YEAR_FORMAT) {
        date = YEAR_FORMAT.parse(dateString);
      }
    } else if (dateString.length() == 6) {
      synchronized (MONTH_FORMAT) {
        date = MONTH_FORMAT.parse(dateString);
      }
    } else if (dateString.length() == 8) {
      synchronized (DAY_FORMAT) {
        date = DAY_FORMAT.parse(dateString);
      }
    } else if (dateString.length() == 10) {
      synchronized (HOUR_FORMAT) {
        date = HOUR_FORMAT.parse(dateString);
      }
    } else if (dateString.length() == 12) {
      synchronized (MINUTE_FORMAT) {
        date = MINUTE_FORMAT.parse(dateString);
      }
    } else if (dateString.length() == 14) {
      synchronized (SECOND_FORMAT) {
        date = SECOND_FORMAT.parse(dateString);
      }
    } else if (dateString.length() == 17) {
      synchronized (MILLISECOND_FORMAT) {
        date = MILLISECOND_FORMAT.parse(dateString);
      }
    } else {
      throw new ParseException(""Input is not valid date string: "" + dateString, 0);
    }
    return date;
  }
  
  
  public static Date round(Date date, Resolution resolution) {
    return new Date(round(date.getTime(), resolution));
  }
  
  
  public static long round(long time, Resolution resolution) {
    Calendar cal = Calendar.getInstance(GMT);

    
    
    
    cal.setTime(new Date(time));
    
    if (resolution == Resolution.YEAR) {
      cal.set(Calendar.MONTH, 0);
      cal.set(Calendar.DAY_OF_MONTH, 1);
      cal.set(Calendar.HOUR_OF_DAY, 0);
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.MONTH) {
      cal.set(Calendar.DAY_OF_MONTH, 1);
      cal.set(Calendar.HOUR_OF_DAY, 0);
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.DAY) {
      cal.set(Calendar.HOUR_OF_DAY, 0);
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.HOUR) {
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.MINUTE) {
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.SECOND) {
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.MILLISECOND) {
      
    } else {
      throw new IllegalArgumentException(""unknown resolution "" + resolution);
    }
    return cal.getTime().getTime();
  }

  
  public static class Resolution {
    
    public static final Resolution YEAR = new Resolution(""year"");
    public static final Resolution MONTH = new Resolution(""month"");
    public static final Resolution DAY = new Resolution(""day"");
    public static final Resolution HOUR = new Resolution(""hour"");
    public static final Resolution MINUTE = new Resolution(""minute"");
    public static final Resolution SECOND = new Resolution(""second"");
    public static final Resolution MILLISECOND = new Resolution(""millisecond"");

    private String resolution;

    private Resolution() {
    }
    
    private Resolution(String resolution) {
      this.resolution = resolution;
    }
    
    public String toString() {
      return resolution;
    }

  }

}
"
lucene,2.2,org.apache.lucene.search.ScoreDocComparator,4,1,0,12,6,6,11,3,3,1.0,15,0.0,2,0.0,0.833333333,0,0,2.25,1,0.75,1,"package org.apache.lucene.search;





public interface ScoreDocComparator {

	
	static final ScoreDocComparator RELEVANCE = new ScoreDocComparator() {
		public int compare (ScoreDoc i, ScoreDoc j) {
			if (i.score > j.score) return -1;
			if (i.score < j.score) return 1;
			return 0;
		}
		public Comparable sortValue (ScoreDoc i) {
			return new Float (i.score);
		}
		public int sortType() {
			return SortField.SCORE;
		}
	};

	
	static final ScoreDocComparator INDEXORDER = new ScoreDocComparator() {
		public int compare (ScoreDoc i, ScoreDoc j) {
			if (i.doc < j.doc) return -1;
			if (i.doc > j.doc) return 1;
			return 0;
		}
		public Comparable sortValue (ScoreDoc i) {
			return new Integer (i.doc);
		}
		public int sortType() {
			return SortField.DOC;
		}
	};

	
	int compare (ScoreDoc i, ScoreDoc j);

	
	Comparable sortValue (ScoreDoc i);

	
	int sortType();
}
"
lucene,2.2,org.apache.lucene.index.Payload,7,1,0,3,12,1,3,0,6,0.277777778,103,1.0,0,0.0,0.619047619,0,0,13.28571429,3,1.0,2,"package org.apache.lucene.index;



import java.io.Serializable;

import org.apache.lucene.analysis.Token;
import org.apache.lucene.analysis.TokenStream;

     
  
  public class Payload implements Serializable {
    
    protected byte[] data;
    
    
    protected int offset;
    
    
    protected int length;
    
    
    protected Payload() {
      
    }
    
    
    public Payload(byte[] data) {
      this(data, 0, data.length);
    }

    
    public Payload(byte[] data, int offset, int length) {
      if (offset < 0 || offset + length > data.length) {
        throw new IllegalArgumentException();
      }
      this.data = data;
      this.offset = offset;
      this.length = length;
    }
    
    
    public int length() {
      return this.length;
    }
    
    
    public byte byteAt(int index) {
      if (0 <= index && index < this.length) {
        return this.data[this.offset + index];    
      }
      throw new ArrayIndexOutOfBoundsException(index);
    }
    
    
    public byte[] toByteArray() {
      byte[] retArray = new byte[this.length];
      System.arraycopy(this.data, this.offset, retArray, 0, this.length);
      return retArray;
    }
    
    
    public void copyTo(byte[] target, int targetOffset) {
      if (this.length > target.length + targetOffset) {
        throw new ArrayIndexOutOfBoundsException();
      }
      System.arraycopy(this.data, this.offset, target, targetOffset, this.length);
    }
}
"
lucene,2.2,org.apache.lucene.search.Filter,2,1,5,25,3,1,24,1,2,2.0,5,0.0,0,0.0,0.75,0,0,1.5,1,0.5,1,"package org.apache.lucene.search;



import java.util.BitSet;
import java.io.IOException;
import org.apache.lucene.index.IndexReader;


public abstract class Filter implements java.io.Serializable {
  
  public abstract BitSet bits(IndexReader reader) throws IOException;
}
"
lucene,2.2,org.apache.lucene.search.FieldCache,13,1,0,16,14,78,10,8,12,1.041666667,20,0.0,1,0.0,0.427083333,0,0,0.384615385,1,0.9231,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import java.io.IOException;


public interface FieldCache {

  
  
  
  public static final int STRING_INDEX = -1;


  
  public static class StringIndex {

    
    public final String[] lookup;

    
    public final int[] order;

    
    public StringIndex (int[] values, String[] lookup) {
      this.order = values;
      this.lookup = lookup;
    }
  }

  
  public interface ByteParser {
    
    public byte parseByte(String string);
  }

  
  public interface ShortParser {
    
    public short parseShort(String string);
  }

  
  public interface IntParser {
    
    public int parseInt(String string);
  }

  
  public interface FloatParser {
    
    public float parseFloat(String string);
  }

  
  public static FieldCache DEFAULT = new FieldCacheImpl();

  
  public byte[] getBytes (IndexReader reader, String field)
  throws IOException;

  
  public byte[] getBytes (IndexReader reader, String field, ByteParser parser)
  throws IOException;

  
  public short[] getShorts (IndexReader reader, String field)
  throws IOException;

  
  public short[] getShorts (IndexReader reader, String field, ShortParser parser)
  throws IOException;

  
  public int[] getInts (IndexReader reader, String field)
  throws IOException;

  
  public int[] getInts (IndexReader reader, String field, IntParser parser)
  throws IOException;

  
  public float[] getFloats (IndexReader reader, String field)
  throws IOException;

  
  public float[] getFloats (IndexReader reader, String field,
                            FloatParser parser) throws IOException;

  
  public String[] getStrings (IndexReader reader, String field)
  throws IOException;

  
  public StringIndex getStringIndex (IndexReader reader, String field)
  throws IOException;

  
  public Object getAuto (IndexReader reader, String field)
  throws IOException;

  
  public Comparable[] getCustom (IndexReader reader, String field, SortComparator comparator)
  throws IOException;
  
}
"
lucene,2.2,org.apache.lucene.util.SmallFloat,7,1,0,1,10,21,1,0,7,2.0,155,0.0,0,0.0,0.321428571,0,0,21.14285714,4,2.5714,1,"package org.apache.lucene.util;




public class SmallFloat {

  
  public static byte floatToByte(float f, int numMantissaBits, int zeroExp) {
    
    
    int fzero = (63-zeroExp)<<numMantissaBits;
    int bits = Float.floatToRawIntBits(f);
    int smallfloat = bits >> (24-numMantissaBits);
    if (smallfloat < fzero) {
      return (bits<=0) ?
        (byte)0   
       :(byte)1;  
    } else if (smallfloat >= fzero + 0x100) {
      return -1;  
    } else {
      return (byte)(smallfloat - fzero);
    }
  }

  
  public static float byteToFloat(byte b, int numMantissaBits, int zeroExp) {
    
    
    if (b == 0) return 0.0f;
    int bits = (b&0xff) << (24-numMantissaBits);
    bits += (63-zeroExp) << 24;
    return Float.intBitsToFloat(bits);
  }


  
  
  
  
  

  
  public static byte floatToByte315(float f) {
    int bits = Float.floatToRawIntBits(f);
    int smallfloat = bits >> (24-3);
    if (smallfloat < (63-15)<<3) {
      return (bits<=0) ? (byte)0 : (byte)1;
    }
    if (smallfloat >= ((63-15)<<3) + 0x100) {
      return -1;
    }
    return (byte)(smallfloat - ((63-15)<<3));
 }

  
  public static float byte315ToFloat(byte b) {
    
    
    if (b == 0) return 0.0f;
    int bits = (b&0xff) << (24-3);
    bits += (63-15) << 24;
    return Float.intBitsToFloat(bits);
  }


  
  public static byte floatToByte52(float f) {
    int bits = Float.floatToRawIntBits(f);
    int smallfloat = bits >> (24-5);
    if (smallfloat < (63-2)<<5) {
      return (bits<=0) ? (byte)0 : (byte)1;
    }
    if (smallfloat >= ((63-2)<<5) + 0x100) {
      return -1;
    }
    return (byte)(smallfloat - ((63-2)<<5));
  }

  
  public static float byte52ToFloat(byte b) {
    
    
    if (b == 0) return 0.0f;
    int bits = (b&0xff) << (24-5);
    bits += (63-2) << 24;
    return Float.intBitsToFloat(bits);
  }
}
"
lucene,2.2,org.apache.lucene.index.IndexFileDeleter,16,1,0,11,68,8,3,9,4,0.683333333,814,1.0,2,0.0,0.236111111,0,0,49.375,2,1.0,11,"package org.apache.lucene.index;



import org.apache.lucene.index.IndexFileNames;
import org.apache.lucene.index.SegmentInfos;
import org.apache.lucene.index.SegmentInfo;
import org.apache.lucene.store.Directory;

import java.io.IOException;
import java.io.PrintStream;
import java.util.Map;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.ArrayList;
import java.util.Collections;



final class IndexFileDeleter {

  
  private List deletable;

  
  private Map refCounts = new HashMap();

  
  private List commits = new ArrayList();

  
  private List lastFiles = new ArrayList();

   
  private List commitsToDelete = new ArrayList();

  private PrintStream infoStream;
  private Directory directory;
  private IndexDeletionPolicy policy;

  void setInfoStream(PrintStream infoStream) {
    this.infoStream = infoStream;
  }
  
  private void message(String message) {
    infoStream.println(this + "" "" + Thread.currentThread().getName() + "": "" + message);
  }

  
  public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, SegmentInfos segmentInfos, PrintStream infoStream)
    throws CorruptIndexException, IOException {

    this.infoStream = infoStream;
    this.policy = policy;
    this.directory = directory;

    
    
    long currentGen = segmentInfos.getGeneration();
    IndexFileNameFilter filter = IndexFileNameFilter.getFilter();

    String[] files = directory.list();
    if (files == null)
      throw new IOException(""cannot read directory "" + directory + "": list() returned null"");

    CommitPoint currentCommitPoint = null;

    for(int i=0;i<files.length;i++) {

      String fileName = files[i];

      if (filter.accept(null, fileName) && !fileName.equals(IndexFileNames.SEGMENTS_GEN)) {

        
        getRefCount(fileName);

        if (fileName.startsWith(IndexFileNames.SEGMENTS)) {

          
          
          
          if (SegmentInfos.generationFromSegmentsFileName(fileName) <= currentGen) {
            if (infoStream != null) {
              message(""init: load commit \"""" + fileName + ""\"""");
            }
            SegmentInfos sis = new SegmentInfos();
            sis.read(directory, fileName);
            CommitPoint commitPoint = new CommitPoint(sis);
            if (sis.getGeneration() == segmentInfos.getGeneration()) {
              currentCommitPoint = commitPoint;
            }
            commits.add(commitPoint);
            incRef(sis, true);
          }
        }
      }
    }

    if (currentCommitPoint == null) {
      throw new CorruptIndexException(""failed to locate current segments_N file"");
    }

    
    Collections.sort(commits);

    
    
    
    Iterator it = refCounts.keySet().iterator();
    while(it.hasNext()) {
      String fileName = (String) it.next();
      RefCount rc = (RefCount) refCounts.get(fileName);
      if (0 == rc.count) {
        if (infoStream != null) {
          message(""init: removing unreferenced file \"""" + fileName + ""\"""");
        }
        deleteFile(fileName);
      }
    }

    
    
    policy.onInit(commits);

    
    
    
    if (currentCommitPoint.deleted) {
      checkpoint(segmentInfos, false);
    }
    
    deleteCommits();
  }

  
  private void deleteCommits() throws IOException {

    int size = commitsToDelete.size();

    if (size > 0) {

      
      
      for(int i=0;i<size;i++) {
        CommitPoint commit = (CommitPoint) commitsToDelete.get(i);
        if (infoStream != null) {
          message(""deleteCommits: now remove commit \"""" + commit.getSegmentsFileName() + ""\"""");
        }
        int size2 = commit.files.size();
        for(int j=0;j<size2;j++) {
          decRef((List) commit.files.get(j));
        }
        decRef(commit.getSegmentsFileName());
      }
      commitsToDelete.clear();

      
      size = commits.size();
      int readFrom = 0;
      int writeTo = 0;
      while(readFrom < size) {
        CommitPoint commit = (CommitPoint) commits.get(readFrom);
        if (!commit.deleted) {
          if (writeTo != readFrom) {
            commits.set(writeTo, commits.get(readFrom));
          }
          writeTo++;
        }
        readFrom++;
      }

      while(size > writeTo) {
        commits.remove(size-1);
        size--;
      }
    }
  }

  
  public void refresh() throws IOException {
    String[] files = directory.list();
    if (files == null)
      throw new IOException(""cannot read directory "" + directory + "": list() returned null"");
    IndexFileNameFilter filter = IndexFileNameFilter.getFilter();
    for(int i=0;i<files.length;i++) {
      String fileName = files[i];
      if (filter.accept(null, fileName) && !refCounts.containsKey(fileName) && !fileName.equals(IndexFileNames.SEGMENTS_GEN)) {
        
        if (infoStream != null) {
          message(""refresh: removing newly created unreferenced file \"""" + fileName + ""\"""");
        }
        deleteFile(fileName);
      }
    }
  }

  
  public void checkpoint(SegmentInfos segmentInfos, boolean isCommit) throws IOException {

    if (infoStream != null) {
      message(""now checkpoint \"""" + segmentInfos.getCurrentSegmentFileName() + ""\"" [isCommit = "" + isCommit + ""]"");
    }

    
    
    if (deletable != null) {
      List oldDeletable = deletable;
      deletable = null;
      int size = oldDeletable.size();
      for(int i=0;i<size;i++) {
        deleteFile((String) oldDeletable.get(i));
      }
    }

    
    incRef(segmentInfos, isCommit);

    if (isCommit) {
      
      commits.add(new CommitPoint(segmentInfos));

      
      policy.onCommit(commits);

      
      deleteCommits();
    }

    
    int size = lastFiles.size();
    if (size > 0) {
      for(int i=0;i<size;i++) {
        decRef((List) lastFiles.get(i));
      }
      lastFiles.clear();
    }

    if (!isCommit) {
      
      size = segmentInfos.size();
      for(int i=0;i<size;i++) {
        SegmentInfo segmentInfo = segmentInfos.info(i);
        if (segmentInfo.dir == directory) {
          lastFiles.add(segmentInfo.files());
        }
      }
    }
  }

  void incRef(SegmentInfos segmentInfos, boolean isCommit) throws IOException {
    int size = segmentInfos.size();
    for(int i=0;i<size;i++) {
      SegmentInfo segmentInfo = segmentInfos.info(i);
      if (segmentInfo.dir == directory) {
        incRef(segmentInfo.files());
      }
    }

    if (isCommit) {
      
      
      getRefCount(segmentInfos.getCurrentSegmentFileName()).IncRef();
    }
  }

  private void incRef(List files) throws IOException {
    int size = files.size();
    for(int i=0;i<size;i++) {
      String fileName = (String) files.get(i);
      RefCount rc = getRefCount(fileName);
      if (infoStream != null) {
        message(""  IncRef \"""" + fileName + ""\"": pre-incr count is "" + rc.count);
      }
      rc.IncRef();
    }
  }

  private void decRef(List files) throws IOException {
    int size = files.size();
    for(int i=0;i<size;i++) {
      decRef((String) files.get(i));
    }
  }

  private void decRef(String fileName) throws IOException {
    RefCount rc = getRefCount(fileName);
    if (infoStream != null) {
      message(""  DecRef \"""" + fileName + ""\"": pre-decr count is "" + rc.count);
    }
    if (0 == rc.DecRef()) {
      
      
      deleteFile(fileName);
      refCounts.remove(fileName);
    }
  }

  void decRef(SegmentInfos segmentInfos) throws IOException {
    final int size = segmentInfos.size();
    for(int i=0;i<size;i++) {
      SegmentInfo segmentInfo = segmentInfos.info(i);
      if (segmentInfo.dir == directory) {
        decRef(segmentInfo.files());
      }
    }
  }

  private RefCount getRefCount(String fileName) {
    RefCount rc;
    if (!refCounts.containsKey(fileName)) {
      rc = new RefCount();
      refCounts.put(fileName, rc);
    } else {
      rc = (RefCount) refCounts.get(fileName);
    }
    return rc;
  }

  private void deleteFile(String fileName)
       throws IOException {
    try {
      if (infoStream != null) {
        message(""delete \"""" + fileName + ""\"""");
      }
      directory.deleteFile(fileName);
    } catch (IOException e) {			  
      if (directory.fileExists(fileName)) {

        
        
        
        
        
        

        if (infoStream != null) {
          message(""IndexFileDeleter: unable to remove file \"""" + fileName + ""\"": "" + e.toString() + ""; Will re-try later."");
        }
        if (deletable == null) {
          deletable = new ArrayList();
        }
        deletable.add(fileName);                  
      }
    }
  }

  
  public void deleteDirect(Directory otherDir, List segments) throws IOException {
    int size = segments.size();
    for(int i=0;i<size;i++) {
      List filestoDelete = ((SegmentInfo) segments.get(i)).files();
      int size2 = filestoDelete.size();
      for(int j=0;j<size2;j++) {
        otherDir.deleteFile((String) filestoDelete.get(j));
      }
    }
  }

  
  final private static class RefCount {

    int count;

    final private int IncRef() {
      return ++count;
    }

    final private int DecRef() {
      return --count;
    }
  }

  

  final private class CommitPoint implements Comparable, IndexCommitPoint {

    long gen;
    List files;
    String segmentsFileName;
    boolean deleted;

    public CommitPoint(SegmentInfos segmentInfos) throws IOException {
      segmentsFileName = segmentInfos.getCurrentSegmentFileName();
      int size = segmentInfos.size();
      files = new ArrayList(size);
      gen = segmentInfos.getGeneration();
      for(int i=0;i<size;i++) {
        SegmentInfo segmentInfo = segmentInfos.info(i);
        if (segmentInfo.dir == directory) {
          files.add(segmentInfo.files());
        }
      }
    }

    
    public String getSegmentsFileName() {
      return segmentsFileName;
    }

    
    public void delete() {
      if (!deleted) {
        deleted = true;
        commitsToDelete.add(this);
      }
    }

    public int compareTo(Object obj) {
      CommitPoint commit = (CommitPoint) obj;
      if (gen < commit.gen) {
        return -1;
      } else if (gen > commit.gen) {
        return 1;
      } else {
        return 0;
      }
    }
  }
}
"
lucene,2.2,org.apache.lucene.analysis.KeywordTokenizer,3,3,0,3,10,1,1,2,3,0.5,63,1.0,0,0.8,0.666666667,0,0,19.0,1,0.3333,3,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.io.Reader;


public class KeywordTokenizer extends Tokenizer {
  
  private static final int DEFAULT_BUFFER_SIZE = 256;

  private boolean done;
  private final char[] buffer;

  public KeywordTokenizer(Reader input) {
    this(input, DEFAULT_BUFFER_SIZE);
  }

  public KeywordTokenizer(Reader input, int bufferSize) {
    super(input);
    this.buffer = new char[bufferSize];
    this.done = false;
  }

  public Token next() throws IOException {
    if (!done) {
      done = true;
      StringBuffer buffer = new StringBuffer();
      int length;
      while (true) {
        length = input.read(this.buffer);
        if (length == -1) break;

        buffer.append(this.buffer, 0, length);
      }
      String text = buffer.toString();
      return new Token(text, 0, text.length());
    }
    return null;
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.QueryParserConstants,1,1,0,2,1,0,2,0,0,2.0,174,0.0,0,0.0,0.0,0,0,136.0,0,0.0,2,"
package org.apache.lucene.queryParser;

public interface QueryParserConstants {

  int EOF = 0;
  int _NUM_CHAR = 1;
  int _ESCAPED_CHAR = 2;
  int _TERM_START_CHAR = 3;
  int _TERM_CHAR = 4;
  int _WHITESPACE = 5;
  int AND = 7;
  int OR = 8;
  int NOT = 9;
  int PLUS = 10;
  int MINUS = 11;
  int LPAREN = 12;
  int RPAREN = 13;
  int COLON = 14;
  int STAR = 15;
  int CARAT = 16;
  int QUOTED = 17;
  int TERM = 18;
  int FUZZY_SLOP = 19;
  int PREFIXTERM = 20;
  int WILDTERM = 21;
  int RANGEIN_START = 22;
  int RANGEEX_START = 23;
  int NUMBER = 24;
  int RANGEIN_TO = 25;
  int RANGEIN_END = 26;
  int RANGEIN_QUOTED = 27;
  int RANGEIN_GOOP = 28;
  int RANGEEX_TO = 29;
  int RANGEEX_END = 30;
  int RANGEEX_QUOTED = 31;
  int RANGEEX_GOOP = 32;

  int Boost = 0;
  int RangeEx = 1;
  int RangeIn = 2;
  int DEFAULT = 3;

  String[] tokenImage = {
    ""<EOF>"",
    ""<_NUM_CHAR>"",
    ""<_ESCAPED_CHAR>"",
    ""<_TERM_START_CHAR>"",
    ""<_TERM_CHAR>"",
    ""<_WHITESPACE>"",
    ""<token of kind 6>"",
    ""<AND>"",
    ""<OR>"",
    ""<NOT>"",
    ""\""+\"""",
    ""\""-\"""",
    ""\""(\"""",
    ""\"")\"""",
    ""\"":\"""",
    ""\""*\"""",
    ""\""^\"""",
    ""<QUOTED>"",
    ""<TERM>"",
    ""<FUZZY_SLOP>"",
    ""<PREFIXTERM>"",
    ""<WILDTERM>"",
    ""\""[\"""",
    ""\""{\"""",
    ""<NUMBER>"",
    ""\""TO\"""",
    ""\""]\"""",
    ""<RANGEIN_QUOTED>"",
    ""<RANGEIN_GOOP>"",
    ""\""TO\"""",
    ""\""}\"""",
    ""<RANGEEX_QUOTED>"",
    ""<RANGEEX_GOOP>"",
  };

}
"
lucene,2.2,org.apache.lucene.index.TermFreqVector,6,1,0,11,6,15,11,0,6,2.0,6,0.0,0,0.0,0.375,0,0,0.0,1,1.0,0,"package org.apache.lucene.index;




public interface TermFreqVector {
   
  public String getField();
  
  
  public int size();

  
  public String[] getTerms();


  
  public int[] getTermFrequencies();
  

  
  public int indexOf(String term);


  
  public int[] indexesOf(String[] terms, int start, int len);

}
"
lucene,2.2,org.apache.lucene.index.IndexFileNames,3,1,0,5,8,3,5,0,0,1.333333333,205,0.0,0,0.0,0.5,0,0,63.33333333,3,1.0,3,"package org.apache.lucene.index;




final class IndexFileNames {

  
  static final String SEGMENTS = ""segments"";

  
  static final String SEGMENTS_GEN = ""segments.gen"";
  
  
  static final String DELETABLE = ""deletable"";
   
  
  static final String NORMS_EXTENSION = ""nrm"";

  
  static final String COMPOUND_FILE_EXTENSION = ""cfs"";

  
  static final String DELETES_EXTENSION = ""del"";

  
  static final String PLAIN_NORMS_EXTENSION = ""f"";

  
  static final String SEPARATE_NORMS_EXTENSION = ""s"";

  
  static final String INDEX_EXTENSIONS[] = new String[] {
      ""cfs"", ""fnm"", ""fdx"", ""fdt"", ""tii"", ""tis"", ""frq"", ""prx"", ""del"",
      ""tvx"", ""tvd"", ""tvf"", ""gen"", ""nrm"" 
  };

  
  static final String[] INDEX_EXTENSIONS_IN_COMPOUND_FILE = new String[] {
      ""fnm"", ""fdx"", ""fdt"", ""tii"", ""tis"", ""frq"", ""prx"",
      ""tvx"", ""tvd"", ""tvf"", ""nrm"" 
  };
  
  
  static final String COMPOUND_EXTENSIONS[] = new String[] {
    ""fnm"", ""frq"", ""prx"", ""fdx"", ""fdt"", ""tii"", ""tis""
  };
  
  
  static final String VECTOR_EXTENSIONS[] = new String[] {
    ""tvx"", ""tvd"", ""tvf""
  };

  
  static final String fileNameFromGeneration(String base, String extension, long gen) {
    if (gen == SegmentInfo.NO) {
      return null;
    } else if (gen == SegmentInfo.WITHOUT_GEN) {
      return base + extension;
    } else {
      return base + ""_"" + Long.toString(gen, Character.MAX_RADIX) + extension;
    }
  }
}
"
lucene,2.2,org.apache.lucene.index.SegmentInfos,30,4,0,16,75,349,10,8,23,0.936781609,515,0.666666667,0,0.738317757,0.155172414,1,3,15.76666667,6,1.2667,8,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.PrintStream;
import java.util.Vector;

final class SegmentInfos extends Vector {
  
  
  
  
  public static final int FORMAT = -1;

  
  public static final int FORMAT_LOCKLESS = -2;

  
  public static final int FORMAT_SINGLE_NORM_FILE = -3;

  
  private static final int CURRENT_FORMAT = FORMAT_SINGLE_NORM_FILE;
  
  public int counter = 0;    
  
  private long version = System.currentTimeMillis();

  private long generation = 0;     
  private long lastGeneration = 0; 
                                   
                                   

  
  private static PrintStream infoStream;

  public final SegmentInfo info(int i) {
    return (SegmentInfo) elementAt(i);
  }

  
  public static long getCurrentSegmentGeneration(String[] files) {
    if (files == null) {
      return -1;
    }
    long max = -1;
    for (int i = 0; i < files.length; i++) {
      String file = files[i];
      if (file.startsWith(IndexFileNames.SEGMENTS) && !file.equals(IndexFileNames.SEGMENTS_GEN)) {
        long gen = generationFromSegmentsFileName(file);
        if (gen > max) {
          max = gen;
        }
      }
    }
    return max;
  }

  
  public static long getCurrentSegmentGeneration(Directory directory) throws IOException {
    String[] files = directory.list();
    if (files == null)
      throw new IOException(""cannot read directory "" + directory + "": list() returned null"");
    return getCurrentSegmentGeneration(files);
  }

  

  public static String getCurrentSegmentFileName(String[] files) throws IOException {
    return IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                 """",
                                                 getCurrentSegmentGeneration(files));
  }

  
  public static String getCurrentSegmentFileName(Directory directory) throws IOException {
    return IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                 """",
                                                 getCurrentSegmentGeneration(directory));
  }

  
  public String getCurrentSegmentFileName() {
    return IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                 """",
                                                 lastGeneration);
  }

  
  public static long generationFromSegmentsFileName(String fileName) {
    if (fileName.equals(IndexFileNames.SEGMENTS)) {
      return 0;
    } else if (fileName.startsWith(IndexFileNames.SEGMENTS)) {
      return Long.parseLong(fileName.substring(1+IndexFileNames.SEGMENTS.length()),
                            Character.MAX_RADIX);
    } else {
      throw new IllegalArgumentException(""fileName \"""" + fileName + ""\"" is not a segments file"");
    }
  }


  
  public String getNextSegmentFileName() {
    long nextGeneration;

    if (generation == -1) {
      nextGeneration = 1;
    } else {
      nextGeneration = generation+1;
    }
    return IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                 """",
                                                 nextGeneration);
  }

  
  public final void read(Directory directory, String segmentFileName) throws CorruptIndexException, IOException {
    boolean success = false;

    IndexInput input = directory.openInput(segmentFileName);

    generation = generationFromSegmentsFileName(segmentFileName);

    lastGeneration = generation;

    try {
      int format = input.readInt();
      if(format < 0){     
        
        if (format < CURRENT_FORMAT)
          throw new CorruptIndexException(""Unknown format version: "" + format);
        version = input.readLong(); 
        counter = input.readInt(); 
      }
      else{     
        counter = format;
      }
      
      for (int i = input.readInt(); i > 0; i--) { 
        addElement(new SegmentInfo(directory, format, input));
      }
      
      if(format >= 0){    
        if (input.getFilePointer() >= input.length())
          version = System.currentTimeMillis(); 
        else
          version = input.readLong(); 
      }
      success = true;
    }
    finally {
      input.close();
      if (!success) {
        
        
        clear();
      }
    }
  }
  
  public final void read(Directory directory) throws CorruptIndexException, IOException {

    generation = lastGeneration = -1;

    new FindSegmentsFile(directory) {

      protected Object doBody(String segmentFileName) throws CorruptIndexException, IOException {
        read(directory, segmentFileName);
        return null;
      }
    }.run();
  }

  public final void write(Directory directory) throws IOException {

    String segmentFileName = getNextSegmentFileName();

    
    if (generation == -1) {
      generation = 1;
    } else {
      generation++;
    }

    IndexOutput output = directory.createOutput(segmentFileName);

    boolean success = false;

    try {
      output.writeInt(CURRENT_FORMAT); 
      output.writeLong(++version); 
                                   
      output.writeInt(counter); 
      output.writeInt(size()); 
      for (int i = 0; i < size(); i++) {
        info(i).write(output);
      }         
    }
    finally {
      try {
        output.close();
        success = true;
      } finally {
        if (!success) {
          
          
          directory.deleteFile(segmentFileName);
        }
      }
    }

    try {
      output = directory.createOutput(IndexFileNames.SEGMENTS_GEN);
      try {
        output.writeInt(FORMAT_LOCKLESS);
        output.writeLong(generation);
        output.writeLong(generation);
      } finally {
        output.close();
      }
    } catch (IOException e) {
      
      
    }
    
    lastGeneration = generation;
  }

  
  
  public Object clone() {
    SegmentInfos sis = (SegmentInfos) super.clone();
    for(int i=0;i<sis.size();i++) {
      sis.setElementAt(((SegmentInfo) sis.elementAt(i)).clone(), i);
    }
    return sis;
  }

  
  public long getVersion() {
    return version;
  }
  public long getGeneration() {
    return generation;
  }

  
  public static long readCurrentVersion(Directory directory)
    throws CorruptIndexException, IOException {

    return ((Long) new FindSegmentsFile(directory) {
        protected Object doBody(String segmentFileName) throws CorruptIndexException, IOException {

          IndexInput input = directory.openInput(segmentFileName);

          int format = 0;
          long version = 0;
          try {
            format = input.readInt();
            if(format < 0){
              if (format < CURRENT_FORMAT)
                throw new CorruptIndexException(""Unknown format version: "" + format);
              version = input.readLong(); 
            }
          }
          finally {
            input.close();
          }
     
          if(format < 0)
            return new Long(version);

          
          
          SegmentInfos sis = new SegmentInfos();
          sis.read(directory, segmentFileName);
          return new Long(sis.getVersion());
        }
      }.run()).longValue();
  }

  
  public static void setInfoStream(PrintStream infoStream) {
    SegmentInfos.infoStream = infoStream;
  }

  
  private static int defaultGenFileRetryCount = 10;
  private static int defaultGenFileRetryPauseMsec = 50;
  private static int defaultGenLookaheadCount = 10;

  
  public static void setDefaultGenFileRetryCount(int count) {
    defaultGenFileRetryCount = count;
  }

  
  public static int getDefaultGenFileRetryCount() {
    return defaultGenFileRetryCount;
  }

  
  public static void setDefaultGenFileRetryPauseMsec(int msec) {
    defaultGenFileRetryPauseMsec = msec;
  }

  
  public static int getDefaultGenFileRetryPauseMsec() {
    return defaultGenFileRetryPauseMsec;
  }

  
  public static void setDefaultGenLookaheadCount(int count) {
    defaultGenLookaheadCount = count;
  }
  
  public static int getDefaultGenLookahedCount() {
    return defaultGenLookaheadCount;
  }

  
  public static PrintStream getInfoStream() {
    return infoStream;
  }

  private static void message(String message) {
    if (infoStream != null) {
      infoStream.println(Thread.currentThread().getName() + "": "" + message);
    }
  }

  
  public abstract static class FindSegmentsFile {
    
    File fileDirectory;
    Directory directory;

    public FindSegmentsFile(File directory) {
      this.fileDirectory = directory;
    }

    public FindSegmentsFile(Directory directory) {
      this.directory = directory;
    }

    public Object run() throws CorruptIndexException, IOException {
      String segmentFileName = null;
      long lastGen = -1;
      long gen = 0;
      int genLookaheadCount = 0;
      IOException exc = null;
      boolean retry = false;

      int method = 0;

      
      
      
      
      
      
      
      
      
      
      
      
      

      while(true) {

        
        
        
        
        String[] files = null;

        if (0 == method) {
          if (directory != null) {
            files = directory.list();
            if (files == null)
              throw new FileNotFoundException(""cannot read directory "" + directory + "": list() returned null"");
          } else {
            files = fileDirectory.list();
            if (files == null)
              throw new FileNotFoundException(""cannot read directory "" + fileDirectory + "": list() returned null"");
          }

          gen = getCurrentSegmentGeneration(files);

          if (gen == -1) {
            String s = """";
            for(int i=0;i<files.length;i++) {
              s += "" "" + files[i];
            }
            throw new FileNotFoundException(""no segments* file found in "" + directory + "": files:"" + s);
          }
        }

        
        
        
        if (1 == method || (0 == method && lastGen == gen && retry)) {

          method = 1;
            
          for(int i=0;i<defaultGenFileRetryCount;i++) {
            IndexInput genInput = null;
            try {
              genInput = directory.openInput(IndexFileNames.SEGMENTS_GEN);
            } catch (IOException e) {
              message(""segments.gen open: IOException "" + e);
            }
            if (genInput != null) {

              try {
                int version = genInput.readInt();
                if (version == FORMAT_LOCKLESS) {
                  long gen0 = genInput.readLong();
                  long gen1 = genInput.readLong();
                  message(""fallback check: "" + gen0 + ""; "" + gen1);
                  if (gen0 == gen1) {
                    
                    if (gen0 > gen) {
                      message(""fallback to '"" + IndexFileNames.SEGMENTS_GEN + ""' check: now try generation "" + gen0 + "" > "" + gen);
                      gen = gen0;
                    }
                    break;
                  }
                }
              } catch (IOException err2) {
                
              } finally {
                genInput.close();
              }
            }
            try {
              Thread.sleep(defaultGenFileRetryPauseMsec);
            } catch (InterruptedException e) {
              
            }
          }
        }

        
        
        
        
        if (2 == method || (1 == method && lastGen == gen && retry)) {

          method = 2;

          if (genLookaheadCount < defaultGenLookaheadCount) {
            gen++;
            genLookaheadCount++;
            message(""look ahead increment gen to "" + gen);
          }
        }

        if (lastGen == gen) {

          
          
          
          

          if (retry) {
            
            
            
            
            throw exc;
          } else {
            retry = true;
          }

        } else {
          
          
          retry = false;
        }

        lastGen = gen;

        segmentFileName = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                                """",
                                                                gen);

        try {
          Object v = doBody(segmentFileName);
          if (exc != null) {
            message(""success on "" + segmentFileName);
          }
          return v;
        } catch (IOException err) {

          
          if (exc == null) {
            exc = err;
          }

          message(""primary Exception on '"" + segmentFileName + ""': "" + err + ""'; will retry: retry="" + retry + ""; gen = "" + gen);

          if (!retry && gen > 1) {

            
            
            
            
            
            String prevSegmentFileName = IndexFileNames.fileNameFromGeneration(IndexFileNames.SEGMENTS,
                                                                               """",
                                                                               gen-1);
            
            if (directory.fileExists(prevSegmentFileName)) {
              message(""fallback to prior segment file '"" + prevSegmentFileName + ""'"");
              try {
                Object v = doBody(prevSegmentFileName);
                if (exc != null) {
                  message(""success on fallback "" + prevSegmentFileName);
                }
                return v;
              } catch (IOException err2) {
                message(""secondary Exception on '"" + prevSegmentFileName + ""': "" + err2 + ""'; will retry"");
              }
            }
          }
        }
      }
    }

    
    protected abstract Object doBody(String segmentFileName) throws CorruptIndexException, IOException;
  }
}
"
lucene,2.2,org.apache.lucene.document.Field,11,2,0,8,21,0,2,6,11,2.0,392,0.0,0,0.8,0.352272727,1,4,34.63636364,2,0.7273,2,"package org.apache.lucene.document;



import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.index.IndexWriter;   
import org.apache.lucene.util.Parameter;

import java.io.Reader;
import java.io.Serializable;



public final class Field extends AbstractField implements Fieldable, Serializable {
  
  
  public static final class Store extends Parameter implements Serializable {

    private Store(String name) {
      super(name);
    }

    
    public static final Store COMPRESS = new Store(""COMPRESS"");

    
    public static final Store YES = new Store(""YES"");

    
    public static final Store NO = new Store(""NO"");
  }

  
  public static final class Index extends Parameter implements Serializable {

    private Index(String name) {
      super(name);
    }

    
    public static final Index NO = new Index(""NO"");

    
    public static final Index TOKENIZED = new Index(""TOKENIZED"");

    
    public static final Index UN_TOKENIZED = new Index(""UN_TOKENIZED"");

    
    public static final Index NO_NORMS = new Index(""NO_NORMS"");

  }

  
  public static final class TermVector  extends Parameter implements Serializable {
    
    private TermVector(String name) {
      super(name);
    }
    
    
    public static final TermVector NO = new TermVector(""NO"");
    
    
    public static final TermVector YES = new TermVector(""YES"");
    
     
    public static final TermVector WITH_POSITIONS = new TermVector(""WITH_POSITIONS"");
    
     
    public static final TermVector WITH_OFFSETS = new TermVector(""WITH_OFFSETS"");
    
     
    public static final TermVector WITH_POSITIONS_OFFSETS = new TermVector(""WITH_POSITIONS_OFFSETS"");
  }
  
  
  
  public String stringValue()   { return fieldsData instanceof String ? (String)fieldsData : null; }
  
  
  public Reader readerValue()   { return fieldsData instanceof Reader ? (Reader)fieldsData : null; }
  
  
  public byte[] binaryValue()   { return fieldsData instanceof byte[] ? (byte[])fieldsData : null; }
  
  
  public TokenStream tokenStreamValue()   { return fieldsData instanceof TokenStream ? (TokenStream)fieldsData : null; }
  
  
  public Field(String name, String value, Store store, Index index) {
    this(name, value, store, index, TermVector.NO);
  }
  
   
  public Field(String name, String value, Store store, Index index, TermVector termVector) {
    if (name == null)
      throw new NullPointerException(""name cannot be null"");
    if (value == null)
      throw new NullPointerException(""value cannot be null"");
    if (name.length() == 0 && value.length() == 0)
      throw new IllegalArgumentException(""name and value cannot both be empty"");
    if (index == Index.NO && store == Store.NO)
      throw new IllegalArgumentException(""it doesn't make sense to have a field that ""
         + ""is neither indexed nor stored"");
    if (index == Index.NO && termVector != TermVector.NO)
      throw new IllegalArgumentException(""cannot store term vector information ""
         + ""for a field that is not indexed"");
          
    this.name = name.intern();        
    this.fieldsData = value;

    if (store == Store.YES){
      this.isStored = true;
      this.isCompressed = false;
    }
    else if (store == Store.COMPRESS) {
      this.isStored = true;
      this.isCompressed = true;
    }
    else if (store == Store.NO){
      this.isStored = false;
      this.isCompressed = false;
    }
    else
      throw new IllegalArgumentException(""unknown store parameter "" + store);
   
    if (index == Index.NO) {
      this.isIndexed = false;
      this.isTokenized = false;
    } else if (index == Index.TOKENIZED) {
      this.isIndexed = true;
      this.isTokenized = true;
    } else if (index == Index.UN_TOKENIZED) {
      this.isIndexed = true;
      this.isTokenized = false;
    } else if (index == Index.NO_NORMS) {
      this.isIndexed = true;
      this.isTokenized = false;
      this.omitNorms = true;
    } else {
      throw new IllegalArgumentException(""unknown index parameter "" + index);
    }
    
    this.isBinary = false;

    setStoreTermVector(termVector);
  }

  
  public Field(String name, Reader reader) {
    this(name, reader, TermVector.NO);
  }

   
  public Field(String name, Reader reader, TermVector termVector) {
    if (name == null)
      throw new NullPointerException(""name cannot be null"");
    if (reader == null)
      throw new NullPointerException(""reader cannot be null"");
    
    this.name = name.intern();        
    this.fieldsData = reader;
    
    this.isStored = false;
    this.isCompressed = false;
    
    this.isIndexed = true;
    this.isTokenized = true;
    
    this.isBinary = false;
    
    setStoreTermVector(termVector);
  }

   
  public Field(String name, TokenStream tokenStream) {
    this(name, tokenStream, TermVector.NO);
  }
  
   
  public Field(String name, TokenStream tokenStream, TermVector termVector) {
    if (name == null)
      throw new NullPointerException(""name cannot be null"");
    if (tokenStream == null)
      throw new NullPointerException(""tokenStream cannot be null"");
    
    this.name = name.intern();        
    this.fieldsData = tokenStream;
    
    this.isStored = false;
    this.isCompressed = false;
    
    this.isIndexed = true;
    this.isTokenized = true;
    
    this.isBinary = false;
    
    setStoreTermVector(termVector);
  }

  
  
  public Field(String name, byte[] value, Store store) {
    if (name == null)
      throw new IllegalArgumentException(""name cannot be null"");
    if (value == null)
      throw new IllegalArgumentException(""value cannot be null"");
    
    this.name = name.intern();
    this.fieldsData = value;
    
    if (store == Store.YES){
      this.isStored = true;
      this.isCompressed = false;
    }
    else if (store == Store.COMPRESS) {
      this.isStored = true;
      this.isCompressed = true;
    }
    else if (store == Store.NO)
      throw new IllegalArgumentException(""binary values can't be unstored"");
    else
      throw new IllegalArgumentException(""unknown store parameter "" + store);
    
    this.isIndexed   = false;
    this.isTokenized = false;
    
    this.isBinary    = true;
    
    setStoreTermVector(TermVector.NO);
  }


}
"
lucene,2.2,org.apache.lucene.search.TopDocCollector,5,2,1,7,13,0,2,5,4,0.4375,110,0.5,1,0.25,0.5,0,0,20.2,4,1.6,2,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;


public class TopDocCollector extends HitCollector {
  private int numHits;
  private float minScore = 0.0f;

  int totalHits;
  PriorityQueue hq;
    
  
  public TopDocCollector(int numHits) {
    this(numHits, new HitQueue(numHits));
  }

  TopDocCollector(int numHits, PriorityQueue hq) {
    this.numHits = numHits;
    this.hq = hq;
  }

  
  public void collect(int doc, float score) {
    if (score > 0.0f) {
      totalHits++;
      if (hq.size() < numHits || score >= minScore) {
        hq.insert(new ScoreDoc(doc, score));
        minScore = ((ScoreDoc)hq.top()).score; 
      }
    }
  }

  
  public int getTotalHits() { return totalHits; }

  
  public TopDocs topDocs() {
    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size()-1; i >= 0; i--)      
      scoreDocs[i] = (ScoreDoc)hq.pop();
      
    float maxScore = (totalHits==0)
      ? Float.NEGATIVE_INFINITY
      : scoreDocs[0].score;
    
    return new TopDocs(totalHits, scoreDocs, maxScore);
  }
}
"
lucene,2.2,org.apache.lucene.analysis.KeywordAnalyzer,2,2,0,3,4,1,0,3,2,2.0,10,0.0,0,0.666666667,0.666666667,0,0,4.0,1,0.5,1,"package org.apache.lucene.analysis;



import java.io.Reader;


public class KeywordAnalyzer extends Analyzer {
  public TokenStream tokenStream(String fieldName,
                                 final Reader reader) {
    return new KeywordTokenizer(reader);
  }
}"
lucene,2.2,org.apache.lucene.store.FSDirectory,28,2,1,16,89,86,6,10,23,0.844444444,1021,0.8,0,0.395348837,0.265432099,1,7,35.10714286,2,1.0,11,"package org.apache.lucene.store;



import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.Hashtable;

import org.apache.lucene.index.IndexFileNameFilter;


import org.apache.lucene.index.IndexWriter;


public class FSDirectory extends Directory {
    
  
  private static final Hashtable DIRECTORIES = new Hashtable();

  private static boolean disableLocks = false;

  
  

  
  public static void setDisableLocks(boolean doDisableLocks) {
    FSDirectory.disableLocks = doDisableLocks;
  }

  
  public static boolean getDisableLocks() {
    return FSDirectory.disableLocks;
  }

  
  public static final String LOCK_DIR = System.getProperty(""org.apache.lucene.lockDir"",
                                                           System.getProperty(""java.io.tmpdir""));

  
  private static Class IMPL;
  static {
    try {
      String name =
        System.getProperty(""org.apache.lucene.FSDirectory.class"",
                           FSDirectory.class.getName());
      IMPL = Class.forName(name);
    } catch (ClassNotFoundException e) {
      throw new RuntimeException(""cannot load FSDirectory class: "" + e.toString(), e);
    } catch (SecurityException se) {
      try {
        IMPL = Class.forName(FSDirectory.class.getName());
      } catch (ClassNotFoundException e) {
        throw new RuntimeException(""cannot load default FSDirectory class: "" + e.toString(), e);
      }
    }
  }

  private static MessageDigest DIGESTER;

  static {
    try {
      DIGESTER = MessageDigest.getInstance(""MD5"");
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e.toString(), e);
    }
  }

  
  private byte[] buffer = null;

  
  public static FSDirectory getDirectory(String path)
      throws IOException {
    return getDirectory(new File(path), null);
  }

  
  public static FSDirectory getDirectory(String path, LockFactory lockFactory)
      throws IOException {
    return getDirectory(new File(path), lockFactory);
  }

  
  public static FSDirectory getDirectory(File file)
    throws IOException {
    return getDirectory(file, null);
  }

  
  public static FSDirectory getDirectory(File file, LockFactory lockFactory)
    throws IOException
  {
    file = new File(file.getCanonicalPath());

    if (file.exists() && !file.isDirectory())
      throw new IOException(file + "" not a directory"");

    if (!file.exists())
      if (!file.mkdirs())
        throw new IOException(""Cannot create directory: "" + file);

    FSDirectory dir;
    synchronized (DIRECTORIES) {
      dir = (FSDirectory)DIRECTORIES.get(file);
      if (dir == null) {
        try {
          dir = (FSDirectory)IMPL.newInstance();
        } catch (Exception e) {
          throw new RuntimeException(""cannot load FSDirectory class: "" + e.toString(), e);
        }
        dir.init(file, lockFactory);
        DIRECTORIES.put(file, dir);
      } else {
        
        
        if (lockFactory != null && lockFactory != dir.getLockFactory()) {
          throw new IOException(""Directory was previously created with a different LockFactory instance; please pass null as the lockFactory instance and use setLockFactory to change it"");
        }
      }
    }
    synchronized (dir) {
      dir.refCount++;
    }
    return dir;
  }


  
  public static FSDirectory getDirectory(String path, boolean create)
      throws IOException {
    return getDirectory(new File(path), create);
  }

  
  public static FSDirectory getDirectory(File file, boolean create)
    throws IOException
  {
    FSDirectory dir = getDirectory(file, null);

    
    
    if (create) {
      dir.create();
    }

    return dir;
  }

  private void create() throws IOException {
    if (directory.exists()) {
      String[] files = directory.list(IndexFileNameFilter.getFilter());            
      if (files == null)
        throw new IOException(""cannot read directory "" + directory.getAbsolutePath() + "": list() returned null"");
      for (int i = 0; i < files.length; i++) {
        File file = new File(directory, files[i]);
        if (!file.delete())
          throw new IOException(""Cannot delete "" + file);
      }
    }
    lockFactory.clearLock(IndexWriter.WRITE_LOCK_NAME);
  }

  private File directory = null;
  private int refCount;

  protected FSDirectory() {};                     

  private void init(File path, LockFactory lockFactory) throws IOException {

    
    
    
    

    directory = path;

    boolean doClearLockID = false;

    if (lockFactory == null) {

      if (disableLocks) {
        
        lockFactory = NoLockFactory.getNoLockFactory();
      } else {
        String lockClassName = System.getProperty(""org.apache.lucene.store.FSDirectoryLockFactoryClass"");

        if (lockClassName != null && !lockClassName.equals("""")) {
          Class c;

          try {
            c = Class.forName(lockClassName);
          } catch (ClassNotFoundException e) {
            throw new IOException(""unable to find LockClass "" + lockClassName);
          }

          try {
            lockFactory = (LockFactory) c.newInstance();          
          } catch (IllegalAccessException e) {
            throw new IOException(""IllegalAccessException when instantiating LockClass "" + lockClassName);
          } catch (InstantiationException e) {
            throw new IOException(""InstantiationException when instantiating LockClass "" + lockClassName);
          } catch (ClassCastException e) {
            throw new IOException(""unable to cast LockClass "" + lockClassName + "" instance to a LockFactory"");
          }

          if (lockFactory instanceof NativeFSLockFactory) {
            ((NativeFSLockFactory) lockFactory).setLockDir(path);
          } else if (lockFactory instanceof SimpleFSLockFactory) {
            ((SimpleFSLockFactory) lockFactory).setLockDir(path);
          }
        } else {
          
          
          lockFactory = new SimpleFSLockFactory(path);
          doClearLockID = true;
        }
      }
    }

    setLockFactory(lockFactory);

    if (doClearLockID) {
      
      
      lockFactory.setLockPrefix(null);
    }
  }

  
  public String[] list() {
    return directory.list(IndexFileNameFilter.getFilter());
  }

  
  public boolean fileExists(String name) {
    File file = new File(directory, name);
    return file.exists();
  }

  
  public long fileModified(String name) {
    File file = new File(directory, name);
    return file.lastModified();
  }

  
  public static long fileModified(File directory, String name) {
    File file = new File(directory, name);
    return file.lastModified();
  }

  
  public void touchFile(String name) {
    File file = new File(directory, name);
    file.setLastModified(System.currentTimeMillis());
  }

  
  public long fileLength(String name) {
    File file = new File(directory, name);
    return file.length();
  }

  
  public void deleteFile(String name) throws IOException {
    File file = new File(directory, name);
    if (!file.delete())
      throw new IOException(""Cannot delete "" + file);
  }

  
  public synchronized void renameFile(String from, String to)
      throws IOException {
    File old = new File(directory, from);
    File nu = new File(directory, to);

    

    if (nu.exists())
      if (!nu.delete())
        throw new IOException(""Cannot delete "" + nu);

    
    
    
    if (!old.renameTo(nu)) {
      java.io.InputStream in = null;
      java.io.OutputStream out = null;
      try {
        in = new FileInputStream(old);
        out = new FileOutputStream(nu);
        
        
        
        if (buffer == null) {
          buffer = new byte[1024];
        }
        int len;
        while ((len = in.read(buffer)) >= 0) {
          out.write(buffer, 0, len);
        }

        
        old.delete();
      }
      catch (IOException ioe) {
        IOException newExc = new IOException(""Cannot rename "" + old + "" to "" + nu);
        newExc.initCause(ioe);
        throw newExc;
      }
      finally {
        try {
          if (in != null) {
            try {
              in.close();
            } catch (IOException e) {
              throw new RuntimeException(""Cannot close input stream: "" + e.toString(), e);
            }
          }
        } finally {
          if (out != null) {
            try {
              out.close();
            } catch (IOException e) {
              throw new RuntimeException(""Cannot close output stream: "" + e.toString(), e);
            }
          }
        }
      }
    }
  }

  
  public IndexOutput createOutput(String name) throws IOException {

    File file = new File(directory, name);
    if (file.exists() && !file.delete())          
      throw new IOException(""Cannot overwrite: "" + file);

    return new FSIndexOutput(file);
  }

  
  public IndexInput openInput(String name) throws IOException {
    return new FSIndexInput(new File(directory, name));
  }

  
  public IndexInput openInput(String name, int bufferSize) throws IOException {
    return new FSIndexInput(new File(directory, name), bufferSize);
  }

  
  private static final char[] HEX_DIGITS =
  {'0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f'};

  
  public String getLockID() {
    String dirName;                               
    try {
      dirName = directory.getCanonicalPath();
    } catch (IOException e) {
      throw new RuntimeException(e.toString(), e);
    }

    byte digest[];
    synchronized (DIGESTER) {
      digest = DIGESTER.digest(dirName.getBytes());
    }
    StringBuffer buf = new StringBuffer();
    buf.append(""lucene-"");
    for (int i = 0; i < digest.length; i++) {
      int b = digest[i];
      buf.append(HEX_DIGITS[(b >> 4) & 0xf]);
      buf.append(HEX_DIGITS[b & 0xf]);
    }

    return buf.toString();
  }

  
  public synchronized void close() {
    if (--refCount <= 0) {
      synchronized (DIRECTORIES) {
        DIRECTORIES.remove(directory);
      }
    }
  }

  public File getFile() {
    return directory;
  }

  
  public String toString() {
    return this.getClass().getName() + ""@"" + directory;
  }

  protected static class FSIndexInput extends BufferedIndexInput {
  
    private static class Descriptor extends RandomAccessFile {
      
      
      private boolean isOpen;
      long position;
      final long length;
      
      public Descriptor(File file, String mode) throws IOException {
        super(file, mode);
        isOpen=true;
        length=length();
      }
  
      public void close() throws IOException {
        if (isOpen) {
          isOpen=false;
          super.close();
        }
      }
  
      protected void finalize() throws Throwable {
        try {
          close();
        } finally {
          super.finalize();
        }
      }
    }
  
    private final Descriptor file;
    boolean isClone;
  
    public FSIndexInput(File path) throws IOException {
      this(path, BufferedIndexInput.BUFFER_SIZE);
    }
  
    public FSIndexInput(File path, int bufferSize) throws IOException {
      super(bufferSize);
      file = new Descriptor(path, ""r"");
    }
  
    
    protected void readInternal(byte[] b, int offset, int len)
         throws IOException {
      synchronized (file) {
        long position = getFilePointer();
        if (position != file.position) {
          file.seek(position);
          file.position = position;
        }
        int total = 0;
        do {
          int i = file.read(b, offset+total, len-total);
          if (i == -1)
            throw new IOException(""read past EOF"");
          file.position += i;
          total += i;
        } while (total < len);
      }
    }
  
    public void close() throws IOException {
      
      if (!isClone) file.close();
    }
  
    protected void seekInternal(long position) {
    }
  
    public long length() {
      return file.length;
    }
  
    public Object clone() {
      FSIndexInput clone = (FSIndexInput)super.clone();
      clone.isClone = true;
      return clone;
    }
  
    
    boolean isFDValid() throws IOException {
      return file.getFD().valid();
    }
  }

  protected static class FSIndexOutput extends BufferedIndexOutput {
    RandomAccessFile file = null;
  
    
    
    private boolean isOpen;
  
    public FSIndexOutput(File path) throws IOException {
      file = new RandomAccessFile(path, ""rw"");
      isOpen = true;
    }
  
    
    public void flushBuffer(byte[] b, int offset, int size) throws IOException {
      file.write(b, offset, size);
    }
    public void close() throws IOException {
      
      if (isOpen) {
        super.close();
        file.close();
        isOpen = false;
      }
    }
  
    
    public void seek(long pos) throws IOException {
      super.seek(pos);
      file.seek(pos);
    }
    public long length() throws IOException {
      return file.length();
    }
  
  }
}
"
lucene,2.2,org.apache.lucene.analysis.CachingTokenFilter,4,3,0,3,10,2,0,3,3,0.666666667,57,1.0,0,0.571428571,0.625,0,0,12.75,1,0.75,2,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.util.LinkedList;
import java.util.List;


public class CachingTokenFilter extends TokenFilter {
  private List cache;
  private int index;
  
  public CachingTokenFilter(TokenStream input) {
    super(input);
  }
  
  public Token next() throws IOException {
    if (cache == null) {
      
      cache = new LinkedList();
      fillCache();
    }
    
    if (index == cache.size()) {
      
      return null;
    }
    
    return (Token) cache.get(index++);
  }
  
  public void reset() throws IOException {
    index = 0;
  }
  
  private void fillCache() throws IOException {
    Token token;
    while ( (token = input.next()) != null) {
      cache.add(token);
    }
  }

}
"
lucene,2.2,org.apache.lucene.search.spans.SpanOrQuery,11,3,0,8,42,0,3,6,10,0.45,286,1.0,0,0.615384615,0.220779221,2,2,24.81818182,7,1.7273,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.List;
import java.util.Collection;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.PriorityQueue;
import org.apache.lucene.util.ToStringUtils;
import org.apache.lucene.search.Query;


public class SpanOrQuery extends SpanQuery {
  private List clauses;
  private String field;

  
  public SpanOrQuery(SpanQuery[] clauses) {

    
    this.clauses = new ArrayList(clauses.length);
    for (int i = 0; i < clauses.length; i++) {
      SpanQuery clause = clauses[i];
      if (i == 0) {                               
        field = clause.getField();
      } else if (!clause.getField().equals(field)) {
        throw new IllegalArgumentException(""Clauses must have same field."");
      }
      this.clauses.add(clause);
    }
  }

  
  public SpanQuery[] getClauses() {
    return (SpanQuery[])clauses.toArray(new SpanQuery[clauses.size()]);
  }

  public String getField() { return field; }

  
  public Collection getTerms() {
    Collection terms = new ArrayList();
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      terms.addAll(clause.getTerms());
    }
    return terms;
  }
  
  public void extractTerms(Set terms) {
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      clause.extractTerms(terms);
    }
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanOrQuery clone = null;
    for (int i = 0 ; i < clauses.size(); i++) {
      SpanQuery c = (SpanQuery)clauses.get(i);
      SpanQuery query = (SpanQuery) c.rewrite(reader);
      if (query != c) {                     
        if (clone == null)
          clone = (SpanOrQuery) this.clone();
        clone.clauses.set(i,query);
      }
    }
    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanOr(["");
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      buffer.append(clause.toString(field));
      if (i.hasNext()) {
        buffer.append("", "");
      }
    }
    buffer.append(""])"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    final SpanOrQuery that = (SpanOrQuery) o;

    if (!clauses.equals(that.clauses)) return false;
    if (!field.equals(that.field)) return false;

    return getBoost() == that.getBoost();
  }

  public int hashCode() {
    int h = clauses.hashCode();
    h ^= (h << 10) | (h >>> 23);
    h ^= Float.floatToRawIntBits(getBoost());
    return h;
  }


  private class SpanQueue extends PriorityQueue {
    public SpanQueue(int size) {
      initialize(size);
    }

    protected final boolean lessThan(Object o1, Object o2) {
      Spans spans1 = (Spans)o1;
      Spans spans2 = (Spans)o2;
      if (spans1.doc() == spans2.doc()) {
        if (spans1.start() == spans2.start()) {
          return spans1.end() < spans2.end();
        } else {
          return spans1.start() < spans2.start();
        }
      } else {
        return spans1.doc() < spans2.doc();
      }
    }
  }


  public Spans getSpans(final IndexReader reader) throws IOException {
    if (clauses.size() == 1)                      
      return ((SpanQuery)clauses.get(0)).getSpans(reader);

    return new Spans() {
        private SpanQueue queue = null;

        private boolean initSpanQueue(int target) throws IOException {
          queue = new SpanQueue(clauses.size());
          Iterator i = clauses.iterator();
          while (i.hasNext()) {
            Spans spans = ((SpanQuery)i.next()).getSpans(reader);
            if (   ((target == -1) && spans.next())
                || ((target != -1) && spans.skipTo(target))) {
              queue.put(spans);
            }
          }
          return queue.size() != 0;
        }

        public boolean next() throws IOException {
          if (queue == null) {
            return initSpanQueue(-1);
          }

          if (queue.size() == 0) { 
            return false;
          }

          if (top().next()) { 
            queue.adjustTop();
            return true;
          }

          queue.pop();  
          return queue.size() != 0;
        }

        private Spans top() { return (Spans)queue.top(); }

        public boolean skipTo(int target) throws IOException {
          if (queue == null) {
            return initSpanQueue(target);
          }

          while (queue.size() != 0 && top().doc() < target) {
            if (top().skipTo(target)) {
              queue.adjustTop();
            } else {
              queue.pop();
            }
          }

          return queue.size() != 0;
        }

        public int doc() { return top().doc(); }
        public int start() { return top().start(); }
        public int end() { return top().end(); }

        public String toString() {
          return ""spans(""+SpanOrQuery.this+"")@""+
            ((queue == null)?""START""
             :(queue.size()>0?(doc()+"":""+start()+""-""+end()):""END""));
        }

      };
  }

}
"
lucene,2.2,org.apache.lucene.store.NoLockFactory,5,2,0,4,7,6,1,3,4,0.75,24,1.0,2,0.571428571,0.625,0,0,3.4,1,0.6,0,"package org.apache.lucene.store;



import java.io.IOException;



public class NoLockFactory extends LockFactory {

  
  private static NoLock singletonLock = new NoLock();
  private static NoLockFactory singleton = new NoLockFactory();

  public static NoLockFactory getNoLockFactory() {
    return singleton;
  }

  public Lock makeLock(String lockName) {
    return singletonLock;
  }

  public void clearLock(String lockName) {};
};

class NoLock extends Lock {
  public boolean obtain() throws IOException {
    return true;
  }

  public void release() {
  }

  public boolean isLocked() {
    return false;
  }

  public String toString() {
    return ""NoLock"";
  }
}
"
lucene,2.2,org.apache.lucene.search.ScoreDoc,1,1,1,19,2,0,19,0,1,2.0,12,0.0,0,0.0,1.0,0,0,9.0,0,0.0,0,"package org.apache.lucene.search;




public class ScoreDoc implements java.io.Serializable {
  
  public float score;

  
  public int doc;

  
  public ScoreDoc(int doc, float score) {
    this.doc = doc;
    this.score = score;
  }
}
"
lucene,2.2,org.apache.lucene.search.spans.NearSpansOrdered,15,1,0,6,41,25,3,5,7,0.747252747,661,0.846153846,3,0.0,0.202380952,0,0,42.2,6,1.5333,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Arrays;
import java.util.Comparator;

import org.apache.lucene.index.IndexReader;


class NearSpansOrdered implements Spans {
  private final int allowedSlop;
  private boolean firstTime = true;
  private boolean more = false;

  
  private final Spans[] subSpans;

  
  private boolean inSameDoc = false;

  private int matchDoc = -1;
  private int matchStart = -1;
  private int matchEnd = -1;

  private final Spans[] subSpansByDoc;
  private final Comparator spanDocComparator = new Comparator() {
    public int compare(Object o1, Object o2) {
      return ((Spans)o1).doc() - ((Spans)o2).doc();
    }
  };
  
  private SpanNearQuery query;

  public NearSpansOrdered(SpanNearQuery spanNearQuery, IndexReader reader)
  throws IOException {
    if (spanNearQuery.getClauses().length < 2) {
      throw new IllegalArgumentException(""Less than 2 clauses: ""
                                         + spanNearQuery);
    }
    allowedSlop = spanNearQuery.getSlop();
    SpanQuery[] clauses = spanNearQuery.getClauses();
    subSpans = new Spans[clauses.length];
    subSpansByDoc = new Spans[clauses.length];
    for (int i = 0; i < clauses.length; i++) {
      subSpans[i] = clauses[i].getSpans(reader);
      subSpansByDoc[i] = subSpans[i]; 
    }
    query = spanNearQuery; 
  }

  
  public int doc() { return matchDoc; }

  
  public int start() { return matchStart; }

  
  public int end() { return matchEnd; }

  
  public boolean next() throws IOException {
    if (firstTime) {
      firstTime = false;
      for (int i = 0; i < subSpans.length; i++) {
        if (! subSpans[i].next()) {
          more = false;
          return false;
        }
      }
      more = true;
    }
    return advanceAfterOrdered();
  }

  
  public boolean skipTo(int target) throws IOException {
    if (firstTime) {
      firstTime = false;
      for (int i = 0; i < subSpans.length; i++) {
        if (! subSpans[i].skipTo(target)) {
          more = false;
          return false;
        }
      }
      more = true;
    } else if (more && (subSpans[0].doc() < target)) {
      if (subSpans[0].skipTo(target)) {
        inSameDoc = false;
      } else {
        more = false;
        return false;
      }
    }
    return advanceAfterOrdered();
  }
  
  
  private boolean advanceAfterOrdered() throws IOException {
    while (more && (inSameDoc || toSameDoc())) {
      if (stretchToOrder() && shrinkToAfterShortestMatch()) {
        return true;
      }
    }
    return false; 
  }


  
  private boolean toSameDoc() throws IOException {
    Arrays.sort(subSpansByDoc, spanDocComparator);
    int firstIndex = 0;
    int maxDoc = subSpansByDoc[subSpansByDoc.length - 1].doc();
    while (subSpansByDoc[firstIndex].doc() != maxDoc) {
      if (! subSpansByDoc[firstIndex].skipTo(maxDoc)) {
        more = false;
        inSameDoc = false;
        return false;
      }
      maxDoc = subSpansByDoc[firstIndex].doc();
      if (++firstIndex == subSpansByDoc.length) {
        firstIndex = 0;
      }
    }
    for (int i = 0; i < subSpansByDoc.length; i++) {
      assert (subSpansByDoc[i].doc() == maxDoc)
             : "" NearSpansOrdered.toSameDoc() spans "" + subSpansByDoc[0]
                                 + ""\n at doc "" + subSpansByDoc[i].doc()
                                 + "", but should be at "" + maxDoc;
    }
    inSameDoc = true;
    return true;
  }
  
  
  static final boolean docSpansOrdered(Spans spans1, Spans spans2) {
    assert spans1.doc() == spans2.doc() : ""doc1 "" + spans1.doc() + "" != doc2 "" + spans2.doc();
    int start1 = spans1.start();
    int start2 = spans2.start();
    
    return (start1 == start2) ? (spans1.end() < spans2.end()) : (start1 < start2);
  }

  
  private static final boolean docSpansOrdered(int start1, int end1, int start2, int end2) {
    return (start1 == start2) ? (end1 < end2) : (start1 < start2);
  }

  
  private boolean stretchToOrder() throws IOException {
    matchDoc = subSpans[0].doc();
    for (int i = 1; inSameDoc && (i < subSpans.length); i++) {
      while (! docSpansOrdered(subSpans[i-1], subSpans[i])) {
        if (! subSpans[i].next()) {
          inSameDoc = false;
          more = false;
          break;
        } else if (matchDoc != subSpans[i].doc()) {
          inSameDoc = false;
          break;
        }
      }
    }
    return inSameDoc;
  }

  
  private boolean shrinkToAfterShortestMatch() throws IOException {
    matchStart = subSpans[subSpans.length - 1].start();
    matchEnd = subSpans[subSpans.length - 1].end();
    int matchSlop = 0;
    int lastStart = matchStart;
    int lastEnd = matchEnd;
    for (int i = subSpans.length - 2; i >= 0; i--) {
      Spans prevSpans = subSpans[i];
      int prevStart = prevSpans.start();
      int prevEnd = prevSpans.end();
      while (true) { 
        if (! prevSpans.next()) {
          inSameDoc = false;
          more = false;
          break; 
        } else if (matchDoc != prevSpans.doc()) {
          inSameDoc = false; 
          break; 
        } else {
          int ppStart = prevSpans.start();
          int ppEnd = prevSpans.end(); 
          if (! docSpansOrdered(ppStart, ppEnd, lastStart, lastEnd)) {
            break; 
          } else { 
            prevStart = ppStart;
            prevEnd = ppEnd;
          }
        }
      }
      assert prevStart <= matchStart;
      if (matchStart > prevEnd) { 
        matchSlop += (matchStart - prevEnd);
      }
      
      matchStart = prevStart;
      lastStart = prevStart;
      lastEnd = prevEnd;
    }
    return matchSlop <= allowedSlop; 
  }

  public String toString() {
    return getClass().getName() + ""(""+query.toString()+"")@""+
      (firstTime?""START"":(more?(doc()+"":""+start()+""-""+end()):""END""));
  }
}

"
lucene,2.2,org.apache.lucene.analysis.LengthFilter,2,3,0,3,6,0,0,3,2,0.0,41,0.0,0,0.8,0.666666667,0,0,18.5,1,0.5,1,"package org.apache.lucene.analysis;



import java.io.IOException;


public final class LengthFilter extends TokenFilter {

  final int min;
  final int max;

  
  public LengthFilter(TokenStream in, int min, int max)
  {
    super(in);
    this.min = min;
    this.max = max;
  }

  
  public final Token next() throws IOException
  {
    
    for (Token token = input.next(); token != null; token = input.next())
    {
      int len = token.termText().length();
      if (len >= min && len <= max) {
          return token;
      }
      
    }
    
    return null;
  }
}
"
lucene,2.2,org.apache.lucene.search.IndexSearcher,15,2,0,21,34,0,3,19,14,0.357142857,164,0.5,1,0.666666667,0.18974359,1,3,9.8,1,0.7333,2,"package org.apache.lucene.search;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.index.CorruptIndexException;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.store.Directory;

import java.io.IOException;
import java.util.BitSet;


public class IndexSearcher extends Searcher {
  IndexReader reader;
  private boolean closeReader;

  
  public IndexSearcher(String path) throws CorruptIndexException, IOException {
    this(IndexReader.open(path), true);
  }

  
  public IndexSearcher(Directory directory) throws CorruptIndexException, IOException {
    this(IndexReader.open(directory), true);
  }

  
  public IndexSearcher(IndexReader r) {
    this(r, false);
  }
  
  private IndexSearcher(IndexReader r, boolean closeReader) {
    reader = r;
    this.closeReader = closeReader;
  }

  
  public IndexReader getIndexReader() {
    return reader;
  }

  
  public void close() throws IOException {
    if(closeReader)
      reader.close();
  }

  
  public int docFreq(Term term) throws IOException {
    return reader.docFreq(term);
  }

  
  public Document doc(int i) throws CorruptIndexException, IOException {
    return reader.document(i);
  }
  
  
  public Document doc(int i, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
	    return reader.document(i, fieldSelector);
  }
  
  
  public int maxDoc() throws IOException {
    return reader.maxDoc();
  }

  
  public TopDocs search(Weight weight, Filter filter, final int nDocs)
       throws IOException {

    if (nDocs <= 0)  
      throw new IllegalArgumentException(""nDocs must be > 0"");

    TopDocCollector collector = new TopDocCollector(nDocs);
    search(weight, filter, collector);
    return collector.topDocs();
  }

  
  public TopFieldDocs search(Weight weight, Filter filter, final int nDocs,
                             Sort sort)
      throws IOException {

    TopFieldDocCollector collector =
      new TopFieldDocCollector(reader, sort, nDocs);
    search(weight, filter, collector);
    return (TopFieldDocs)collector.topDocs();
  }

  
  public void search(Weight weight, Filter filter,
                     final HitCollector results) throws IOException {
    HitCollector collector = results;
    if (filter != null) {
      final BitSet bits = filter.bits(reader);
      collector = new HitCollector() {
          public final void collect(int doc, float score) {
            if (bits.get(doc)) {                  
              results.collect(doc, score);
            }
          }
        };
    }

    Scorer scorer = weight.scorer(reader);
    if (scorer == null)
      return;
    scorer.score(collector);
  }

  public Query rewrite(Query original) throws IOException {
    Query query = original;
    for (Query rewrittenQuery = query.rewrite(reader); rewrittenQuery != query;
         rewrittenQuery = query.rewrite(reader)) {
      query = rewrittenQuery;
    }
    return query;
  }

  public Explanation explain(Weight weight, int doc) throws IOException {
    return weight.explain(reader, doc);
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.ParseException,5,3,0,3,18,0,2,1,4,0.55,387,0.4,1,0.866666667,0.4,1,1,75.4,14,4.8,3,"
package org.apache.lucene.queryParser;


public class ParseException extends Exception {

  
  public ParseException(Token currentTokenVal,
                        int[][] expectedTokenSequencesVal,
                        String[] tokenImageVal
                       )
  {
    super("""");
    specialConstructor = true;
    currentToken = currentTokenVal;
    expectedTokenSequences = expectedTokenSequencesVal;
    tokenImage = tokenImageVal;
  }

  

  public ParseException() {
    super();
    specialConstructor = false;
  }

  public ParseException(String message) {
    super(message);
    specialConstructor = false;
  }

  
  protected boolean specialConstructor;

  
  public Token currentToken;

  
  public int[][] expectedTokenSequences;

  
  public String[] tokenImage;

  
  public String getMessage() {
    if (!specialConstructor) {
      return super.getMessage();
    }
    String expected = """";
    int maxSize = 0;
    for (int i = 0; i < expectedTokenSequences.length; i++) {
      if (maxSize < expectedTokenSequences[i].length) {
        maxSize = expectedTokenSequences[i].length;
      }
      for (int j = 0; j < expectedTokenSequences[i].length; j++) {
        expected += tokenImage[expectedTokenSequences[i][j]] + "" "";
      }
      if (expectedTokenSequences[i][expectedTokenSequences[i].length - 1] != 0) {
        expected += ""..."";
      }
      expected += eol + ""    "";
    }
    String retval = ""Encountered \"""";
    Token tok = currentToken.next;
    for (int i = 0; i < maxSize; i++) {
      if (i != 0) retval += "" "";
      if (tok.kind == 0) {
        retval += tokenImage[0];
        break;
      }
      retval += add_escapes(tok.image);
      tok = tok.next; 
    }
    retval += ""\"" at line "" + currentToken.next.beginLine + "", column "" + currentToken.next.beginColumn;
    retval += ""."" + eol;
    if (expectedTokenSequences.length == 1) {
      retval += ""Was expecting:"" + eol + ""    "";
    } else {
      retval += ""Was expecting one of:"" + eol + ""    "";
    }
    retval += expected;
    return retval;
  }

  
  protected String eol = System.getProperty(""line.separator"", ""\n"");
 
  
  protected String add_escapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

}
"
lucene,2.2,org.apache.lucene.search.Weight,6,1,0,47,6,15,44,4,6,2.0,6,0.0,0,0.0,0.416666667,0,0,0.0,1,1.0,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;


public interface Weight extends java.io.Serializable {
  
  Query getQuery();

  
  float getValue();

  
  float sumOfSquaredWeights() throws IOException;

  
  void normalize(float norm);

  
  Scorer scorer(IndexReader reader) throws IOException;

  
  Explanation explain(IndexReader reader, int doc) throws IOException;
}
"
lucene,2.2,org.apache.lucene.search.Scorer,9,1,17,38,11,34,35,3,7,0.875,47,1.0,1,0.0,0.416666667,0,0,4.111111111,1,0.8889,1,"package org.apache.lucene.search;



import java.io.IOException;


public abstract class Scorer {
  private Similarity similarity;

  
  protected Scorer(Similarity similarity) {
    this.similarity = similarity;
  }

  
  public Similarity getSimilarity() {
    return this.similarity;
  }

  
  public void score(HitCollector hc) throws IOException {
    while (next()) {
      hc.collect(doc(), score());
    }
  }

  
  protected boolean score(HitCollector hc, int max) throws IOException {
    while (doc() < max) {
      hc.collect(doc(), score());
      if (!next())
        return false;
    }
    return true;
  }

  
  public abstract boolean next() throws IOException;

  
  public abstract int doc();

  
  public abstract float score() throws IOException;

  
  public abstract boolean skipTo(int target) throws IOException;

  
  public abstract Explanation explain(int doc) throws IOException;

}
"
lucene,2.2,org.apache.lucene.index.IndexReader,62,1,4,118,125,1757,93,27,46,0.877794337,815,1.0,5,0.0,0.102822581,0,0,11.96774194,11,1.2258,11,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.FieldSelector;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.Lock;
import org.apache.lucene.store.LockObtainFailedException;
import org.apache.lucene.store.AlreadyClosedException;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.Arrays;
import java.util.Collection;


public abstract class IndexReader {

  public static final class FieldOption {
    private String option;
    private FieldOption() { }
    private FieldOption(String option) {
      this.option = option;
    }
    public String toString() {
      return this.option;
    }
    
    public static final FieldOption ALL = new FieldOption (""ALL"");
    
    public static final FieldOption INDEXED = new FieldOption (""INDEXED"");
    
    public static final FieldOption STORES_PAYLOADS = new FieldOption (""STORES_PAYLOADS"");
    
    public static final FieldOption UNINDEXED = new FieldOption (""UNINDEXED"");
    
    public static final FieldOption INDEXED_WITH_TERMVECTOR = new FieldOption (""INDEXED_WITH_TERMVECTOR"");
    
    public static final FieldOption INDEXED_NO_TERMVECTOR = new FieldOption (""INDEXED_NO_TERMVECTOR"");
    
    public static final FieldOption TERMVECTOR = new FieldOption (""TERMVECTOR"");
    
    public static final FieldOption TERMVECTOR_WITH_POSITION = new FieldOption (""TERMVECTOR_WITH_POSITION"");
    
    public static final FieldOption TERMVECTOR_WITH_OFFSET = new FieldOption (""TERMVECTOR_WITH_OFFSET"");
    
    public static final FieldOption TERMVECTOR_WITH_POSITION_OFFSET = new FieldOption (""TERMVECTOR_WITH_POSITION_OFFSET"");
  }

  
  protected IndexReader(Directory directory) {
    this.directory = directory;
  }

  
  IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory) {
    init(directory, segmentInfos, closeDirectory, true);
  }

  void init(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory, boolean directoryOwner) {
    this.directory = directory;
    this.segmentInfos = segmentInfos;
    this.directoryOwner = directoryOwner;
    this.closeDirectory = closeDirectory;
  }

  private Directory directory;
  private boolean directoryOwner;
  private boolean closeDirectory;
  private IndexDeletionPolicy deletionPolicy;
  private boolean closed;

  
  protected final void ensureOpen() throws AlreadyClosedException {
    if (closed) {
      throw new AlreadyClosedException(""this IndexReader is closed"");
    }
  }

  private SegmentInfos segmentInfos;
  private Lock writeLock;
  private boolean stale;
  private boolean hasChanges;

  
  private boolean rollbackHasChanges;
  private SegmentInfos rollbackSegmentInfos;

  
  public static IndexReader open(String path) throws CorruptIndexException, IOException {
    return open(FSDirectory.getDirectory(path), true, null);
  }

  
  public static IndexReader open(File path) throws CorruptIndexException, IOException {
    return open(FSDirectory.getDirectory(path), true, null);
  }

  
  public static IndexReader open(final Directory directory) throws CorruptIndexException, IOException {
    return open(directory, false, null);
  }

  
  public static IndexReader open(final Directory directory, IndexDeletionPolicy deletionPolicy) throws CorruptIndexException, IOException {
    return open(directory, false, deletionPolicy);
  }

  private static IndexReader open(final Directory directory, final boolean closeDirectory, final IndexDeletionPolicy deletionPolicy) throws CorruptIndexException, IOException {

    return (IndexReader) new SegmentInfos.FindSegmentsFile(directory) {

      protected Object doBody(String segmentFileName) throws CorruptIndexException, IOException {

        SegmentInfos infos = new SegmentInfos();
        infos.read(directory, segmentFileName);

        IndexReader reader;

        if (infos.size() == 1) {		  
          reader = SegmentReader.get(infos, infos.info(0), closeDirectory);
        } else {

          
          
          
          

          IndexReader[] readers = new IndexReader[infos.size()];
          for (int i = infos.size()-1; i >= 0; i--) {
            try {
              readers[i] = SegmentReader.get(infos.info(i));
            } catch (IOException e) {
              
              for(i++;i<infos.size();i++) {
                readers[i].close();
              }
              throw e;
            }
          }

          reader = new MultiReader(directory, infos, closeDirectory, readers);
        }
        reader.deletionPolicy = deletionPolicy;
        return reader;
      }
    }.run();
  }

  
  public Directory directory() {
    ensureOpen();
    return directory;
  }

  
  public static long lastModified(String directory) throws CorruptIndexException, IOException {
    return lastModified(new File(directory));
  }

  
  public static long lastModified(File fileDirectory) throws CorruptIndexException, IOException {
    return ((Long) new SegmentInfos.FindSegmentsFile(fileDirectory) {
        public Object doBody(String segmentFileName) {
          return new Long(FSDirectory.fileModified(fileDirectory, segmentFileName));
        }
      }.run()).longValue();
  }

  
  public static long lastModified(final Directory directory2) throws CorruptIndexException, IOException {
    return ((Long) new SegmentInfos.FindSegmentsFile(directory2) {
        public Object doBody(String segmentFileName) throws IOException {
          return new Long(directory2.fileModified(segmentFileName));
        }
      }.run()).longValue();
  }

  
  public static long getCurrentVersion(String directory) throws CorruptIndexException, IOException {
    return getCurrentVersion(new File(directory));
  }

  
  public static long getCurrentVersion(File directory) throws CorruptIndexException, IOException {
    Directory dir = FSDirectory.getDirectory(directory);
    long version = getCurrentVersion(dir);
    dir.close();
    return version;
  }

  
  public static long getCurrentVersion(Directory directory) throws CorruptIndexException, IOException {
    return SegmentInfos.readCurrentVersion(directory);
  }

  
  public long getVersion() {
    ensureOpen();
    return segmentInfos.getVersion();
  }

  
  public boolean isCurrent() throws CorruptIndexException, IOException {
    ensureOpen();
    return SegmentInfos.readCurrentVersion(directory) == segmentInfos.getVersion();
  }

  
  public boolean isOptimized() {
    ensureOpen();
    return segmentInfos.size() == 1 && hasDeletions() == false;
  }

  
  abstract public TermFreqVector[] getTermFreqVectors(int docNumber)
          throws IOException;


  
  abstract public TermFreqVector getTermFreqVector(int docNumber, String field)
          throws IOException;

  
  public static boolean indexExists(String directory) {
    return indexExists(new File(directory));
  }

  

  public static boolean indexExists(File directory) {
    return SegmentInfos.getCurrentSegmentGeneration(directory.list()) != -1;
  }

  
  public static boolean indexExists(Directory directory) throws IOException {
    return SegmentInfos.getCurrentSegmentGeneration(directory) != -1;
  }

  
  public abstract int numDocs();

  
  public abstract int maxDoc();

  
  public Document document(int n) throws CorruptIndexException, IOException {
    ensureOpen();
    return document(n, null);
  }

  
  
  public abstract Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException;
  
  

  
  public abstract boolean isDeleted(int n);

  
  public abstract boolean hasDeletions();

  
  public boolean hasNorms(String field) throws IOException {
    
    
    ensureOpen();
    return norms(field) != null;
  }

  
  public abstract byte[] norms(String field) throws IOException;

  
  public abstract void norms(String field, byte[] bytes, int offset)
    throws IOException;

  
  public final synchronized  void setNorm(int doc, String field, byte value)
          throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    if(directoryOwner)
      acquireWriteLock();
    hasChanges = true;
    doSetNorm(doc, field, value);
  }

  
  protected abstract void doSetNorm(int doc, String field, byte value)
          throws CorruptIndexException, IOException;

  
  public void setNorm(int doc, String field, float value)
          throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    setNorm(doc, field, Similarity.encodeNorm(value));
  }

  
  public abstract TermEnum terms() throws IOException;

  
  public abstract TermEnum terms(Term t) throws IOException;

  
  public abstract int docFreq(Term t) throws IOException;

  
  public TermDocs termDocs(Term term) throws IOException {
    ensureOpen();
    TermDocs termDocs = termDocs();
    termDocs.seek(term);
    return termDocs;
  }

  
  public abstract TermDocs termDocs() throws IOException;

  
  public TermPositions termPositions(Term term) throws IOException {
    ensureOpen();
    TermPositions termPositions = termPositions();
    termPositions.seek(term);
    return termPositions;
  }

  
  public abstract TermPositions termPositions() throws IOException;

  
  private void acquireWriteLock() throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    if (stale)
      throw new StaleReaderException(""IndexReader out of date and no longer valid for delete, undelete, or setNorm operations"");

    if (writeLock == null) {
      Lock writeLock = directory.makeLock(IndexWriter.WRITE_LOCK_NAME);
      if (!writeLock.obtain(IndexWriter.WRITE_LOCK_TIMEOUT)) 
        throw new LockObtainFailedException(""Index locked for write: "" + writeLock);
      this.writeLock = writeLock;

      
      
      if (SegmentInfos.readCurrentVersion(directory) > segmentInfos.getVersion()) {
        stale = true;
        this.writeLock.release();
        this.writeLock = null;
        throw new StaleReaderException(""IndexReader out of date and no longer valid for delete, undelete, or setNorm operations"");
      }
    }
  }


  
  public final synchronized void deleteDocument(int docNum) throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    if(directoryOwner)
      acquireWriteLock();
    hasChanges = true;
    doDelete(docNum);
  }


  
  protected abstract void doDelete(int docNum) throws CorruptIndexException, IOException;


  
  public final int deleteDocuments(Term term) throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    TermDocs docs = termDocs(term);
    if (docs == null) return 0;
    int n = 0;
    try {
      while (docs.next()) {
        deleteDocument(docs.doc());
        n++;
      }
    } finally {
      docs.close();
    }
    return n;
  }

  
  public final synchronized void undeleteAll() throws StaleReaderException, CorruptIndexException, LockObtainFailedException, IOException {
    ensureOpen();
    if(directoryOwner)
      acquireWriteLock();
    hasChanges = true;
    doUndeleteAll();
  }

  
  protected abstract void doUndeleteAll() throws CorruptIndexException, IOException;

  
  void startCommit() {
    if (directoryOwner) {
      rollbackSegmentInfos = (SegmentInfos) segmentInfos.clone();
    }
    rollbackHasChanges = hasChanges;
  }

  
  void rollbackCommit() {
    if (directoryOwner) {
      for(int i=0;i<segmentInfos.size();i++) {
        
        
        
        
        segmentInfos.info(i).reset(rollbackSegmentInfos.info(i));
      }
      rollbackSegmentInfos = null;
    }

    hasChanges = rollbackHasChanges;
  }

  
  protected final synchronized void commit() throws IOException {
    if(hasChanges){
      if(directoryOwner){

        
        
        IndexFileDeleter deleter =  new IndexFileDeleter(directory,
                                                         deletionPolicy == null ? new KeepOnlyLastCommitDeletionPolicy() : deletionPolicy,
                                                         segmentInfos, null);

        
        
        startCommit();

        boolean success = false;
        try {
          doCommit();
          segmentInfos.write(directory);
          success = true;
        } finally {

          if (!success) {

            
            
            
            
            
            rollbackCommit();

            
            
            
            deleter.refresh();
          }
        }

        
        
        deleter.checkpoint(segmentInfos, true);

        if (writeLock != null) {
          writeLock.release();  
          writeLock = null;
        }
      }
      else
        doCommit();
    }
    hasChanges = false;
  }

  
  protected abstract void doCommit() throws IOException;

  
  public final synchronized void close() throws IOException {
    if (!closed) {
      commit();
      doClose();
      if (directoryOwner)
        closed = true;
      if(closeDirectory)
        directory.close();
    }
  }

  
  protected abstract void doClose() throws IOException;

  
  protected void finalize() throws Throwable {
    try {
      if (writeLock != null) {
        writeLock.release();                        
        writeLock = null;
      }
    } finally {
      super.finalize();
    }
  }


  
  public abstract Collection getFieldNames(FieldOption fldOption);

  
  public static boolean isLocked(Directory directory) throws IOException {
    return
      directory.makeLock(IndexWriter.WRITE_LOCK_NAME).isLocked();
  }

  
  public static boolean isLocked(String directory) throws IOException {
    Directory dir = FSDirectory.getDirectory(directory);
    boolean result = isLocked(dir);
    dir.close();
    return result;
  }

  
  public static void unlock(Directory directory) throws IOException {
    directory.makeLock(IndexWriter.WRITE_LOCK_NAME).release();
  }

  
  public static void main(String [] args) {
    String filename = null;
    boolean extract = false;

    for (int i = 0; i < args.length; ++i) {
      if (args[i].equals(""-extract"")) {
        extract = true;
      } else if (filename == null) {
        filename = args[i];
      }
    }

    if (filename == null) {
      System.out.println(""Usage: org.apache.lucene.index.IndexReader [-extract] <cfsfile>"");
      return;
    }

    Directory dir = null;
    CompoundFileReader cfr = null;

    try {
      File file = new File(filename);
      String dirname = file.getAbsoluteFile().getParent();
      filename = file.getName();
      dir = FSDirectory.getDirectory(dirname);
      cfr = new CompoundFileReader(dir, filename);

      String [] files = cfr.list();
      Arrays.sort(files);   

      for (int i = 0; i < files.length; ++i) {
        long len = cfr.fileLength(files[i]);

        if (extract) {
          System.out.println(""extract "" + files[i] + "" with "" + len + "" bytes to local directory..."");
          IndexInput ii = cfr.openInput(files[i]);

          FileOutputStream f = new FileOutputStream(files[i]);

          
          byte[] buffer = new byte[1024];
          int chunk = buffer.length;
          while(len > 0) {
            final int bufLen = (int) Math.min(chunk, len);
            ii.readBytes(buffer, 0, bufLen);
            f.write(buffer, 0, bufLen);
            len -= bufLen;
          }

          f.close();
          ii.close();
        }
        else
          System.out.println(files[i] + "": "" + len + "" bytes"");
      }
    } catch (IOException ioe) {
      ioe.printStackTrace();
    }
    finally {
      try {
        if (dir != null)
          dir.close();
        if (cfr != null)
          cfr.close();
      }
      catch (IOException ioe) {
        ioe.printStackTrace();
      }
    }
  }
}
"
lucene,2.2,org.apache.lucene.search.QueryWrapperFilter,5,2,0,7,17,0,2,6,5,0.0,62,1.0,1,0.2,0.4,1,1,11.2,2,1.0,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.BitSet;

import org.apache.lucene.index.IndexReader;


public class QueryWrapperFilter extends Filter {
  private Query query;

  
  public QueryWrapperFilter(Query query) {
    this.query = query;
  }

  public BitSet bits(IndexReader reader) throws IOException {
    final BitSet bits = new BitSet(reader.maxDoc());

    new IndexSearcher(reader).search(query, new HitCollector() {
      public final void collect(int doc, float score) {
        bits.set(doc);  
      }
    });
    return bits;
  }

  public String toString() {
    return ""QueryWrapperFilter("" + query + "")"";
  }

  public boolean equals(Object o) {
    if (!(o instanceof QueryWrapperFilter))
      return false;
    return this.query.equals(((QueryWrapperFilter)o).query);
  }

  public int hashCode() {
    return query.hashCode() ^ 0x923F64B9;
  }
}
"
lucene,2.2,org.apache.lucene.analysis.StopAnalyzer,7,2,0,6,13,0,1,5,6,0.5,189,0.5,0,0.666666667,0.333333333,0,0,25.71428571,1,0.1429,0,"package org.apache.lucene.analysis;



import java.io.File;
import java.io.IOException;
import java.io.Reader;
import java.util.Set;



public final class StopAnalyzer extends Analyzer {
  private Set stopWords;

  
  public static final String[] ENGLISH_STOP_WORDS = {
    ""a"", ""an"", ""and"", ""are"", ""as"", ""at"", ""be"", ""but"", ""by"",
    ""for"", ""if"", ""in"", ""into"", ""is"", ""it"",
    ""no"", ""not"", ""of"", ""on"", ""or"", ""such"",
    ""that"", ""the"", ""their"", ""then"", ""there"", ""these"",
    ""they"", ""this"", ""to"", ""was"", ""will"", ""with""
  };

  
  public StopAnalyzer() {
    stopWords = StopFilter.makeStopSet(ENGLISH_STOP_WORDS);
  }

  
  public StopAnalyzer(Set stopWords) {
    this.stopWords = stopWords;
  }

  
  public StopAnalyzer(String[] stopWords) {
    this.stopWords = StopFilter.makeStopSet(stopWords);
  }
  
  
  public StopAnalyzer(File stopwordsFile) throws IOException {
    stopWords = WordlistLoader.getWordSet(stopwordsFile);
  }

  
  public StopAnalyzer(Reader stopwords) throws IOException {
    stopWords = WordlistLoader.getWordSet(stopwords);
  }

  
  public TokenStream tokenStream(String fieldName, Reader reader) {
    return new StopFilter(new LowerCaseTokenizer(reader), stopWords);
  }
}

"
lucene,2.2,org.apache.lucene.index.TermVectorsReader,10,1,0,9,37,17,1,8,0,0.555555556,659,1.0,4,0.0,0.277777778,0,0,64.2,4,1.1,11,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.BufferedIndexInput;

import java.io.IOException;


class TermVectorsReader implements Cloneable {
  private FieldInfos fieldInfos;

  private IndexInput tvx;
  private IndexInput tvd;
  private IndexInput tvf;
  private int size;
  
  private int tvdFormat;
  private int tvfFormat;

  TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos)
    throws CorruptIndexException, IOException {
    this(d, segment, fieldInfos, BufferedIndexInput.BUFFER_SIZE);
  }

  TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos, int readBufferSize)
    throws CorruptIndexException, IOException {
    if (d.fileExists(segment + TermVectorsWriter.TVX_EXTENSION)) {
      tvx = d.openInput(segment + TermVectorsWriter.TVX_EXTENSION, readBufferSize);
      checkValidFormat(tvx);
      tvd = d.openInput(segment + TermVectorsWriter.TVD_EXTENSION, readBufferSize);
      tvdFormat = checkValidFormat(tvd);
      tvf = d.openInput(segment + TermVectorsWriter.TVF_EXTENSION, readBufferSize);
      tvfFormat = checkValidFormat(tvf);
      size = (int) tvx.length() / 8;
    }

    this.fieldInfos = fieldInfos;
  }
  
  private int checkValidFormat(IndexInput in) throws CorruptIndexException, IOException
  {
    int format = in.readInt();
    if (format > TermVectorsWriter.FORMAT_VERSION)
    {
      throw new CorruptIndexException(""Incompatible format version: "" + format + "" expected "" 
                                      + TermVectorsWriter.FORMAT_VERSION + "" or less"");
    }
    return format;
  }

  void close() throws IOException {
  	
  	
  	IOException keep = null;
  	if (tvx != null) try { tvx.close(); } catch (IOException e) { if (keep == null) keep = e; }
  	if (tvd != null) try { tvd.close(); } catch (IOException e) { if (keep == null) keep = e; }
  	if (tvf  != null) try {  tvf.close(); } catch (IOException e) { if (keep == null) keep = e; }
  	if (keep != null) throw (IOException) keep.fillInStackTrace();
  }

  
  int size() {
    return size;
  }

   
  TermFreqVector get(int docNum, String field) throws IOException {
    
    int fieldNumber = fieldInfos.fieldNumber(field);
    TermFreqVector result = null;
    if (tvx != null) {
      
      
      
      
      tvx.seek((docNum * 8L) + TermVectorsWriter.FORMAT_SIZE);
      
      long position = tvx.readLong();

      tvd.seek(position);
      int fieldCount = tvd.readVInt();
      
      
      
      
      int number = 0;
      int found = -1;
      for (int i = 0; i < fieldCount; i++) {
        if(tvdFormat == TermVectorsWriter.FORMAT_VERSION)
          number = tvd.readVInt();
        else
          number += tvd.readVInt();
        
        if (number == fieldNumber)
          found = i;
      }

      
      
      if (found != -1) {
        
        position = 0;
        for (int i = 0; i <= found; i++)
          position += tvd.readVLong();

        result = readTermVector(field, position);
      } else {
        
      }
    } else {
      
    }
    return result;
  }

  
  TermFreqVector[] get(int docNum) throws IOException {
    TermFreqVector[] result = null;
    
    if (tvx != null) {
      
      tvx.seek((docNum * 8L) + TermVectorsWriter.FORMAT_SIZE);
      long position = tvx.readLong();

      tvd.seek(position);
      int fieldCount = tvd.readVInt();

      
      if (fieldCount != 0) {
        int number = 0;
        String[] fields = new String[fieldCount];
        
        for (int i = 0; i < fieldCount; i++) {
          if(tvdFormat == TermVectorsWriter.FORMAT_VERSION)
            number = tvd.readVInt();
          else
            number += tvd.readVInt();

          fields[i] = fieldInfos.fieldName(number);
        }

        
        position = 0;
        long[] tvfPointers = new long[fieldCount];
        for (int i = 0; i < fieldCount; i++) {
          position += tvd.readVLong();
          tvfPointers[i] = position;
        }

        result = readTermVectors(fields, tvfPointers);
      }
    } else {
      
    }
    return result;
  }


  private SegmentTermVector[] readTermVectors(String fields[], long tvfPointers[])
          throws IOException {
    SegmentTermVector res[] = new SegmentTermVector[fields.length];
    for (int i = 0; i < fields.length; i++) {
      res[i] = readTermVector(fields[i], tvfPointers[i]);
    }
    return res;
  }

   
  private SegmentTermVector readTermVector(String field, long tvfPointer)
          throws IOException {

    
    
    tvf.seek(tvfPointer);

    int numTerms = tvf.readVInt();
    
    
    if (numTerms == 0) 
      return new SegmentTermVector(field, null, null);
    
    boolean storePositions;
    boolean storeOffsets;
    
    if(tvfFormat == TermVectorsWriter.FORMAT_VERSION){
      byte bits = tvf.readByte();
      storePositions = (bits & TermVectorsWriter.STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      storeOffsets = (bits & TermVectorsWriter.STORE_OFFSET_WITH_TERMVECTOR) != 0;
    }
    else{
      tvf.readVInt();
      storePositions = false;
      storeOffsets = false;
    }

    String terms[] = new String[numTerms];
    int termFreqs[] = new int[numTerms];
    
    
    int positions[][] = null;
    TermVectorOffsetInfo offsets[][] = null;
    if(storePositions)
      positions = new int[numTerms][];
    if(storeOffsets)
      offsets = new TermVectorOffsetInfo[numTerms][];
    
    int start = 0;
    int deltaLength = 0;
    int totalLength = 0;
    char [] buffer = new char[10];    
    char[] previousBuffer = {};
    
    for (int i = 0; i < numTerms; i++) {
      start = tvf.readVInt();
      deltaLength = tvf.readVInt();
      totalLength = start + deltaLength;
      if (buffer.length < totalLength) {  
        buffer = null;    
        buffer = new char[totalLength];
        
        if (start > 0)  
          System.arraycopy(previousBuffer, 0, buffer, 0, start);
      }
      
      tvf.readChars(buffer, start, deltaLength);
      terms[i] = new String(buffer, 0, totalLength);
      previousBuffer = buffer;
      int freq = tvf.readVInt();
      termFreqs[i] = freq;
      
      if (storePositions) { 
        int [] pos = new int[freq];
        positions[i] = pos;
        int prevPosition = 0;
        for (int j = 0; j < freq; j++)
        {
          pos[j] = prevPosition + tvf.readVInt();
          prevPosition = pos[j];
        }
      }
      
      if (storeOffsets) {
        TermVectorOffsetInfo[] offs = new TermVectorOffsetInfo[freq];
        offsets[i] = offs;
        int prevOffset = 0;
        for (int j = 0; j < freq; j++) {
          int startOffset = prevOffset + tvf.readVInt();
          int endOffset = startOffset + tvf.readVInt();
          offs[j] = new TermVectorOffsetInfo(startOffset, endOffset);
          prevOffset = endOffset;
        }
      }
    }
    
    SegmentTermVector tv;
    if (storePositions || storeOffsets){
      tv = new SegmentTermPositionVector(field, terms, termFreqs, positions, offsets);
    }
    else {
      tv = new SegmentTermVector(field, terms, termFreqs);
    }
    return tv;
  }

  protected Object clone() {
    
    if (tvx == null || tvd == null || tvf == null)
      return null;
    
    TermVectorsReader clone = null;
    try {
      clone = (TermVectorsReader) super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.tvx = (IndexInput) tvx.clone();
    clone.tvd = (IndexInput) tvd.clone();
    clone.tvf = (IndexInput) tvf.clone();
    
    return clone;
  }
}
"
lucene,2.2,org.apache.lucene.analysis.standard.StandardTokenizerTokenManager,22,1,0,5,38,153,1,4,7,0.850340136,3785,0.114285714,1,0.0,0.380952381,0,0,169.4545455,236,14.0455,0,"
package org.apache.lucene.analysis.standard;
import java.io.*;

public class StandardTokenizerTokenManager implements StandardTokenizerConstants
{
  public  java.io.PrintStream debugStream = System.out;
  public  void setDebugStream(java.io.PrintStream ds) { debugStream = ds; }
private final int jjMoveStringLiteralDfa0_0()
{
   return jjMoveNfa_0(0, 0);
}
private final void jjCheckNAdd(int state)
{
   if (jjrounds[state] != jjround)
   {
      jjstateSet[jjnewStateCnt++] = state;
      jjrounds[state] = jjround;
   }
}
private final void jjAddStates(int start, int end)
{
   do {
      jjstateSet[jjnewStateCnt++] = jjnextStates[start];
   } while (start++ != end);
}
private final void jjCheckNAddTwoStates(int state1, int state2)
{
   jjCheckNAdd(state1);
   jjCheckNAdd(state2);
}
private final void jjCheckNAddStates(int start, int end)
{
   do {
      jjCheckNAdd(jjnextStates[start]);
   } while (start++ != end);
}
private final void jjCheckNAddStates(int start)
{
   jjCheckNAdd(jjnextStates[start]);
   jjCheckNAdd(jjnextStates[start + 1]);
}
static final long[] jjbitVec0 = {
   0xfff0000000000000L, 0xffffffffffffdfffL, 0xffffffffL, 0x600000000000000L
};
static final long[] jjbitVec2 = {
   0x0L, 0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffffffL
};
static final long[] jjbitVec3 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffL, 0xffff000000000000L
};
static final long[] jjbitVec4 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0x0L, 0x0L
};
static final long[] jjbitVec5 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffffffL, 0x0L
};
static final long[] jjbitVec6 = {
   0x0L, 0xffffffe000000000L, 0xffffffffL, 0x0L
};
static final long[] jjbitVec7 = {
   0x20000L, 0x0L, 0xfffff00000000000L, 0x7fffffL
};
static final long[] jjbitVec8 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffL, 0x0L
};
static final long[] jjbitVec9 = {
   0xfffffffeL, 0x0L, 0x0L, 0x0L
};
static final long[] jjbitVec10 = {
   0x0L, 0x0L, 0x0L, 0xff7fffffff7fffffL
};
static final long[] jjbitVec11 = {
   0x0L, 0x0L, 0xffffffff00000000L, 0x1fffffffL
};
static final long[] jjbitVec12 = {
   0x1600L, 0x0L, 0x0L, 0x0L
};
static final long[] jjbitVec13 = {
   0x0L, 0xffc000000000L, 0x0L, 0xffc000000000L
};
static final long[] jjbitVec14 = {
   0x0L, 0x3ff00000000L, 0x0L, 0x3ff000000000000L
};
static final long[] jjbitVec15 = {
   0x0L, 0xffc000000000L, 0x0L, 0xff8000000000L
};
static final long[] jjbitVec16 = {
   0x0L, 0xffc000000000L, 0x0L, 0x0L
};
static final long[] jjbitVec17 = {
   0x0L, 0x3ff0000L, 0x0L, 0x3ff0000L
};
static final long[] jjbitVec18 = {
   0x0L, 0x3ffL, 0x0L, 0x0L
};
static final long[] jjbitVec19 = {
   0xfffffffeL, 0x0L, 0xfffff00000000000L, 0x7fffffL
};
private final int jjMoveNfa_0(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 75;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x3ff000000000000L & l) != 0L)
                  {
                     if (kind > 1)
                        kind = 1;
                     jjCheckNAddStates(0, 11);
                  }
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(12, 17);
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 2:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 3:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(3, 4);
                  break;
               case 4:
               case 5:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(5, 6);
                  break;
               case 6:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(7);
                  break;
               case 7:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(7);
                  break;
               case 8:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(8, 9);
                  break;
               case 9:
               case 10:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 11:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(12);
                  break;
               case 12:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(12, 13);
                  break;
               case 13:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 14:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 15:
               case 16:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 17:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(17, 18);
                  break;
               case 18:
               case 19:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(19, 20);
                  break;
               case 20:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(21);
                  break;
               case 21:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(21, 22);
                  break;
               case 22:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 23:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 24:
               case 25:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(25, 26);
                  break;
               case 26:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(27);
                  break;
               case 27:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(22, 27);
                  break;
               case 28:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(12, 17);
                  break;
               case 29:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAddStates(0, 11);
                  break;
               case 30:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAdd(30);
                  break;
               case 31:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(24, 26);
                  break;
               case 32:
                  if ((0x600000000000L & l) != 0L)
                     jjCheckNAdd(33);
                  break;
               case 33:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(27, 29);
                  break;
               case 35:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(35, 36);
                  break;
               case 36:
                  if ((0x600000000000L & l) != 0L)
                     jjCheckNAdd(37);
                  break;
               case 37:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 5)
                     kind = 5;
                  jjCheckNAddTwoStates(36, 37);
                  break;
               case 38:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(38, 39);
                  break;
               case 39:
                  if (curChar == 46)
                     jjCheckNAdd(40);
                  break;
               case 40:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 6)
                     kind = 6;
                  jjCheckNAddTwoStates(39, 40);
                  break;
               case 41:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(41, 42);
                  break;
               case 42:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 43:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 44:
               case 45:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(45);
                  break;
               case 46:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(46, 47);
                  break;
               case 47:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 48:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 49:
               case 50:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(50, 51);
                  break;
               case 51:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(52);
                  break;
               case 52:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(47, 52);
                  break;
               case 53:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(53, 54);
                  break;
               case 54:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 55:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 56:
               case 57:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 58:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(59);
                  break;
               case 59:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(59, 60);
                  break;
               case 60:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 61:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 62:
               case 63:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 66:
                  if (curChar == 39)
                     jjstateSet[jjnewStateCnt++] = 67;
                  break;
               case 69:
                  if (curChar == 46)
                     jjCheckNAdd(70);
                  break;
               case 71:
                  if (curChar != 46)
                     break;
                  if (kind > 3)
                     kind = 3;
                  jjCheckNAdd(70);
                  break;
               case 73:
                  if (curChar == 38)
                     jjstateSet[jjnewStateCnt++] = 74;
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(30, 35);
                  if ((0x7fffffe07fffffeL & l) != 0L)
                  {
                     if (kind > 1)
                        kind = 1;
                     jjCheckNAddStates(0, 11);
                  }
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 2:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 3:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(3, 4);
                  break;
               case 5:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(36, 37);
                  break;
               case 6:
                  if (curChar == 95)
                     jjCheckNAdd(7);
                  break;
               case 7:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(7);
                  break;
               case 8:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(8, 9);
                  break;
               case 10:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 11:
                  if (curChar == 95)
                     jjCheckNAdd(12);
                  break;
               case 12:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(12, 13);
                  break;
               case 13:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 14:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 16:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 17:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(17, 18);
                  break;
               case 19:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(38, 39);
                  break;
               case 20:
                  if (curChar == 95)
                     jjCheckNAdd(21);
                  break;
               case 21:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(21, 22);
                  break;
               case 22:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 23:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 25:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(40, 41);
                  break;
               case 26:
                  if (curChar == 95)
                     jjCheckNAdd(27);
                  break;
               case 27:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(22, 27);
                  break;
               case 29:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAddStates(0, 11);
                  break;
               case 30:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAdd(30);
                  break;
               case 31:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(24, 26);
                  break;
               case 32:
                  if (curChar == 95)
                     jjCheckNAdd(33);
                  break;
               case 33:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(27, 29);
                  break;
               case 34:
                  if (curChar == 64)
                     jjCheckNAdd(35);
                  break;
               case 35:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(35, 36);
                  break;
               case 37:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 5)
                     kind = 5;
                  jjCheckNAddTwoStates(36, 37);
                  break;
               case 38:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(38, 39);
                  break;
               case 40:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 6)
                     kind = 6;
                  jjCheckNAddTwoStates(39, 40);
                  break;
               case 41:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(41, 42);
                  break;
               case 42:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 43:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 45:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjstateSet[jjnewStateCnt++] = 45;
                  break;
               case 46:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(46, 47);
                  break;
               case 47:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 48:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 50:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(42, 43);
                  break;
               case 51:
                  if (curChar == 95)
                     jjCheckNAdd(52);
                  break;
               case 52:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(47, 52);
                  break;
               case 53:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(53, 54);
                  break;
               case 54:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 55:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 57:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 58:
                  if (curChar == 95)
                     jjCheckNAdd(59);
                  break;
               case 59:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(59, 60);
                  break;
               case 60:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 61:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 63:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 64:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(30, 35);
                  break;
               case 65:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(65, 66);
                  break;
               case 67:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 2)
                     kind = 2;
                  jjCheckNAddTwoStates(66, 67);
                  break;
               case 68:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(68, 69);
                  break;
               case 70:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(44, 45);
                  break;
               case 72:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(72, 73);
                  break;
               case 73:
                  if (curChar == 64)
                     jjCheckNAdd(74);
                  break;
               case 74:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 4)
                     kind = 4;
                  jjCheckNAdd(74);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 12)
                        kind = 12;
                  }
                  if (jjCanMove_1(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 13)
                        kind = 13;
                  }
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(18, 23);
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(12, 17);
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 1)
                        kind = 1;
                     jjCheckNAddStates(0, 11);
                  }
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(30, 35);
                  break;
               case 1:
                  if (jjCanMove_1(hiByte, i1, i2, l1, l2) && kind > 13)
                     kind = 13;
                  break;
               case 2:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(18, 23);
                  break;
               case 3:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(3, 4);
                  break;
               case 4:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(5, 6);
                  break;
               case 5:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(5, 6);
                  break;
               case 7:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjstateSet[jjnewStateCnt++] = 7;
                  break;
               case 8:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(8, 9);
                  break;
               case 9:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 10:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 12:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjAddStates(46, 47);
                  break;
               case 14:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(48, 49);
                  break;
               case 15:
                  if (!jjCanMove_3(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 16:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 17:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(17, 18);
                  break;
               case 18:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(19, 20);
                  break;
               case 19:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(19, 20);
                  break;
               case 21:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(21, 22);
                  break;
               case 23:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(50, 51);
                  break;
               case 24:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(25, 26);
                  break;
               case 25:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(25, 26);
                  break;
               case 27:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(22, 27);
                  break;
               case 28:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(12, 17);
                  break;
               case 29:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAddStates(0, 11);
                  break;
               case 30:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAdd(30);
                  break;
               case 31:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(24, 26);
                  break;
               case 33:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(27, 29);
                  break;
               case 35:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(35, 36);
                  break;
               case 37:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 5)
                     kind = 5;
                  jjCheckNAddTwoStates(36, 37);
                  break;
               case 38:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(38, 39);
                  break;
               case 40:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 6)
                     kind = 6;
                  jjCheckNAddTwoStates(39, 40);
                  break;
               case 41:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(41, 42);
                  break;
               case 43:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(52, 53);
                  break;
               case 44:
                  if (!jjCanMove_3(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(45);
                  break;
               case 45:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(45);
                  break;
               case 46:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(46, 47);
                  break;
               case 48:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(54, 55);
                  break;
               case 49:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(50, 51);
                  break;
               case 50:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(50, 51);
                  break;
               case 52:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(47, 52);
                  break;
               case 53:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(53, 54);
                  break;
               case 55:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(56, 57);
                  break;
               case 56:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 57:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 59:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjAddStates(58, 59);
                  break;
               case 61:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(60, 61);
                  break;
               case 62:
                  if (!jjCanMove_3(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 63:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 64:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(30, 35);
                  break;
               case 65:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(65, 66);
                  break;
               case 67:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 2)
                     kind = 2;
                  jjCheckNAddTwoStates(66, 67);
                  break;
               case 68:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(68, 69);
                  break;
               case 70:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(44, 45);
                  break;
               case 72:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(72, 73);
                  break;
               case 74:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 4)
                     kind = 4;
                  jjstateSet[jjnewStateCnt++] = 74;
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 75 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
static final int[] jjnextStates = {
   30, 31, 32, 34, 38, 39, 41, 42, 46, 47, 53, 54, 5, 6, 10, 11, 
   19, 20, 3, 4, 8, 9, 17, 18, 31, 32, 34, 32, 33, 34, 65, 66, 
   68, 69, 72, 73, 5, 6, 19, 20, 25, 26, 50, 51, 70, 71, 12, 13, 
   14, 15, 23, 24, 43, 44, 48, 49, 55, 56, 59, 60, 61, 62, 
};
private static final boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 48:
         return ((jjbitVec2[i2] & l2) != 0L);
      case 49:
         return ((jjbitVec3[i2] & l2) != 0L);
      case 51:
         return ((jjbitVec4[i2] & l2) != 0L);
      case 77:
         return ((jjbitVec5[i2] & l2) != 0L);
      case 255:
         return ((jjbitVec6[i2] & l2) != 0L);
      default : 
         if ((jjbitVec0[i1] & l1) != 0L)
            return true;
         return false;
   }
}
private static final boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 215:
         return ((jjbitVec8[i2] & l2) != 0L);
      default : 
         if ((jjbitVec7[i1] & l1) != 0L)
            return true;
         return false;
   }
}
private static final boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 0:
         return ((jjbitVec10[i2] & l2) != 0L);
      case 255:
         return ((jjbitVec11[i2] & l2) != 0L);
      default : 
         if ((jjbitVec9[i1] & l1) != 0L)
            return true;
         return false;
   }
}
private static final boolean jjCanMove_3(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 6:
         return ((jjbitVec14[i2] & l2) != 0L);
      case 11:
         return ((jjbitVec15[i2] & l2) != 0L);
      case 13:
         return ((jjbitVec16[i2] & l2) != 0L);
      case 14:
         return ((jjbitVec17[i2] & l2) != 0L);
      case 16:
         return ((jjbitVec18[i2] & l2) != 0L);
      default : 
         if ((jjbitVec12[i1] & l1) != 0L)
            if ((jjbitVec13[i2] & l2) == 0L)
               return false;
            else
            return true;
         return false;
   }
}
private static final boolean jjCanMove_4(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 0:
         return ((jjbitVec10[i2] & l2) != 0L);
      case 215:
         return ((jjbitVec8[i2] & l2) != 0L);
      case 255:
         return ((jjbitVec11[i2] & l2) != 0L);
      default : 
         if ((jjbitVec19[i1] & l1) != 0L)
            return true;
         return false;
   }
}
public static final String[] jjstrLiteralImages = {
"""", null, null, null, null, null, null, null, null, null, null, null, null, 
null, null, null, };
public static final String[] lexStateNames = {
   ""DEFAULT"", 
};
static final long[] jjtoToken = {
   0x30ffL, 
};
static final long[] jjtoSkip = {
   0x8000L, 
};
protected CharStream input_stream;
private final int[] jjrounds = new int[75];
private final int[] jjstateSet = new int[150];
protected char curChar;
public StandardTokenizerTokenManager(CharStream stream)
{
   input_stream = stream;
}
public StandardTokenizerTokenManager(CharStream stream, int lexState)
{
   this(stream);
   SwitchTo(lexState);
}
public void ReInit(CharStream stream)
{
   jjmatchedPos = jjnewStateCnt = 0;
   curLexState = defaultLexState;
   input_stream = stream;
   ReInitRounds();
}
private final void ReInitRounds()
{
   int i;
   jjround = 0x80000001;
   for (i = 75; i-- > 0;)
      jjrounds[i] = 0x80000000;
}
public void ReInit(CharStream stream, int lexState)
{
   ReInit(stream);
   SwitchTo(lexState);
}
public void SwitchTo(int lexState)
{
   if (lexState >= 1 || lexState < 0)
      throw new TokenMgrError(""Error: Ignoring invalid lexical state : "" + lexState + "". State unchanged."", TokenMgrError.INVALID_LEXICAL_STATE);
   else
      curLexState = lexState;
}

protected Token jjFillToken()
{
   Token t = Token.newToken(jjmatchedKind);
   t.kind = jjmatchedKind;
   String im = jjstrLiteralImages[jjmatchedKind];
   t.image = (im == null) ? input_stream.GetImage() : im;
   t.beginLine = input_stream.getBeginLine();
   t.beginColumn = input_stream.getBeginColumn();
   t.endLine = input_stream.getEndLine();
   t.endColumn = input_stream.getEndColumn();
   return t;
}

int curLexState = 0;
int defaultLexState = 0;
int jjnewStateCnt;
int jjround;
int jjmatchedPos;
int jjmatchedKind;

public Token getNextToken() 
{
  int kind;
  Token specialToken = null;
  Token matchedToken;
  int curPos = 0;

  EOFLoop :
  for (;;)
  {   
   try   
   {     
      curChar = input_stream.BeginToken();
   }     
   catch(java.io.IOException e)
   {        
      jjmatchedKind = 0;
      matchedToken = jjFillToken();
      return matchedToken;
   }

   jjmatchedKind = 0x7fffffff;
   jjmatchedPos = 0;
   curPos = jjMoveStringLiteralDfa0_0();
   if (jjmatchedPos == 0 && jjmatchedKind > 15)
   {
      jjmatchedKind = 15;
   }
   if (jjmatchedKind != 0x7fffffff)
   {
      if (jjmatchedPos + 1 < curPos)
         input_stream.backup(curPos - jjmatchedPos - 1);
      if ((jjtoToken[jjmatchedKind >> 6] & (1L << (jjmatchedKind & 077))) != 0L)
      {
         matchedToken = jjFillToken();
         return matchedToken;
      }
      else
      {
         continue EOFLoop;
      }
   }
   int error_line = input_stream.getEndLine();
   int error_column = input_stream.getEndColumn();
   String error_after = null;
   boolean EOFSeen = false;
   try { input_stream.readChar(); input_stream.backup(1); }
   catch (java.io.IOException e1) {
      EOFSeen = true;
      error_after = curPos <= 1 ? """" : input_stream.GetImage();
      if (curChar == '\n' || curChar == '\r') {
         error_line++;
         error_column = 0;
      }
      else
         error_column++;
   }
   if (!EOFSeen) {
      input_stream.backup(1);
      error_after = curPos <= 1 ? """" : input_stream.GetImage();
   }
   throw new TokenMgrError(EOFSeen, curLexState, error_line, error_column, error_after, curChar, TokenMgrError.LEXICAL_ERROR);
  }
}

}
"
lucene,2.2,org.apache.lucene.store.NativeFSLockFactory,7,2,0,4,27,9,1,3,4,0.333333333,186,1.0,0,0.5,0.571428571,0,0,25.42857143,2,0.7143,2,"package org.apache.lucene.store;



import java.nio.channels.FileChannel;
import java.nio.channels.FileLock;
import java.io.File;
import java.io.RandomAccessFile;
import java.io.IOException;
import java.util.HashSet;
import java.util.Random;



public class NativeFSLockFactory extends LockFactory {

  

  private File lockDir;

  
  
  
  
  
  
  private void acquireTestLock() throws IOException {
    String randomLockName = ""lucene-"" + Long.toString(new Random().nextInt(), Character.MAX_RADIX) + ""-test.lock"";
    
    Lock l = makeLock(randomLockName);
    try {
      l.obtain();
    } catch (IOException e) {
      IOException e2 = new IOException(""Failed to acquire random test lock; please verify filesystem for lock directory '"" + lockDir + ""' supports locking"");
      e2.initCause(e);
      throw e2;
    }

    l.release();
  }

  
  NativeFSLockFactory() throws IOException {
    this((File) null);
  }

  
  public NativeFSLockFactory(String lockDirName) throws IOException {
    this(new File(lockDirName));
  }

  
  public NativeFSLockFactory(File lockDir) throws IOException {
    setLockDir(lockDir);
  }

  
  void setLockDir(File lockDir) throws IOException {
    this.lockDir = lockDir;
    if (lockDir != null) {
      
      if (!lockDir.exists()) {
        if (!lockDir.mkdirs())
          throw new IOException(""Cannot create directory: "" +
                                lockDir.getAbsolutePath());
      } else if (!lockDir.isDirectory()) {
        throw new IOException(""Found regular file where directory expected: "" + 
                              lockDir.getAbsolutePath());
      }

      acquireTestLock();
    }
  }

  public synchronized Lock makeLock(String lockName) {
    if (lockPrefix != null)
      lockName = lockPrefix + ""-n-"" + lockName;
    return new NativeFSLock(lockDir, lockName);
  }

  public void clearLock(String lockName) throws IOException {
    
    
    
    
    if (lockDir.exists()) {
      if (lockPrefix != null) {
        lockName = lockPrefix + ""-n-"" + lockName;
      }
      File lockFile = new File(lockDir, lockName);
      if (lockFile.exists() && !lockFile.delete()) {
        throw new IOException(""Cannot delete "" + lockFile);
      }
    }
  }
};

class NativeFSLock extends Lock {

  private RandomAccessFile f;
  private FileChannel channel;
  private FileLock lock;
  private File path;
  private File lockDir;

  
  private static HashSet LOCK_HELD = new HashSet();

  public NativeFSLock(File lockDir, String lockFileName) {
    this.lockDir = lockDir;
    path = new File(lockDir, lockFileName);
  }

  public synchronized boolean obtain() throws IOException {

    if (isLocked()) {
      
      return false;
    }

    
    if (!lockDir.exists()) {
      if (!lockDir.mkdirs())
        throw new IOException(""Cannot create directory: "" +
                              lockDir.getAbsolutePath());
    } else if (!lockDir.isDirectory()) {
      throw new IOException(""Found regular file where directory expected: "" + 
                            lockDir.getAbsolutePath());
    }

    String canonicalPath = path.getCanonicalPath();

    boolean markedHeld = false;

    try {

      
      

      synchronized(LOCK_HELD) {
        if (LOCK_HELD.contains(canonicalPath)) {
          
          return false;
        } else {
          
          
          
          
          LOCK_HELD.add(canonicalPath);
          markedHeld = true;
        }
      }

      try {
        f = new RandomAccessFile(path, ""rw"");
      } catch (IOException e) {
        
        
        
        
        failureReason = e;
        f = null;
      }

      if (f != null) {
        try {
          channel = f.getChannel();
          try {
            lock = channel.tryLock();
          } catch (IOException e) {
            
            
            
            
            
            
            
            
            
            failureReason = e;
          } finally {
            if (lock == null) {
              try {
                channel.close();
              } finally {
                channel = null;
              }
            }
          }
        } finally {
          if (channel == null) {
            try {
              f.close();
            } finally {
              f = null;
            }
          }
        }
      }

    } finally {
      if (markedHeld && !isLocked()) {
        synchronized(LOCK_HELD) {
          if (LOCK_HELD.contains(canonicalPath)) {
            LOCK_HELD.remove(canonicalPath);
          }
        }
      }
    }
    return isLocked();
  }

  public synchronized void release() {
    try {
      if (isLocked()) {
        try {
          lock.release();
        } finally {
          lock = null;
          try {
            channel.close();
          } finally {
            channel = null;
            try {
              f.close();
            } finally {
              f = null;
              synchronized(LOCK_HELD) {
                LOCK_HELD.remove(path.getCanonicalPath());
              }
            }
          }
        }
        path.delete();
      }
    } catch (IOException e) {
      
      
      throw new RuntimeException(e);
    }
  }

  public boolean isLocked() {
    return lock != null;
  }

  public String toString() {
    return ""NativeFSLock@"" + path;
  }

  public void finalize() throws Throwable {
    try {
      if (isLocked()) {
        release();
      }
    } finally {
      super.finalize();
    }
  }
}
"
lucene,2.2,org.apache.lucene.analysis.ISOLatin1AccentFilter,3,3,0,3,13,3,0,3,3,2.0,170,0.0,0,0.666666667,0.444444444,0,0,55.66666667,3,1.3333,3,"package org.apache.lucene.analysis;




public class ISOLatin1AccentFilter extends TokenFilter {
	public ISOLatin1AccentFilter(TokenStream input) {
		super(input);
	}

	public final Token next() throws java.io.IOException {
		final Token t = input.next();
    if (t != null)
      t.setTermText(removeAccents(t.termText()));
    return t;
	}

	
	public final static String removeAccents(String input) {
		final StringBuffer output = new StringBuffer();
		for (int i = 0; i < input.length(); i++) {
			switch (input.charAt(i)) {
				case '\u00C0' : 
				case '\u00C1' : 
				case '\u00C2' : 
				case '\u00C3' : 
				case '\u00C4' : 
				case '\u00C5' : 
					output.append(""A"");
					break;
				case '\u00C6' : 
					output.append(""AE"");
					break;
				case '\u00C7' : 
					output.append(""C"");
					break;
				case '\u00C8' : 
				case '\u00C9' : 
				case '\u00CA' : 
				case '\u00CB' : 
					output.append(""E"");
					break;
				case '\u00CC' : 
				case '\u00CD' : 
				case '\u00CE' : 
				case '\u00CF' : 
					output.append(""I"");
					break;
				case '\u00D0' : 
					output.append(""D"");
					break;
				case '\u00D1' : 
					output.append(""N"");
					break;
				case '\u00D2' : 
				case '\u00D3' : 
				case '\u00D4' : 
				case '\u00D5' : 
				case '\u00D6' : 
				case '\u00D8' : 
					output.append(""O"");
					break;
				case '\u0152' : 
					output.append(""OE"");
					break;
				case '\u00DE' : 
					output.append(""TH"");
					break;
				case '\u00D9' : 
				case '\u00DA' : 
				case '\u00DB' : 
				case '\u00DC' : 
					output.append(""U"");
					break;
				case '\u00DD' : 
				case '\u0178' : 
					output.append(""Y"");
					break;
				case '\u00E0' : 
				case '\u00E1' : 
				case '\u00E2' : 
				case '\u00E3' : 
				case '\u00E4' : 
				case '\u00E5' : 
					output.append(""a"");
					break;
				case '\u00E6' : 
					output.append(""ae"");
					break;
				case '\u00E7' : 
					output.append(""c"");
					break;
				case '\u00E8' : 
				case '\u00E9' : 
				case '\u00EA' : 
				case '\u00EB' : 
					output.append(""e"");
					break;
				case '\u00EC' : 
				case '\u00ED' : 
				case '\u00EE' : 
				case '\u00EF' : 
					output.append(""i"");
					break;
				case '\u00F0' : 
					output.append(""d"");
					break;
				case '\u00F1' : 
					output.append(""n"");
					break;
				case '\u00F2' : 
				case '\u00F3' : 
				case '\u00F4' : 
				case '\u00F5' : 
				case '\u00F6' : 
				case '\u00F8' : 
					output.append(""o"");
					break;
				case '\u0153' : 
					output.append(""oe"");
					break;
				case '\u00DF' : 
					output.append(""ss"");
					break;
				case '\u00FE' : 
					output.append(""th"");
					break;
				case '\u00F9' : 
				case '\u00FA' : 
				case '\u00FB' : 
				case '\u00FC' : 
					output.append(""u"");
					break;
				case '\u00FD' : 
				case '\u00FF' : 
					output.append(""y"");
					break;
				default :
					output.append(input.charAt(i));
					break;
			}
		}
		return output.toString();
	}
}"
lucene,2.2,org.apache.lucene.analysis.standard.Token,3,1,0,3,4,3,3,0,3,1.4375,23,0.0,2,0.0,0.5,0,0,4.0,2,1.0,0,"
package org.apache.lucene.analysis.standard;



public class Token {

  
  public int kind;

  
  public int beginLine, beginColumn, endLine, endColumn;

  
  public String image;

  
  public Token next;

  
  public Token specialToken;

  
  public String toString()
  {
     return image;
  }

  
  public static final Token newToken(int ofKind)
  {
     switch(ofKind)
     {
       default : return new Token();
     }
  }

}
"
lucene,2.2,org.apache.lucene.search.RemoteCachingWrapperFilter,2,2,0,3,6,0,0,3,2,0.0,18,1.0,1,0.5,0.666666667,0,0,7.5,1,0.5,2,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.BitSet;

import org.apache.lucene.index.IndexReader;


public class RemoteCachingWrapperFilter extends Filter {
  protected Filter filter;

  public RemoteCachingWrapperFilter(Filter filter) {
    this.filter = filter;
  }

  
  public BitSet bits(IndexReader reader) throws IOException {
    Filter cachedFilter = FilterManager.getInstance().getFilter(filter);
    return cachedFilter.bits(reader);
  }
}
"
lucene,2.2,org.apache.lucene.search.RangeQuery,9,2,0,9,32,0,1,8,9,0.291666667,340,1.0,2,0.6,0.259259259,2,3,36.44444444,11,3.0,2,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class RangeQuery extends Query
{
    private Term lowerTerm;
    private Term upperTerm;
    private boolean inclusive;

    
    public RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive)
    {
        if (lowerTerm == null && upperTerm == null)
        {
            throw new IllegalArgumentException(""At least one term must be non-null"");
        }
        if (lowerTerm != null && upperTerm != null && lowerTerm.field() != upperTerm.field())
        {
            throw new IllegalArgumentException(""Both terms must be for the same field"");
        }

        
        if (lowerTerm != null) {
            this.lowerTerm = lowerTerm;
        }
        else {
            this.lowerTerm = new Term(upperTerm.field(), """");
        }

        this.upperTerm = upperTerm;
        this.inclusive = inclusive;
    }

    public Query rewrite(IndexReader reader) throws IOException {

        BooleanQuery query = new BooleanQuery(true);
        TermEnum enumerator = reader.terms(lowerTerm);

        try {

            boolean checkLower = false;
            if (!inclusive) 
                checkLower = true;

            String testField = getField();

            do {
                Term term = enumerator.term();
                if (term != null && term.field() == testField) { 
                    if (!checkLower || term.text().compareTo(lowerTerm.text()) > 0) {
                        checkLower = false;
                        if (upperTerm != null) {
                            int compare = upperTerm.text().compareTo(term.text());
                            
                            if ((compare < 0) || (!inclusive && compare == 0))
                                break;
                        }
                        TermQuery tq = new TermQuery(term); 
                        tq.setBoost(getBoost()); 
                        query.add(tq, BooleanClause.Occur.SHOULD); 
                    }
                }
                else {
                    break;
                }
            }
            while (enumerator.next());
        }
        finally {
            enumerator.close();
        }
        return query;
    }

    
    public String getField() {
      return (lowerTerm != null ? lowerTerm.field() : upperTerm.field());
    }

    
    public Term getLowerTerm() { return lowerTerm; }

    
    public Term getUpperTerm() { return upperTerm; }

    
    public boolean isInclusive() { return inclusive; }


    
    public String toString(String field)
    {
        StringBuffer buffer = new StringBuffer();
        if (!getField().equals(field))
        {
            buffer.append(getField());
            buffer.append("":"");
        }
        buffer.append(inclusive ? ""["" : ""{"");
        buffer.append(lowerTerm != null ? lowerTerm.text() : ""null"");
        buffer.append("" TO "");
        buffer.append(upperTerm != null ? upperTerm.text() : ""null"");
        buffer.append(inclusive ? ""]"" : ""}"");
        buffer.append(ToStringUtils.boost(getBoost()));
        return buffer.toString();
    }

    
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof RangeQuery)) return false;

        final RangeQuery other = (RangeQuery) o;
        if (this.getBoost() != other.getBoost()) return false;
        if (this.inclusive != other.inclusive) return false;
        
        if (this.lowerTerm != null ? !this.lowerTerm.equals(other.lowerTerm) : other.lowerTerm != null) return false;
        if (this.upperTerm != null ? !this.upperTerm.equals(other.upperTerm) : other.upperTerm != null) return false;
        return true;
    }

    
    public int hashCode() {
      int h = Float.floatToIntBits(getBoost());
      h ^= lowerTerm != null ? lowerTerm.hashCode() : 0;
      
      
      h ^= (h << 25) | (h >>> 8);
      h ^= upperTerm != null ? upperTerm.hashCode() : 0;
      h ^= this.inclusive ? 0x2742E74A : 0;
      return h;
    }
}
"
lucene,2.2,org.apache.lucene.search.PrefixQuery,6,2,0,9,28,0,1,8,6,0.0,147,1.0,1,0.705882353,0.333333333,2,3,23.33333333,4,1.5,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class PrefixQuery extends Query {
  private Term prefix;

  
  public PrefixQuery(Term prefix) {
    this.prefix = prefix;
  }

  
  public Term getPrefix() { return prefix; }

  public Query rewrite(IndexReader reader) throws IOException {
    BooleanQuery query = new BooleanQuery(true);
    TermEnum enumerator = reader.terms(prefix);
    try {
      String prefixText = prefix.text();
      String prefixField = prefix.field();
      do {
        Term term = enumerator.term();
        if (term != null &&
            term.text().startsWith(prefixText) &&
            term.field() == prefixField) 
        {
          TermQuery tq = new TermQuery(term);	  
          tq.setBoost(getBoost());                
          query.add(tq, BooleanClause.Occur.SHOULD);		  
          
        } else {
          break;
        }
      } while (enumerator.next());
    } finally {
      enumerator.close();
    }
    return query;
  }

  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    if (!prefix.field().equals(field)) {
      buffer.append(prefix.field());
      buffer.append("":"");
    }
    buffer.append(prefix.text());
    buffer.append('*');
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof PrefixQuery))
      return false;
    PrefixQuery other = (PrefixQuery)o;
    return (this.getBoost() == other.getBoost())
      && this.prefix.equals(other.prefix);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ prefix.hashCode() ^ 0x6634D93C;
  }
}
"
lucene,2.2,org.apache.lucene.analysis.standard.StandardTokenizer,15,3,0,9,29,15,1,8,11,0.6,524,0.7,3,0.266666667,0.285714286,1,1,33.26666667,10,1.7333,6,"
package org.apache.lucene.analysis.standard;

import java.io.*;


public class StandardTokenizer extends org.apache.lucene.analysis.Tokenizer implements StandardTokenizerConstants {

  
  public StandardTokenizer(Reader reader) {
    this(new FastCharStream(reader));
    this.input = reader;
  }


  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {
  Token token = null;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case ALPHANUM:
      token = jj_consume_token(ALPHANUM);
      break;
    case APOSTROPHE:
      token = jj_consume_token(APOSTROPHE);
      break;
    case ACRONYM:
      token = jj_consume_token(ACRONYM);
      break;
    case COMPANY:
      token = jj_consume_token(COMPANY);
      break;
    case EMAIL:
      token = jj_consume_token(EMAIL);
      break;
    case HOST:
      token = jj_consume_token(HOST);
      break;
    case NUM:
      token = jj_consume_token(NUM);
      break;
    case CJ:
      token = jj_consume_token(CJ);
      break;
    case 0:
      token = jj_consume_token(0);
      break;
    default:
      jj_la1[0] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
      if (token.kind == EOF) {
        {if (true) return null;}
      } else {
        {if (true) return
          new org.apache.lucene.analysis.Token(token.image,
                                        token.beginColumn,token.endColumn,
                                        tokenImage[token.kind]);}
      }
    throw new Error(""Missing return statement in function"");
  }

  public StandardTokenizerTokenManager token_source;
  public Token token, jj_nt;
  private int jj_ntk;
  private int jj_gen;
  final private int[] jj_la1 = new int[1];
  static private int[] jj_la1_0;
  static {
      jj_la1_0();
   }
   private static void jj_la1_0() {
      jj_la1_0 = new int[] {0x10ff,};
   }

  public StandardTokenizer(CharStream stream) {
    token_source = new StandardTokenizerTokenManager(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  public void ReInit(CharStream stream) {
    token_source.ReInit(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  public StandardTokenizer(StandardTokenizerTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  public void ReInit(StandardTokenizerTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  final private Token jj_consume_token(int kind) throws ParseException {
    Token oldToken;
    if ((oldToken = token).next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    if (token.kind == kind) {
      jj_gen++;
      return token;
    }
    token = oldToken;
    jj_kind = kind;
    throw generateParseException();
  }

  final public Token getNextToken() {
    if (token.next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    jj_gen++;
    return token;
  }

  final public Token getToken(int index) {
    Token t = token;
    for (int i = 0; i < index; i++) {
      if (t.next != null) t = t.next;
      else t = t.next = token_source.getNextToken();
    }
    return t;
  }

  final private int jj_ntk() {
    if ((jj_nt=token.next) == null)
      return (jj_ntk = (token.next=token_source.getNextToken()).kind);
    else
      return (jj_ntk = jj_nt.kind);
  }

  private java.util.Vector jj_expentries = new java.util.Vector();
  private int[] jj_expentry;
  private int jj_kind = -1;

  public ParseException generateParseException() {
    jj_expentries.removeAllElements();
    boolean[] la1tokens = new boolean[16];
    for (int i = 0; i < 16; i++) {
      la1tokens[i] = false;
    }
    if (jj_kind >= 0) {
      la1tokens[jj_kind] = true;
      jj_kind = -1;
    }
    for (int i = 0; i < 1; i++) {
      if (jj_la1[i] == jj_gen) {
        for (int j = 0; j < 32; j++) {
          if ((jj_la1_0[i] & (1<<j)) != 0) {
            la1tokens[j] = true;
          }
        }
      }
    }
    for (int i = 0; i < 16; i++) {
      if (la1tokens[i]) {
        jj_expentry = new int[1];
        jj_expentry[0] = i;
        jj_expentries.addElement(jj_expentry);
      }
    }
    int[][] exptokseq = new int[jj_expentries.size()][];
    for (int i = 0; i < jj_expentries.size(); i++) {
      exptokseq[i] = (int[])jj_expentries.elementAt(i);
    }
    return new ParseException(token, exptokseq, tokenImage);
  }

  final public void enable_tracing() {
  }

  final public void disable_tracing() {
  }

}
"
lucene,2.2,org.apache.lucene.search.function.ByteFieldSource,7,3,0,7,22,9,2,6,6,0.777777778,122,0.333333333,1,0.705882353,0.333333333,2,3,16.0,6,1.7143,1,"package org.apache.lucene.search.function;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;
import org.apache.lucene.search.function.DocValues;

import java.io.IOException;


public class ByteFieldSource extends FieldCacheSource {
  private FieldCache.ByteParser parser;

  
  public ByteFieldSource(String field) {
    this(field, null);
  }

  
  public ByteFieldSource(String field, FieldCache.ByteParser parser) {
    super(field);
    this.parser = parser;
  }

  
  public String description() {
    return ""byte("" + super.description() + ')';
  }

  
  public DocValues getCachedFieldValues (FieldCache cache, String field, IndexReader reader) throws IOException {
    final byte[] arr = (parser==null) ?  
      cache.getBytes(reader, field) : 
      cache.getBytes(reader, field, parser);
    return new DocValues(reader.maxDoc()) {
      
      public float floatVal(int doc) { 
        return (float) arr[doc]; 
      }
      
      public  int intVal(int doc) { 
        return arr[doc]; 
      }
      
      public String toString(int doc) { 
        return  description() + '=' + intVal(doc);  
      }
      
      Object getInnerArray() {
        return arr;
      }
    };
  }

  
  public boolean cachedFieldSourceEquals(FieldCacheSource o) {
    if (o.getClass() !=  ByteFieldSource.class) {
      return false;
    }
    ByteFieldSource other = (ByteFieldSource)o;
    return this.parser==null ? 
      other.parser==null :
      this.parser.getClass() == other.parser.getClass();
  }

  
  public int cachedFieldSourceHashCode() {
    return parser==null ? 
      Byte.class.hashCode() : parser.getClass().hashCode();
  }

}
"
lucene,2.2,org.apache.lucene.search.function.OrdFieldSource,7,2,0,6,21,0,1,6,5,0.666666667,92,0.666666667,0,0.5,0.375,2,2,11.71428571,3,1.0,2,"

package org.apache.lucene.search.function;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.FieldCache;

import java.io.IOException;



public class OrdFieldSource extends ValueSource {
  protected String field;

  
  public OrdFieldSource(String field) {
    this.field = field;
  }

  
  public String description() {
    return ""ord("" + field + ')';
  }

  
  public DocValues getValues(IndexReader reader) throws IOException {
    final int[] arr = FieldCache.DEFAULT.getStringIndex(reader, field).order;
    return new DocValues(arr.length) {
      
      public float floatVal(int doc) {
        return (float)arr[doc];
      }
      
      public String strVal(int doc) {
        
        return Integer.toString(arr[doc]);
      }
      
      public String toString(int doc) {
        return description() + '=' + intVal(doc);
      }
      
      Object getInnerArray() {
        return arr;
      }
    };
  }

  
  public boolean equals(Object o) {
    if (o.getClass() !=  OrdFieldSource.class) return false;
    OrdFieldSource other = (OrdFieldSource)o;
    return this.field.equals(other.field);
  }

  private static final int hcode = OrdFieldSource.class.hashCode();
  
  
  public int hashCode() {
    return hcode + field.hashCode();
  }
}
"
lucene,2.2,org.apache.lucene.document.MapFieldSelector,4,1,0,2,10,0,0,2,4,0.0,83,0.0,0,0.0,0.4,0,0,19.5,2,0.5,1,"package org.apache.lucene.document;



import java.util.HashMap;
import java.util.List;
import java.util.Map;


public class MapFieldSelector implements FieldSelector {
    
    Map fieldSelections;
    
    
    public MapFieldSelector(Map fieldSelections) {
        this.fieldSelections = fieldSelections;
    }
    
    
    public MapFieldSelector(List fields) {
        fieldSelections = new HashMap(fields.size()*5/3);
        for (int i=0; i<fields.size(); i++)
            fieldSelections.put(fields.get(i), FieldSelectorResult.LOAD);
    }
    
    
    public MapFieldSelector(String[] fields) {
        fieldSelections = new HashMap(fields.length*5/3);
        for (int i=0; i<fields.length; i++)
            fieldSelections.put(fields[i], FieldSelectorResult.LOAD);
    }
    
    
    public FieldSelectorResult accept(String field) {
        FieldSelectorResult selection = (FieldSelectorResult) fieldSelections.get(field);
        return selection!=null ? selection : FieldSelectorResult.NO_LOAD;
    }
    
}
"
lucene,2.2,org.apache.lucene.index.IndexFileNameFilter,5,1,0,3,14,4,2,1,4,0.583333333,145,0.666666667,1,0.0,0.5,0,0,27.4,7,2.6,1,"package org.apache.lucene.index;



import java.io.File;
import java.io.FilenameFilter;
import java.util.HashSet;


public class IndexFileNameFilter implements FilenameFilter {

  static IndexFileNameFilter singleton = new IndexFileNameFilter();
  private HashSet extensions;
  private HashSet extensionsInCFS;

  public IndexFileNameFilter() {
    extensions = new HashSet();
    for (int i = 0; i < IndexFileNames.INDEX_EXTENSIONS.length; i++) {
      extensions.add(IndexFileNames.INDEX_EXTENSIONS[i]);
    }
    extensionsInCFS = new HashSet();
    for (int i = 0; i < IndexFileNames.INDEX_EXTENSIONS_IN_COMPOUND_FILE.length; i++) {
      extensionsInCFS.add(IndexFileNames.INDEX_EXTENSIONS_IN_COMPOUND_FILE[i]);
    }
  }

  
  public boolean accept(File dir, String name) {
    int i = name.lastIndexOf('.');
    if (i != -1) {
      String extension = name.substring(1+i);
      if (extensions.contains(extension)) {
        return true;
      } else if (extension.startsWith(""f"") &&
                 extension.matches(""f\\d+"")) {
        return true;
      } else if (extension.startsWith(""s"") &&
                 extension.matches(""s\\d+"")) {
        return true;
      }
    } else {
      if (name.equals(IndexFileNames.DELETABLE)) return true;
      else if (name.startsWith(IndexFileNames.SEGMENTS)) return true;
    }
    return false;
  }

  
  public boolean isCFSFile(String name) {
    int i = name.lastIndexOf('.');
    if (i != -1) {
      String extension = name.substring(1+i);
      if (extensionsInCFS.contains(extension)) {
        return true;
      }
      if (extension.startsWith(""f"") &&
          extension.matches(""f\\d+"")) {
        return true;
      }
    }
    return false;
  }

  public static IndexFileNameFilter getFilter() {
    return singleton;
  }
}
"
lucene,2.2,org.apache.lucene.analysis.LowerCaseTokenizer,2,5,0,3,4,1,2,1,1,2.0,9,0.0,0,0.888888889,0.666666667,1,1,3.5,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;


public final class LowerCaseTokenizer extends LetterTokenizer {
  
  public LowerCaseTokenizer(Reader in) {
    super(in);
  }

  
  protected char normalize(char c) {
    return Character.toLowerCase(c);
  }
}
"
lucene,2.2,org.apache.lucene.util.BitVector,14,1,0,5,28,0,2,3,8,0.288461538,1483,1.0,0,0.0,0.320512821,0,0,104.6428571,10,1.8571,0,"package org.apache.lucene.util;



import java.io.IOException;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;


public final class BitVector {

  private byte[] bits;
  private int size;
  private int count = -1;

  
  public BitVector(int n) {
    size = n;
    bits = new byte[(size >> 3) + 1];
  }

  
  public final void set(int bit) {
    if (bit >= size) {
      throw new ArrayIndexOutOfBoundsException(bit);
    }
    bits[bit >> 3] |= 1 << (bit & 7);
    count = -1;
  }

  
  public final void clear(int bit) {
    if (bit >= size) {
      throw new ArrayIndexOutOfBoundsException(bit);
    }
    bits[bit >> 3] &= ~(1 << (bit & 7));
    count = -1;
  }

  
  public final boolean get(int bit) {
    if (bit >= size) {
      throw new ArrayIndexOutOfBoundsException(bit);
    }
    return (bits[bit >> 3] & (1 << (bit & 7))) != 0;
  }

  
  public final int size() {
    return size;
  }

  
  public final int count() {
    
    if (count == -1) {
      int c = 0;
      int end = bits.length;
      for (int i = 0; i < end; i++)
        c += BYTE_COUNTS[bits[i] & 0xFF];	  
      count = c;
    }
    return count;
  }

  private static final byte[] BYTE_COUNTS = {	  
    0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8
  };


  
  public final void write(Directory d, String name) throws IOException {
    IndexOutput output = d.createOutput(name);
    try {
      if (isSparse()) { 
        writeDgaps(output); 
      } else {
        writeBits(output);
      }
    } finally {
      output.close();
    }
  }
     
  
  private void writeBits(IndexOutput output) throws IOException {
    output.writeInt(size());        
    output.writeInt(count());       
    output.writeBytes(bits, bits.length);
  }
  
  
  private void writeDgaps(IndexOutput output) throws IOException {
    output.writeInt(-1);            
    output.writeInt(size());        
    output.writeInt(count());       
    int last=0;
    int n = count();
    int m = bits.length;
    for (int i=0; i<m && n>0; i++) {
      if (bits[i]!=0) {
        output.writeVInt(i-last);
        output.writeByte(bits[i]);
        last = i;
        n -= BYTE_COUNTS[bits[i] & 0xFF];
      }
    }
  }

  
  private boolean isSparse() {
    
    
    
    
    
    
    
    int factor = 10;  
    if (bits.length < (1<< 7)) return factor * (4 + (8+ 8)*count()) < size();
    if (bits.length < (1<<14)) return factor * (4 + (8+16)*count()) < size();
    if (bits.length < (1<<21)) return factor * (4 + (8+24)*count()) < size();
    if (bits.length < (1<<28)) return factor * (4 + (8+32)*count()) < size();
    return                            factor * (4 + (8+40)*count()) < size();
  }

  
  public BitVector(Directory d, String name) throws IOException {
    IndexInput input = d.openInput(name);
    try {
      size = input.readInt();       
      if (size == -1) {
        readDgaps(input);
      } else {
        readBits(input);
      }
    } finally {
      input.close();
    }
  }

  
  private void readBits(IndexInput input) throws IOException {
    count = input.readInt();        
    bits = new byte[(size >> 3) + 1];     
    input.readBytes(bits, 0, bits.length);
  }

   
  private void readDgaps(IndexInput input) throws IOException {
    size = input.readInt();       
    count = input.readInt();        
    bits = new byte[(size >> 3) + 1];     
    int last=0;
    int n = count();
    while (n>0) {
      last += input.readVInt();
      bits[last] = input.readByte();
      n -= BYTE_COUNTS[bits[last] & 0xFF];
    }          
  }
  
}
"
lucene,2.2,org.apache.lucene.document.AbstractField,18,1,3,7,28,51,3,4,15,0.809954751,503,1.0,0,0.0,0.198412698,0,0,26.22222222,19,2.1667,2,"package org.apache.lucene.document;




public abstract class AbstractField implements Fieldable {

  protected String name = ""body"";
  protected boolean storeTermVector = false;
  protected boolean storeOffsetWithTermVector = false;
  protected boolean storePositionWithTermVector = false;
  protected boolean omitNorms = false;
  protected boolean isStored = false;
  protected boolean isIndexed = true;
  protected boolean isTokenized = true;
  protected boolean isBinary = false;
  protected boolean isCompressed = false;
  protected boolean lazy = false;
  protected float boost = 1.0f;
  
  protected Object fieldsData = null;

  protected AbstractField()
  {
    
  }

  protected AbstractField(String name, Field.Store store, Field.Index index, Field.TermVector termVector) {
    if (name == null)
      throw new NullPointerException(""name cannot be null"");
    this.name = name.intern();        

    if (store == Field.Store.YES){
      this.isStored = true;
      this.isCompressed = false;
    }
    else if (store == Field.Store.COMPRESS) {
      this.isStored = true;
      this.isCompressed = true;
    }
    else if (store == Field.Store.NO){
      this.isStored = false;
      this.isCompressed = false;
    }
    else
      throw new IllegalArgumentException(""unknown store parameter "" + store);

    if (index == Field.Index.NO) {
      this.isIndexed = false;
      this.isTokenized = false;
    } else if (index == Field.Index.TOKENIZED) {
      this.isIndexed = true;
      this.isTokenized = true;
    } else if (index == Field.Index.UN_TOKENIZED) {
      this.isIndexed = true;
      this.isTokenized = false;
    } else if (index == Field.Index.NO_NORMS) {
      this.isIndexed = true;
      this.isTokenized = false;
      this.omitNorms = true;
    } else {
      throw new IllegalArgumentException(""unknown index parameter "" + index);
    }

    this.isBinary = false;

    setStoreTermVector(termVector);
  }

  
  public void setBoost(float boost) {
    this.boost = boost;
  }

  
  public float getBoost() {
    return boost;
  }

  
  public String name()    { return name; }

  protected void setStoreTermVector(Field.TermVector termVector) {
    if (termVector == Field.TermVector.NO) {
      this.storeTermVector = false;
      this.storePositionWithTermVector = false;
      this.storeOffsetWithTermVector = false;
    }
    else if (termVector == Field.TermVector.YES) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = false;
      this.storeOffsetWithTermVector = false;
    }
    else if (termVector == Field.TermVector.WITH_POSITIONS) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = true;
      this.storeOffsetWithTermVector = false;
    }
    else if (termVector == Field.TermVector.WITH_OFFSETS) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = false;
      this.storeOffsetWithTermVector = true;
    }
    else if (termVector == Field.TermVector.WITH_POSITIONS_OFFSETS) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = true;
      this.storeOffsetWithTermVector = true;
    }
    else {
      throw new IllegalArgumentException(""unknown termVector parameter "" + termVector);
    }
  }

  
  public final boolean  isStored()  { return isStored; }

  
  public final boolean  isIndexed()   { return isIndexed; }

  
  public final boolean  isTokenized()   { return isTokenized; }

  
  public final boolean  isCompressed()   { return isCompressed; }

  
  public final boolean isTermVectorStored() { return storeTermVector; }

  
  public boolean isStoreOffsetWithTermVector(){
    return storeOffsetWithTermVector;
  }

  
  public boolean isStorePositionWithTermVector(){
    return storePositionWithTermVector;
  }

  
  public final boolean  isBinary()      { return isBinary; }

  
  public boolean getOmitNorms() { return omitNorms; }

  
  public void setOmitNorms(boolean omitNorms) { this.omitNorms=omitNorms; }

  public boolean isLazy() {
    return lazy;
  }

  
  public final String toString() {
    StringBuffer result = new StringBuffer();
    if (isStored) {
      result.append(""stored"");
      if (isCompressed)
        result.append(""/compressed"");
      else
        result.append(""/uncompressed"");
    }
    if (isIndexed) {
      if (result.length() > 0)
        result.append("","");
      result.append(""indexed"");
    }
    if (isTokenized) {
      if (result.length() > 0)
        result.append("","");
      result.append(""tokenized"");
    }
    if (storeTermVector) {
      if (result.length() > 0)
        result.append("","");
      result.append(""termVector"");
    }
    if (storeOffsetWithTermVector) {
      if (result.length() > 0)
        result.append("","");
      result.append(""termVectorOffsets"");
    }
    if (storePositionWithTermVector) {
      if (result.length() > 0)
        result.append("","");
      result.append(""termVectorPosition"");
    }
    if (isBinary) {
      if (result.length() > 0)
        result.append("","");
      result.append(""binary"");
    }
    if (omitNorms) {
      result.append("",omitNorms"");
    }
    if (lazy){
      result.append("",lazy"");
    }
    result.append('<');
    result.append(name);
    result.append(':');

    if (fieldsData != null && lazy == false) {
      result.append(fieldsData);
    }

    result.append('>');
    return result.toString();
  }
}
"
lucene,2.2,org.apache.lucene.search.DisjunctionMaxQuery,14,2,0,6,38,0,1,6,11,0.384615385,318,1.0,0,0.5,0.171428571,2,5,21.57142857,6,1.5714,2,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Collection;
import java.util.Set;


public class DisjunctionMaxQuery extends Query {

  
  private ArrayList disjuncts = new ArrayList();

  
  private float tieBreakerMultiplier = 0.0f;

  
  public DisjunctionMaxQuery(float tieBreakerMultiplier) {
    this.tieBreakerMultiplier = tieBreakerMultiplier;
  }

  
  public DisjunctionMaxQuery(Collection disjuncts, float tieBreakerMultiplier) {
    this.tieBreakerMultiplier = tieBreakerMultiplier;
    add(disjuncts);
  }

  
  public void add(Query query) {
    disjuncts.add(query);
  }

  
  public void add(Collection disjuncts) {
    this.disjuncts.addAll(disjuncts);
  }

  
  public Iterator iterator() {
    return disjuncts.iterator();
  }

  
  private class DisjunctionMaxWeight implements Weight {

    private Searcher searcher;       
    private ArrayList weights = new ArrayList();  

    
    public DisjunctionMaxWeight(Searcher searcher) throws IOException {
      this.searcher = searcher;
      for (int i = 0; i < disjuncts.size(); i++)
        weights.add(((Query) disjuncts.get(i)).createWeight(searcher));
    }

    
    public Query getQuery() { return DisjunctionMaxQuery.this; }

    
    public float getValue() { return getBoost(); }

    
    public float sumOfSquaredWeights() throws IOException {
      float max = 0.0f, sum = 0.0f;
      for (int i = 0; i < weights.size(); i++) {
        float sub = ((Weight) weights.get(i)).sumOfSquaredWeights();
        sum += sub;
        max = Math.max(max, sub);
      }
      return (((sum - max) * tieBreakerMultiplier * tieBreakerMultiplier) + max) * getBoost() * getBoost();
    }

    
    public void normalize(float norm) {
      norm *= getBoost();  
      for (int i = 0 ; i < weights.size(); i++)
        ((Weight) weights.get(i)).normalize(norm);
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      DisjunctionMaxScorer result = new DisjunctionMaxScorer(tieBreakerMultiplier, getSimilarity(searcher));
      for (int i = 0 ; i < weights.size(); i++) {
        Weight w = (Weight) weights.get(i);
        Scorer subScorer = w.scorer(reader);
        if (subScorer == null) return null;
        result.add(subScorer);
      }
      return result;
    }

    
    public Explanation explain(IndexReader reader, int doc) throws IOException {
      if ( disjuncts.size() == 1) return ((Weight) weights.get(0)).explain(reader,doc);
      ComplexExplanation result = new ComplexExplanation();
      float max = 0.0f, sum = 0.0f;
      result.setDescription(tieBreakerMultiplier == 0.0f ? ""max of:"" : ""max plus "" + tieBreakerMultiplier + "" times others of:"");
      for (int i = 0 ; i < weights.size(); i++) {
        Explanation e = ((Weight) weights.get(i)).explain(reader, doc);
        if (e.isMatch()) {
          result.setMatch(Boolean.TRUE);
          result.addDetail(e);
          sum += e.getValue();
          max = Math.max(max, e.getValue());
        }
      }
      result.setValue(max + (sum - max)*tieBreakerMultiplier);
      return result;
    }

  }  

  
  protected Weight createWeight(Searcher searcher) throws IOException {
    return new DisjunctionMaxWeight(searcher);
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    if (disjuncts.size() == 1) {
      Query singleton = (Query) disjuncts.get(0);
      Query result = singleton.rewrite(reader);
      if (getBoost() != 1.0f) {
        if (result == singleton) result = (Query)result.clone();
        result.setBoost(getBoost() * result.getBoost());
      }
      return result;
    }
    DisjunctionMaxQuery clone = null;
    for (int i = 0 ; i < disjuncts.size(); i++) {
      Query clause = (Query) disjuncts.get(i);
      Query rewrite = clause.rewrite(reader);
      if (rewrite != clause) {
        if (clone == null) clone = (DisjunctionMaxQuery)this.clone();
        clone.disjuncts.set(i, rewrite);
      }
    }
    if (clone != null) return clone;
    else return this;
  }

  
  public Object clone() {
    DisjunctionMaxQuery clone = (DisjunctionMaxQuery)super.clone();
    clone.disjuncts = (ArrayList)this.disjuncts.clone();
    return clone;
  }


  
  public void extractTerms(Set terms) {
      for (int i = 0; i < disjuncts.size(); i++) {
          ((Query)disjuncts.get(i)).extractTerms(terms);
      }
  }


  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""("");
    for (int i = 0 ; i < disjuncts.size(); i++) {
      Query subquery = (Query) disjuncts.get(i);
      if (subquery instanceof BooleanQuery) {   
        buffer.append(""("");
        buffer.append(subquery.toString(field));
        buffer.append("")"");
      }
      else buffer.append(subquery.toString(field));
      if (i != disjuncts.size()-1) buffer.append("" | "");
    }
    buffer.append("")"");
    if (tieBreakerMultiplier != 0.0f) {
      buffer.append(""~"");
      buffer.append(tieBreakerMultiplier);
    }
    if (getBoost() != 1.0) {
      buffer.append(""^"");
      buffer.append(getBoost());
    }
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (! (o instanceof DisjunctionMaxQuery) ) return false;
    DisjunctionMaxQuery other = (DisjunctionMaxQuery)o;
    return this.getBoost() == other.getBoost()
            && this.tieBreakerMultiplier == other.tieBreakerMultiplier
            && this.disjuncts.equals(other.disjuncts);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost())
            + Float.floatToIntBits(tieBreakerMultiplier)
            + disjuncts.hashCode();
  }

}
"
lucene,2.2,org.apache.lucene.index.DocumentWriter,11,1,0,20,102,1,1,20,0,0.733333333,1192,1.0,5,0.0,0.227272727,0,0,106.0,10,2.3636,0,"package org.apache.lucene.index;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.Token;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Fieldable;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;

import java.io.IOException;
import java.io.PrintStream;
import java.io.Reader;
import java.io.StringReader;
import java.util.Arrays;
import java.util.BitSet;
import java.util.Enumeration;
import java.util.Hashtable;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;

final class DocumentWriter {
  private Analyzer analyzer;
  private Directory directory;
  private Similarity similarity;
  private FieldInfos fieldInfos;
  private int maxFieldLength;
  private int termIndexInterval = IndexWriter.DEFAULT_TERM_INDEX_INTERVAL;
  private PrintStream infoStream;

   
  DocumentWriter(Directory directory, Analyzer analyzer,
                 Similarity similarity, int maxFieldLength) {
    this.directory = directory;
    this.analyzer = analyzer;
    this.similarity = similarity;
    this.maxFieldLength = maxFieldLength;
  }

  DocumentWriter(Directory directory, Analyzer analyzer, IndexWriter writer) {
    this.directory = directory;
    this.analyzer = analyzer;
    this.similarity = writer.getSimilarity();
    this.maxFieldLength = writer.getMaxFieldLength();
    this.termIndexInterval = writer.getTermIndexInterval();
  }

  final void addDocument(String segment, Document doc)
          throws CorruptIndexException, IOException {
    
    fieldInfos = new FieldInfos();
    fieldInfos.add(doc);
    
    
    postingTable.clear();			  
    fieldLengths = new int[fieldInfos.size()];    
    fieldPositions = new int[fieldInfos.size()];  
    fieldOffsets = new int[fieldInfos.size()];    
    fieldStoresPayloads = new BitSet(fieldInfos.size());
    
    fieldBoosts = new float[fieldInfos.size()];	  
    Arrays.fill(fieldBoosts, doc.getBoost());

    try {
    
      
      
      
      
      invertDocument(doc);
    
      
      Posting[] postings = sortPostingTable();
    
      
      fieldInfos.write(directory, segment + "".fnm"");

      
      FieldsWriter fieldsWriter =
        new FieldsWriter(directory, segment, fieldInfos);
      try {
        fieldsWriter.addDocument(doc);
      } finally {
        fieldsWriter.close();
      }
    
      

      
      writePostings(postings, segment);

      
      writeNorms(segment);
    } finally {
      
      IOException ex = null;
      
      Iterator it = openTokenStreams.iterator();
      while (it.hasNext()) {
        try {
          ((TokenStream) it.next()).close();
        } catch (IOException e) {
          if (ex != null) {
            ex = e;
          }
        }
      }
      openTokenStreams.clear();
      
      if (ex != null) {
        throw ex;
      }
    }
  }

  
  
  private final Hashtable postingTable = new Hashtable();
  private int[] fieldLengths;
  private int[] fieldPositions;
  private int[] fieldOffsets;
  private float[] fieldBoosts;
  
  
  
  private BitSet fieldStoresPayloads;
  
  
  
  private List openTokenStreams = new LinkedList();

  
  private final void invertDocument(Document doc)
          throws IOException {
    Iterator fieldIterator = doc.getFields().iterator();
    while (fieldIterator.hasNext()) {
      Fieldable field = (Fieldable) fieldIterator.next();
      String fieldName = field.name();
      int fieldNumber = fieldInfos.fieldNumber(fieldName);

      int length = fieldLengths[fieldNumber];     
      int position = fieldPositions[fieldNumber]; 
      if (length>0) position+=analyzer.getPositionIncrementGap(fieldName);
      int offset = fieldOffsets[fieldNumber];       

      if (field.isIndexed()) {
        if (!field.isTokenized()) {		  
          String stringValue = field.stringValue();
          if(field.isStoreOffsetWithTermVector())
            addPosition(fieldName, stringValue, position++, null, new TermVectorOffsetInfo(offset, offset + stringValue.length()));
          else
            addPosition(fieldName, stringValue, position++, null, null);
          offset += stringValue.length();
          length++;
        } else 
        { 
          TokenStream stream = field.tokenStreamValue();
          
          
          
          if (stream == null) {
            Reader reader;			  
            if (field.readerValue() != null)
              reader = field.readerValue();
            else if (field.stringValue() != null)
              reader = new StringReader(field.stringValue());
            else
              throw new IllegalArgumentException
                      (""field must have either String or Reader value"");
  
            
            stream = analyzer.tokenStream(fieldName, reader);
          }
          
          
          openTokenStreams.add(stream);
          
          
          stream.reset();
          

          Token lastToken = null;
          for (Token t = stream.next(); t != null; t = stream.next()) {
            position += (t.getPositionIncrement() - 1);
              
            Payload payload = t.getPayload();
            if (payload != null) {
              
              fieldStoresPayloads.set(fieldNumber);
            }
              
            TermVectorOffsetInfo termVectorOffsetInfo;
            if (field.isStoreOffsetWithTermVector()) {
              termVectorOffsetInfo = new TermVectorOffsetInfo(offset + t.startOffset(), offset + t.endOffset());
            } else {
              termVectorOffsetInfo = null;
            }
            addPosition(fieldName, t.termText(), position++, payload, termVectorOffsetInfo);
              
            lastToken = t;
            if (++length >= maxFieldLength) {
              if (infoStream != null)
                infoStream.println(""maxFieldLength "" +maxFieldLength+ "" reached, ignoring following tokens"");
              break;
            }
          }
            
          if(lastToken != null)
            offset += lastToken.endOffset() + 1;
        }

        fieldLengths[fieldNumber] = length;	  
        fieldPositions[fieldNumber] = position;	  
        fieldBoosts[fieldNumber] *= field.getBoost();
        fieldOffsets[fieldNumber] = offset;
      }
    }
    
    
    for (int i = fieldStoresPayloads.nextSetBit(0); i >= 0; i = fieldStoresPayloads.nextSetBit(i+1)) { 
    	fieldInfos.fieldInfo(i).storePayloads = true;
    }
  }

  private final Term termBuffer = new Term("""", """"); 

  private final void addPosition(String field, String text, int position, Payload payload, TermVectorOffsetInfo offset) {
    termBuffer.set(field, text);
    
    Posting ti = (Posting) postingTable.get(termBuffer);
    if (ti != null) {				  
      int freq = ti.freq;
      if (ti.positions.length == freq) {	  
        int[] newPositions = new int[freq * 2];	  
        int[] positions = ti.positions;
        System.arraycopy(positions, 0, newPositions, 0, freq);
        ti.positions = newPositions;
        
        if (ti.payloads != null) {
          
          Payload[] newPayloads = new Payload[freq * 2];  
          Payload[] payloads = ti.payloads;
          System.arraycopy(payloads, 0, newPayloads, 0, payloads.length);
          ti.payloads = newPayloads;
        }
      }
      ti.positions[freq] = position;		  

      if (payload != null) {
        if (ti.payloads == null) {
          
          ti.payloads = new Payload[ti.positions.length];
        }
        ti.payloads[freq] = payload;
      }
      
      if (offset != null) {
        if (ti.offsets.length == freq){
          TermVectorOffsetInfo [] newOffsets = new TermVectorOffsetInfo[freq*2];
          TermVectorOffsetInfo [] offsets = ti.offsets;
          System.arraycopy(offsets, 0, newOffsets, 0, freq);
          ti.offsets = newOffsets;
        }
        ti.offsets[freq] = offset;
      }
      ti.freq = freq + 1;			  
    } else {					  
      Term term = new Term(field, text, false);
      postingTable.put(term, new Posting(term, position, payload, offset));
    }
  }

  private final Posting[] sortPostingTable() {
    
    Posting[] array = new Posting[postingTable.size()];
    Enumeration postings = postingTable.elements();
    for (int i = 0; postings.hasMoreElements(); i++)
      array[i] = (Posting) postings.nextElement();

    
    quickSort(array, 0, array.length - 1);

    return array;
  }

  private static final void quickSort(Posting[] postings, int lo, int hi) {
    if (lo >= hi)
      return;

    int mid = (lo + hi) / 2;

    if (postings[lo].term.compareTo(postings[mid].term) > 0) {
      Posting tmp = postings[lo];
      postings[lo] = postings[mid];
      postings[mid] = tmp;
    }

    if (postings[mid].term.compareTo(postings[hi].term) > 0) {
      Posting tmp = postings[mid];
      postings[mid] = postings[hi];
      postings[hi] = tmp;

      if (postings[lo].term.compareTo(postings[mid].term) > 0) {
        Posting tmp2 = postings[lo];
        postings[lo] = postings[mid];
        postings[mid] = tmp2;
      }
    }

    int left = lo + 1;
    int right = hi - 1;

    if (left >= right)
      return;

    Term partition = postings[mid].term;

    for (; ;) {
      while (postings[right].term.compareTo(partition) > 0)
        --right;

      while (left < right && postings[left].term.compareTo(partition) <= 0)
        ++left;

      if (left < right) {
        Posting tmp = postings[left];
        postings[left] = postings[right];
        postings[right] = tmp;
        --right;
      } else {
        break;
      }
    }

    quickSort(postings, lo, left);
    quickSort(postings, left + 1, hi);
  }

  private final void writePostings(Posting[] postings, String segment)
          throws CorruptIndexException, IOException {
    IndexOutput freq = null, prox = null;
    TermInfosWriter tis = null;
    TermVectorsWriter termVectorWriter = null;
    try {
      
      freq = directory.createOutput(segment + "".frq"");
      prox = directory.createOutput(segment + "".prx"");
      tis = new TermInfosWriter(directory, segment, fieldInfos,
                                termIndexInterval);
      TermInfo ti = new TermInfo();
      String currentField = null;
      boolean currentFieldHasPayloads = false;
      
      for (int i = 0; i < postings.length; i++) {
        Posting posting = postings[i];

        
        String termField = posting.term.field();
        if (currentField != termField) {
          
          currentField = termField;
          FieldInfo fi = fieldInfos.fieldInfo(currentField);
          currentFieldHasPayloads = fi.storePayloads;
          if (fi.storeTermVector) {
            if (termVectorWriter == null) {
              termVectorWriter =
                new TermVectorsWriter(directory, segment, fieldInfos);
              termVectorWriter.openDocument();
            }
            termVectorWriter.openField(currentField);

          } else if (termVectorWriter != null) {
            termVectorWriter.closeField();
          }
        }
        
        
        ti.set(1, freq.getFilePointer(), prox.getFilePointer(), -1);
        tis.add(posting.term, ti);

        
        int postingFreq = posting.freq;
        if (postingFreq == 1)				  
          freq.writeVInt(1);			  
        else {
          freq.writeVInt(0);			  
          freq.writeVInt(postingFreq);			  
        }

        int lastPosition = 0;			  
        int[] positions = posting.positions;
        Payload[] payloads = posting.payloads;
        int lastPayloadLength = -1;
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        for (int j = 0; j < postingFreq; j++) {		  
          int position = positions[j];
          int delta = position - lastPosition;
          if (currentFieldHasPayloads) {
            int payloadLength = 0;
            Payload payload = null;
            if (payloads != null) {
              payload = payloads[j];
              if (payload != null) {
                payloadLength = payload.length;
              }
            }
            if (payloadLength == lastPayloadLength) {
            	
            	
            	
              prox.writeVInt(delta * 2);
            } else {
            	
            	
            	
              prox.writeVInt(delta * 2 + 1);
              prox.writeVInt(payloadLength);
              lastPayloadLength = payloadLength;
            }
            if (payloadLength > 0) {
            	
              prox.writeBytes(payload.data, payload.offset, payload.length);
            }
          } else {
          	
            prox.writeVInt(delta);
          }
          lastPosition = position;
        }
        if (termVectorWriter != null && termVectorWriter.isFieldOpen()) {
            termVectorWriter.addTerm(posting.term.text(), postingFreq, posting.positions, posting.offsets);
        }
      }
      if (termVectorWriter != null)
        termVectorWriter.closeDocument();
    } finally {
      
      
      IOException keep = null;
      if (freq != null) try { freq.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (prox != null) try { prox.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (tis  != null) try {  tis.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (termVectorWriter  != null) try {  termVectorWriter.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (keep != null) throw (IOException) keep.fillInStackTrace();
    }
  }

  private final void writeNorms(String segment) throws IOException { 
    for(int n = 0; n < fieldInfos.size(); n++){
      FieldInfo fi = fieldInfos.fieldInfo(n);
      if(fi.isIndexed && !fi.omitNorms){
        float norm = fieldBoosts[n] * similarity.lengthNorm(fi.name, fieldLengths[n]);
        IndexOutput norms = directory.createOutput(segment + "".f"" + n);
        try {
          norms.writeByte(Similarity.encodeNorm(norm));
        } finally {
          norms.close();
        }
      }
    }
  }
  
  
  void setInfoStream(PrintStream infoStream) {
    this.infoStream = infoStream;
  }

  int getNumFields() {
    return fieldInfos.size();
  }
}

final class Posting {				  
  Term term;					  
  int freq;					  
  int[] positions;				  
  Payload[] payloads; 
  TermVectorOffsetInfo [] offsets;
  

  Posting(Term t, int position, Payload payload, TermVectorOffsetInfo offset) {
    term = t;
    freq = 1;
    positions = new int[1];
    positions[0] = position;
    
    if (payload != null) {
      payloads = new Payload[1];
      payloads[0] = payload;
    } else 
      payloads = null;    
    

    if(offset != null){
      offsets = new TermVectorOffsetInfo[1];
      offsets[0] = offset;
    } else
      offsets = null;
  }
}
"
lucene,2.2,org.apache.lucene.util.Constants,2,1,0,0,5,1,0,0,0,1.0,44,0.0,0,0.0,1.0,0,0,17.0,0,0.0,0,"package org.apache.lucene.util;





public final class Constants {
  private Constants() {}			  

  
  public static final String JAVA_VERSION = System.getProperty(""java.version"");
  
  public static final boolean JAVA_1_1 = JAVA_VERSION.startsWith(""1.1."");
  
  public static final boolean JAVA_1_2 = JAVA_VERSION.startsWith(""1.2."");
  
  public static final boolean JAVA_1_3 = JAVA_VERSION.startsWith(""1.3."");
 
  
  public static final String OS_NAME = System.getProperty(""os.name"");
  
  public static final boolean LINUX = OS_NAME.startsWith(""Linux"");
  
  public static final boolean WINDOWS = OS_NAME.startsWith(""Windows"");
  
  public static final boolean SUN_OS = OS_NAME.startsWith(""SunOS"");
}
"
lucene,2.2,org.apache.lucene.search.MultiTermQuery,7,2,2,10,27,1,2,8,6,0.333333333,134,1.0,1,0.666666667,0.342857143,2,3,18.0,5,1.5714,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.util.ToStringUtils;


public abstract class MultiTermQuery extends Query {
    private Term term;

    
    public MultiTermQuery(Term term) {
        this.term = term;
    }

    
    public Term getTerm() { return term; }

    
    protected abstract FilteredTermEnum getEnum(IndexReader reader)
      throws IOException;

    public Query rewrite(IndexReader reader) throws IOException {
      FilteredTermEnum enumerator = getEnum(reader);
      BooleanQuery query = new BooleanQuery(true);
      try {
        do {
          Term t = enumerator.term();
          if (t != null) {
            TermQuery tq = new TermQuery(t);      
            tq.setBoost(getBoost() * enumerator.difference()); 
            query.add(tq, BooleanClause.Occur.SHOULD);          
          }
        } while (enumerator.next());
      } finally {
        enumerator.close();
      }
      return query;
    }

    
    public String toString(String field) {
        StringBuffer buffer = new StringBuffer();
        if (!term.field().equals(field)) {
            buffer.append(term.field());
            buffer.append("":"");
        }
        buffer.append(term.text());
        buffer.append(ToStringUtils.boost(getBoost()));
        return buffer.toString();
    }

    public boolean equals(Object o) {
      if (this == o) return true;
      if (!(o instanceof MultiTermQuery)) return false;

      final MultiTermQuery multiTermQuery = (MultiTermQuery) o;

      if (!term.equals(multiTermQuery.term)) return false;

      return getBoost() == multiTermQuery.getBoost();
    }

    public int hashCode() {
      return term.hashCode() + Float.floatToRawIntBits(getBoost());
    }
}
"
lucene,2.2,org.apache.lucene.search.BooleanScorer,12,2,0,8,29,26,1,7,7,0.609090909,461,1.0,3,0.444444444,0.305555556,1,3,36.58333333,2,1.0833,0,"package org.apache.lucene.search;



import java.io.IOException;

final class BooleanScorer extends Scorer {
  private SubScorer scorers = null;
  private BucketTable bucketTable = new BucketTable();

  private int maxCoord = 1;
  private float[] coordFactors = null;

  private int requiredMask = 0;
  private int prohibitedMask = 0;
  private int nextMask = 1;

  private final int minNrShouldMatch;

  BooleanScorer(Similarity similarity) {
    this(similarity, 1);
  }
  
  BooleanScorer(Similarity similarity, int minNrShouldMatch) {
    super(similarity);
    this.minNrShouldMatch = minNrShouldMatch;
  }
  
  static final class SubScorer {
    public Scorer scorer;
    public boolean done;
    public boolean required = false;
    public boolean prohibited = false;
    public HitCollector collector;
    public SubScorer next;

    public SubScorer(Scorer scorer, boolean required, boolean prohibited,
                     HitCollector collector, SubScorer next)
      throws IOException {
      this.scorer = scorer;
      this.done = !scorer.next();
      this.required = required;
      this.prohibited = prohibited;
      this.collector = collector;
      this.next = next;
    }
  }

  final void add(Scorer scorer, boolean required, boolean prohibited)
    throws IOException {
    int mask = 0;
    if (required || prohibited) {
      if (nextMask == 0)
        throw new IndexOutOfBoundsException
          (""More than 32 required/prohibited clauses in query."");
      mask = nextMask;
      nextMask = nextMask << 1;
    } else
      mask = 0;

    if (!prohibited)
      maxCoord++;

    if (prohibited)
      prohibitedMask |= mask;                     
    else if (required)
      requiredMask |= mask;                       

    scorers = new SubScorer(scorer, required, prohibited,
                            bucketTable.newCollector(mask), scorers);
  }

  private final void computeCoordFactors() {
    coordFactors = new float[maxCoord];
    for (int i = 0; i < maxCoord; i++)
      coordFactors[i] = getSimilarity().coord(i, maxCoord-1);
  }

  private int end;
  private Bucket current;

  public void score(HitCollector hc) throws IOException {
    next();
    score(hc, Integer.MAX_VALUE);
  }

  protected boolean score(HitCollector hc, int max) throws IOException {
    if (coordFactors == null)
      computeCoordFactors();

    boolean more;
    Bucket tmp;
    
    do {
      bucketTable.first = null;
      
      while (current != null) {         

        
        if ((current.bits & prohibitedMask) == 0 && 
            (current.bits & requiredMask) == requiredMask) {
          
          if (current.doc >= max){
            tmp = current;
            current = current.next;
            tmp.next = bucketTable.first;
            bucketTable.first = tmp;
            continue;
          }
          
          if (current.coord >= minNrShouldMatch) {
            hc.collect(current.doc, current.score * coordFactors[current.coord]);
          }
        }
        
        current = current.next;         
      }
      
      if (bucketTable.first != null){
        current = bucketTable.first;
        bucketTable.first = current.next;
        return true;
      }

      
      more = false;
      end += BucketTable.SIZE;
      for (SubScorer sub = scorers; sub != null; sub = sub.next) {
        if (!sub.done) {
          sub.done = !sub.scorer.score(sub.collector, end);
          if (!sub.done)
            more = true;
        }
      }
      current = bucketTable.first;
      
    } while (current != null || more);

    return false;
  }

  public int doc() { return current.doc; }

  public boolean next() throws IOException {
    boolean more;
    do {
      while (bucketTable.first != null) {         
        current = bucketTable.first;
        bucketTable.first = current.next;         

        
        if ((current.bits & prohibitedMask) == 0 &&
            (current.bits & requiredMask) == requiredMask &&
            current.coord >= minNrShouldMatch) {
          return true;
        }
      }

      
      more = false;
      end += BucketTable.SIZE;
      for (SubScorer sub = scorers; sub != null; sub = sub.next) {
        Scorer scorer = sub.scorer;
        while (!sub.done && scorer.doc() < end) {
          sub.collector.collect(scorer.doc(), scorer.score());
          sub.done = !scorer.next();
        }
        if (!sub.done) {
          more = true;
        }
      }
    } while (bucketTable.first != null || more);

    return false;
  }

  public float score() {
    if (coordFactors == null)
      computeCoordFactors();
    return current.score * coordFactors[current.coord];
  }

  static final class Bucket {
    int doc = -1;                                 
    float       score;                            
    int bits;                                     
    int coord;                                    
    Bucket      next;                             
  }

  
  static final class BucketTable {
    public static final int SIZE = 1 << 11;
    public static final int MASK = SIZE - 1;

    final Bucket[] buckets = new Bucket[SIZE];
    Bucket first = null;                          
  
    public BucketTable() {}

    public final int size() { return SIZE; }

    public HitCollector newCollector(int mask) {
      return new Collector(mask, this);
    }
  }

  static final class Collector extends HitCollector {
    private BucketTable bucketTable;
    private int mask;
    public Collector(int mask, BucketTable bucketTable) {
      this.mask = mask;
      this.bucketTable = bucketTable;
    }
    public final void collect(final int doc, final float score) {
      final BucketTable table = bucketTable;
      final int i = doc & BucketTable.MASK;
      Bucket bucket = table.buckets[i];
      if (bucket == null)
        table.buckets[i] = bucket = new Bucket();
      
      if (bucket.doc != doc) {                    
        bucket.doc = doc;                         
        bucket.score = score;                     
        bucket.bits = mask;                       
        bucket.coord = 1;                         

        bucket.next = table.first;                
        table.first = bucket;
      } else {                                    
        bucket.score += score;                    
        bucket.bits |= mask;                      
        bucket.coord++;                           
      }
    }
  }

  public boolean skipTo(int target) {
    throw new UnsupportedOperationException();
  }

  public Explanation explain(int doc) {
    throw new UnsupportedOperationException();
  }

  public String toString() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""boolean("");
    for (SubScorer sub = scorers; sub != null; sub = sub.next) {
      buffer.append(sub.scorer.toString());
      buffer.append("" "");
    }
    buffer.append("")"");
    return buffer.toString();
  }

}
"
lucene,2.2,org.apache.lucene.search.QueryFilter,3,3,0,4,7,3,0,4,3,2.0,20,0.0,0,0.714285714,0.555555556,2,3,5.666666667,1,0.6667,0,"package org.apache.lucene.search;





public class QueryFilter extends CachingWrapperFilter {

  
  public QueryFilter(Query query) {
    super(new QueryWrapperFilter(query));
  }

  public boolean equals(Object o) {
    return super.equals((QueryFilter)o);
  }

  public int hashCode() {
    return super.hashCode() ^ 0x923F64B9;  
  }
}
"
lucene,2.2,org.apache.lucene.search.ParallelMultiSearcher,6,3,0,16,33,3,1,16,6,0.4,297,1.0,1,0.880952381,0.351851852,2,3,48.16666667,1,0.8333,1,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.util.PriorityQueue;


public class ParallelMultiSearcher extends MultiSearcher {

  private Searchable[] searchables;
  private int[] starts;
	
  
  public ParallelMultiSearcher(Searchable[] searchables) throws IOException {
    super(searchables);
    this.searchables=searchables;
    this.starts=getStarts();
  }

  
  public int docFreq(Term term) throws IOException {
    return super.docFreq(term);
  }

  
  public TopDocs search(Weight weight, Filter filter, int nDocs)
    throws IOException {
    HitQueue hq = new HitQueue(nDocs);
    int totalHits = 0;
    MultiSearcherThread[] msta =
      new MultiSearcherThread[searchables.length];
    for (int i = 0; i < searchables.length; i++) { 
      
      msta[i] =
        new MultiSearcherThread(
                                searchables[i],
                                weight,
                                filter,
                                nDocs,
                                hq,
                                i,
                                starts,
                                ""MultiSearcher thread #"" + (i + 1));
      msta[i].start();
    }

    for (int i = 0; i < searchables.length; i++) {
      try {
        msta[i].join();
      } catch (InterruptedException ie) {
        ; 
      }
      IOException ioe = msta[i].getIOException();
      if (ioe == null) {
        totalHits += msta[i].hits();
      } else {
        
        throw ioe;
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size() - 1; i >= 0; i--) 
      scoreDocs[i] = (ScoreDoc) hq.pop();

    float maxScore = (totalHits==0) ? Float.NEGATIVE_INFINITY : scoreDocs[0].score;
    
    return new TopDocs(totalHits, scoreDocs, maxScore);
  }

  
  public TopFieldDocs search(Weight weight, Filter filter, int nDocs, Sort sort)
    throws IOException {
    
    FieldDocSortedHitQueue hq = new FieldDocSortedHitQueue (null, nDocs);
    int totalHits = 0;
    MultiSearcherThread[] msta = new MultiSearcherThread[searchables.length];
    for (int i = 0; i < searchables.length; i++) { 
      
      msta[i] =
        new MultiSearcherThread(
                                searchables[i],
                                weight,
                                filter,
                                nDocs,
                                hq,
                                sort,
                                i,
                                starts,
                                ""MultiSearcher thread #"" + (i + 1));
      msta[i].start();
    }

    float maxScore=Float.NEGATIVE_INFINITY;
    
    for (int i = 0; i < searchables.length; i++) {
      try {
        msta[i].join();
      } catch (InterruptedException ie) {
        ; 
      }
      IOException ioe = msta[i].getIOException();
      if (ioe == null) {
        totalHits += msta[i].hits();
        maxScore=Math.max(maxScore, msta[i].getMaxScore());
      } else {
        
        throw ioe;
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size() - 1; i >= 0; i--) 
      scoreDocs[i] = (ScoreDoc) hq.pop();

    return new TopFieldDocs(totalHits, scoreDocs, hq.getFields(), maxScore);
  }

  
  public void search(Weight weight, Filter filter, final HitCollector results)
    throws IOException {
    for (int i = 0; i < searchables.length; i++) {

      final int start = starts[i];

      searchables[i].search(weight, filter, new HitCollector() {
          public void collect(int doc, float score) {
            results.collect(doc + start, score);
          }
        });

    }
  }

  
  public Query rewrite(Query original) throws IOException {
    return super.rewrite(original);
  }

}


class MultiSearcherThread extends Thread {

  private Searchable searchable;
  private Weight weight;
  private Filter filter;
  private int nDocs;
  private TopDocs docs;
  private int i;
  private PriorityQueue hq;
  private int[] starts;
  private IOException ioe;
  private Sort sort;

  public MultiSearcherThread(
                             Searchable searchable,
                             Weight weight,
                             Filter filter,
                             int nDocs,
                             HitQueue hq,
                             int i,
                             int[] starts,
                             String name) {
    super(name);
    this.searchable = searchable;
    this.weight = weight;
    this.filter = filter;
    this.nDocs = nDocs;
    this.hq = hq;
    this.i = i;
    this.starts = starts;
  }

  public MultiSearcherThread(
                             Searchable searchable,
                             Weight weight,
                             Filter filter,
                             int nDocs,
                             FieldDocSortedHitQueue hq,
                             Sort sort,
                             int i,
                             int[] starts,
                             String name) {
    super(name);
    this.searchable = searchable;
    this.weight = weight;
    this.filter = filter;
    this.nDocs = nDocs;
    this.hq = hq;
    this.i = i;
    this.starts = starts;
    this.sort = sort;
  }

  public void run() {
    try {
      docs = (sort == null) ? searchable.search (weight, filter, nDocs)
        : searchable.search (weight, filter, nDocs, sort);
    }
    
    catch (IOException ioe) {
      this.ioe = ioe;
    }
    if (ioe == null) {
      
      
      
      if (sort != null) {
        ((FieldDocSortedHitQueue)hq).setFields (((TopFieldDocs)docs).fields);
      }
      ScoreDoc[] scoreDocs = docs.scoreDocs;
      for (int j = 0;
           j < scoreDocs.length;
           j++) { 
        ScoreDoc scoreDoc = scoreDocs[j];
        scoreDoc.doc += starts[i]; 
        
        synchronized (hq) {
          if (!hq.insert(scoreDoc))
            break;
        } 
      }
    }
  }

  public int hits() {
    return docs.totalHits;
  }

  public float getMaxScore() {
      return docs.getMaxScore();
  }
  
  public IOException getIOException() {
    return ioe;
  }

}
"
lucene,2.2,org.apache.lucene.search.ConjunctionScorer,10,2,1,6,21,0,3,4,6,0.412698413,340,1.0,1,0.470588235,0.3,1,3,32.3,2,1.1,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Arrays;
import java.util.Comparator;


class ConjunctionScorer extends Scorer {
  private Scorer[] scorers = new Scorer[2];
  private int length = 0;
  private int first = 0;
  private int last = -1;
  private boolean firstTime = true;
  private boolean more = true;
  private float coord;

  public ConjunctionScorer(Similarity similarity) {
    super(similarity);
  }

  final void add(Scorer scorer) {
    if (length >= scorers.length) {
      
      Scorer[] temps = new Scorer[scorers.length * 2];
      System.arraycopy(scorers, 0, temps, 0, length);
      scorers = temps;
    }
    last += 1;
    length += 1;
    scorers[last] = scorer;
  }

  public int doc() { return scorers[first].doc(); }

  public boolean next() throws IOException {
    if (firstTime) {
      init(true);
    } else if (more) {
      more = scorers[last].next();                   
    }
    return doNext();
  }
  
  private boolean doNext() throws IOException {
    while (more && scorers[first].doc() < scorers[last].doc()) { 
      more = scorers[first].skipTo(scorers[last].doc());      
      last = first; 
      first = (first == length-1) ? 0 : first+1;
    }
    return more;                                
  }

  public boolean skipTo(int target) throws IOException {
    if(firstTime) {
      init(false);
    }
    
    for (int i = 0, pos = first; i < length; i++) {
      if (!more) break; 
      more = scorers[pos].skipTo(target);
      pos = (pos == length-1) ? 0 : pos+1;
    }
    
    if (more)
      sortScorers();                              
    
    return doNext();
  }

  public float score() throws IOException {
    float sum = 0.0f;
    for (int i = 0; i < length; i++) {
      sum += scorers[i].score();
    }
    return sum * coord;
  }
  
  private void init(boolean initScorers) throws IOException {
    
    coord = getSimilarity().coord(length, length);
   
    more = length > 0;

    if(initScorers){
      
      for (int i = 0, pos = first; i < length; i++) {
        if (!more) break; 
        more = scorers[pos].next();
        pos = (pos == length-1) ? 0 : pos+1;
      }
      
      if (more) 
        sortScorers();
    }

    firstTime = false;
  }

  private void sortScorers() {
    
    if (length != scorers.length) {
      Scorer[] temps = new Scorer[length];
      System.arraycopy(scorers, 0, temps, 0, length);
      scorers = temps;
    }
    
    
    Arrays.sort(scorers, new Comparator() {         
        public int compare(Object o1, Object o2) {
          return ((Scorer)o1).doc() - ((Scorer)o2).doc();
        }
      });
   
    first = 0;
    last = length - 1;
  }

  public Explanation explain(int doc) {
    throw new UnsupportedOperationException();
  }

}
"
lucene,2.2,org.apache.lucene.analysis.Token,13,1,0,15,22,24,14,1,13,0.75,177,0.166666667,1,0.0,0.384615385,1,1,12.15384615,3,1.0769,8,"package org.apache.lucene.analysis;

import org.apache.lucene.index.Payload;
import org.apache.lucene.index.TermPositions;




  
public class Token implements Cloneable {
  String termText;				  
  int startOffset;				  
  int endOffset;				  
  String type = ""word"";				  
  
  Payload payload;
  
  private int positionIncrement = 1;

  
  public Token(String text, int start, int end) {
    termText = text;
    startOffset = start;
    endOffset = end;
  }

  
  public Token(String text, int start, int end, String typ) {
    termText = text;
    startOffset = start;
    endOffset = end;
    type = typ;
  }

  
  public void setPositionIncrement(int positionIncrement) {
    if (positionIncrement < 0)
      throw new IllegalArgumentException
        (""Increment must be zero or greater: "" + positionIncrement);
    this.positionIncrement = positionIncrement;
  }

  
  public int getPositionIncrement() { return positionIncrement; }

  
  public void setTermText(String text) {
    termText = text;
  }

  
  public final String termText() { return termText; }

  
  public final int startOffset() { return startOffset; }

  
  public final int endOffset() { return endOffset; }

  
  public final String type() { return type; }

  
  
  public void setPayload(Payload payload) {
    this.payload = payload;
  }
  
  
  
  public Payload getPayload() {
    return this.payload;
  }

  public String toString() {
    StringBuffer sb = new StringBuffer();
    sb.append(""("" + termText + "","" + startOffset + "","" + endOffset);
    if (!type.equals(""word""))
      sb.append("",type=""+type);
    if (positionIncrement != 1)
      sb.append("",posIncr=""+positionIncrement);
    sb.append("")"");
    return sb.toString();
  }

  public Object clone() {
    try {
      return super.clone();
    } catch (CloneNotSupportedException e) {
      throw new RuntimeException(e); 
    }
  }
}
"
lucene,2.2,org.apache.lucene.queryParser.FastCharStream,14,1,0,2,25,3,1,1,13,0.602564103,237,0.0,0,0.0,0.404761905,0,0,15.5,1,0.9286,0,"
package org.apache.lucene.queryParser;



import java.io.*;


public final class FastCharStream implements CharStream {
  char[] buffer = null;

  int bufferLength = 0;				  
  int bufferPosition = 0;			  

  int tokenStart = 0;				  
  int bufferStart = 0;				  

  Reader input;					  

  
  public FastCharStream(Reader r) {
    input = r;
  }

  public final char readChar() throws IOException {
    if (bufferPosition >= bufferLength)
      refill();
    return buffer[bufferPosition++];
  }

  private final void refill() throws IOException {
    int newPosition = bufferLength - tokenStart;

    if (tokenStart == 0) {			  
      if (buffer == null) {			  
	buffer = new char[2048];
      } else if (bufferLength == buffer.length) { 
	char[] newBuffer = new char[buffer.length*2];
	System.arraycopy(buffer, 0, newBuffer, 0, bufferLength);
	buffer = newBuffer;
      }
    } else {					  
      System.arraycopy(buffer, tokenStart, buffer, 0, newPosition);
    }

    bufferLength = newPosition;			  
    bufferPosition = newPosition;
    bufferStart += tokenStart;
    tokenStart = 0;

    int charsRead =				  
      input.read(buffer, newPosition, buffer.length-newPosition);
    if (charsRead == -1)
      throw new IOException(""read past eof"");
    else
      bufferLength += charsRead;
  }

  public final char BeginToken() throws IOException {
    tokenStart = bufferPosition;
    return readChar();
  }

  public final void backup(int amount) {
    bufferPosition -= amount;
  }

  public final String GetImage() {
    return new String(buffer, tokenStart, bufferPosition - tokenStart);
  }

  public final char[] GetSuffix(int len) {
    char[] value = new char[len];
    System.arraycopy(buffer, bufferPosition - len, value, 0, len);
    return value;
  }

  public final void Done() {
    try {
      input.close();
    } catch (IOException e) {
      System.err.println(""Caught: "" + e + ""; ignoring."");
    }
  }

  public final int getColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getLine() {
    return 1;
  }
  public final int getEndColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getEndLine() {
    return 1;
  }
  public final int getBeginColumn() {
    return bufferStart + tokenStart;
  }
  public final int getBeginLine() {
    return 1;
  }
}
"
lucene,2.2,org.apache.lucene.search.WildcardTermEnum,6,3,0,5,20,5,1,4,5,0.825,247,0.0,1,0.722222222,0.333333333,1,4,38.83333333,16,3.6667,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;


public class WildcardTermEnum extends FilteredTermEnum {
  Term searchTerm;
  String field = """";
  String text = """";
  String pre = """";
  int preLen = 0;
  boolean endEnum = false;

  
  public WildcardTermEnum(IndexReader reader, Term term) throws IOException {
    super();
    searchTerm = term;
    field = searchTerm.field();
    text = searchTerm.text();

    int sidx = text.indexOf(WILDCARD_STRING);
    int cidx = text.indexOf(WILDCARD_CHAR);
    int idx = sidx;
    if (idx == -1) {
      idx = cidx;
    }
    else if (cidx >= 0) {
      idx = Math.min(idx, cidx);
    }

    pre = searchTerm.text().substring(0,idx);
    preLen = pre.length();
    text = text.substring(preLen);
    setEnum(reader.terms(new Term(searchTerm.field(), pre)));
  }

  protected final boolean termCompare(Term term) {
    if (field == term.field()) {
      String searchText = term.text();
      if (searchText.startsWith(pre)) {
        return wildcardEquals(text, 0, searchText, preLen);
      }
    }
    endEnum = true;
    return false;
  }

  public final float difference() {
    return 1.0f;
  }

  public final boolean endEnum() {
    return endEnum;
  }

  

  public static final char WILDCARD_STRING = '*';
  public static final char WILDCARD_CHAR = '?';

  
  public static final boolean wildcardEquals(String pattern, int patternIdx,
    String string, int stringIdx)
  {
    int p = patternIdx;
    
    for (int s = stringIdx; ; ++p, ++s)
      {
        
        boolean sEnd = (s >= string.length());
        
        boolean pEnd = (p >= pattern.length());

        
        if (sEnd)
        {
          
          boolean justWildcardsLeft = true;

          
          int wildcardSearchPos = p;
          
          
          while (wildcardSearchPos < pattern.length() && justWildcardsLeft)
          {
            
            char wildchar = pattern.charAt(wildcardSearchPos);
            
            
            
            if (wildchar != WILDCARD_CHAR && wildchar != WILDCARD_STRING)
            {
              justWildcardsLeft = false;
            }
            else
            {
              
              if (wildchar == WILDCARD_CHAR) {
                return false;
              }
              
              
              wildcardSearchPos++;
            }
          }

          
          
          if (justWildcardsLeft)
          {
            return true;
          }
        }

        
        
        if (sEnd || pEnd)
        {
          break;
        }

        
        if (pattern.charAt(p) == WILDCARD_CHAR)
        {
          continue;
        }

        
        if (pattern.charAt(p) == WILDCARD_STRING)
        {
          
          ++p;
          
          for (int i = string.length(); i >= s; --i)
          {
            if (wildcardEquals(pattern, p, string, i))
            {
              return true;
            }
          }
          break;
        }
        if (pattern.charAt(p) != string.charAt(s))
        {
          break;
        }
      }
      return false;
  }

  public void close() throws IOException
  {
    super.close();
    searchTerm = null;
    field = null;
    text = null;
  }
}
"
lucene,2.2,org.apache.lucene.store.LockObtainFailedException,1,4,0,5,2,0,5,0,1,2.0,5,0.0,0,1.0,1.0,0,0,4.0,0,0.0,0,"

package org.apache.lucene.store;

import java.io.IOException;


public class LockObtainFailedException extends IOException {
  public LockObtainFailedException(String message) {
    super(message);
  }
}
"
lucene,2.2,org.apache.lucene.search.Sort,14,1,0,12,22,61,11,1,13,0.692307692,175,0.0,3,0.0,0.320512821,0,0,11.28571429,3,0.7143,2,"package org.apache.lucene.search;



import java.io.Serializable;



public class Sort
implements Serializable {

  
  public static final Sort RELEVANCE = new Sort();

  
  public static final Sort INDEXORDER = new Sort(SortField.FIELD_DOC);

  
  SortField[] fields;

  
  public Sort() {
    this(new SortField[] { SortField.FIELD_SCORE, SortField.FIELD_DOC });
  }

  
  public Sort(String field) {
    setSort(field, false);
  }

  
  public Sort(String field, boolean reverse) {
    setSort(field, reverse);
  }

  
  public Sort(String[] fields) {
    setSort(fields);
  }

  
  public Sort(SortField field) {
    setSort(field);
  }

  
  public Sort(SortField[] fields) {
    setSort(fields);
  }

  
  public final void setSort(String field) {
    setSort(field, false);
  }

  
  public void setSort(String field, boolean reverse) {
    SortField[] nfields = new SortField[] {
        new SortField(field, SortField.AUTO, reverse), SortField.FIELD_DOC };
    fields = nfields;
  }

  
  public void setSort(String[] fieldnames) {
    final int n = fieldnames.length;
    SortField[] nfields = new SortField[n];
    for (int i = 0; i < n; ++i) {
      nfields[i] = new SortField(fieldnames[i], SortField.AUTO);
    }
    fields = nfields;
  }

  
  public void setSort(SortField field) {
    this.fields = new SortField[] { field };
  }

  
  public void setSort(SortField[] fields) {
    this.fields = fields;
  }
  
  
  public SortField[] getSort() {
    return fields;
  }

  public String toString() {
    StringBuffer buffer = new StringBuffer();

    for (int i = 0; i < fields.length; i++) {
      buffer.append(fields[i].toString());
      if ((i+1) < fields.length)
        buffer.append(',');
    }

    return buffer.toString();
  }
}
"
lucene,2.2,org.apache.lucene.index.IndexWriter,80,1,0,23,171,1344,4,22,52,0.843178622,2846,0.722222222,10,0.0,0.1005996,0,0,34.125,4,0.9875,47,"package org.apache.lucene.index;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.Lock;
import org.apache.lucene.store.LockObtainFailedException;
import org.apache.lucene.store.AlreadyClosedException;
import org.apache.lucene.store.RAMDirectory;

import java.io.File;
import java.io.IOException;
import java.io.PrintStream;
import java.util.ArrayList;
import java.util.List;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map.Entry;




public class IndexWriter {

  
  public static long WRITE_LOCK_TIMEOUT = 1000;

  private long writeLockTimeout = WRITE_LOCK_TIMEOUT;

  
  public static final String WRITE_LOCK_NAME = ""write.lock"";

  
  public final static int DEFAULT_MERGE_FACTOR = 10;

  
  public final static int DEFAULT_MAX_BUFFERED_DOCS = 10;

  
  public final static int DEFAULT_MAX_BUFFERED_DELETE_TERMS = 1000;

  
  public final static int DEFAULT_MAX_MERGE_DOCS = Integer.MAX_VALUE;

  
  public final static int DEFAULT_MAX_FIELD_LENGTH = 10000;

  
  public final static int DEFAULT_TERM_INDEX_INTERVAL = 128;
  
  
  
  
  
  
  
  private final static int MERGE_READ_BUFFER_SIZE = 4096;

  private Directory directory;  
  private Analyzer analyzer;    

  private Similarity similarity = Similarity.getDefault(); 

  private boolean commitPending; 
  private SegmentInfos rollbackSegmentInfos;      

  private SegmentInfos localRollbackSegmentInfos;      
  private boolean localAutoCommit;                
  private boolean autoCommit = true;              

  SegmentInfos segmentInfos = new SegmentInfos();       
  SegmentInfos ramSegmentInfos = new SegmentInfos();    
  private final RAMDirectory ramDirectory = new RAMDirectory(); 
  private IndexFileDeleter deleter;

  private Lock writeLock;

  private int termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL;

  
  
  private int maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;

  
  
  
  private HashMap bufferedDeleteTerms = new HashMap();
  private int numBufferedDeleteTerms = 0;

  
  private boolean useCompoundFile = true;

  private boolean closeDir;
  private boolean closed;

  
  protected final void ensureOpen() throws AlreadyClosedException {
    if (closed) {
      throw new AlreadyClosedException(""this IndexWriter is closed"");
    }
  }

  
  public boolean getUseCompoundFile() {
    ensureOpen();
    return useCompoundFile;
  }

  
  public void setUseCompoundFile(boolean value) {
    ensureOpen();
    useCompoundFile = value;
  }

  
  public void setSimilarity(Similarity similarity) {
    ensureOpen();
    this.similarity = similarity;
  }

  
  public Similarity getSimilarity() {
    ensureOpen();
    return this.similarity;
  }

  
  public void setTermIndexInterval(int interval) {
    ensureOpen();
    this.termIndexInterval = interval;
  }

  
  public int getTermIndexInterval() {
    ensureOpen();
    return termIndexInterval;
  }

  
  public IndexWriter(String path, Analyzer a, boolean create)
       throws CorruptIndexException, LockObtainFailedException, IOException {
    init(FSDirectory.getDirectory(path), a, create, true, null, true);
  }

  
  public IndexWriter(File path, Analyzer a, boolean create)
       throws CorruptIndexException, LockObtainFailedException, IOException {
    init(FSDirectory.getDirectory(path), a, create, true, null, true);
  }

  
  public IndexWriter(Directory d, Analyzer a, boolean create)
       throws CorruptIndexException, LockObtainFailedException, IOException {
    init(d, a, create, false, null, true);
  }

  
  public IndexWriter(String path, Analyzer a) 
    throws CorruptIndexException, LockObtainFailedException, IOException {
    init(FSDirectory.getDirectory(path), a, true, null, true);
  }

  
  public IndexWriter(File path, Analyzer a) 
    throws CorruptIndexException, LockObtainFailedException, IOException {
    init(FSDirectory.getDirectory(path), a, true, null, true);
  }

  
  public IndexWriter(Directory d, Analyzer a) 
    throws CorruptIndexException, LockObtainFailedException, IOException {
    init(d, a, false, null, true);
  }

  
  public IndexWriter(Directory d, boolean autoCommit, Analyzer a) 
    throws CorruptIndexException, LockObtainFailedException, IOException {
    init(d, a, false, null, autoCommit);
  }

  
  public IndexWriter(Directory d, boolean autoCommit, Analyzer a, boolean create)
       throws CorruptIndexException, LockObtainFailedException, IOException {
    init(d, a, create, false, null, autoCommit);
  }

  
  public IndexWriter(Directory d, boolean autoCommit, Analyzer a, IndexDeletionPolicy deletionPolicy) 
    throws CorruptIndexException, LockObtainFailedException, IOException {
    init(d, a, false, deletionPolicy, autoCommit);
  }

  
  public IndexWriter(Directory d, boolean autoCommit, Analyzer a, boolean create, IndexDeletionPolicy deletionPolicy)
       throws CorruptIndexException, LockObtainFailedException, IOException {
    init(d, a, create, false, deletionPolicy, autoCommit);
  }

  private void init(Directory d, Analyzer a, boolean closeDir, IndexDeletionPolicy deletionPolicy, boolean autoCommit)
    throws CorruptIndexException, LockObtainFailedException, IOException {
    if (IndexReader.indexExists(d)) {
      init(d, a, false, closeDir, deletionPolicy, autoCommit);
    } else {
      init(d, a, true, closeDir, deletionPolicy, autoCommit);
    }
  }

  private void init(Directory d, Analyzer a, final boolean create, boolean closeDir, IndexDeletionPolicy deletionPolicy, boolean autoCommit)
    throws CorruptIndexException, LockObtainFailedException, IOException {
    this.closeDir = closeDir;
    directory = d;
    analyzer = a;
    this.infoStream = defaultInfoStream;

    if (create) {
      
      directory.clearLock(IndexWriter.WRITE_LOCK_NAME);
    }

    Lock writeLock = directory.makeLock(IndexWriter.WRITE_LOCK_NAME);
    if (!writeLock.obtain(writeLockTimeout)) 
      throw new LockObtainFailedException(""Index locked for write: "" + writeLock);
    this.writeLock = writeLock;                   

    try {
      if (create) {
        
        
        
        
        try {
          segmentInfos.read(directory);
          segmentInfos.clear();
        } catch (IOException e) {
          
        }
        segmentInfos.write(directory);
      } else {
        segmentInfos.read(directory);
      }

      this.autoCommit = autoCommit;
      if (!autoCommit) {
        rollbackSegmentInfos = (SegmentInfos) segmentInfos.clone();
      }

      
      
      deleter = new IndexFileDeleter(directory,
                                     deletionPolicy == null ? new KeepOnlyLastCommitDeletionPolicy() : deletionPolicy,
                                     segmentInfos, infoStream);

    } catch (IOException e) {
      this.writeLock.release();
      this.writeLock = null;
      throw e;
    }
  }

  
  public void setMaxMergeDocs(int maxMergeDocs) {
    ensureOpen();
    this.maxMergeDocs = maxMergeDocs;
  }

  
  public int getMaxMergeDocs() {
    ensureOpen();
    return maxMergeDocs;
  }

  
  public void setMaxFieldLength(int maxFieldLength) {
    ensureOpen();
    this.maxFieldLength = maxFieldLength;
  }

  
  public int getMaxFieldLength() {
    ensureOpen();
    return maxFieldLength;
  }

  
  public void setMaxBufferedDocs(int maxBufferedDocs) {
    ensureOpen();
    if (maxBufferedDocs < 2)
      throw new IllegalArgumentException(""maxBufferedDocs must at least be 2"");
    this.minMergeDocs = maxBufferedDocs;
  }

  
  public int getMaxBufferedDocs() {
    ensureOpen();
    return minMergeDocs;
  }

  
  public void setMaxBufferedDeleteTerms(int maxBufferedDeleteTerms) {
    ensureOpen();
    if (maxBufferedDeleteTerms < 1)
      throw new IllegalArgumentException(""maxBufferedDeleteTerms must at least be 1"");
    this.maxBufferedDeleteTerms = maxBufferedDeleteTerms;
  }

  
  public int getMaxBufferedDeleteTerms() {
    ensureOpen();
    return maxBufferedDeleteTerms;
  }

  
  public void setMergeFactor(int mergeFactor) {
    ensureOpen();
    if (mergeFactor < 2)
      throw new IllegalArgumentException(""mergeFactor cannot be less than 2"");
    this.mergeFactor = mergeFactor;
  }

  
  public int getMergeFactor() {
    ensureOpen();
    return mergeFactor;
  }

  
  public static void setDefaultInfoStream(PrintStream infoStream) {
    IndexWriter.defaultInfoStream = infoStream;
  }

  
  public static PrintStream getDefaultInfoStream() {
    return IndexWriter.defaultInfoStream;
  }

  
  public void setInfoStream(PrintStream infoStream) {
    ensureOpen();
    this.infoStream = infoStream;
    deleter.setInfoStream(infoStream);
  }

  
  public PrintStream getInfoStream() {
    ensureOpen();
    return infoStream;
  }

  
  public void setWriteLockTimeout(long writeLockTimeout) {
    ensureOpen();
    this.writeLockTimeout = writeLockTimeout;
  }

  
  public long getWriteLockTimeout() {
    ensureOpen();
    return writeLockTimeout;
  }

  
  public static void setDefaultWriteLockTimeout(long writeLockTimeout) {
    IndexWriter.WRITE_LOCK_TIMEOUT = writeLockTimeout;
  }

  
  public static long getDefaultWriteLockTimeout() {
    return IndexWriter.WRITE_LOCK_TIMEOUT;
  }

  
  public synchronized void close() throws CorruptIndexException, IOException {
    if (!closed) {
      flushRamSegments();

      if (commitPending) {
        segmentInfos.write(directory);         
        deleter.checkpoint(segmentInfos, true);
        commitPending = false;
        rollbackSegmentInfos = null;
      }

      ramDirectory.close();
      if (writeLock != null) {
        writeLock.release();                          
        writeLock = null;
      }
      closed = true;

      if(closeDir)
        directory.close();
    }
  }

  
  protected void finalize() throws Throwable {
    try {
      if (writeLock != null) {
        writeLock.release();                        
        writeLock = null;
      }
    } finally {
      super.finalize();
    }
  }

  
  public Directory getDirectory() {
    ensureOpen();
    return directory;
  }

  
  public Analyzer getAnalyzer() {
    ensureOpen();
    return analyzer;
  }


  
  public synchronized int docCount() {
    ensureOpen();
    int count = ramSegmentInfos.size();
    for (int i = 0; i < segmentInfos.size(); i++) {
      SegmentInfo si = segmentInfos.info(i);
      count += si.docCount;
    }
    return count;
  }

  
  private int maxFieldLength = DEFAULT_MAX_FIELD_LENGTH;

  
  public void addDocument(Document doc) throws CorruptIndexException, IOException {
    addDocument(doc, analyzer);
  }

  
  public void addDocument(Document doc, Analyzer analyzer) throws CorruptIndexException, IOException {
    ensureOpen();
    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);
    synchronized (this) {
      ramSegmentInfos.addElement(newSegmentInfo);
      maybeFlushRamSegments();
    }
  }

  SegmentInfo buildSingleDocSegment(Document doc, Analyzer analyzer)
      throws CorruptIndexException, IOException {
    DocumentWriter dw = new DocumentWriter(ramDirectory, analyzer, this);
    dw.setInfoStream(infoStream);
    String segmentName = newRamSegmentName();
    dw.addDocument(segmentName, doc);
    SegmentInfo si = new SegmentInfo(segmentName, 1, ramDirectory, false, false);
    si.setNumFields(dw.getNumFields());
    return si;
  }

  
  public synchronized void deleteDocuments(Term term) throws CorruptIndexException, IOException {
    ensureOpen();
    bufferDeleteTerm(term);
    maybeFlushRamSegments();
  }

  
  public synchronized void deleteDocuments(Term[] terms) throws CorruptIndexException, IOException {
    ensureOpen();
    for (int i = 0; i < terms.length; i++) {
      bufferDeleteTerm(terms[i]);
    }
    maybeFlushRamSegments();
  }

  
  public void updateDocument(Term term, Document doc) throws CorruptIndexException, IOException {
    ensureOpen();
    updateDocument(term, doc, getAnalyzer());
  }

  
  public void updateDocument(Term term, Document doc, Analyzer analyzer)
      throws CorruptIndexException, IOException {
    ensureOpen();
    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);
    synchronized (this) {
      bufferDeleteTerm(term);
      ramSegmentInfos.addElement(newSegmentInfo);
      maybeFlushRamSegments();
    }
  }

  final synchronized String newRamSegmentName() {
    return ""_ram_"" + Integer.toString(ramSegmentInfos.counter++, Character.MAX_RADIX);
  }

  
  final synchronized int getSegmentCount(){
    return segmentInfos.size();
  }

  
  final synchronized int getRamSegmentCount(){
    return ramSegmentInfos.size();
  }

  
  final synchronized int getDocCount(int i) {
    if (i >= 0 && i < segmentInfos.size()) {
      return segmentInfos.info(i).docCount;
    } else {
      return -1;
    }
  }

  final synchronized String newSegmentName() {
    return ""_"" + Integer.toString(segmentInfos.counter++, Character.MAX_RADIX);
  }

  
  private int mergeFactor = DEFAULT_MERGE_FACTOR;

  
  private int minMergeDocs = DEFAULT_MAX_BUFFERED_DOCS;


  
  private int maxMergeDocs = DEFAULT_MAX_MERGE_DOCS;

  
  private PrintStream infoStream = null;
  private static PrintStream defaultInfoStream = null;

  
  public synchronized void optimize() throws CorruptIndexException, IOException {
    ensureOpen();
    flushRamSegments();
    while (segmentInfos.size() > 1 ||
           (segmentInfos.size() == 1 &&
            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||
             SegmentReader.hasSeparateNorms(segmentInfos.info(0)) ||
             segmentInfos.info(0).dir != directory ||
             (useCompoundFile &&
              (!SegmentReader.usesCompoundFile(segmentInfos.info(0))))))) {
      int minSegment = segmentInfos.size() - mergeFactor;
      mergeSegments(segmentInfos, minSegment < 0 ? 0 : minSegment, segmentInfos.size());
    }
  }

  
  private void startTransaction() throws IOException {
    localRollbackSegmentInfos = (SegmentInfos) segmentInfos.clone();
    localAutoCommit = autoCommit;
    if (localAutoCommit) {
      flushRamSegments();
      
      autoCommit = false;
    } else
      
      
      deleter.incRef(segmentInfos, false);
  }

  
  private void rollbackTransaction() throws IOException {

    
    autoCommit = localAutoCommit;

    
    
    
    
    segmentInfos.clear();
    segmentInfos.addAll(localRollbackSegmentInfos);
    localRollbackSegmentInfos = null;

    
    
    deleter.checkpoint(segmentInfos, false);

    if (!autoCommit)
      
      deleter.decRef(segmentInfos);

    deleter.refresh();
  }

  
  private void commitTransaction() throws IOException {

    
    autoCommit = localAutoCommit;

    boolean success = false;
    try {
      checkpoint();
      success = true;
    } finally {
      if (!success) {
        rollbackTransaction();
      }
    }

    if (!autoCommit)
      
      deleter.decRef(localRollbackSegmentInfos);

    localRollbackSegmentInfos = null;

    
    deleter.checkpoint(segmentInfos, autoCommit);
  }

  
  public synchronized void abort() throws IOException {
    ensureOpen();
    if (!autoCommit) {

      
      
      
      
      segmentInfos.clear();
      segmentInfos.addAll(rollbackSegmentInfos);

      
      
      deleter.checkpoint(segmentInfos, false);
      deleter.refresh();

      ramSegmentInfos = new SegmentInfos();
      bufferedDeleteTerms.clear();
      numBufferedDeleteTerms = 0;

      commitPending = false;
      close();

    } else {
      throw new IllegalStateException(""abort() can only be called when IndexWriter was opened with autoCommit=false"");
    }
  }
 
  
  private void checkpoint() throws IOException {
    if (autoCommit) {
      segmentInfos.write(directory);
    } else {
      commitPending = true;
    }
  }

  
  public synchronized void addIndexes(Directory[] dirs)
    throws CorruptIndexException, IOException {

    ensureOpen();
    optimize();					  

    int start = segmentInfos.size();

    boolean success = false;

    startTransaction();

    try {
      for (int i = 0; i < dirs.length; i++) {
        SegmentInfos sis = new SegmentInfos();	  
        sis.read(dirs[i]);
        for (int j = 0; j < sis.size(); j++) {
          segmentInfos.addElement(sis.info(j));	  
        }
      }

      
      while (segmentInfos.size() > start+mergeFactor) {
        for (int base = start; base < segmentInfos.size(); base++) {
          int end = Math.min(segmentInfos.size(), base+mergeFactor);
          if (end-base > 1) {
            mergeSegments(segmentInfos, base, end);
          }
        }
      }
      success = true;
    } finally {
      if (success) {
        commitTransaction();
      } else {
        rollbackTransaction();
      }
    }

    optimize();					  
  }

  
  public synchronized void addIndexesNoOptimize(Directory[] dirs)
      throws CorruptIndexException, IOException {
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    

    ensureOpen();
    flushRamSegments();

    
    int startUpperBound = minMergeDocs;

    boolean success = false;

    startTransaction();

    try {

      for (int i = 0; i < dirs.length; i++) {
        if (directory == dirs[i]) {
          
          throw new IllegalArgumentException(""Cannot add this index to itself"");
        }

        SegmentInfos sis = new SegmentInfos(); 
        sis.read(dirs[i]);
        for (int j = 0; j < sis.size(); j++) {
          SegmentInfo info = sis.info(j);
          segmentInfos.addElement(info); 
          
          while (startUpperBound < info.docCount) {
            startUpperBound *= mergeFactor; 
            if (startUpperBound > maxMergeDocs) {
              
              throw new IllegalArgumentException(""Upper bound cannot exceed maxMergeDocs"");
            }
          }
        }
      }

      
      maybeMergeSegments(startUpperBound);

      
      int segmentCount = segmentInfos.size();
      int numTailSegments = 0;
      while (numTailSegments < segmentCount
             && startUpperBound >= segmentInfos.info(segmentCount - 1 - numTailSegments).docCount) {
        numTailSegments++;
      }
      if (numTailSegments == 0) {
        success = true;
        return;
      }

      
      if (checkNonDecreasingLevels(segmentCount - numTailSegments)) {
        
        int numSegmentsToCopy = 0;
        while (numSegmentsToCopy < segmentCount
               && directory != segmentInfos.info(segmentCount - 1 - numSegmentsToCopy).dir) {
          numSegmentsToCopy++;
        }
        if (numSegmentsToCopy == 0) {
          success = true;
          return;
        }

        
        for (int i = segmentCount - numSegmentsToCopy; i < segmentCount; i++) {
          mergeSegments(segmentInfos, i, i + 1);
        }
        if (checkNonDecreasingLevels(segmentCount - numSegmentsToCopy)) {
          success = true;
          return;
        }
      }

      
      mergeSegments(segmentInfos, segmentCount - numTailSegments, segmentCount);

      
      if (segmentInfos.info(segmentInfos.size() - 1).docCount > startUpperBound) {
        maybeMergeSegments(startUpperBound * mergeFactor);
      }

      success = true;
    } finally {
      if (success) {
        commitTransaction();
      } else {
        rollbackTransaction();
      }
    }
  }

  
  public synchronized void addIndexes(IndexReader[] readers)
    throws CorruptIndexException, IOException {

    ensureOpen();
    optimize();					  

    final String mergedName = newSegmentName();
    SegmentMerger merger = new SegmentMerger(this, mergedName);

    SegmentInfo info;

    IndexReader sReader = null;
    try {
      if (segmentInfos.size() == 1){ 
        sReader = SegmentReader.get(segmentInfos.info(0));
        merger.add(sReader);
      }

      for (int i = 0; i < readers.length; i++)      
        merger.add(readers[i]);

      boolean success = false;

      startTransaction();

      try {
        int docCount = merger.merge();                

        if(sReader != null) {
          sReader.close();
          sReader = null;
        }

        segmentInfos.setSize(0);                      
        info = new SegmentInfo(mergedName, docCount, directory, false, true);
        segmentInfos.addElement(info);

        success = true;

      } finally {
        if (!success) {
          rollbackTransaction();
        } else {
          commitTransaction();
        }
      }
    } finally {
      if (sReader != null) {
        sReader.close();
      }
    }
    
    if (useCompoundFile) {

      boolean success = false;

      startTransaction();

      try {
        merger.createCompoundFile(mergedName + "".cfs"");
        info.setUseCompoundFile(true);
      } finally {
        if (!success) {
          rollbackTransaction();
        } else {
          commitTransaction();
        }
      }
    }
  }

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  
  
  void doAfterFlush()
    throws IOException {
  }

  
  protected final void maybeFlushRamSegments() throws CorruptIndexException, IOException {
    
    
    if (ramSegmentInfos.size() >= minMergeDocs || numBufferedDeleteTerms >= maxBufferedDeleteTerms) {
      flushRamSegments();
    }
  }

  
  private final synchronized void flushRamSegments() throws CorruptIndexException, IOException {
    flushRamSegments(true);
  }
    
  
  protected final synchronized void flushRamSegments(boolean triggerMerge) 
      throws CorruptIndexException, IOException {
    if (ramSegmentInfos.size() > 0 || bufferedDeleteTerms.size() > 0) {
      mergeSegments(ramSegmentInfos, 0, ramSegmentInfos.size());
      if (triggerMerge) maybeMergeSegments(minMergeDocs);
    }
  }
  
  
  public final synchronized void flush() throws CorruptIndexException, IOException {
    ensureOpen();
    flushRamSegments();
  }

  
  public final long ramSizeInBytes() {
    ensureOpen();
    return ramDirectory.sizeInBytes();
  }

  
  public final synchronized int numRamDocs() {
    ensureOpen();
    return ramSegmentInfos.size();
  }
  
  
  private final void maybeMergeSegments(int startUpperBound) throws CorruptIndexException, IOException {
    long lowerBound = -1;
    long upperBound = startUpperBound;

    while (upperBound < maxMergeDocs) {
      int minSegment = segmentInfos.size();
      int maxSegment = -1;

      
      while (--minSegment >= 0) {
        SegmentInfo si = segmentInfos.info(minSegment);

        if (maxSegment == -1 && si.docCount > lowerBound && si.docCount <= upperBound) {
          
          maxSegment = minSegment;
        } else if (si.docCount > upperBound) {
          
          break;
        }
      }

      minSegment++;
      maxSegment++;
      int numSegments = maxSegment - minSegment;

      if (numSegments < mergeFactor) {
        break;
      } else {
        boolean exceedsUpperLimit = false;

        
        
        while (numSegments >= mergeFactor) {
          

          int docCount = mergeSegments(segmentInfos, minSegment, minSegment + mergeFactor);
          numSegments -= mergeFactor;

          if (docCount > upperBound) {
            
            minSegment++;
            exceedsUpperLimit = true;
          } else {
            
            
            numSegments++;
          }
        }

        if (!exceedsUpperLimit) {
          
          break;
        }
      }

      lowerBound = upperBound;
      upperBound *= mergeFactor;
    }
  }

  
  private final int mergeSegments(SegmentInfos sourceSegments, int minSegment, int end)
    throws CorruptIndexException, IOException {

    
    
    boolean doMerge = end > 0;
    final String mergedName = newSegmentName();
    SegmentMerger merger = null;

    final List ramSegmentsToDelete = new ArrayList();

    SegmentInfo newSegment = null;

    int mergedDocCount = 0;
    boolean anyDeletes = (bufferedDeleteTerms.size() != 0);

    
    try {

      if (doMerge) {
        if (infoStream != null) infoStream.print(""merging segments"");
        merger = new SegmentMerger(this, mergedName);

        for (int i = minSegment; i < end; i++) {
          SegmentInfo si = sourceSegments.info(i);
          if (infoStream != null)
            infoStream.print("" "" + si.name + "" ("" + si.docCount + "" docs)"");
          IndexReader reader = SegmentReader.get(si, MERGE_READ_BUFFER_SIZE); 
          merger.add(reader);
          if (reader.directory() == this.ramDirectory) {
            ramSegmentsToDelete.add(si);
          }
        }
      }

      SegmentInfos rollback = null;
      boolean success = false;

      
      
      try {

        if (doMerge) {
          mergedDocCount = merger.merge();

          if (infoStream != null) {
            infoStream.println("" into ""+mergedName+"" (""+mergedDocCount+"" docs)"");
          }

          newSegment = new SegmentInfo(mergedName, mergedDocCount,
                                       directory, false, true);
        }
        
        if (sourceSegments != ramSegmentInfos || anyDeletes) {
          
          
          rollback = (SegmentInfos) segmentInfos.clone();
        }

        if (doMerge) {
          if (sourceSegments == ramSegmentInfos) {
            segmentInfos.addElement(newSegment);
          } else {
            for (int i = end-1; i > minSegment; i--)     
              sourceSegments.remove(i);

            segmentInfos.set(minSegment, newSegment);
          }
        }

        if (sourceSegments == ramSegmentInfos) {
          maybeApplyDeletes(doMerge);
          doAfterFlush();
        }
        
        checkpoint();

        success = true;

      } finally {

        if (success) {
          
          
          
          if (sourceSegments == ramSegmentInfos) {
            ramSegmentInfos.removeAllElements();
          }
        } else {

          
          if (sourceSegments == ramSegmentInfos && !anyDeletes) {
            
            
            
            if (newSegment != null && 
                segmentInfos.size() > 0 && 
                segmentInfos.info(segmentInfos.size()-1) == newSegment) {
              segmentInfos.remove(segmentInfos.size()-1);
            }
          } else if (rollback != null) {
            
            
            
            
            segmentInfos.clear();
            segmentInfos.addAll(rollback);
          }

          
          deleter.refresh();
        }
      }
    } finally {
      
      if (doMerge) merger.closeReaders();
    }

    
    deleter.deleteDirect(ramDirectory, ramSegmentsToDelete);

    
    deleter.checkpoint(segmentInfos, autoCommit);

    if (useCompoundFile && doMerge) {

      boolean success = false;

      try {

        merger.createCompoundFile(mergedName + "".cfs"");
        newSegment.setUseCompoundFile(true);
        checkpoint();
        success = true;

      } finally {
        if (!success) {  
          
          newSegment.setUseCompoundFile(false);
          deleter.refresh();
        }
      }
      
      
      deleter.checkpoint(segmentInfos, autoCommit);
    }

    return mergedDocCount;
  }

  
  
  
  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {

    if (bufferedDeleteTerms.size() > 0) {
      if (infoStream != null)
        infoStream.println(""flush "" + numBufferedDeleteTerms + "" buffered deleted terms on ""
                           + segmentInfos.size() + "" segments."");

      if (doMerge) {
        IndexReader reader = null;
        try {
          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));

          
          
          
          applyDeletesSelectively(bufferedDeleteTerms, reader);
        } finally {
          if (reader != null) {
            try {
              reader.doCommit();
            } finally {
              reader.doClose();
            }
          }
        }
      }

      int infosEnd = segmentInfos.size();
      if (doMerge) {
        infosEnd--;
      }

      for (int i = 0; i < infosEnd; i++) {
        IndexReader reader = null;
        try {
          reader = SegmentReader.get(segmentInfos.info(i));

          
          
          applyDeletes(bufferedDeleteTerms, reader);
        } finally {
          if (reader != null) {
            try {
              reader.doCommit();
            } finally {
              reader.doClose();
            }
          }
        }
      }

      
      bufferedDeleteTerms.clear();
      numBufferedDeleteTerms = 0;
    }
  }

  private final boolean checkNonDecreasingLevels(int start) {
    int lowerBound = -1;
    int upperBound = minMergeDocs;

    for (int i = segmentInfos.size() - 1; i >= start; i--) {
      int docCount = segmentInfos.info(i).docCount;
      if (docCount <= lowerBound) {
        return false;
      }

      while (docCount > upperBound) {
        lowerBound = upperBound;
        upperBound *= mergeFactor;
      }
    }
    return true;
  }

  
  final synchronized int getBufferedDeleteTermsSize() {
    return bufferedDeleteTerms.size();
  }

  
  final synchronized int getNumBufferedDeleteTerms() {
    return numBufferedDeleteTerms;
  }

  
  private static class Num {
    private int num;

    Num(int num) {
      this.num = num;
    }

    int getNum() {
      return num;
    }

    void setNum(int num) {
      this.num = num;
    }
  }

  
  
  
  
  private void bufferDeleteTerm(Term term) {
    Num num = (Num) bufferedDeleteTerms.get(term);
    if (num == null) {
      bufferedDeleteTerms.put(term, new Num(ramSegmentInfos.size()));
    } else {
      num.setNum(ramSegmentInfos.size());
    }
    numBufferedDeleteTerms++;
  }

  
  
  
  private final void applyDeletesSelectively(HashMap deleteTerms,
      IndexReader reader) throws CorruptIndexException, IOException {
    Iterator iter = deleteTerms.entrySet().iterator();
    while (iter.hasNext()) {
      Entry entry = (Entry) iter.next();
      Term term = (Term) entry.getKey();

      TermDocs docs = reader.termDocs(term);
      if (docs != null) {
        int num = ((Num) entry.getValue()).getNum();
        try {
          while (docs.next()) {
            int doc = docs.doc();
            if (doc >= num) {
              break;
            }
            reader.deleteDocument(doc);
          }
        } finally {
          docs.close();
        }
      }
    }
  }

  
  private final void applyDeletes(HashMap deleteTerms, IndexReader reader)
      throws CorruptIndexException, IOException {
    Iterator iter = deleteTerms.entrySet().iterator();
    while (iter.hasNext()) {
      Entry entry = (Entry) iter.next();
      reader.deleteDocuments((Term) entry.getKey());
    }
  }
}
"
lucene,2.2,org.apache.lucene.index.TermInfosReader,17,1,0,9,35,72,2,7,4,0.65,474,1.0,6,0.0,0.31372549,0,0,26.29411765,4,1.1176,4,"package org.apache.lucene.index;



import java.io.IOException;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.BufferedIndexInput;



final class TermInfosReader {
  private Directory directory;
  private String segment;
  private FieldInfos fieldInfos;

  private ThreadLocal enumerators = new ThreadLocal();
  private SegmentTermEnum origEnum;
  private long size;

  private Term[] indexTerms = null;
  private TermInfo[] indexInfos;
  private long[] indexPointers;
  
  private SegmentTermEnum indexEnum;

  TermInfosReader(Directory dir, String seg, FieldInfos fis)
       throws CorruptIndexException, IOException {
    this(dir, seg, fis, BufferedIndexInput.BUFFER_SIZE);
  }

  TermInfosReader(Directory dir, String seg, FieldInfos fis, int readBufferSize)
       throws CorruptIndexException, IOException {
    directory = dir;
    segment = seg;
    fieldInfos = fis;

    origEnum = new SegmentTermEnum(directory.openInput(segment + "".tis"", readBufferSize),
                                   fieldInfos, false);
    size = origEnum.size;

    indexEnum =
      new SegmentTermEnum(directory.openInput(segment + "".tii"", readBufferSize),
			  fieldInfos, true);
  }

  public int getSkipInterval() {
    return origEnum.skipInterval;
  }
  
  public int getMaxSkipLevels() {
    return origEnum.maxSkipLevels;
  }
  
  final void close() throws IOException {
    if (origEnum != null)
      origEnum.close();
    if (indexEnum != null)
      indexEnum.close();
    enumerators.set(null);
  }

  
  final long size() {
    return size;
  }

  private SegmentTermEnum getEnum() {
    SegmentTermEnum termEnum = (SegmentTermEnum)enumerators.get();
    if (termEnum == null) {
      termEnum = terms();
      enumerators.set(termEnum);
    }
    return termEnum;
  }

  private synchronized void ensureIndexIsRead() throws IOException {
    if (indexTerms != null)                       
      return;                                     
    try {
      int indexSize = (int)indexEnum.size;        

      indexTerms = new Term[indexSize];
      indexInfos = new TermInfo[indexSize];
      indexPointers = new long[indexSize];
        
      for (int i = 0; indexEnum.next(); i++) {
        indexTerms[i] = indexEnum.term();
        indexInfos[i] = indexEnum.termInfo();
        indexPointers[i] = indexEnum.indexPointer;
      }
    } finally {
        indexEnum.close();
        indexEnum = null;
    }
  }

  
  private final int getIndexOffset(Term term) {
    int lo = 0;					  
    int hi = indexTerms.length - 1;

    while (hi >= lo) {
      int mid = (lo + hi) >> 1;
      int delta = term.compareTo(indexTerms[mid]);
      if (delta < 0)
	hi = mid - 1;
      else if (delta > 0)
	lo = mid + 1;
      else
	return mid;
    }
    return hi;
  }

  private final void seekEnum(int indexOffset) throws IOException {
    getEnum().seek(indexPointers[indexOffset],
	      (indexOffset * getEnum().indexInterval) - 1,
	      indexTerms[indexOffset], indexInfos[indexOffset]);
  }

  
  TermInfo get(Term term) throws IOException {
    if (size == 0) return null;

    ensureIndexIsRead();

    
    SegmentTermEnum enumerator = getEnum();
    if (enumerator.term() != null                 
	&& ((enumerator.prev() != null && term.compareTo(enumerator.prev())> 0)
	    || term.compareTo(enumerator.term()) >= 0)) {
      int enumOffset = (int)(enumerator.position/enumerator.indexInterval)+1;
      if (indexTerms.length == enumOffset	  
	  || term.compareTo(indexTerms[enumOffset]) < 0)
	return scanEnum(term);			  
    }

    
    seekEnum(getIndexOffset(term));
    return scanEnum(term);
  }

  
  private final TermInfo scanEnum(Term term) throws IOException {
    SegmentTermEnum enumerator = getEnum();
    enumerator.scanTo(term);
    if (enumerator.term() != null && term.compareTo(enumerator.term()) == 0)
      return enumerator.termInfo();
    else
      return null;
  }

  
  final Term get(int position) throws IOException {
    if (size == 0) return null;

    SegmentTermEnum enumerator = getEnum();
    if (enumerator != null && enumerator.term() != null &&
        position >= enumerator.position &&
	position < (enumerator.position + enumerator.indexInterval))
      return scanEnum(position);		  

    seekEnum(position / enumerator.indexInterval); 
    return scanEnum(position);
  }

  private final Term scanEnum(int position) throws IOException {
    SegmentTermEnum enumerator = getEnum();
    while(enumerator.position < position)
      if (!enumerator.next())
	return null;

    return enumerator.term();
  }

  
  final long getPosition(Term term) throws IOException {
    if (size == 0) return -1;

    ensureIndexIsRead();
    int indexOffset = getIndexOffset(term);
    seekEnum(indexOffset);

    SegmentTermEnum enumerator = getEnum();
    while(term.compareTo(enumerator.term()) > 0 && enumerator.next()) {}

    if (term.compareTo(enumerator.term()) == 0)
      return enumerator.position;
    else
      return -1;
  }

  
  public SegmentTermEnum terms() {
    return (SegmentTermEnum)origEnum.clone();
  }

  
  public SegmentTermEnum terms(Term term) throws IOException {
    get(term);
    return (SegmentTermEnum)getEnum().clone();
  }
}
"
lucene,2.2,org.apache.lucene.search.PhraseScorer,13,2,2,9,34,0,2,7,6,0.666666667,345,1.0,4,0.4,0.21978022,1,3,24.84615385,3,1.1538,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.*;


abstract class PhraseScorer extends Scorer {
  private Weight weight;
  protected byte[] norms;
  protected float value;

  private boolean firstTime = true;
  private boolean more = true;
  protected PhraseQueue pq;
  protected PhrasePositions first, last;

  private float freq; 


  PhraseScorer(Weight weight, TermPositions[] tps, int[] offsets, Similarity similarity,
               byte[] norms) {
    super(similarity);
    this.norms = norms;
    this.weight = weight;
    this.value = weight.getValue();

    
    
    
    
    
    for (int i = 0; i < tps.length; i++) {
      PhrasePositions pp = new PhrasePositions(tps[i], offsets[i]);
      if (last != null) {			  
        last.next = pp;
      } else
        first = pp;
      last = pp;
    }

    pq = new PhraseQueue(tps.length);             

  }

  public int doc() { return first.doc; }

  public boolean next() throws IOException {
    if (firstTime) {
      init();
      firstTime = false;
    } else if (more) {
      more = last.next();                         
    }
    return doNext();
  }
  
  
  private boolean doNext() throws IOException {
    while (more) {
      while (more && first.doc < last.doc) {      
        more = first.skipTo(last.doc);            
        firstToLast();                            
      }

      if (more) {
        
        freq = phraseFreq();                      
        if (freq == 0.0f)                         
          more = last.next();                     
        else
          return true;                            
      }
    }
    return false;                                 
  }

  public float score() throws IOException {
    
    float raw = getSimilarity().tf(freq) * value; 
    return raw * Similarity.decodeNorm(norms[first.doc]); 
  }

  public boolean skipTo(int target) throws IOException {
    firstTime = false;
    for (PhrasePositions pp = first; more && pp != null; pp = pp.next) {
      more = pp.skipTo(target);
    }
    if (more)
      sort();                                     
    return doNext();
  }

  
  protected abstract float phraseFreq() throws IOException;

  private void init() throws IOException {
    for (PhrasePositions pp = first; more && pp != null; pp = pp.next) 
      more = pp.next();
    if(more)
      sort();
  }
  
  private void sort() {
    pq.clear();
    for (PhrasePositions pp = first; pp != null; pp = pp.next)
      pq.put(pp);
    pqToList();
  }

  protected final void pqToList() {
    last = first = null;
    while (pq.top() != null) {
      PhrasePositions pp = (PhrasePositions) pq.pop();
      if (last != null) {			  
        last.next = pp;
      } else
        first = pp;
      last = pp;
      pp.next = null;
    }
  }

  protected final void firstToLast() {
    last.next = first;			  
    last = first;
    first = first.next;
    last.next = null;
  }

  public Explanation explain(final int doc) throws IOException {
    Explanation tfExplanation = new Explanation();

    while (next() && doc() < doc) {}

    float phraseFreq = (doc() == doc) ? freq : 0.0f;
    tfExplanation.setValue(getSimilarity().tf(phraseFreq));
    tfExplanation.setDescription(""tf(phraseFreq="" + phraseFreq + "")"");

    return tfExplanation;
  }

  public String toString() { return ""scorer("" + weight + "")""; }

}
"
lucene,2.2,org.apache.lucene.store.MMapDirectory,2,3,0,5,10,1,0,5,2,1.0,48,1.0,0,0.977272727,0.75,1,2,22.5,1,0.5,1,"package org.apache.lucene.store;


 
import java.io.IOException;
import java.io.File;
import java.io.RandomAccessFile;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.channels.FileChannel.MapMode;


public class MMapDirectory extends FSDirectory {

  private static class MMapIndexInput extends IndexInput {

    private ByteBuffer buffer;
    private final long length;

    private MMapIndexInput(RandomAccessFile raf) throws IOException {
        this.length = raf.length();
        this.buffer = raf.getChannel().map(MapMode.READ_ONLY, 0, length);
    }

    public byte readByte() throws IOException {
      return buffer.get();
    }

    public void readBytes(byte[] b, int offset, int len)
      throws IOException {
      buffer.get(b, offset, len);
    }

    public long getFilePointer() {
      return buffer.position();
    }

    public void seek(long pos) throws IOException {
      buffer.position((int)pos);
    }

    public long length() {
      return length;
    }

    public Object clone() {
      MMapIndexInput clone = (MMapIndexInput)super.clone();
      clone.buffer = buffer.duplicate();
      return clone;
    }

    public void close() throws IOException {}
  }

  private static class MultiMMapIndexInput extends IndexInput {
  
    private ByteBuffer[] buffers;
    private int[] bufSizes; 
  
    private final long length;
  
    private int curBufIndex;
    private final int maxBufSize;
  
    private ByteBuffer curBuf; 
    private int curAvail; 
  
    
    public MultiMMapIndexInput(RandomAccessFile raf, int maxBufSize)
      throws IOException {
      this.length = raf.length();
      this.maxBufSize = maxBufSize;
      
      if (maxBufSize <= 0)
        throw new IllegalArgumentException(""Non positive maxBufSize: ""
                                           + maxBufSize);
      
      if ((length / maxBufSize) > Integer.MAX_VALUE)
        throw new IllegalArgumentException
          (""RandomAccessFile too big for maximum buffer size: ""
           + raf.toString());
      
      int nrBuffers = (int) (length / maxBufSize);
      if ((nrBuffers * maxBufSize) < length) nrBuffers++;
      
      this.buffers = new ByteBuffer[nrBuffers];
      this.bufSizes = new int[nrBuffers];
      
      long bufferStart = 0;
      FileChannel rafc = raf.getChannel();
      for (int bufNr = 0; bufNr < nrBuffers; bufNr++) { 
        int bufSize = (length > (bufferStart + maxBufSize))
          ? maxBufSize
          : (int) (length - bufferStart);
        this.buffers[bufNr] = rafc.map(MapMode.READ_ONLY,bufferStart,bufSize);
        this.bufSizes[bufNr] = bufSize;
        bufferStart += bufSize;
      }
      seek(0L);
    }
  
    public byte readByte() throws IOException {
      
      
      if (curAvail == 0) {
        curBufIndex++;
        curBuf = buffers[curBufIndex]; 
        curBuf.position(0);
        curAvail = bufSizes[curBufIndex];
      }
      curAvail--;
      return curBuf.get();
    }
  
    public void readBytes(byte[] b, int offset, int len) throws IOException {
      while (len > curAvail) {
        curBuf.get(b, offset, curAvail);
        len -= curAvail;
        offset += curAvail;
        curBufIndex++;
        curBuf = buffers[curBufIndex]; 
        curBuf.position(0);
        curAvail = bufSizes[curBufIndex];
      }
      curBuf.get(b, offset, len);
      curAvail -= len;
    }
  
    public long getFilePointer() {
      return (curBufIndex * (long) maxBufSize) + curBuf.position();
    }
  
    public void seek(long pos) throws IOException {
      curBufIndex = (int) (pos / maxBufSize);
      curBuf = buffers[curBufIndex];
      int bufOffset = (int) (pos - (curBufIndex * maxBufSize));
      curBuf.position(bufOffset);
      curAvail = bufSizes[curBufIndex] - bufOffset;
    }
  
    public long length() {
      return length;
    }
  
    public Object clone() {
      MultiMMapIndexInput clone = (MultiMMapIndexInput)super.clone();
      clone.buffers = new ByteBuffer[buffers.length];
      
      
      
      for (int bufNr = 0; bufNr < buffers.length; bufNr++) {
        clone.buffers[bufNr] = buffers[bufNr].duplicate();
      }
      try {
        clone.seek(getFilePointer());
      } catch(IOException ioe) {
        RuntimeException newException = new RuntimeException(ioe);
        newException.initCause(ioe);
        throw newException;
      };
      return clone;
    }
  
    public void close() throws IOException {}
  }
  
  private final int MAX_BBUF = Integer.MAX_VALUE;

  public IndexInput openInput(String name) throws IOException {
    File f =  new File(getFile(), name);
    RandomAccessFile raf = new RandomAccessFile(f, ""r"");
    try {
      return (raf.length() <= MAX_BBUF)
             ? (IndexInput) new MMapIndexInput(raf)
             : (IndexInput) new MultiMMapIndexInput(raf, MAX_BBUF);
    } finally {
      raf.close();
    }
  }
}
"
lucene,2.2,org.apache.lucene.document.SetBasedFieldSelector,2,1,0,2,4,0,0,2,2,0.0,33,1.0,0,0.0,0.666666667,0,0,14.5,3,1.5,0,"package org.apache.lucene.document;

import java.util.Set;



public class SetBasedFieldSelector implements FieldSelector {
  
  private Set fieldsToLoad;
  private Set lazyFieldsToLoad;
  
  

  
  public SetBasedFieldSelector(Set fieldsToLoad, Set lazyFieldsToLoad) {
    this.fieldsToLoad = fieldsToLoad;
    this.lazyFieldsToLoad = lazyFieldsToLoad;
  }

  
  public FieldSelectorResult accept(String fieldName) {
    FieldSelectorResult result = FieldSelectorResult.NO_LOAD;
    if (fieldsToLoad.contains(fieldName) == true){
      result = FieldSelectorResult.LOAD;
    }
    if (lazyFieldsToLoad.contains(fieldName) == true){
      result = FieldSelectorResult.LAZY_LOAD;
    }                                           
    return result;
  }
}"
lucene,2.2,org.apache.lucene.search.Explanation,13,1,1,41,21,64,41,0,11,0.611111111,197,1.0,0,0.0,0.292307692,0,0,13.92307692,4,1.4615,0,"package org.apache.lucene.search;



import java.util.ArrayList;


public class Explanation implements java.io.Serializable {
  private float value;                            
  private String description;                     
  private ArrayList details;                      

  public Explanation() {}

  public Explanation(float value, String description) {
    this.value = value;
    this.description = description;
  }

  
  public boolean isMatch() {
    return (0.0f < getValue());
  }


  
  
  public float getValue() { return value; }
  
  public void setValue(float value) { this.value = value; }

  
  public String getDescription() { return description; }
  
  public void setDescription(String description) {
    this.description = description;
  }

  
  protected String getSummary() {
    return getValue() + "" = "" + getDescription();
  }
  
  
  public Explanation[] getDetails() {
    if (details == null)
      return null;
    return (Explanation[])details.toArray(new Explanation[0]);
  }

  
  public void addDetail(Explanation detail) {
    if (details == null)
      details = new ArrayList();
    details.add(detail);
  }

  
  public String toString() {
    return toString(0);
  }
  protected String toString(int depth) {
    StringBuffer buffer = new StringBuffer();
    for (int i = 0; i < depth; i++) {
      buffer.append(""  "");
    }
    buffer.append(getSummary());
    buffer.append(""\n"");

    Explanation[] details = getDetails();
    if (details != null) {
      for (int i = 0 ; i < details.length; i++) {
        buffer.append(details[i].toString(depth+1));
      }
    }

    return buffer.toString();
  }


  
  public String toHtml() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""<ul>\n"");

    buffer.append(""<li>"");
    buffer.append(getSummary());
    buffer.append(""<br />\n"");

    Explanation[] details = getDetails();
    if (details != null) {
      for (int i = 0 ; i < details.length; i++) {
        buffer.append(details[i].toHtml());
      }
    }

    buffer.append(""</li>\n"");
    buffer.append(""</ul>\n"");

    return buffer.toString();
  }
}
"
lucene,2.2,org.apache.lucene.index.FieldReaderException,4,4,0,1,8,6,1,0,4,2.0,20,0.0,0,1.0,0.666666667,0,0,4.0,0,0.0,0,"package org.apache.lucene.index;



public class FieldReaderException extends RuntimeException{
  
  public FieldReaderException() {
  }

  
  public FieldReaderException(Throwable cause) {
    super(cause);
  }

  
  public FieldReaderException(String message) {
    super(message);
  }

  
  public FieldReaderException(String message, Throwable cause) {
    super(message, cause);
  }
}
"
lucene,2.2,org.apache.lucene.index.FieldInfo,1,1,0,8,2,0,8,0,0,2.0,36,0.0,0,0.0,1.0,0,0,27.0,0,0.0,1,"package org.apache.lucene.index;



final class FieldInfo {
  String name;
  boolean isIndexed;
  int number;

  
  boolean storeTermVector;
  boolean storeOffsetWithTermVector;
  boolean storePositionWithTermVector;

  boolean omitNorms; 
  
  boolean storePayloads; 

  FieldInfo(String na, boolean tk, int nu, boolean storeTermVector, 
            boolean storePositionWithTermVector,  boolean storeOffsetWithTermVector, 
            boolean omitNorms, boolean storePayloads) {
    name = na;
    isIndexed = tk;
    number = nu;
    this.storeTermVector = storeTermVector;
    this.storeOffsetWithTermVector = storeOffsetWithTermVector;
    this.storePositionWithTermVector = storePositionWithTermVector;
    this.omitNorms = omitNorms;
    this.storePayloads = storePayloads;
  }
}
"
lucene,2.2,org.apache.lucene.search.HitIterator,5,1,0,2,10,0,1,2,4,0.375,60,1.0,1,0.0,0.6,0,0,10.6,2,1.2,2,"

package org.apache.lucene.search;

import java.util.Iterator;
import java.util.NoSuchElementException;


public class HitIterator implements Iterator {
  private Hits hits;
  private int hitNumber = 0;

  
  HitIterator(Hits hits) {
    this.hits = hits;
  }

  
  public boolean hasNext() {
    return hitNumber < hits.length();
  }

  
  public Object next() {
    if (hitNumber == hits.length())
      throw new NoSuchElementException();

    Object next = new Hit(hits, hitNumber);
    hitNumber++;
    return next;
  }

  
  public void remove() {
    throw new UnsupportedOperationException();
  }

  
  public int length() {
    return hits.length();
  }
}

"
lucene,2.2,org.apache.lucene.search.BooleanScorer2,21,2,0,16,58,104,5,15,10,0.65625,511,1.0,3,0.32,0.2375,1,3,22.95238095,6,1.6667,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Iterator;


class BooleanScorer2 extends Scorer {
  private ArrayList requiredScorers = new ArrayList();
  private ArrayList optionalScorers = new ArrayList();
  private ArrayList prohibitedScorers = new ArrayList();

  private class Coordinator {
    int maxCoord = 0; 
    
    private float[] coordFactors = null;
    
    void init() { 
      coordFactors = new float[maxCoord + 1];
      Similarity sim = getSimilarity();
      for (int i = 0; i <= maxCoord; i++) {
        coordFactors[i] = sim.coord(i, maxCoord);
      }
    }
    
    int nrMatchers; 

    void initDoc() {
      nrMatchers = 0;
    }
    
    float coordFactor() {
      return coordFactors[nrMatchers];
    }
  }

  private final Coordinator coordinator;

  
  private Scorer countingSumScorer = null;

  
  private final int minNrShouldMatch;
  
    
  private boolean allowDocsOutOfOrder;


  
  public BooleanScorer2(Similarity similarity, int minNrShouldMatch, boolean allowDocsOutOfOrder) {
    super(similarity);
    if (minNrShouldMatch < 0) {
      throw new IllegalArgumentException(""Minimum number of optional scorers should not be negative"");
    }
    coordinator = new Coordinator();
    this.minNrShouldMatch = minNrShouldMatch;
    this.allowDocsOutOfOrder = allowDocsOutOfOrder;
  }

  
  public BooleanScorer2(Similarity similarity, int minNrShouldMatch) {
    this(similarity, minNrShouldMatch, false);
  }
  
  
  public BooleanScorer2(Similarity similarity) {
    this(similarity, 0, false);
  }

  public void add(final Scorer scorer, boolean required, boolean prohibited) {
    if (!prohibited) {
      coordinator.maxCoord++;
    }

    if (required) {
      if (prohibited) {
        throw new IllegalArgumentException(""scorer cannot be required and prohibited"");
      }
      requiredScorers.add(scorer);
    } else if (prohibited) {
      prohibitedScorers.add(scorer);
    } else {
      optionalScorers.add(scorer);
    }
  }

  
  private void initCountingSumScorer() {
    coordinator.init();
    countingSumScorer = makeCountingSumScorer();
  }

  
  private class SingleMatchScorer extends Scorer {
    private Scorer scorer;
    private int lastScoredDoc = -1;

    SingleMatchScorer(Scorer scorer) {
      super(scorer.getSimilarity());
      this.scorer = scorer;
    }
    public float score() throws IOException {
      if (this.doc() >= lastScoredDoc) {
        lastScoredDoc = this.doc();
        coordinator.nrMatchers++;
      }
      return scorer.score();
    }
    public int doc() {
      return scorer.doc();
    }
    public boolean next() throws IOException {
      return scorer.next();
    }
    public boolean skipTo(int docNr) throws IOException {
      return scorer.skipTo(docNr);
    }
    public Explanation explain(int docNr) throws IOException {
      return scorer.explain(docNr);
    }
  }

  private Scorer countingDisjunctionSumScorer(final List scorers,
                                              int minNrShouldMatch)
  
  {
    return new DisjunctionSumScorer(scorers, minNrShouldMatch) {
      private int lastScoredDoc = -1;
      public float score() throws IOException {
        if (this.doc() >= lastScoredDoc) {
          lastScoredDoc = this.doc();
          coordinator.nrMatchers += super.nrMatchers;
        }
        return super.score();
      }
    };
  }

  private static Similarity defaultSimilarity = new DefaultSimilarity();

  private Scorer countingConjunctionSumScorer(List requiredScorers) {
    
    final int requiredNrMatchers = requiredScorers.size();
    ConjunctionScorer cs = new ConjunctionScorer(defaultSimilarity) {
      private int lastScoredDoc = -1;

      public float score() throws IOException {
        if (this.doc() >= lastScoredDoc) {
          lastScoredDoc = this.doc();
          coordinator.nrMatchers += requiredNrMatchers;
        }
        
        
        
        
        return super.score();
      }
    };
    Iterator rsi = requiredScorers.iterator();
    while (rsi.hasNext()) {
      cs.add((Scorer) rsi.next());
    }
    return cs;
  }

  private Scorer dualConjunctionSumScorer(Scorer req1, Scorer req2) { 
    ConjunctionScorer cs = new ConjunctionScorer(defaultSimilarity);
    
    
    
    
    cs.add(req1);
    cs.add(req2);
    return cs;
  }

  
  private Scorer makeCountingSumScorer() { 
    return (requiredScorers.size() == 0)
          ? makeCountingSumScorerNoReq()
          : makeCountingSumScorerSomeReq();
  }

  private Scorer makeCountingSumScorerNoReq() { 
    if (optionalScorers.size() == 0) {
      return new NonMatchingScorer(); 
    } else { 
      
      int nrOptRequired = (minNrShouldMatch < 1) ? 1 : minNrShouldMatch;
      if (optionalScorers.size() < nrOptRequired) { 
        return new NonMatchingScorer(); 
      } else { 
        Scorer requiredCountingSumScorer =
              (optionalScorers.size() > nrOptRequired)
              ? countingDisjunctionSumScorer(optionalScorers, nrOptRequired)
              : 
              (optionalScorers.size() == 1)
              ? new SingleMatchScorer((Scorer) optionalScorers.get(0))
              : countingConjunctionSumScorer(optionalScorers);
        return addProhibitedScorers(requiredCountingSumScorer);
      }
    }
  }

  private Scorer makeCountingSumScorerSomeReq() { 
    if (optionalScorers.size() < minNrShouldMatch) {
      return new NonMatchingScorer(); 
    } else if (optionalScorers.size() == minNrShouldMatch) { 
      ArrayList allReq = new ArrayList(requiredScorers);
      allReq.addAll(optionalScorers);
      return addProhibitedScorers(countingConjunctionSumScorer(allReq));
    } else { 
      Scorer requiredCountingSumScorer =
            (requiredScorers.size() == 1)
            ? new SingleMatchScorer((Scorer) requiredScorers.get(0))
            : countingConjunctionSumScorer(requiredScorers);
      if (minNrShouldMatch > 0) { 
        return addProhibitedScorers( 
                      dualConjunctionSumScorer( 
                              requiredCountingSumScorer,
                              countingDisjunctionSumScorer(
                                      optionalScorers,
                                      minNrShouldMatch)));
      } else { 
        return new ReqOptSumScorer(
                      addProhibitedScorers(requiredCountingSumScorer),
                      ((optionalScorers.size() == 1)
                        ? new SingleMatchScorer((Scorer) optionalScorers.get(0))
                        : countingDisjunctionSumScorer(optionalScorers, 1))); 
      }
    }
  }
  
  
  private Scorer addProhibitedScorers(Scorer requiredCountingSumScorer)
  {
    return (prohibitedScorers.size() == 0)
          ? requiredCountingSumScorer 
          : new ReqExclScorer(requiredCountingSumScorer,
                              ((prohibitedScorers.size() == 1)
                                ? (Scorer) prohibitedScorers.get(0)
                                : new DisjunctionSumScorer(prohibitedScorers)));
  }

  
  public void score(HitCollector hc) throws IOException {
    if (allowDocsOutOfOrder && requiredScorers.size() == 0
            && prohibitedScorers.size() < 32) {
      
      BooleanScorer bs = new BooleanScorer(getSimilarity(), minNrShouldMatch);
      Iterator si = optionalScorers.iterator();
      while (si.hasNext()) {
        bs.add((Scorer) si.next(), false , false );
      }
      si = prohibitedScorers.iterator();
      while (si.hasNext()) {
        bs.add((Scorer) si.next(), false , true );
      }
      bs.score(hc);
    } else {
      if (countingSumScorer == null) {
        initCountingSumScorer();
      }
      while (countingSumScorer.next()) {
        hc.collect(countingSumScorer.doc(), score());
      }
    }
  }

  
  protected boolean score(HitCollector hc, int max) throws IOException {
    
    int docNr = countingSumScorer.doc();
    while (docNr < max) {
      hc.collect(docNr, score());
      if (! countingSumScorer.next()) {
        return false;
      }
      docNr = countingSumScorer.doc();
    }
    return true;
  }

  public int doc() { return countingSumScorer.doc(); }

  public boolean next() throws IOException {
    if (countingSumScorer == null) {
      initCountingSumScorer();
    }
    return countingSumScorer.next();
  }

  public float score() throws IOException {
    coordinator.initDoc();
    float sum = countingSumScorer.score();
    return sum * coordinator.coordFactor();
  }

  
  public boolean skipTo(int target) throws IOException {
    if (countingSumScorer == null) {
      initCountingSumScorer();
    }
    return countingSumScorer.skipTo(target);
  }

  
  public Explanation explain(int doc) {
    throw new UnsupportedOperationException();
 
  }
}


"
