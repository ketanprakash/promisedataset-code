name,version,name.1,wmc,dit,noc,cbo,rfc,lcom,ca,ce,npm,lcom3,loc,dam,moa,mfa,cam,ic,cbm,amc,max_cc,avg_cc,bug,code
lucene,2,org.apache.lucene.analysis.WhitespaceAnalyzer,2,2,0,3,4,1,0,3,2,2.0,10,0.0,0,0.666666667,0.666666667,0,0,4.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public final class WhitespaceAnalyzer extends Analyzer {
  public TokenStream tokenStream(String fieldName, Reader reader) {
    return new WhitespaceTokenizer(reader);
  }
}
"
lucene,2,org.apache.lucene.search.QueryTermVector,10,1,0,4,37,0,0,4,9,0.388888889,278,1.0,0,0.0,0.34,0,0,26.6,5,1.6,0,"package org.apache.lucene.search;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.Token;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.index.TermFreqVector;

import java.io.IOException;
import java.io.StringReader;
import java.util.*;


public class QueryTermVector implements TermFreqVector {
  private String [] terms = new String[0];
  private int [] termFreqs = new int[0];

  public String getField() { return null;  }

   
  public QueryTermVector(String [] queryTerms) {

    processTerms(queryTerms);
  }

  public QueryTermVector(String queryString, Analyzer analyzer) {    
    if (analyzer != null)
    {
      TokenStream stream = analyzer.tokenStream("""", new StringReader(queryString));
      if (stream != null)
      {
        Token next = null;
        List terms = new ArrayList();
        try {
          while ((next = stream.next()) != null)
          {
            terms.add(next.termText());
          }
          processTerms((String[])terms.toArray(new String[terms.size()]));
        } catch (IOException e) {
        }
      }
    }                                                              
  }
  
  private void processTerms(String[] queryTerms) {
    if (queryTerms != null) {
      Arrays.sort(queryTerms);
      Map tmpSet = new HashMap(queryTerms.length);
      
      List tmpList = new ArrayList(queryTerms.length);
      List tmpFreqs = new ArrayList(queryTerms.length);
      int j = 0;
      for (int i = 0; i < queryTerms.length; i++) {
        String term = queryTerms[i];
        Integer position = (Integer)tmpSet.get(term);
        if (position == null) {
          tmpSet.put(term, new Integer(j++));
          tmpList.add(term);
          tmpFreqs.add(new Integer(1));
        }       
        else {
          Integer integer = (Integer)tmpFreqs.get(position.intValue());
          tmpFreqs.set(position.intValue(), new Integer(integer.intValue() + 1));          
        }
      }
      terms = (String[])tmpList.toArray(terms);
      
      termFreqs = new int[tmpFreqs.size()];
      int i = 0;
      for (Iterator iter = tmpFreqs.iterator(); iter.hasNext();) {
        Integer integer = (Integer) iter.next();
        termFreqs[i++] = integer.intValue();
      }
    }
  }
  
  public final String toString() {
        StringBuffer sb = new StringBuffer();
        sb.append('{');
        for (int i=0; i<terms.length; i++) {
            if (i>0) sb.append("", "");
            sb.append(terms[i]).append('/').append(termFreqs[i]);
        }
        sb.append('}');
        return sb.toString();
    }
  

  public int size() {
    return terms.length;
  }

  public String[] getTerms() {
    return terms;
  }

  public int[] getTermFrequencies() {
    return termFreqs;
  }

  public int indexOf(String term) {
    int res = Arrays.binarySearch(terms, term);
        return res >= 0 ? res : -1;
  }

  public int[] indexesOf(String[] terms, int start, int len) {
    int res[] = new int[len];

    for (int i=0; i < len; i++) {
        res[i] = indexOf(terms[i]);
    }
    return res;                  
  }

}
"
lucene,2,org.apache.lucene.analysis.PorterStemmer,27,1,0,1,43,13,1,0,13,0.600961538,1174,1.0,0,0.0,0.25308642,0,0,42.18518519,26,5.7407,0,"package org.apache.lucene.analysis;






import java.io.*;



class PorterStemmer
{
  private char[] b;
  private int i,    
    j, k, k0;
  private boolean dirty = false;
  private static final int INC = 50; 
  private static final int EXTRA = 1;

  public PorterStemmer() {
    b = new char[INC];
    i = 0;
  }

  
  public void reset() { i = 0; dirty = false; }

  
  public void add(char ch) {
    if (b.length <= i + EXTRA) {
      char[] new_b = new char[b.length+INC];
      for (int c = 0; c < b.length; c++)
        new_b[c] = b[c];
      b = new_b;
    }
    b[i++] = ch;
  }

  
  public String toString() { return new String(b,0,i); }

  
  public int getResultLength() { return i; }

  
  public char[] getResultBuffer() { return b; }

  

  private final boolean cons(int i) {
    switch (b[i]) {
    case 'a': case 'e': case 'i': case 'o': case 'u':
      return false;
    case 'y':
      return (i==k0) ? true : !cons(i-1);
    default:
      return true;
    }
  }

  

  private final int m() {
    int n = 0;
    int i = k0;
    while(true) {
      if (i > j)
        return n;
      if (! cons(i))
        break;
      i++;
    }
    i++;
    while(true) {
      while(true) {
        if (i > j)
          return n;
        if (cons(i))
          break;
        i++;
      }
      i++;
      n++;
      while(true) {
        if (i > j)
          return n;
        if (! cons(i))
          break;
        i++;
      }
      i++;
    }
  }

  

  private final boolean vowelinstem() {
    int i;
    for (i = k0; i <= j; i++)
      if (! cons(i))
        return true;
    return false;
  }

  

  private final boolean doublec(int j) {
    if (j < k0+1)
      return false;
    if (b[j] != b[j-1])
      return false;
    return cons(j);
  }

  

  private final boolean cvc(int i) {
    if (i < k0+2 || !cons(i) || cons(i-1) || !cons(i-2))
      return false;
    else {
      int ch = b[i];
      if (ch == 'w' || ch == 'x' || ch == 'y') return false;
    }
    return true;
  }

  private final boolean ends(String s) {
    int l = s.length();
    int o = k-l+1;
    if (o < k0)
      return false;
    for (int i = 0; i < l; i++)
      if (b[o+i] != s.charAt(i))
        return false;
    j = k-l;
    return true;
  }

  

  void setto(String s) {
    int l = s.length();
    int o = j+1;
    for (int i = 0; i < l; i++)
      b[o+i] = s.charAt(i);
    k = j+l;
    dirty = true;
  }

  

  void r(String s) { if (m() > 0) setto(s); }

  

  private final void step1() {
    if (b[k] == 's') {
      if (ends(""sses"")) k -= 2;
      else if (ends(""ies"")) setto(""i"");
      else if (b[k-1] != 's') k--;
    }
    if (ends(""eed"")) {
      if (m() > 0)
        k--;
    }
    else if ((ends(""ed"") || ends(""ing"")) && vowelinstem()) {
      k = j;
      if (ends(""at"")) setto(""ate"");
      else if (ends(""bl"")) setto(""ble"");
      else if (ends(""iz"")) setto(""ize"");
      else if (doublec(k)) {
        int ch = b[k--];
        if (ch == 'l' || ch == 's' || ch == 'z')
          k++;
      }
      else if (m() == 1 && cvc(k))
        setto(""e"");
    }
  }

  

  private final void step2() {
    if (ends(""y"") && vowelinstem()) {
      b[k] = 'i';
      dirty = true;
    }
  }

  

  private final void step3() {
    if (k == k0) return; 
    switch (b[k-1]) {
    case 'a':
      if (ends(""ational"")) { r(""ate""); break; }
      if (ends(""tional"")) { r(""tion""); break; }
      break;
    case 'c':
      if (ends(""enci"")) { r(""ence""); break; }
      if (ends(""anci"")) { r(""ance""); break; }
      break;
    case 'e':
      if (ends(""izer"")) { r(""ize""); break; }
      break;
    case 'l':
      if (ends(""bli"")) { r(""ble""); break; }
      if (ends(""alli"")) { r(""al""); break; }
      if (ends(""entli"")) { r(""ent""); break; }
      if (ends(""eli"")) { r(""e""); break; }
      if (ends(""ousli"")) { r(""ous""); break; }
      break;
    case 'o':
      if (ends(""ization"")) { r(""ize""); break; }
      if (ends(""ation"")) { r(""ate""); break; }
      if (ends(""ator"")) { r(""ate""); break; }
      break;
    case 's':
      if (ends(""alism"")) { r(""al""); break; }
      if (ends(""iveness"")) { r(""ive""); break; }
      if (ends(""fulness"")) { r(""ful""); break; }
      if (ends(""ousness"")) { r(""ous""); break; }
      break;
    case 't':
      if (ends(""aliti"")) { r(""al""); break; }
      if (ends(""iviti"")) { r(""ive""); break; }
      if (ends(""biliti"")) { r(""ble""); break; }
      break;
    case 'g':
      if (ends(""logi"")) { r(""log""); break; }
    }
  }

  

  private final void step4() {
    switch (b[k]) {
    case 'e':
      if (ends(""icate"")) { r(""ic""); break; }
      if (ends(""ative"")) { r(""""); break; }
      if (ends(""alize"")) { r(""al""); break; }
      break;
    case 'i':
      if (ends(""iciti"")) { r(""ic""); break; }
      break;
    case 'l':
      if (ends(""ical"")) { r(""ic""); break; }
      if (ends(""ful"")) { r(""""); break; }
      break;
    case 's':
      if (ends(""ness"")) { r(""""); break; }
      break;
    }
  }

  

  private final void step5() {
    if (k == k0) return; 
    switch (b[k-1]) {
    case 'a':
      if (ends(""al"")) break;
      return;
    case 'c':
      if (ends(""ance"")) break;
      if (ends(""ence"")) break;
      return;
    case 'e':
      if (ends(""er"")) break; return;
    case 'i':
      if (ends(""ic"")) break; return;
    case 'l':
      if (ends(""able"")) break;
      if (ends(""ible"")) break; return;
    case 'n':
      if (ends(""ant"")) break;
      if (ends(""ement"")) break;
      if (ends(""ment"")) break;
      
      if (ends(""ent"")) break;
      return;
    case 'o':
      if (ends(""ion"") && j >= 0 && (b[j] == 's' || b[j] == 't')) break;
      
      if (ends(""ou"")) break;
      return;
      
    case 's':
      if (ends(""ism"")) break;
      return;
    case 't':
      if (ends(""ate"")) break;
      if (ends(""iti"")) break;
      return;
    case 'u':
      if (ends(""ous"")) break;
      return;
    case 'v':
      if (ends(""ive"")) break;
      return;
    case 'z':
      if (ends(""ize"")) break;
      return;
    default:
      return;
    }
    if (m() > 1)
      k = j;
  }

  

  private final void step6() {
    j = k;
    if (b[k] == 'e') {
      int a = m();
      if (a > 1 || a == 1 && !cvc(k-1))
        k--;
    }
    if (b[k] == 'l' && doublec(k) && m() > 1)
      k--;
  }


  
  public String stem(String s) {
    if (stem(s.toCharArray(), s.length()))
      return toString();
    else
      return s;
  }

  
  public boolean stem(char[] word) {
    return stem(word, word.length);
  }

  
  public boolean stem(char[] wordBuffer, int offset, int wordLen) {
    reset();
    if (b.length < wordLen) {
      char[] new_b = new char[wordLen + EXTRA];
      b = new_b;
    }
    for (int j=0; j<wordLen; j++)
      b[j] = wordBuffer[offset+j];
    i = wordLen;
    return stem(0);
  }

  
  public boolean stem(char[] word, int wordLen) {
    return stem(word, 0, wordLen);
  }

  
  public boolean stem() {
    return stem(0);
  }

  public boolean stem(int i0) {
    k = i - 1;
    k0 = i0;
    if (k > k0+1) {
      step1(); step2(); step3(); step4(); step5(); step6();
    }
    
    
    if (i != k+1)
      dirty = true;
    i = k+1;
    return dirty;
  }

  
  public static void main(String[] args) {
    PorterStemmer s = new PorterStemmer();

    for (int i = 0; i < args.length; i++) {
      try {
        InputStream in = new FileInputStream(args[i]);
        byte[] buffer = new byte[1024];
        int bufferLen, offset, ch;

        bufferLen = in.read(buffer);
        offset = 0;
        s.reset();

        while(true) {
          if (offset < bufferLen)
            ch = buffer[offset++];
          else {
            bufferLen = in.read(buffer);
            offset = 0;
            if (bufferLen < 0)
              ch = -1;
            else
              ch = buffer[offset++];
          }

          if (Character.isLetter((char) ch)) {
            s.add(Character.toLowerCase((char) ch));
          }
          else {
             s.stem();
             System.out.print(s.toString());
             s.reset();
             if (ch < 0)
               break;
             else {
               System.out.print((char) ch);
             }
           }
        }

        in.close();
      }
      catch (IOException e) {
        System.out.println(""error reading "" + args[i]);
      }
    }
  }
}

"
lucene,2,org.apache.lucene.index.TermPositions,1,1,0,21,1,0,20,1,1,2.0,1,0.0,0,0.0,1.0,0,0,0.0,1,1.0,3,"package org.apache.lucene.index;



import java.io.IOException;



public interface TermPositions
    extends TermDocs
{
    
    int nextPosition() throws IOException;
}
"
lucene,2,org.apache.lucene.analysis.TokenStream,3,1,2,19,4,3,18,1,3,2.0,7,0.0,0,0.0,1.0,0,0,1.333333333,1,0.6667,1,"package org.apache.lucene.analysis;



import java.io.IOException;



public abstract class TokenStream {
  
  public abstract Token next() throws IOException;

  
  public void close() throws IOException {}
}
"
lucene,2,org.apache.lucene.search.ExactPhraseScorer,2,3,0,8,8,1,2,6,0,2.0,61,0.0,0,0.952380952,0.583333333,1,1,29.5,1,0.5,1,"package org.apache.lucene.search;



import java.io.IOException;
import org.apache.lucene.index.*;

final class ExactPhraseScorer extends PhraseScorer {

  ExactPhraseScorer(Weight weight, TermPositions[] tps, int[] positions, Similarity similarity,
                    byte[] norms) {
    super(weight, tps, positions, similarity, norms);
  }

  protected final float phraseFreq() throws IOException {
    
    for (PhrasePositions pp = first; pp != null; pp = pp.next) {
      pp.firstPosition();
      pq.put(pp);				  
    }
    pqToList();					  

    int freq = 0;
    do {					  
      while (first.position < last.position) {	  
	do {
	  if (!first.nextPosition())
	    return (float)freq;
	} while (first.position < last.position);
	firstToLast();
      }
      freq++;					  
    } while (last.nextPosition());
  
    return (float)freq;
  }
}
"
lucene,2,org.apache.lucene.search.RangeFilter,7,2,0,6,30,1,1,5,7,0.0,373,1.0,0,0.142857143,0.314285714,1,1,51.57142857,12,3.5714,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermDocs;
import org.apache.lucene.index.TermEnum;

import java.io.IOException;
import java.util.BitSet;


public class RangeFilter extends Filter {
    
    private String fieldName;
    private String lowerTerm;
    private String upperTerm;
    private boolean includeLower;
    private boolean includeUpper;

    
    public RangeFilter(String fieldName, String lowerTerm, String upperTerm,
                       boolean includeLower, boolean includeUpper) {
        this.fieldName = fieldName;
        this.lowerTerm = lowerTerm;
        this.upperTerm = upperTerm;
        this.includeLower = includeLower;
        this.includeUpper = includeUpper;
        
        if (null == lowerTerm && null == upperTerm) {
            throw new IllegalArgumentException
                (""At least one value must be non-null"");
        }
        if (includeLower && null == lowerTerm) {
            throw new IllegalArgumentException
                (""The lower bound must be non-null to be inclusive"");
        }
        if (includeUpper && null == upperTerm) {
            throw new IllegalArgumentException
                (""The upper bound must be non-null to be inclusive"");
        }
    }
    
    
    public static RangeFilter Less(String fieldName, String upperTerm) {
        return new RangeFilter(fieldName, null, upperTerm, false, true);
    }

    
    public static RangeFilter More(String fieldName, String lowerTerm) {
        return new RangeFilter(fieldName, lowerTerm, null, true, false);
    }
    
    
    public BitSet bits(IndexReader reader) throws IOException {
        BitSet bits = new BitSet(reader.maxDoc());
        TermEnum enumerator =
            (null != lowerTerm
             ? reader.terms(new Term(fieldName, lowerTerm))
             : reader.terms(new Term(fieldName,"""")));
        
        try {
            
            if (enumerator.term() == null) {
                return bits;
            }
            
            boolean checkLower = false;
            if (!includeLower) 
                checkLower = true;
        
            TermDocs termDocs = reader.termDocs();
            try {
                
                do {
                    Term term = enumerator.term();
                    if (term != null && term.field().equals(fieldName)) {
                        if (!checkLower || null==lowerTerm || term.text().compareTo(lowerTerm) > 0) {
                            checkLower = false;
                            if (upperTerm != null) {
                                int compare = upperTerm.compareTo(term.text());
                                
                                if ((compare < 0) ||
                                    (!includeUpper && compare==0)) {
                                    break;
                                }
                            }
                            
                            
                            termDocs.seek(enumerator.term());
                            while (termDocs.next()) {
                                bits.set(termDocs.doc());
                            }
                        }
                    } else {
                        break;
                    }
                }
                while (enumerator.next());
                
            } finally {
                termDocs.close();
            }
        } finally {
            enumerator.close();
        }

        return bits;
    }
    
    public String toString() {
        StringBuffer buffer = new StringBuffer();
        buffer.append(fieldName);
        buffer.append("":"");
        buffer.append(includeLower ? ""["" : ""{"");
        if (null != lowerTerm) {
            buffer.append(lowerTerm);
        }
        buffer.append(""-"");
        if (null != upperTerm) {
            buffer.append(upperTerm);
        }
        buffer.append(includeUpper ? ""]"" : ""}"");
        return buffer.toString();
    }

    
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof RangeFilter)) return false;
        RangeFilter other = (RangeFilter) o;

        if (!this.fieldName.equals(other.fieldName)
            || this.includeLower != other.includeLower
            || this.includeUpper != other.includeUpper
           ) { return false; }
        if (this.lowerTerm != null ? !this.lowerTerm.equals(other.lowerTerm) : other.lowerTerm != null) return false;
        if (this.upperTerm != null ? !this.upperTerm.equals(other.upperTerm) : other.upperTerm != null) return false;
        return true;
    }

    
    public int hashCode() {
      int h = fieldName.hashCode();
      h ^= lowerTerm != null ? lowerTerm.hashCode() : 0xB6ECE882;
      h = (h << 1) | (h >>> 31);  
      h ^= (upperTerm != null ? (upperTerm.hashCode()) : 0x91BEC2C2);
      h ^= (includeLower ? 0xD484B933 : 0)
         ^ (includeUpper ? 0x6AE423AC : 0);
      return h;
    }
}
"
lucene,2,org.apache.lucene.index.SegmentInfo,1,1,0,5,2,0,4,1,1,2.0,16,0.0,1,0.0,1.0,0,0,12.0,0,0.0,6,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;

final class SegmentInfo {
  public String name;				  
  public int docCount;				  
  public Directory dir;				  

  public SegmentInfo(String name, int docCount, Directory dir) {
    this.name = name;
    this.docCount = docCount;
    this.dir = dir;
  }
}
"
lucene,2,org.apache.lucene.store.BufferedIndexInput,9,2,3,4,14,0,3,1,6,0.575,204,0.8,0,0.619047619,0.416666667,1,4,21.11111111,2,1.0,3,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class BufferedIndexInput extends IndexInput {
  static final int BUFFER_SIZE = BufferedIndexOutput.BUFFER_SIZE;

  private byte[] buffer;

  private long bufferStart = 0;			  
  private int bufferLength = 0;			  
  private int bufferPosition = 0;		  

  public byte readByte() throws IOException {
    if (bufferPosition >= bufferLength)
      refill();
    return buffer[bufferPosition++];
  }

  public void readBytes(byte[] b, int offset, int len)
       throws IOException {
    if (len < BUFFER_SIZE) {
      for (int i = 0; i < len; i++)		  
	b[i + offset] = (byte)readByte();
    } else {					  
      long start = getFilePointer();
      seekInternal(start);
      readInternal(b, offset, len);

      bufferStart = start + len;		  
      bufferPosition = 0;
      bufferLength = 0;				  
    }
  }

  private void refill() throws IOException {
    long start = bufferStart + bufferPosition;
    long end = start + BUFFER_SIZE;
    if (end > length())				  
      end = length();
    bufferLength = (int)(end - start);
    if (bufferLength <= 0)
      throw new IOException(""read past EOF"");

    if (buffer == null)
      buffer = new byte[BUFFER_SIZE];		  
    readInternal(buffer, 0, bufferLength);

    bufferStart = start;
    bufferPosition = 0;
  }

  
  protected abstract void readInternal(byte[] b, int offset, int length)
       throws IOException;

  public long getFilePointer() { return bufferStart + bufferPosition; }

  public void seek(long pos) throws IOException {
    if (pos >= bufferStart && pos < (bufferStart + bufferLength))
      bufferPosition = (int)(pos - bufferStart);  
    else {
      bufferStart = pos;
      bufferPosition = 0;
      bufferLength = 0;				  
      seekInternal(pos);
    }
  }

  
  protected abstract void seekInternal(long pos) throws IOException;

  public Object clone() {
    BufferedIndexInput clone = (BufferedIndexInput)super.clone();

    if (buffer != null) {
      clone.buffer = new byte[BUFFER_SIZE];
      System.arraycopy(buffer, 0, clone.buffer, 0, bufferLength);
    }

    return clone;
  }

}
"
lucene,2,org.apache.lucene.index.TermInfosWriter,6,1,0,8,29,0,2,6,0,0.436363636,383,0.727272727,5,0.0,0.479166667,0,0,61.0,1,0.6667,2,"package org.apache.lucene.index;




import java.io.IOException;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.Directory;
import org.apache.lucene.util.StringHelper;



final class TermInfosWriter {
  
  public static final int FORMAT = -2;

  private FieldInfos fieldInfos;
  private IndexOutput output;
  private Term lastTerm = new Term("""", """");
  private TermInfo lastTi = new TermInfo();
  private long size = 0;

  
  
  
  
  
  

  
  int indexInterval = 128;

  
  int skipInterval = 16;

  private long lastIndexPointer = 0;
  private boolean isIndex = false;

  private TermInfosWriter other = null;

  TermInfosWriter(Directory directory, String segment, FieldInfos fis,
                  int interval)
       throws IOException {
    initialize(directory, segment, fis, interval, false);
    other = new TermInfosWriter(directory, segment, fis, interval, true);
    other.other = this;
  }

  private TermInfosWriter(Directory directory, String segment, FieldInfos fis,
                          int interval, boolean isIndex) throws IOException {
    initialize(directory, segment, fis, interval, isIndex);
  }

  private void initialize(Directory directory, String segment, FieldInfos fis,
                          int interval, boolean isi) throws IOException {
    indexInterval = interval;
    fieldInfos = fis;
    isIndex = isi;
    output = directory.createOutput(segment + (isIndex ? "".tii"" : "".tis""));
    output.writeInt(FORMAT);                      
    output.writeLong(0);                          
    output.writeInt(indexInterval);             
    output.writeInt(skipInterval);              
  }

  
  final void add(Term term, TermInfo ti)
       throws IOException {
    if (!isIndex && term.compareTo(lastTerm) <= 0)
      throw new IOException(""term out of order (\"""" + term + 
          ""\"".compareTo(\"""" + lastTerm + ""\"") <= 0)"");
    if (ti.freqPointer < lastTi.freqPointer)
      throw new IOException(""freqPointer out of order ("" + ti.freqPointer +
          "" < "" + lastTi.freqPointer + "")"");
    if (ti.proxPointer < lastTi.proxPointer)
      throw new IOException(""proxPointer out of order ("" + ti.proxPointer + 
          "" < "" + lastTi.proxPointer + "")"");

    if (!isIndex && size % indexInterval == 0)
      other.add(lastTerm, lastTi);                      

    writeTerm(term);                                    
    output.writeVInt(ti.docFreq);                       
    output.writeVLong(ti.freqPointer - lastTi.freqPointer); 
    output.writeVLong(ti.proxPointer - lastTi.proxPointer);

    if (ti.docFreq >= skipInterval) {
      output.writeVInt(ti.skipOffset);
    }

    if (isIndex) {
      output.writeVLong(other.output.getFilePointer() - lastIndexPointer);
      lastIndexPointer = other.output.getFilePointer(); 
    }

    lastTi.set(ti);
    size++;
  }

  private final void writeTerm(Term term)
       throws IOException {
    int start = StringHelper.stringDifference(lastTerm.text, term.text);
    int length = term.text.length() - start;

    output.writeVInt(start);                   
    output.writeVInt(length);                  
    output.writeChars(term.text, start, length);  

    output.writeVInt(fieldInfos.fieldNumber(term.field)); 

    lastTerm = term;
  }



  
  final void close() throws IOException {
    output.seek(4);          
    output.writeLong(size);
    output.close();

    if (!isIndex)
      other.close();
  }

}
"
lucene,2,org.apache.lucene.search.MultiSearcher,15,2,1,19,50,0,2,18,13,0.476190476,557,1.0,1,0.611111111,0.251851852,1,5,35.93333333,6,1.2667,3,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

import org.apache.lucene.document.Document;
import org.apache.lucene.index.Term;


public class MultiSearcher extends Searcher {
    
  private static class CachedDfSource extends Searcher {
    private Map dfMap; 
    private int maxDoc; 

    public CachedDfSource(Map dfMap, int maxDoc) {
      this.dfMap = dfMap;
      this.maxDoc = maxDoc;
    }

    public int docFreq(Term term) {
      int df;
      try {
        df = ((Integer) dfMap.get(term)).intValue();
      } catch (NullPointerException e) {
        throw new IllegalArgumentException(""df for term "" + term.text()
            + "" not available"");
      }
      return df;
    }

    public int[] docFreqs(Term[] terms) {
      int[] result = new int[terms.length];
      for (int i = 0; i < terms.length; i++) {
        result[i] = docFreq(terms[i]);
      }
      return result;
    }

    public int maxDoc() {
      return maxDoc;
    }

    public Query rewrite(Query query) {
      
      
      
      
      return query;
    }

    public void close() {
      throw new UnsupportedOperationException();
    }

    public Document doc(int i) {
      throw new UnsupportedOperationException();
    }

    public Explanation explain(Weight weight,int doc) {
      throw new UnsupportedOperationException();
    }

    public void search(Weight weight, Filter filter, HitCollector results) {
      throw new UnsupportedOperationException();
    }

    public TopDocs search(Weight weight,Filter filter,int n) {
      throw new UnsupportedOperationException();
    }

    public TopFieldDocs search(Weight weight,Filter filter,int n,Sort sort) {
      throw new UnsupportedOperationException();
    }
  };


  private Searchable[] searchables;
  private int[] starts;
  private int maxDoc = 0;

  
  public MultiSearcher(Searchable[] searchables) throws IOException {
    this.searchables = searchables;

    starts = new int[searchables.length + 1];	  
    for (int i = 0; i < searchables.length; i++) {
      starts[i] = maxDoc;
      maxDoc += searchables[i].maxDoc();          
    }
    starts[searchables.length] = maxDoc;
  }
  
  
  public Searchable[] getSearchables() {
    return searchables;
  }

  protected int[] getStarts() {
  	return starts;
  }

  
  public void close() throws IOException {
    for (int i = 0; i < searchables.length; i++)
      searchables[i].close();
  }

  public int docFreq(Term term) throws IOException {
    int docFreq = 0;
    for (int i = 0; i < searchables.length; i++)
      docFreq += searchables[i].docFreq(term);
    return docFreq;
  }

  
  public Document doc(int n) throws IOException {
    int i = subSearcher(n);			  
    return searchables[i].doc(n - starts[i]);	  
  }


  
  public int subSearcher(int n) {                 
    
    int lo = 0;					  
    int hi = searchables.length - 1;		  
						  
    while (hi >= lo) {
      int mid = (lo + hi) >> 1;
      int midValue = starts[mid];
      if (n < midValue)
	hi = mid - 1;
      else if (n > midValue)
	lo = mid + 1;
      else {                                      
        while (mid+1 < searchables.length && starts[mid+1] == midValue) {
          mid++;                                  
        }
	return mid;
      }
    }
    return hi;
  }

  
  public int subDoc(int n) {
    return n - starts[subSearcher(n)];
  }

  public int maxDoc() throws IOException {
    return maxDoc;
  }

  public TopDocs search(Weight weight, Filter filter, int nDocs)
  throws IOException {

    HitQueue hq = new HitQueue(nDocs);
    int totalHits = 0;

    for (int i = 0; i < searchables.length; i++) { 
      TopDocs docs = searchables[i].search(weight, filter, nDocs);
      totalHits += docs.totalHits;		  
      ScoreDoc[] scoreDocs = docs.scoreDocs;
      for (int j = 0; j < scoreDocs.length; j++) { 
	ScoreDoc scoreDoc = scoreDocs[j];
        scoreDoc.doc += starts[i];                
        if(!hq.insert(scoreDoc))
            break;                                
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size()-1; i >= 0; i--)	  
      scoreDocs[i] = (ScoreDoc)hq.pop();
    
    float maxScore = (totalHits==0) ? Float.NEGATIVE_INFINITY : scoreDocs[0].score;
    
    return new TopDocs(totalHits, scoreDocs, maxScore);
  }

  public TopFieldDocs search (Weight weight, Filter filter, int n, Sort sort)
  throws IOException {
    FieldDocSortedHitQueue hq = null;
    int totalHits = 0;

    float maxScore=Float.NEGATIVE_INFINITY;
    
    for (int i = 0; i < searchables.length; i++) { 
      TopFieldDocs docs = searchables[i].search (weight, filter, n, sort);
      
      if (hq == null) hq = new FieldDocSortedHitQueue (docs.fields, n);
      totalHits += docs.totalHits;		  
      maxScore = Math.max(maxScore, docs.getMaxScore());
      ScoreDoc[] scoreDocs = docs.scoreDocs;
      for (int j = 0; j < scoreDocs.length; j++) { 
        ScoreDoc scoreDoc = scoreDocs[j];
        scoreDoc.doc += starts[i];                
        if (!hq.insert (scoreDoc))
          break;                                  
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size() - 1; i >= 0; i--)	  
      scoreDocs[i] = (ScoreDoc) hq.pop();

    return new TopFieldDocs (totalHits, scoreDocs, hq.getFields(), maxScore);
  }


  
  public void search(Weight weight, Filter filter, final HitCollector results)
    throws IOException {
    for (int i = 0; i < searchables.length; i++) {

      final int start = starts[i];

      searchables[i].search(weight, filter, new HitCollector() {
	  public void collect(int doc, float score) {
	    results.collect(doc + start, score);
	  }
	});

    }
  }

  public Query rewrite(Query original) throws IOException {
    Query[] queries = new Query[searchables.length];
    for (int i = 0; i < searchables.length; i++) {
      queries[i] = searchables[i].rewrite(original);
    }
    return queries[0].combine(queries);
  }

  public Explanation explain(Weight weight, int doc) throws IOException {
    int i = subSearcher(doc);			  
    return searchables[i].explain(weight,doc-starts[i]); 
  }

  
  protected Weight createWeight(Query original) throws IOException {
    
    Query rewrittenQuery = rewrite(original);

    
    Set terms = new HashSet();
    rewrittenQuery.extractTerms(terms);

    
    Term[] allTermsArray = new Term[terms.size()];
    terms.toArray(allTermsArray);
    int[] aggregatedDfs = new int[terms.size()];
    for (int i = 0; i < searchables.length; i++) {
      int[] dfs = searchables[i].docFreqs(allTermsArray);
      for(int j=0; j<aggregatedDfs.length; j++){
        aggregatedDfs[j] += dfs[j];
      }
    }

    HashMap dfMap = new HashMap();
    for(int i=0; i<allTermsArray.length; i++) {
      dfMap.put(allTermsArray[i], new Integer(aggregatedDfs[i]));
    }

    
    int numDocs = maxDoc();
    CachedDfSource cacheSim = new CachedDfSource(dfMap, numDocs);

    return rewrittenQuery.weight(cacheSim);
  }

}
"
lucene,2,org.apache.lucene.analysis.standard.ParseException,5,4,0,2,18,0,1,1,4,0.55,380,0.4,1,0.866666667,0.4,1,1,74.0,14,4.8,1,"
package org.apache.lucene.analysis.standard;


public class ParseException extends java.io.IOException {

  
  public ParseException(Token currentTokenVal,
                        int[][] expectedTokenSequencesVal,
                        String[] tokenImageVal
                       )
  {
    super("""");
    specialConstructor = true;
    currentToken = currentTokenVal;
    expectedTokenSequences = expectedTokenSequencesVal;
    tokenImage = tokenImageVal;
  }

  

  public ParseException() {
    super();
    specialConstructor = false;
  }

  public ParseException(String message) {
    super(message);
    specialConstructor = false;
  }

  
  protected boolean specialConstructor;

  
  public Token currentToken;

  
  public int[][] expectedTokenSequences;

  
  public String[] tokenImage;

  
  public String getMessage() {
    if (!specialConstructor) {
      return super.getMessage();
    }
    String expected = """";
    int maxSize = 0;
    for (int i = 0; i < expectedTokenSequences.length; i++) {
      if (maxSize < expectedTokenSequences[i].length) {
        maxSize = expectedTokenSequences[i].length;
      }
      for (int j = 0; j < expectedTokenSequences[i].length; j++) {
        expected += tokenImage[expectedTokenSequences[i][j]] + "" "";
      }
      if (expectedTokenSequences[i][expectedTokenSequences[i].length - 1] != 0) {
        expected += ""..."";
      }
      expected += eol + ""    "";
    }
    String retval = ""Encountered \"""";
    Token tok = currentToken.next;
    for (int i = 0; i < maxSize; i++) {
      if (i != 0) retval += "" "";
      if (tok.kind == 0) {
        retval += tokenImage[0];
        break;
      }
      retval += add_escapes(tok.image);
      tok = tok.next; 
    }
    retval += ""\"" at line "" + currentToken.next.beginLine + "", column "" + currentToken.next.beginColumn + ""."" + eol;
    if (expectedTokenSequences.length == 1) {
      retval += ""Was expecting:"" + eol + ""    "";
    } else {
      retval += ""Was expecting one of:"" + eol + ""    "";
    }
    retval += expected;
    return retval;
  }

  
  protected String eol = System.getProperty(""line.separator"", ""\n"");
 
  
  protected String add_escapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

}
"
lucene,2,org.apache.lucene.search.MultiPhraseQuery,17,2,0,12,55,12,3,10,13,0.625,404,1.0,0,0.428571429,0.158823529,2,4,22.52941176,7,2.0588,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.*;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.MultipleTermPositions;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class MultiPhraseQuery extends Query {
  private String field;
  private ArrayList termArrays = new ArrayList();
  private Vector positions = new Vector();

  private int slop = 0;

  
  public void setSlop(int s) { slop = s; }

  
  public int getSlop() { return slop; }

  
  public void add(Term term) { add(new Term[]{term}); }

  
  public void add(Term[] terms) {
    int position = 0;
    if (positions.size() > 0)
      position = ((Integer) positions.lastElement()).intValue() + 1;

    add(terms, position);
  }

  
  public void add(Term[] terms, int position) {
    if (termArrays.size() == 0)
      field = terms[0].field();

    for (int i = 0; i < terms.length; i++) {
      if (terms[i].field() != field) {
        throw new IllegalArgumentException(
            ""All phrase terms must be in the same field ("" + field + ""): ""
                + terms[i]);
      }
    }

    termArrays.add(terms);
    positions.addElement(new Integer(position));
  }

  
  public List getTermArrays() {
	  return Collections.unmodifiableList(termArrays);
  }

  
  public int[] getPositions() {
    int[] result = new int[positions.size()];
    for (int i = 0; i < positions.size(); i++)
      result[i] = ((Integer) positions.elementAt(i)).intValue();
    return result;
  }

  
  public void extractTerms(Set terms) {
    for (Iterator iter = termArrays.iterator(); iter.hasNext();) {
      Term[] arr = (Term[])iter.next();
      for (int i=0; i<arr.length; i++) {
        terms.add(arr[i]);
      }
    }
  }


  private class MultiPhraseWeight implements Weight {
    private Similarity similarity;
    private float value;
    private float idf;
    private float queryNorm;
    private float queryWeight;

    public MultiPhraseWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);

      
      Iterator i = termArrays.iterator();
      while (i.hasNext()) {
        Term[] terms = (Term[])i.next();
        for (int j=0; j<terms.length; j++) {
          idf += getSimilarity(searcher).idf(terms[j], searcher);
        }
      }
    }

    public Query getQuery() { return MultiPhraseQuery.this; }
    public float getValue() { return value; }

    public float sumOfSquaredWeights() {
      queryWeight = idf * getBoost();             
      return queryWeight * queryWeight;           
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= queryNorm;                   
      value = queryWeight * idf;                  
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      if (termArrays.size() == 0)                  
        return null;

      TermPositions[] tps = new TermPositions[termArrays.size()];
      for (int i=0; i<tps.length; i++) {
        Term[] terms = (Term[])termArrays.get(i);

        TermPositions p;
        if (terms.length > 1)
          p = new MultipleTermPositions(reader, terms);
        else
          p = reader.termPositions(terms[0]);

        if (p == null)
          return null;

        tps[i] = p;
      }

      if (slop == 0)
        return new ExactPhraseScorer(this, tps, getPositions(), similarity,
                                     reader.norms(field));
      else
        return new SloppyPhraseScorer(this, tps, getPositions(), similarity,
                                      slop, reader.norms(field));
    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {
      Explanation result = new Explanation();
      result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");

      Explanation idfExpl = new Explanation(idf, ""idf(""+getQuery()+"")"");

      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

      Explanation boostExpl = new Explanation(getBoost(), ""boost"");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);

      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      
      Explanation fieldExpl = new Explanation();
      fieldExpl.setDescription(""fieldWeight(""+getQuery()+"" in ""+doc+
                               ""), product of:"");

      Explanation tfExpl = scorer(reader).explain(doc);
      fieldExpl.addDetail(tfExpl);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setValue(tfExpl.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);

      
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }
  }

  public Query rewrite(IndexReader reader) {
    if (termArrays.size() == 1) {                 
      Term[] terms = (Term[])termArrays.get(0);
      BooleanQuery boq = new BooleanQuery(true);
      for (int i=0; i<terms.length; i++) {
        boq.add(new TermQuery(terms[i]), BooleanClause.Occur.SHOULD);
      }
      boq.setBoost(getBoost());
      return boq;
    } else {
      return this;
    }
  }

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new MultiPhraseWeight(searcher);
  }

  
  public final String toString(String f) {
    StringBuffer buffer = new StringBuffer();
    if (!field.equals(f)) {
      buffer.append(field);
      buffer.append("":"");
    }

    buffer.append(""\"""");
    Iterator i = termArrays.iterator();
    while (i.hasNext()) {
      Term[] terms = (Term[])i.next();
      if (terms.length > 1) {
        buffer.append(""("");
        for (int j = 0; j < terms.length; j++) {
          buffer.append(terms[j].text());
          if (j < terms.length-1)
            buffer.append("" "");
        }
        buffer.append("")"");
      } else {
        buffer.append(terms[0].text());
      }
      if (i.hasNext())
        buffer.append("" "");
    }
    buffer.append(""\"""");

    if (slop != 0) {
      buffer.append(""~"");
      buffer.append(slop);
    }

    buffer.append(ToStringUtils.boost(getBoost()));

    return buffer.toString();
  }


  
  public boolean equals(Object o) {
    if (!(o instanceof MultiPhraseQuery)) return false;
    MultiPhraseQuery other = (MultiPhraseQuery)o;
    return this.getBoost() == other.getBoost()
      && this.slop == other.slop
      && this.termArrays.equals(other.termArrays)
      && this.positions.equals(other.positions);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost())
      ^ slop
      ^ termArrays.hashCode()
      ^ positions.hashCode()
      ^ 0x4AC65113;
  }
}
"
lucene,2,org.apache.lucene.store.IndexOutput,14,1,1,18,17,91,18,0,14,2.0,189,0.0,0,0.0,0.297619048,0,0,12.5,1,0.9286,1,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class IndexOutput {

  
  public abstract void writeByte(byte b) throws IOException;

  
  public abstract void writeBytes(byte[] b, int length) throws IOException;

  
  public void writeInt(int i) throws IOException {
    writeByte((byte)(i >> 24));
    writeByte((byte)(i >> 16));
    writeByte((byte)(i >>  8));
    writeByte((byte) i);
  }

  
  public void writeVInt(int i) throws IOException {
    while ((i & ~0x7F) != 0) {
      writeByte((byte)((i & 0x7f) | 0x80));
      i >>>= 7;
    }
    writeByte((byte)i);
  }

  
  public void writeLong(long i) throws IOException {
    writeInt((int) (i >> 32));
    writeInt((int) i);
  }

  
  public void writeVLong(long i) throws IOException {
    while ((i & ~0x7F) != 0) {
      writeByte((byte)((i & 0x7f) | 0x80));
      i >>>= 7;
    }
    writeByte((byte)i);
  }

  
  public void writeString(String s) throws IOException {
    int length = s.length();
    writeVInt(length);
    writeChars(s, 0, length);
  }

  
  public void writeChars(String s, int start, int length)
       throws IOException {
    final int end = start + length;
    for (int i = start; i < end; i++) {
      final int code = (int)s.charAt(i);
      if (code >= 0x01 && code <= 0x7F)
	writeByte((byte)code);
      else if (((code >= 0x80) && (code <= 0x7FF)) || code == 0) {
	writeByte((byte)(0xC0 | (code >> 6)));
	writeByte((byte)(0x80 | (code & 0x3F)));
      } else {
	writeByte((byte)(0xE0 | (code >>> 12)));
	writeByte((byte)(0x80 | ((code >> 6) & 0x3F)));
	writeByte((byte)(0x80 | (code & 0x3F)));
      }
    }
  }

  
  public abstract void flush() throws IOException;

  
  public abstract void close() throws IOException;

  
  public abstract long getFilePointer();

  
  public abstract void seek(long pos) throws IOException;

  
  public abstract long length() throws IOException;


}
"
lucene,2,org.apache.lucene.search.HitQueue,2,2,0,6,4,1,4,2,0,2.0,39,0.0,0,0.916666667,0.666666667,1,3,18.5,4,2.0,0,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;

final class HitQueue extends PriorityQueue {
  HitQueue(int size) {
    initialize(size);
  }

  protected final boolean lessThan(Object a, Object b) {
    ScoreDoc hitA = (ScoreDoc)a;
    ScoreDoc hitB = (ScoreDoc)b;
    if (hitA.score == hitB.score)
      return hitA.doc > hitB.doc; 
    else
      return hitA.score < hitB.score;
  }
}
"
lucene,2,org.apache.lucene.search.NonMatchingScorer,6,2,0,4,10,15,1,3,6,2.0,31,0.0,0,0.615384615,0.666666667,1,3,4.166666667,1,0.8333,0,"package org.apache.lucene.search;


 
import java.io.IOException;


class NonMatchingScorer extends Scorer {
  public NonMatchingScorer() { super(null); } 
  
  public int doc() { throw new UnsupportedOperationException(); }

  public boolean next() throws IOException { return false; }

  public float score() { throw new UnsupportedOperationException(); }

  public boolean skipTo(int target) { return false; }

  public Explanation explain(int doc) {
    Explanation e = new Explanation();
    e.setDescription(""No document matches."");
    return e;
  }
}
 

"
lucene,2,org.apache.lucene.search.TopFieldDocs,1,2,0,14,2,0,11,3,0,2.0,11,0.0,1,1.0,1.0,0,0,9.0,0,0.0,0,"package org.apache.lucene.search;





public class TopFieldDocs
extends TopDocs {

	
	public SortField[] fields;
        
	
	TopFieldDocs (int totalHits, ScoreDoc[] scoreDocs, SortField[] fields, float maxScore) {
	  super (totalHits, scoreDocs, maxScore);
	  this.fields = fields;
	}
}"
lucene,2,org.apache.lucene.search.spans.SpanNearQuery,12,3,0,7,46,0,1,7,12,0.613636364,343,1.0,0,0.592592593,0.208333333,2,2,27.25,7,1.75,1,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.List;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Set;


import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class SpanNearQuery extends SpanQuery {
  private List clauses;
  private int slop;
  private boolean inOrder;

  private String field;

  
  public SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder) {

    
    this.clauses = new ArrayList(clauses.length);
    for (int i = 0; i < clauses.length; i++) {
      SpanQuery clause = clauses[i];
      if (i == 0) {                               
        field = clause.getField();
      } else if (!clause.getField().equals(field)) {
        throw new IllegalArgumentException(""Clauses must have same field."");
      }
      this.clauses.add(clause);
    }

    this.slop = slop;
    this.inOrder = inOrder;
  }

  
  public SpanQuery[] getClauses() {
    return (SpanQuery[])clauses.toArray(new SpanQuery[clauses.size()]);
  }

  
  public int getSlop() { return slop; }

  
  public boolean isInOrder() { return inOrder; }

  public String getField() { return field; }
  
  
  public Collection getTerms() {
    Collection terms = new ArrayList();
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      terms.addAll(clause.getTerms());
    }
    return terms;
  }
  
  public void extractTerms(Set terms) {
	    Iterator i = clauses.iterator();
	    while (i.hasNext()) {
	      SpanQuery clause = (SpanQuery)i.next();
	      clause.extractTerms(terms);
	    }
  }  
  

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanNear(["");
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      buffer.append(clause.toString(field));
      if (i.hasNext()) {
        buffer.append("", "");
      }
    }
    buffer.append(""], "");
    buffer.append(slop);
    buffer.append("", "");
    buffer.append(inOrder);
    buffer.append("")"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  public Spans getSpans(final IndexReader reader) throws IOException {
    if (clauses.size() == 0)                      
      return new SpanOrQuery(getClauses()).getSpans(reader);

    if (clauses.size() == 1)                      
      return ((SpanQuery)clauses.get(0)).getSpans(reader);

    return new NearSpans(this, reader);
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanNearQuery clone = null;
    for (int i = 0 ; i < clauses.size(); i++) {
      SpanQuery c = (SpanQuery)clauses.get(i);
      SpanQuery query = (SpanQuery) c.rewrite(reader);
      if (query != c) {                     
        if (clone == null)
          clone = (SpanNearQuery) this.clone();
        clone.clauses.set(i,query);
      }
    }
    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

  
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof SpanNearQuery)) return false;

    final SpanNearQuery spanNearQuery = (SpanNearQuery) o;

    if (inOrder != spanNearQuery.inOrder) return false;
    if (slop != spanNearQuery.slop) return false;
    if (!clauses.equals(spanNearQuery.clauses)) return false;

    return getBoost() == spanNearQuery.getBoost();
  }

  public int hashCode() {
    int result;
    result = clauses.hashCode();
    
    
    
    result ^= (result << 14) | (result >>> 19);  
    result += Float.floatToRawIntBits(getBoost());
    result += slop;
    result ^= (inOrder ? 0x99AFD3BD : 0);
    return result;
  }
}
"
lucene,2,org.apache.lucene.document.Document,14,1,0,23,35,0,22,1,14,0.5,341,0.5,0,0.0,0.428571429,0,0,23.21428571,5,2.5714,1,"package org.apache.lucene.document;



import java.util.Enumeration;
import java.util.Iterator;
import java.util.List;
import java.util.ArrayList;
import java.util.Vector;
import org.apache.lucene.index.IndexReader;       
import org.apache.lucene.search.Searcher;         
import org.apache.lucene.search.Hits;             



public final class Document implements java.io.Serializable {
  List fields = new Vector();
  private float boost = 1.0f;

  
  public Document() {}


  
  public void setBoost(float boost) {
    this.boost = boost;
  }

  
  public float getBoost() {
    return boost;
  }

  
  public final void add(Field field) {
    fields.add(field);
  }
  
  
  public final void removeField(String name) {
    Iterator it = fields.iterator();
    while (it.hasNext()) {
      Field field = (Field)it.next();
      if (field.name().equals(name)) {
        it.remove();
        return;
      }
    }
  }
  
  
  public final void removeFields(String name) {
    Iterator it = fields.iterator();
    while (it.hasNext()) {
      Field field = (Field)it.next();
      if (field.name().equals(name)) {
        it.remove();
      }
    }
  }

  
  public final Field getField(String name) {
    for (int i = 0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      if (field.name().equals(name))
	return field;
    }
    return null;
  }

  
  public final String get(String name) {
    for (int i = 0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      if (field.name().equals(name) && (!field.isBinary()))
        return field.stringValue();
    }
    return null;
  }

  
  public final Enumeration fields() {
    return ((Vector)fields).elements();
  }

  
   public final Field[] getFields(String name) {
     List result = new ArrayList();
     for (int i = 0; i < fields.size(); i++) {
       Field field = (Field)fields.get(i);
       if (field.name().equals(name)) {
         result.add(field);
       }
     }

     if (result.size() == 0)
       return null;

     return (Field[])result.toArray(new Field[result.size()]);
   }

  
  public final String[] getValues(String name) {
    List result = new ArrayList();
    for (int i = 0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      if (field.name().equals(name) && (!field.isBinary()))
        result.add(field.stringValue());
    }
    
    if (result.size() == 0)
      return null;
    
    return (String[])result.toArray(new String[result.size()]);
  }

  
  public final byte[][] getBinaryValues(String name) {
    List result = new ArrayList();
    for (int i = 0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      if (field.name().equals(name) && (field.isBinary()))
        result.add(field.binaryValue());
    }
  
    if (result.size() == 0)
      return null;
  
    return (byte[][])result.toArray(new byte[result.size()][]);
  }
  
  
  public final byte[] getBinaryValue(String name) {
    for (int i=0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      if (field.name().equals(name) && (field.isBinary()))
        return field.binaryValue();
    }
    return null;
  }
  
  
  public final String toString() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""Document<"");
    for (int i = 0; i < fields.size(); i++) {
      Field field = (Field)fields.get(i);
      buffer.append(field.toString());
      if (i != fields.size()-1)
        buffer.append("" "");
    }
    buffer.append("">"");
    return buffer.toString();
  }
}
"
lucene,2,org.apache.lucene.analysis.standard.StandardTokenizerConstants,1,1,0,3,1,0,3,0,0,2.0,87,0.0,0,0.0,0.0,0,0,68.0,0,0.0,0,"
package org.apache.lucene.analysis.standard;

public interface StandardTokenizerConstants {

  int EOF = 0;
  int ALPHANUM = 1;
  int APOSTROPHE = 2;
  int ACRONYM = 3;
  int COMPANY = 4;
  int EMAIL = 5;
  int HOST = 6;
  int NUM = 7;
  int P = 8;
  int HAS_DIGIT = 9;
  int ALPHA = 10;
  int LETTER = 11;
  int CJ = 12;
  int KOREAN = 13;
  int DIGIT = 14;
  int NOISE = 15;

  int DEFAULT = 0;

  String[] tokenImage = {
    ""<EOF>"",
    ""<ALPHANUM>"",
    ""<APOSTROPHE>"",
    ""<ACRONYM>"",
    ""<COMPANY>"",
    ""<EMAIL>"",
    ""<HOST>"",
    ""<NUM>"",
    ""<P>"",
    ""<HAS_DIGIT>"",
    ""<ALPHA>"",
    ""<LETTER>"",
    ""<CJ>"",
    ""<KOREAN>"",
    ""<DIGIT>"",
    ""<NOISE>"",
  };

}
"
lucene,2,org.apache.lucene.queryParser.QueryParserTokenManager,36,1,0,5,52,282,1,4,7,0.720300752,2855,0.210526316,1,0.0,0.405714286,0,0,77.77777778,102,7.0556,4,"
package org.apache.lucene.queryParser;
import java.util.Vector;
import java.io.*;
import java.text.*;
import java.util.*;
import org.apache.lucene.index.Term;
import org.apache.lucene.analysis.*;
import org.apache.lucene.document.*;
import org.apache.lucene.search.*;
import org.apache.lucene.util.Parameter;

public class QueryParserTokenManager implements QueryParserConstants
{
  public  java.io.PrintStream debugStream = System.out;
  public  void setDebugStream(java.io.PrintStream ds) { debugStream = ds; }
private final int jjStopStringLiteralDfa_3(int pos, long active0)
{
   switch (pos)
   {
      default :
         return -1;
   }
}
private final int jjStartNfa_3(int pos, long active0)
{
   return jjMoveNfa_3(jjStopStringLiteralDfa_3(pos, active0), pos + 1);
}
private final int jjStopAtPos(int pos, int kind)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   return pos + 1;
}
private final int jjStartNfaWithStates_3(int pos, int kind, int state)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) { return pos + 1; }
   return jjMoveNfa_3(state, pos + 1);
}
private final int jjMoveStringLiteralDfa0_3()
{
   switch(curChar)
   {
      case 40:
         return jjStopAtPos(0, 12);
      case 41:
         return jjStopAtPos(0, 13);
      case 43:
         return jjStopAtPos(0, 10);
      case 45:
         return jjStopAtPos(0, 11);
      case 58:
         return jjStopAtPos(0, 14);
      case 91:
         return jjStopAtPos(0, 21);
      case 94:
         return jjStopAtPos(0, 15);
      case 123:
         return jjStopAtPos(0, 22);
      default :
         return jjMoveNfa_3(0, 0);
   }
}
private final void jjCheckNAdd(int state)
{
   if (jjrounds[state] != jjround)
   {
      jjstateSet[jjnewStateCnt++] = state;
      jjrounds[state] = jjround;
   }
}
private final void jjAddStates(int start, int end)
{
   do {
      jjstateSet[jjnewStateCnt++] = jjnextStates[start];
   } while (start++ != end);
}
private final void jjCheckNAddTwoStates(int state1, int state2)
{
   jjCheckNAdd(state1);
   jjCheckNAdd(state2);
}
private final void jjCheckNAddStates(int start, int end)
{
   do {
      jjCheckNAdd(jjnextStates[start]);
   } while (start++ != end);
}
private final void jjCheckNAddStates(int start)
{
   jjCheckNAdd(jjnextStates[start]);
   jjCheckNAdd(jjnextStates[start + 1]);
}
static final long[] jjbitVec0 = {
   0xfffffffffffffffeL, 0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffffffL
};
static final long[] jjbitVec2 = {
   0x0L, 0x0L, 0xffffffffffffffffL, 0xffffffffffffffffL
};
private final int jjMoveNfa_3(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 33;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x7bffd0f8ffffd9ffL & l) != 0L)
                  {
                     if (kind > 17)
                        kind = 17;
                     jjCheckNAddStates(0, 6);
                  }
                  else if ((0x100002600L & l) != 0L)
                  {
                     if (kind > 6)
                        kind = 6;
                  }
                  else if (curChar == 34)
                     jjCheckNAdd(15);
                  else if (curChar == 33)
                  {
                     if (kind > 9)
                        kind = 9;
                  }
                  if (curChar == 38)
                     jjstateSet[jjnewStateCnt++] = 4;
                  break;
               case 4:
                  if (curChar == 38 && kind > 7)
                     kind = 7;
                  break;
               case 5:
                  if (curChar == 38)
                     jjstateSet[jjnewStateCnt++] = 4;
                  break;
               case 13:
                  if (curChar == 33 && kind > 9)
                     kind = 9;
                  break;
               case 14:
                  if (curChar == 34)
                     jjCheckNAdd(15);
                  break;
               case 15:
                  if ((0xfffffffbffffffffL & l) != 0L)
                     jjCheckNAddTwoStates(15, 16);
                  break;
               case 16:
                  if (curChar == 34 && kind > 16)
                     kind = 16;
                  break;
               case 18:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjAddStates(7, 8);
                  break;
               case 19:
                  if (curChar == 46)
                     jjCheckNAdd(20);
                  break;
               case 20:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjCheckNAdd(20);
                  break;
               case 21:
                  if ((0x7bffd0f8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddStates(0, 6);
                  break;
               case 22:
                  if ((0x7bfff8f8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddTwoStates(22, 23);
                  break;
               case 24:
                  if ((0x84002f0600000000L & l) == 0L)
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddTwoStates(22, 23);
                  break;
               case 25:
                  if ((0x7bfff8f8ffffd9ffL & l) != 0L)
                     jjCheckNAddStates(9, 11);
                  break;
               case 26:
                  if (curChar == 42 && kind > 19)
                     kind = 19;
                  break;
               case 28:
                  if ((0x84002f0600000000L & l) != 0L)
                     jjCheckNAddStates(9, 11);
                  break;
               case 29:
                  if ((0xfbfffcf8ffffd9ffL & l) == 0L)
                     break;
                  if (kind > 20)
                     kind = 20;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 31:
                  if ((0x84002f0600000000L & l) == 0L)
                     break;
                  if (kind > 20)
                     kind = 20;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x97ffffff97ffffffL & l) != 0L)
                  {
                     if (kind > 17)
                        kind = 17;
                     jjCheckNAddStates(0, 6);
                  }
                  else if (curChar == 126)
                  {
                     if (kind > 18)
                        kind = 18;
                     jjstateSet[jjnewStateCnt++] = 18;
                  }
                  if (curChar == 92)
                     jjCheckNAddStates(12, 14);
                  else if (curChar == 78)
                     jjstateSet[jjnewStateCnt++] = 11;
                  else if (curChar == 124)
                     jjstateSet[jjnewStateCnt++] = 8;
                  else if (curChar == 79)
                     jjstateSet[jjnewStateCnt++] = 6;
                  else if (curChar == 65)
                     jjstateSet[jjnewStateCnt++] = 2;
                  break;
               case 1:
                  if (curChar == 68 && kind > 7)
                     kind = 7;
                  break;
               case 2:
                  if (curChar == 78)
                     jjstateSet[jjnewStateCnt++] = 1;
                  break;
               case 3:
                  if (curChar == 65)
                     jjstateSet[jjnewStateCnt++] = 2;
                  break;
               case 6:
                  if (curChar == 82 && kind > 8)
                     kind = 8;
                  break;
               case 7:
                  if (curChar == 79)
                     jjstateSet[jjnewStateCnt++] = 6;
                  break;
               case 8:
                  if (curChar == 124 && kind > 8)
                     kind = 8;
                  break;
               case 9:
                  if (curChar == 124)
                     jjstateSet[jjnewStateCnt++] = 8;
                  break;
               case 10:
                  if (curChar == 84 && kind > 9)
                     kind = 9;
                  break;
               case 11:
                  if (curChar == 79)
                     jjstateSet[jjnewStateCnt++] = 10;
                  break;
               case 12:
                  if (curChar == 78)
                     jjstateSet[jjnewStateCnt++] = 11;
                  break;
               case 15:
                  jjAddStates(15, 16);
                  break;
               case 17:
                  if (curChar != 126)
                     break;
                  if (kind > 18)
                     kind = 18;
                  jjstateSet[jjnewStateCnt++] = 18;
                  break;
               case 21:
                  if ((0x97ffffff97ffffffL & l) == 0L)
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddStates(0, 6);
                  break;
               case 22:
                  if ((0x97ffffff97ffffffL & l) == 0L)
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddTwoStates(22, 23);
                  break;
               case 23:
                  if (curChar == 92)
                     jjCheckNAddTwoStates(24, 24);
                  break;
               case 24:
                  if ((0x6800000078000000L & l) == 0L)
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddTwoStates(22, 23);
                  break;
               case 25:
                  if ((0x97ffffff97ffffffL & l) != 0L)
                     jjCheckNAddStates(9, 11);
                  break;
               case 27:
                  if (curChar == 92)
                     jjCheckNAddTwoStates(28, 28);
                  break;
               case 28:
                  if ((0x6800000078000000L & l) != 0L)
                     jjCheckNAddStates(9, 11);
                  break;
               case 29:
                  if ((0x97ffffff97ffffffL & l) == 0L)
                     break;
                  if (kind > 20)
                     kind = 20;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 30:
                  if (curChar == 92)
                     jjCheckNAddTwoStates(31, 31);
                  break;
               case 31:
                  if ((0x6800000078000000L & l) == 0L)
                     break;
                  if (kind > 20)
                     kind = 20;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               case 32:
                  if (curChar == 92)
                     jjCheckNAddStates(12, 14);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddStates(0, 6);
                  break;
               case 15:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjAddStates(15, 16);
                  break;
               case 22:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 17)
                     kind = 17;
                  jjCheckNAddTwoStates(22, 23);
                  break;
               case 25:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(9, 11);
                  break;
               case 29:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 20)
                     kind = 20;
                  jjCheckNAddTwoStates(29, 30);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 33 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
private final int jjStopStringLiteralDfa_1(int pos, long active0)
{
   switch (pos)
   {
      case 0:
         if ((active0 & 0x10000000L) != 0L)
         {
            jjmatchedKind = 31;
            return 4;
         }
         return -1;
      default :
         return -1;
   }
}
private final int jjStartNfa_1(int pos, long active0)
{
   return jjMoveNfa_1(jjStopStringLiteralDfa_1(pos, active0), pos + 1);
}
private final int jjStartNfaWithStates_1(int pos, int kind, int state)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) { return pos + 1; }
   return jjMoveNfa_1(state, pos + 1);
}
private final int jjMoveStringLiteralDfa0_1()
{
   switch(curChar)
   {
      case 84:
         return jjMoveStringLiteralDfa1_1(0x10000000L);
      case 125:
         return jjStopAtPos(0, 29);
      default :
         return jjMoveNfa_1(0, 0);
   }
}
private final int jjMoveStringLiteralDfa1_1(long active0)
{
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) {
      jjStopStringLiteralDfa_1(0, active0);
      return 1;
   }
   switch(curChar)
   {
      case 79:
         if ((active0 & 0x10000000L) != 0L)
            return jjStartNfaWithStates_1(1, 28, 4);
         break;
      default :
         break;
   }
   return jjStartNfa_1(0, active0);
}
private final int jjMoveNfa_1(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 5;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0xfffffffeffffffffL & l) != 0L)
                  {
                     if (kind > 31)
                        kind = 31;
                     jjCheckNAdd(4);
                  }
                  if ((0x100002600L & l) != 0L)
                  {
                     if (kind > 6)
                        kind = 6;
                  }
                  else if (curChar == 34)
                     jjCheckNAdd(2);
                  break;
               case 1:
                  if (curChar == 34)
                     jjCheckNAdd(2);
                  break;
               case 2:
                  if ((0xfffffffbffffffffL & l) != 0L)
                     jjCheckNAddTwoStates(2, 3);
                  break;
               case 3:
                  if (curChar == 34 && kind > 30)
                     kind = 30;
                  break;
               case 4:
                  if ((0xfffffffeffffffffL & l) == 0L)
                     break;
                  if (kind > 31)
                     kind = 31;
                  jjCheckNAdd(4);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 4:
                  if ((0xdfffffffffffffffL & l) == 0L)
                     break;
                  if (kind > 31)
                     kind = 31;
                  jjCheckNAdd(4);
                  break;
               case 2:
                  jjAddStates(17, 18);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 4:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 31)
                     kind = 31;
                  jjCheckNAdd(4);
                  break;
               case 2:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjAddStates(17, 18);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 5 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
private final int jjMoveStringLiteralDfa0_0()
{
   return jjMoveNfa_0(0, 0);
}
private final int jjMoveNfa_0(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 3;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 23)
                     kind = 23;
                  jjAddStates(19, 20);
                  break;
               case 1:
                  if (curChar == 46)
                     jjCheckNAdd(2);
                  break;
               case 2:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 23)
                     kind = 23;
                  jjCheckNAdd(2);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 3 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
private final int jjStopStringLiteralDfa_2(int pos, long active0)
{
   switch (pos)
   {
      case 0:
         if ((active0 & 0x1000000L) != 0L)
         {
            jjmatchedKind = 27;
            return 4;
         }
         return -1;
      default :
         return -1;
   }
}
private final int jjStartNfa_2(int pos, long active0)
{
   return jjMoveNfa_2(jjStopStringLiteralDfa_2(pos, active0), pos + 1);
}
private final int jjStartNfaWithStates_2(int pos, int kind, int state)
{
   jjmatchedKind = kind;
   jjmatchedPos = pos;
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) { return pos + 1; }
   return jjMoveNfa_2(state, pos + 1);
}
private final int jjMoveStringLiteralDfa0_2()
{
   switch(curChar)
   {
      case 84:
         return jjMoveStringLiteralDfa1_2(0x1000000L);
      case 93:
         return jjStopAtPos(0, 25);
      default :
         return jjMoveNfa_2(0, 0);
   }
}
private final int jjMoveStringLiteralDfa1_2(long active0)
{
   try { curChar = input_stream.readChar(); }
   catch(java.io.IOException e) {
      jjStopStringLiteralDfa_2(0, active0);
      return 1;
   }
   switch(curChar)
   {
      case 79:
         if ((active0 & 0x1000000L) != 0L)
            return jjStartNfaWithStates_2(1, 24, 4);
         break;
      default :
         break;
   }
   return jjStartNfa_2(0, active0);
}
private final int jjMoveNfa_2(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 5;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0xfffffffeffffffffL & l) != 0L)
                  {
                     if (kind > 27)
                        kind = 27;
                     jjCheckNAdd(4);
                  }
                  if ((0x100002600L & l) != 0L)
                  {
                     if (kind > 6)
                        kind = 6;
                  }
                  else if (curChar == 34)
                     jjCheckNAdd(2);
                  break;
               case 1:
                  if (curChar == 34)
                     jjCheckNAdd(2);
                  break;
               case 2:
                  if ((0xfffffffbffffffffL & l) != 0L)
                     jjCheckNAddTwoStates(2, 3);
                  break;
               case 3:
                  if (curChar == 34 && kind > 26)
                     kind = 26;
                  break;
               case 4:
                  if ((0xfffffffeffffffffL & l) == 0L)
                     break;
                  if (kind > 27)
                     kind = 27;
                  jjCheckNAdd(4);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 4:
                  if ((0xffffffffdfffffffL & l) == 0L)
                     break;
                  if (kind > 27)
                     kind = 27;
                  jjCheckNAdd(4);
                  break;
               case 2:
                  jjAddStates(17, 18);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
               case 4:
                  if (!jjCanMove_0(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 27)
                     kind = 27;
                  jjCheckNAdd(4);
                  break;
               case 2:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                     jjAddStates(17, 18);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 5 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
static final int[] jjnextStates = {
   22, 25, 26, 29, 30, 27, 23, 18, 19, 25, 26, 27, 24, 28, 31, 15, 
   16, 2, 3, 0, 1, 
};
private static final boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 0:
         return ((jjbitVec2[i2] & l2) != 0L);
      default : 
         if ((jjbitVec0[i1] & l1) != 0L)
            return true;
         return false;
   }
}
public static final String[] jjstrLiteralImages = {
"""", null, null, null, null, null, null, null, null, null, ""\53"", ""\55"", ""\50"", 
""\51"", ""\72"", ""\136"", null, null, null, null, null, ""\133"", ""\173"", null, ""\124\117"", 
""\135"", null, null, ""\124\117"", ""\175"", null, null, };
public static final String[] lexStateNames = {
   ""Boost"", 
   ""RangeEx"", 
   ""RangeIn"", 
   ""DEFAULT"", 
};
public static final int[] jjnewLexState = {
   -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 2, 1, 3, -1, 
   3, -1, -1, -1, 3, -1, -1, 
};
static final long[] jjtoToken = {
   0xffffff81L, 
};
static final long[] jjtoSkip = {
   0x40L, 
};
protected CharStream input_stream;
private final int[] jjrounds = new int[33];
private final int[] jjstateSet = new int[66];
protected char curChar;
public QueryParserTokenManager(CharStream stream)
{
   input_stream = stream;
}
public QueryParserTokenManager(CharStream stream, int lexState)
{
   this(stream);
   SwitchTo(lexState);
}
public void ReInit(CharStream stream)
{
   jjmatchedPos = jjnewStateCnt = 0;
   curLexState = defaultLexState;
   input_stream = stream;
   ReInitRounds();
}
private final void ReInitRounds()
{
   int i;
   jjround = 0x80000001;
   for (i = 33; i-- > 0;)
      jjrounds[i] = 0x80000000;
}
public void ReInit(CharStream stream, int lexState)
{
   ReInit(stream);
   SwitchTo(lexState);
}
public void SwitchTo(int lexState)
{
   if (lexState >= 4 || lexState < 0)
      throw new TokenMgrError(""Error: Ignoring invalid lexical state : "" + lexState + "". State unchanged."", TokenMgrError.INVALID_LEXICAL_STATE);
   else
      curLexState = lexState;
}

protected Token jjFillToken()
{
   Token t = Token.newToken(jjmatchedKind);
   t.kind = jjmatchedKind;
   String im = jjstrLiteralImages[jjmatchedKind];
   t.image = (im == null) ? input_stream.GetImage() : im;
   t.beginLine = input_stream.getBeginLine();
   t.beginColumn = input_stream.getBeginColumn();
   t.endLine = input_stream.getEndLine();
   t.endColumn = input_stream.getEndColumn();
   return t;
}

int curLexState = 3;
int defaultLexState = 3;
int jjnewStateCnt;
int jjround;
int jjmatchedPos;
int jjmatchedKind;

public Token getNextToken() 
{
  int kind;
  Token specialToken = null;
  Token matchedToken;
  int curPos = 0;

  EOFLoop :
  for (;;)
  {   
   try   
   {     
      curChar = input_stream.BeginToken();
   }     
   catch(java.io.IOException e)
   {        
      jjmatchedKind = 0;
      matchedToken = jjFillToken();
      return matchedToken;
   }

   switch(curLexState)
   {
     case 0:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_0();
       break;
     case 1:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_1();
       break;
     case 2:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_2();
       break;
     case 3:
       jjmatchedKind = 0x7fffffff;
       jjmatchedPos = 0;
       curPos = jjMoveStringLiteralDfa0_3();
       break;
   }
     if (jjmatchedKind != 0x7fffffff)
     {
        if (jjmatchedPos + 1 < curPos)
           input_stream.backup(curPos - jjmatchedPos - 1);
        if ((jjtoToken[jjmatchedKind >> 6] & (1L << (jjmatchedKind & 077))) != 0L)
        {
           matchedToken = jjFillToken();
       if (jjnewLexState[jjmatchedKind] != -1)
         curLexState = jjnewLexState[jjmatchedKind];
           return matchedToken;
        }
        else
        {
         if (jjnewLexState[jjmatchedKind] != -1)
           curLexState = jjnewLexState[jjmatchedKind];
           continue EOFLoop;
        }
     }
     int error_line = input_stream.getEndLine();
     int error_column = input_stream.getEndColumn();
     String error_after = null;
     boolean EOFSeen = false;
     try { input_stream.readChar(); input_stream.backup(1); }
     catch (java.io.IOException e1) {
        EOFSeen = true;
        error_after = curPos <= 1 ? """" : input_stream.GetImage();
        if (curChar == '\n' || curChar == '\r') {
           error_line++;
           error_column = 0;
        }
        else
           error_column++;
     }
     if (!EOFSeen) {
        input_stream.backup(1);
        error_after = curPos <= 1 ? """" : input_stream.GetImage();
     }
     throw new TokenMgrError(EOFSeen, curLexState, error_line, error_column, error_after, curChar, TokenMgrError.LEXICAL_ERROR);
  }
}

}
"
lucene,2,org.apache.lucene.search.SloppyPhraseScorer,2,3,0,8,11,0,2,6,0,0.0,106,1.0,0,0.952380952,0.571428571,1,1,51.5,1,0.5,1,"package org.apache.lucene.search;



import org.apache.lucene.index.TermPositions;

import java.io.IOException;

final class SloppyPhraseScorer extends PhraseScorer {
    private int slop;

    SloppyPhraseScorer(Weight weight, TermPositions[] tps, int[] positions, Similarity similarity,
                       int slop, byte[] norms) {
        super(weight, tps, positions, similarity, norms);
        this.slop = slop;
    }

    protected final float phraseFreq() throws IOException {
        pq.clear();
        int end = 0;
        for (PhrasePositions pp = first; pp != null; pp = pp.next) {
            pp.firstPosition();
            if (pp.position > end)
                end = pp.position;
            pq.put(pp);				  
        }

        float freq = 0.0f;
        boolean done = false;
        do {
            PhrasePositions pp = (PhrasePositions) pq.pop();
            int start = pp.position;
            int next = ((PhrasePositions) pq.top()).position;
            for (int pos = start; pos <= next; pos = pp.position) {
                start = pos;				  
                if (!pp.nextPosition()) {
                    done = true;				  
                    break;
                }
            }

            int matchLength = end - start;
            if (matchLength <= slop)
                freq += getSimilarity().sloppyFreq(matchLength); 

            if (pp.position > end)
                end = pp.position;
            pq.put(pp);				  
        } while (!done);

        return freq;
    }
}
"
lucene,2,org.apache.lucene.index.TermEnum,6,1,5,25,8,15,24,1,6,2.0,21,0.0,0,0.0,0.583333333,0,0,2.5,1,0.8333,0,"package org.apache.lucene.index;



import java.io.IOException;



public abstract class TermEnum {
  
  public abstract boolean next() throws IOException;

  
  public abstract Term term();

  
  public abstract int docFreq();

  
  public abstract void close() throws IOException;
  

  
  
  public boolean skipTo(Term target) throws IOException {
     do {
        if (!next())
  	        return false;
     } while (target.compareTo(term()) > 0);
     return true;
  }
}
"
lucene,2,org.apache.lucene.index.TermVectorsWriter,15,1,0,13,54,41,2,11,10,0.804761905,675,0.533333333,5,0.0,0.237037037,0,0,43.0,3,1.2,0,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.util.StringHelper;

import java.io.IOException;
import java.util.Vector;


final class TermVectorsWriter {
  static final byte STORE_POSITIONS_WITH_TERMVECTOR = 0x1;
  static final byte STORE_OFFSET_WITH_TERMVECTOR = 0x2;
  
  static final int FORMAT_VERSION = 2;
  
  static final int FORMAT_SIZE = 4;
  
  static final String TVX_EXTENSION = "".tvx"";
  static final String TVD_EXTENSION = "".tvd"";
  static final String TVF_EXTENSION = "".tvf"";
  
  private IndexOutput tvx = null, tvd = null, tvf = null;
  private Vector fields = null;
  private Vector terms = null;
  private FieldInfos fieldInfos;

  private TVField currentField = null;
  private long currentDocPointer = -1;

  public TermVectorsWriter(Directory directory, String segment,
                           FieldInfos fieldInfos)
    throws IOException {
    
    tvx = directory.createOutput(segment + TVX_EXTENSION);
    tvx.writeInt(FORMAT_VERSION);
    tvd = directory.createOutput(segment + TVD_EXTENSION);
    tvd.writeInt(FORMAT_VERSION);
    tvf = directory.createOutput(segment + TVF_EXTENSION);
    tvf.writeInt(FORMAT_VERSION);

    this.fieldInfos = fieldInfos;
    fields = new Vector(fieldInfos.size());
    terms = new Vector();
  }


  public final void openDocument()
          throws IOException {
    closeDocument();
    currentDocPointer = tvd.getFilePointer();
  }


  public final void closeDocument()
          throws IOException {
    if (isDocumentOpen()) {
      closeField();
      writeDoc();
      fields.clear();
      currentDocPointer = -1;
    }
  }


  public final boolean isDocumentOpen() {
    return currentDocPointer != -1;
  }


  
  public final void openField(String field) throws IOException {
    FieldInfo fieldInfo = fieldInfos.fieldInfo(field);
    openField(fieldInfo.number, fieldInfo.storePositionWithTermVector, fieldInfo.storeOffsetWithTermVector);
  }
  
  private void openField(int fieldNumber, boolean storePositionWithTermVector, 
      boolean storeOffsetWithTermVector) throws IOException{
    if (!isDocumentOpen()) 
      throw new IllegalStateException(""Cannot open field when no document is open."");
    closeField();
    currentField = new TVField(fieldNumber, storePositionWithTermVector, storeOffsetWithTermVector);
  }

  
  public final void closeField()
          throws IOException {
    if (isFieldOpen()) {
      
      
      

      
      writeField();
      fields.add(currentField);
      terms.clear();
      currentField = null;
    }
  }

  
  public final boolean isFieldOpen() {
    return currentField != null;
  }

  
  public final void addTerm(String termText, int freq) {
    addTerm(termText, freq, null, null);
  }
  
  public final void addTerm(String termText, int freq, int [] positions, TermVectorOffsetInfo [] offsets)
  {
    if (!isDocumentOpen()) 
      throw new IllegalStateException(""Cannot add terms when document is not open"");
    if (!isFieldOpen()) 
      throw new IllegalStateException(""Cannot add terms when field is not open"");
    
    addTermInternal(termText, freq, positions, offsets);
  }

  private final void addTermInternal(String termText, int freq, int [] positions, TermVectorOffsetInfo [] offsets) {
    TVTerm term = new TVTerm();
    term.termText = termText;
    term.freq = freq;
    term.positions = positions;
    term.offsets = offsets;
    terms.add(term);
  }

  
  public final void addAllDocVectors(TermFreqVector[] vectors)
      throws IOException {
    openDocument();

    if (vectors != null) {
      for (int i = 0; i < vectors.length; i++) {
        boolean storePositionWithTermVector = false;
        boolean storeOffsetWithTermVector = false;

        try {

          TermPositionVector tpVector = (TermPositionVector) vectors[i];

          if (tpVector.size() > 0 && tpVector.getTermPositions(0) != null)
            storePositionWithTermVector = true;
          if (tpVector.size() > 0 && tpVector.getOffsets(0) != null)
            storeOffsetWithTermVector = true;

          FieldInfo fieldInfo = fieldInfos.fieldInfo(tpVector.getField());
          openField(fieldInfo.number, storePositionWithTermVector, storeOffsetWithTermVector);

          for (int j = 0; j < tpVector.size(); j++)
            addTermInternal(tpVector.getTerms()[j], tpVector.getTermFrequencies()[j], tpVector.getTermPositions(j),
                tpVector.getOffsets(j));

          closeField();

        } catch (ClassCastException ignore) {

          TermFreqVector tfVector = vectors[i];

          FieldInfo fieldInfo = fieldInfos.fieldInfo(tfVector.getField());
          openField(fieldInfo.number, storePositionWithTermVector, storeOffsetWithTermVector);

          for (int j = 0; j < tfVector.size(); j++)
            addTermInternal(tfVector.getTerms()[j], tfVector.getTermFrequencies()[j], null, null);

          closeField();

        }
      }
    }

    closeDocument();
  }
  
  
  final void close() throws IOException {
    try {
      closeDocument();
    } finally {
      
      
      IOException keep = null;
      if (tvx != null)
        try {
          tvx.close();
        } catch (IOException e) {
          if (keep == null) keep = e;
        }
      if (tvd != null)
        try {
          tvd.close();
        } catch (IOException e) {
          if (keep == null) keep = e;
        }
      if (tvf != null)
        try {
          tvf.close();
        } catch (IOException e) {
          if (keep == null) keep = e;
        }
      if (keep != null) throw (IOException) keep.fillInStackTrace();
    }
  }

  

  private void writeField() throws IOException {
    
    currentField.tvfPointer = tvf.getFilePointer();
    
    
    final int size = terms.size();
    tvf.writeVInt(size);
    
    boolean storePositions = currentField.storePositions;
    boolean storeOffsets = currentField.storeOffsets;
    byte bits = 0x0;
    if (storePositions) 
      bits |= STORE_POSITIONS_WITH_TERMVECTOR;
    if (storeOffsets) 
      bits |= STORE_OFFSET_WITH_TERMVECTOR;
    tvf.writeByte(bits);
    
    String lastTermText = """";
    for (int i = 0; i < size; i++) {
      TVTerm term = (TVTerm) terms.elementAt(i);
      int start = StringHelper.stringDifference(lastTermText, term.termText);
      int length = term.termText.length() - start;
      tvf.writeVInt(start);       
      tvf.writeVInt(length);        
      tvf.writeChars(term.termText, start, length);  
      tvf.writeVInt(term.freq);
      lastTermText = term.termText;
      
      if(storePositions){
        if(term.positions == null)
          throw new IllegalStateException(""Trying to write positions that are null!"");
        
        
        int position = 0;
        for (int j = 0; j < term.freq; j++){
          tvf.writeVInt(term.positions[j] - position);
          position = term.positions[j];
        }
      }
      
      if(storeOffsets){
        if(term.offsets == null)
          throw new IllegalStateException(""Trying to write offsets that are null!"");
        
        
        int position = 0;
        for (int j = 0; j < term.freq; j++) {
          tvf.writeVInt(term.offsets[j].getStartOffset() - position);
          tvf.writeVInt(term.offsets[j].getEndOffset() - term.offsets[j].getStartOffset()); 
          position = term.offsets[j].getEndOffset();
        }
      }
    }
  }

  private void writeDoc() throws IOException {
    if (isFieldOpen()) 
      throw new IllegalStateException(""Field is still open while writing document"");
    
    
    tvx.writeLong(currentDocPointer);

    
    final int size = fields.size();

    
    tvd.writeVInt(size);

    
    for (int i = 0; i < size; i++) {
      TVField field = (TVField) fields.elementAt(i);
      tvd.writeVInt(field.number);
    }

    
    long lastFieldPointer = 0;
    for (int i = 0; i < size; i++) {
      TVField field = (TVField) fields.elementAt(i);
      tvd.writeVLong(field.tvfPointer - lastFieldPointer);
      lastFieldPointer = field.tvfPointer;
    }
    
  }


  private static class TVField {
    int number;
    long tvfPointer = 0;
    boolean storePositions = false;
    boolean storeOffsets = false;
    TVField(int number, boolean storePos, boolean storeOff) {
      this.number = number;
      storePositions = storePos;
      storeOffsets = storeOff;
    }
  }

  private static class TVTerm {
    String termText;
    int freq = 0;
    int positions[] = null;
    TermVectorOffsetInfo [] offsets = null;
  }


}
"
lucene,2,org.apache.lucene.index.FieldsReader,5,1,0,10,36,2,1,9,0,0.625,319,1.0,3,0.0,0.333333333,0,0,62.0,1,0.8,9,"package org.apache.lucene.index;



import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.util.zip.DataFormatException;
import java.util.zip.Inflater;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;


final class FieldsReader {
  private FieldInfos fieldInfos;
  private IndexInput fieldsStream;
  private IndexInput indexStream;
  private int size;

  FieldsReader(Directory d, String segment, FieldInfos fn) throws IOException {
    fieldInfos = fn;

    fieldsStream = d.openInput(segment + "".fdt"");
    indexStream = d.openInput(segment + "".fdx"");

    size = (int)(indexStream.length() / 8);
  }

  final void close() throws IOException {
    fieldsStream.close();
    indexStream.close();
  }

  final int size() {
    return size;
  }

  final Document doc(int n) throws IOException {
    indexStream.seek(n * 8L);
    long position = indexStream.readLong();
    fieldsStream.seek(position);

    Document doc = new Document();
    int numFields = fieldsStream.readVInt();
    for (int i = 0; i < numFields; i++) {
      int fieldNumber = fieldsStream.readVInt();
      FieldInfo fi = fieldInfos.fieldInfo(fieldNumber);

      byte bits = fieldsStream.readByte();
      
      boolean compressed = (bits & FieldsWriter.FIELD_IS_COMPRESSED) != 0;
      boolean tokenize = (bits & FieldsWriter.FIELD_IS_TOKENIZED) != 0;
      
      if ((bits & FieldsWriter.FIELD_IS_BINARY) != 0) {
        final byte[] b = new byte[fieldsStream.readVInt()];
        fieldsStream.readBytes(b, 0, b.length);
        if (compressed)
          doc.add(new Field(fi.name, uncompress(b), Field.Store.COMPRESS));
        else
          doc.add(new Field(fi.name, b, Field.Store.YES));
      }
      else {
        Field.Index index;
        Field.Store store = Field.Store.YES;
        
        if (fi.isIndexed && tokenize)
          index = Field.Index.TOKENIZED;
        else if (fi.isIndexed && !tokenize)
          index = Field.Index.UN_TOKENIZED;
        else
          index = Field.Index.NO;
        
        Field.TermVector termVector = null;
        if (fi.storeTermVector) {
          if (fi.storeOffsetWithTermVector) {
            if (fi.storePositionWithTermVector) {
              termVector = Field.TermVector.WITH_POSITIONS_OFFSETS;
            }
            else {
              termVector = Field.TermVector.WITH_OFFSETS;
            }
          }
          else if (fi.storePositionWithTermVector) {
            termVector = Field.TermVector.WITH_POSITIONS;
          }
          else {
            termVector = Field.TermVector.YES;
          }
        }
        else {
          termVector = Field.TermVector.NO;
        }
        
        if (compressed) {
          store = Field.Store.COMPRESS;
          final byte[] b = new byte[fieldsStream.readVInt()];
          fieldsStream.readBytes(b, 0, b.length);
          Field f = new Field(fi.name,      
              new String(uncompress(b), ""UTF-8""), 
              store,
              index,
              termVector);
          f.setOmitNorms(fi.omitNorms);
          doc.add(f);
        }
        else {
          Field f = new Field(fi.name,     
                fieldsStream.readString(), 
                store,
                index,
                termVector);
          f.setOmitNorms(fi.omitNorms);
          doc.add(f);
        }
      }
    }

    return doc;
  }
  
  private final byte[] uncompress(final byte[] input)
    throws IOException
  {
  
    Inflater decompressor = new Inflater();
    decompressor.setInput(input);
  
    
    ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length);
  
    
    byte[] buf = new byte[1024];
    while (!decompressor.finished()) {
      try {
        int count = decompressor.inflate(buf);
        bos.write(buf, 0, count);
      }
      catch (DataFormatException e) {
        
        IOException newException = new IOException(""field data are in wrong format: "" + e.toString());
        newException.initCause(e);
        throw newException;
      }
    }
  
    decompressor.end();
    
    
    return bos.toByteArray();
  }
}
"
lucene,2,org.apache.lucene.search.Query,13,1,13,45,39,72,42,7,12,0.833333333,249,1.0,0,0.0,0.230769231,0,0,18.07692308,9,1.8462,0,"package org.apache.lucene.search;



import java.io.IOException;

import java.util.HashSet;
import java.util.Iterator;
import java.util.Set;

import org.apache.lucene.index.IndexReader;


public abstract class Query implements java.io.Serializable, Cloneable {
  private float boost = 1.0f;                     

  
  public void setBoost(float b) { boost = b; }

  
  public float getBoost() { return boost; }

  
  public abstract String toString(String field);

  
  public String toString() {
    return toString("""");
  }

  
  protected Weight createWeight(Searcher searcher) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  public Weight weight(Searcher searcher)
    throws IOException {
    Query query = searcher.rewrite(this);
    Weight weight = query.createWeight(searcher);
    float sum = weight.sumOfSquaredWeights();
    float norm = getSimilarity(searcher).queryNorm(sum);
    weight.normalize(norm);
    return weight;
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    return this;
  }

  
  public Query combine(Query[] queries) {
    HashSet uniques = new HashSet();
    for (int i = 0; i < queries.length; i++) {
      Query query = queries[i];
      BooleanClause[] clauses = null;
      
      boolean splittable = (query instanceof BooleanQuery);
      if(splittable){
        BooleanQuery bq = (BooleanQuery) query;
        splittable = bq.isCoordDisabled();
        clauses = bq.getClauses();
        for (int j = 0; splittable && j < clauses.length; j++) {
          splittable = (clauses[j].getOccur() == BooleanClause.Occur.SHOULD);
        }
      }
      if(splittable){
        for (int j = 0; j < clauses.length; j++) {
          uniques.add(clauses[j].getQuery());
        }
      } else {
        uniques.add(query);
      }
    }
    
    if(uniques.size() == 1){
        return (Query)uniques.iterator().next();
    }
    Iterator it = uniques.iterator();
    BooleanQuery result = new BooleanQuery(true);
    while (it.hasNext())
      result.add((Query) it.next(), BooleanClause.Occur.SHOULD);
    return result;
  }

  
  public void extractTerms(Set terms) {
    
    throw new UnsupportedOperationException();
  }


  
  public static Query mergeBooleanQueries(Query[] queries) {
    HashSet allClauses = new HashSet();
    for (int i = 0; i < queries.length; i++) {
      BooleanClause[] clauses = ((BooleanQuery)queries[i]).getClauses();
      for (int j = 0; j < clauses.length; j++) {
        allClauses.add(clauses[j]);
      }
    }

    boolean coordDisabled =
      queries.length==0? false : ((BooleanQuery)queries[0]).isCoordDisabled();
    BooleanQuery result = new BooleanQuery(coordDisabled);
    Iterator i = allClauses.iterator();
    while (i.hasNext()) {
      result.add((BooleanClause)i.next());
    }
    return result;
  }

  
  public Similarity getSimilarity(Searcher searcher) {
    return searcher.getSimilarity();
  }

  
  public Object clone() {
    try {
      return (Query)super.clone();
    } catch (CloneNotSupportedException e) {
      throw new RuntimeException(""Clone not supported: "" + e.getMessage());
    }
  }
}
"
lucene,2,org.apache.lucene.search.RangeQuery,9,2,0,9,32,0,1,8,9,0.291666667,340,1.0,2,0.6,0.259259259,2,3,36.44444444,11,3.0,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class RangeQuery extends Query
{
    private Term lowerTerm;
    private Term upperTerm;
    private boolean inclusive;

    
    public RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive)
    {
        if (lowerTerm == null && upperTerm == null)
        {
            throw new IllegalArgumentException(""At least one term must be non-null"");
        }
        if (lowerTerm != null && upperTerm != null && lowerTerm.field() != upperTerm.field())
        {
            throw new IllegalArgumentException(""Both terms must be for the same field"");
        }

        
        if (lowerTerm != null) {
            this.lowerTerm = lowerTerm;
        }
        else {
            this.lowerTerm = new Term(upperTerm.field(), """");
        }

        this.upperTerm = upperTerm;
        this.inclusive = inclusive;
    }

    public Query rewrite(IndexReader reader) throws IOException {

        BooleanQuery query = new BooleanQuery(true);
        TermEnum enumerator = reader.terms(lowerTerm);

        try {

            boolean checkLower = false;
            if (!inclusive) 
                checkLower = true;

            String testField = getField();

            do {
                Term term = enumerator.term();
                if (term != null && term.field() == testField) {
                    if (!checkLower || term.text().compareTo(lowerTerm.text()) > 0) {
                        checkLower = false;
                        if (upperTerm != null) {
                            int compare = upperTerm.text().compareTo(term.text());
                            
                            if ((compare < 0) || (!inclusive && compare == 0))
                                break;
                        }
                        TermQuery tq = new TermQuery(term); 
                        tq.setBoost(getBoost()); 
                        query.add(tq, BooleanClause.Occur.SHOULD); 
                    }
                }
                else {
                    break;
                }
            }
            while (enumerator.next());
        }
        finally {
            enumerator.close();
        }
        return query;
    }

    
    public String getField() {
      return (lowerTerm != null ? lowerTerm.field() : upperTerm.field());
    }

    
    public Term getLowerTerm() { return lowerTerm; }

    
    public Term getUpperTerm() { return upperTerm; }

    
    public boolean isInclusive() { return inclusive; }


    
    public String toString(String field)
    {
        StringBuffer buffer = new StringBuffer();
        if (!getField().equals(field))
        {
            buffer.append(getField());
            buffer.append("":"");
        }
        buffer.append(inclusive ? ""["" : ""{"");
        buffer.append(lowerTerm != null ? lowerTerm.text() : ""null"");
        buffer.append("" TO "");
        buffer.append(upperTerm != null ? upperTerm.text() : ""null"");
        buffer.append(inclusive ? ""]"" : ""}"");
        buffer.append(ToStringUtils.boost(getBoost()));
        return buffer.toString();
    }

    
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof RangeQuery)) return false;

        final RangeQuery other = (RangeQuery) o;
        if (this.getBoost() != other.getBoost()) return false;
        if (this.inclusive != other.inclusive) return false;
        
        if (this.lowerTerm != null ? !this.lowerTerm.equals(other.lowerTerm) : other.lowerTerm != null) return false;
        if (this.upperTerm != null ? !this.upperTerm.equals(other.upperTerm) : other.upperTerm != null) return false;
        return true;
    }

    
    public int hashCode() {
      int h = Float.floatToIntBits(getBoost());
      h ^= lowerTerm != null ? lowerTerm.hashCode() : 0;
      
      
      h ^= (h << 25) | (h >>> 8);
      h ^= upperTerm != null ? upperTerm.hashCode() : 0;
      h ^= this.inclusive ? 0x2742E74A : 0;
      return h;
    }
}
"
lucene,2,org.apache.lucene.search.PrefixQuery,6,2,0,9,28,0,1,8,6,0.0,147,1.0,1,0.705882353,0.333333333,2,3,23.33333333,4,1.5,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class PrefixQuery extends Query {
  private Term prefix;

  
  public PrefixQuery(Term prefix) {
    this.prefix = prefix;
  }

  
  public Term getPrefix() { return prefix; }

  public Query rewrite(IndexReader reader) throws IOException {
    BooleanQuery query = new BooleanQuery(true);
    TermEnum enumerator = reader.terms(prefix);
    try {
      String prefixText = prefix.text();
      String prefixField = prefix.field();
      do {
        Term term = enumerator.term();
        if (term != null &&
            term.text().startsWith(prefixText) &&
            term.field() == prefixField) {
          TermQuery tq = new TermQuery(term);	  
          tq.setBoost(getBoost());                
          query.add(tq, BooleanClause.Occur.SHOULD);		  
          
        } else {
          break;
        }
      } while (enumerator.next());
    } finally {
      enumerator.close();
    }
    return query;
  }

  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    if (!prefix.field().equals(field)) {
      buffer.append(prefix.field());
      buffer.append("":"");
    }
    buffer.append(prefix.text());
    buffer.append('*');
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof PrefixQuery))
      return false;
    PrefixQuery other = (PrefixQuery)o;
    return (this.getBoost() == other.getBoost())
      && this.prefix.equals(other.prefix);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ prefix.hashCode() ^ 0x6634D93C;
  }
}
"
lucene,2,org.apache.lucene.analysis.standard.StandardTokenizer,15,3,0,9,29,15,1,8,11,0.6,523,0.7,3,0.214285714,0.285714286,1,1,33.2,10,1.7333,0,"
package org.apache.lucene.analysis.standard;

import java.io.*;


public class StandardTokenizer extends org.apache.lucene.analysis.Tokenizer implements StandardTokenizerConstants {

  
  public StandardTokenizer(Reader reader) {
    this(new FastCharStream(reader));
    this.input = reader;
  }


  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {
  Token token = null;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case ALPHANUM:
      token = jj_consume_token(ALPHANUM);
      break;
    case APOSTROPHE:
      token = jj_consume_token(APOSTROPHE);
      break;
    case ACRONYM:
      token = jj_consume_token(ACRONYM);
      break;
    case COMPANY:
      token = jj_consume_token(COMPANY);
      break;
    case EMAIL:
      token = jj_consume_token(EMAIL);
      break;
    case HOST:
      token = jj_consume_token(HOST);
      break;
    case NUM:
      token = jj_consume_token(NUM);
      break;
    case CJ:
      token = jj_consume_token(CJ);
      break;
    case 0:
      token = jj_consume_token(0);
      break;
    default:
      jj_la1[0] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
      if (token.kind == EOF) {
        {if (true) return null;}
      } else {
        {if (true) return
          new org.apache.lucene.analysis.Token(token.image,
                                        token.beginColumn,token.endColumn,
                                        tokenImage[token.kind]);}
      }
    throw new Error(""Missing return statement in function"");
  }

  public StandardTokenizerTokenManager token_source;
  public Token token, jj_nt;
  private int jj_ntk;
  private int jj_gen;
  final private int[] jj_la1 = new int[1];
  static private int[] jj_la1_0;
  static {
      jj_la1_0();
   }
   private static void jj_la1_0() {
      jj_la1_0 = new int[] {0x10ff,};
   }

  public StandardTokenizer(CharStream stream) {
    token_source = new StandardTokenizerTokenManager(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  public void ReInit(CharStream stream) {
    token_source.ReInit(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  public StandardTokenizer(StandardTokenizerTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  public void ReInit(StandardTokenizerTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 1; i++) jj_la1[i] = -1;
  }

  final private Token jj_consume_token(int kind) throws ParseException {
    Token oldToken;
    if ((oldToken = token).next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    if (token.kind == kind) {
      jj_gen++;
      return token;
    }
    token = oldToken;
    jj_kind = kind;
    throw generateParseException();
  }

  final public Token getNextToken() {
    if (token.next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    jj_gen++;
    return token;
  }

  final public Token getToken(int index) {
    Token t = token;
    for (int i = 0; i < index; i++) {
      if (t.next != null) t = t.next;
      else t = t.next = token_source.getNextToken();
    }
    return t;
  }

  final private int jj_ntk() {
    if ((jj_nt=token.next) == null)
      return (jj_ntk = (token.next=token_source.getNextToken()).kind);
    else
      return (jj_ntk = jj_nt.kind);
  }

  private java.util.Vector jj_expentries = new java.util.Vector();
  private int[] jj_expentry;
  private int jj_kind = -1;

  public ParseException generateParseException() {
    jj_expentries.removeAllElements();
    boolean[] la1tokens = new boolean[16];
    for (int i = 0; i < 16; i++) {
      la1tokens[i] = false;
    }
    if (jj_kind >= 0) {
      la1tokens[jj_kind] = true;
      jj_kind = -1;
    }
    for (int i = 0; i < 1; i++) {
      if (jj_la1[i] == jj_gen) {
        for (int j = 0; j < 32; j++) {
          if ((jj_la1_0[i] & (1<<j)) != 0) {
            la1tokens[j] = true;
          }
        }
      }
    }
    for (int i = 0; i < 16; i++) {
      if (la1tokens[i]) {
        jj_expentry = new int[1];
        jj_expentry[0] = i;
        jj_expentries.addElement(jj_expentry);
      }
    }
    int[][] exptokseq = new int[jj_expentries.size()][];
    for (int i = 0; i < jj_expentries.size(); i++) {
      exptokseq[i] = (int[])jj_expentries.elementAt(i);
    }
    return new ParseException(token, exptokseq, tokenImage);
  }

  final public void enable_tracing() {
  }

  final public void disable_tracing() {
  }

}
"
lucene,2,org.apache.lucene.search.TopDocs,3,1,1,14,4,0,13,1,2,0.666666667,25,0.333333333,1,0.0,0.583333333,0,0,6.333333333,1,0.6667,0,"package org.apache.lucene.search;




public class TopDocs implements java.io.Serializable {
  
  public int totalHits;
  
  public ScoreDoc[] scoreDocs;
  
  private float maxScore;
  
  
  public float getMaxScore() {
      return maxScore;
  }
  
  
  public void setMaxScore(float maxScore) {
      this.maxScore=maxScore;
  }
  
  
  TopDocs(int totalHits, ScoreDoc[] scoreDocs, float maxScore) {
    this.totalHits = totalHits;
    this.scoreDocs = scoreDocs;
    this.maxScore = maxScore;
  }
}
"
lucene,2,org.apache.lucene.analysis.Tokenizer,3,2,3,4,5,1,3,1,1,0.5,17,1.0,0,0.666666667,0.666666667,0,0,4.333333333,1,0.3333,0,"package org.apache.lucene.analysis;



import java.io.Reader;
import java.io.IOException;



public abstract class Tokenizer extends TokenStream {
  
  protected Reader input;

  
  protected Tokenizer() {}

  
  protected Tokenizer(Reader input) {
    this.input = input;
  }

  
  public void close() throws IOException {
    input.close();
  }
}

"
lucene,2,org.apache.lucene.LucenePackage,3,1,0,0,8,3,0,0,1,1.0,27,0.0,0,0.0,0.333333333,0,0,7.666666667,2,1.0,0,"package org.apache.lucene;




public final class LucenePackage {

  private LucenePackage() {}                      

  
  public static Package get() {
    return LucenePackage.class.getPackage();
  }
}
"
lucene,2,org.apache.lucene.util.BitVector,9,1,0,5,18,0,2,3,8,0.5,1224,1.0,0,0.0,0.5,0,0,134.5555556,3,1.0,2,"package org.apache.lucene.util;



import java.io.IOException;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;


public final class BitVector {

  private byte[] bits;
  private int size;
  private int count = -1;

  
  public BitVector(int n) {
    size = n;
    bits = new byte[(size >> 3) + 1];
  }

  
  public final void set(int bit) {
    bits[bit >> 3] |= 1 << (bit & 7);
    count = -1;
  }

  
  public final void clear(int bit) {
    bits[bit >> 3] &= ~(1 << (bit & 7));
    count = -1;
  }

  
  public final boolean get(int bit) {
    return (bits[bit >> 3] & (1 << (bit & 7))) != 0;
  }

  
  public final int size() {
    return size;
  }

  
  public final int count() {
    
    if (count == -1) {
      int c = 0;
      int end = bits.length;
      for (int i = 0; i < end; i++)
        c += BYTE_COUNTS[bits[i] & 0xFF];	  
      count = c;
    }
    return count;
  }

  private static final byte[] BYTE_COUNTS = {	  
    0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
    4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8
  };


  
  public final void write(Directory d, String name) throws IOException {
    IndexOutput output = d.createOutput(name);
    try {
      output.writeInt(size());			  
      output.writeInt(count());			  
      output.writeBytes(bits, bits.length);	  
    } finally {
      output.close();
    }
  }

  
  public BitVector(Directory d, String name) throws IOException {
    IndexInput input = d.openInput(name);
    try {
      size = input.readInt();			  
      count = input.readInt();			  
      bits = new byte[(size >> 3) + 1];		  
      input.readBytes(bits, 0, bits.length);	  
    } finally {
      input.close();
    }
  }

}
"
lucene,2,org.apache.lucene.util.Parameter,6,1,5,5,18,5,5,0,1,0.6,88,0.5,0,0.0,0.7,0,0,13.33333333,1,0.5,0,"package org.apache.lucene.util;



import java.io.ObjectStreamException;
import java.io.Serializable;
import java.io.StreamCorruptedException;
import java.util.HashMap;
import java.util.Map;


public abstract class Parameter implements Serializable
{
  static Map allParameters = new HashMap();
  
  private String name;
  
  private Parameter() {
    
  }
  
  protected Parameter(String name) {
    
    this.name = name;
    String key = makeKey(name);
    
    if(allParameters.containsKey(key))
      throw new IllegalArgumentException(""Parameter name "" + key + "" already used!"");
    
    allParameters.put(key, this);
  }
  
  private String makeKey(String name){
    return getClass() + "" "" + name;
  }
  
  public String toString() {
    return name;
  }
  
  
  protected Object readResolve() throws ObjectStreamException {
    Object par = allParameters.get(makeKey(name));
    
    if(par == null)
      throw new StreamCorruptedException(""Unknown parameter value: "" + name);
      
    return par;
  }
  
 }
"
lucene,2,org.apache.lucene.store.RAMDirectory,16,2,0,10,41,10,2,9,15,0.133333333,257,0.0,0,0.5,0.375,0,0,15.0,2,0.875,12,"package org.apache.lucene.store;



import java.io.IOException;
import java.io.File;
import java.util.Hashtable;
import java.util.Enumeration;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;


public final class RAMDirectory extends Directory {
  Hashtable files = new Hashtable();

  
  public RAMDirectory() {
  }

  
  public RAMDirectory(Directory dir) throws IOException {
    this(dir, false);
  }
  
  private RAMDirectory(Directory dir, boolean closeDir) throws IOException {
    final String[] files = dir.list();
    byte[] buf = new byte[BufferedIndexOutput.BUFFER_SIZE];
    for (int i = 0; i < files.length; i++) {
      
      IndexOutput os = createOutput(files[i]);
      
      IndexInput is = dir.openInput(files[i]);
      
      long len = is.length();
      long readCount = 0;
      while (readCount < len) {
        int toRead = readCount + BufferedIndexOutput.BUFFER_SIZE > len ? (int)(len - readCount) : BufferedIndexOutput.BUFFER_SIZE;
        is.readBytes(buf, 0, toRead);
        os.writeBytes(buf, toRead);
        readCount += toRead;
      }

      
      is.close();
      os.close();
    }
    if(closeDir)
      dir.close();
  }

  
  public RAMDirectory(File dir) throws IOException {
    this(FSDirectory.getDirectory(dir, false), true);
  }

  
  public RAMDirectory(String dir) throws IOException {
    this(FSDirectory.getDirectory(dir, false), true);
  }

  
  public final String[] list() {
    String[] result = new String[files.size()];
    int i = 0;
    Enumeration names = files.keys();
    while (names.hasMoreElements())
      result[i++] = (String)names.nextElement();
    return result;
  }

  
  public final boolean fileExists(String name) {
    RAMFile file = (RAMFile)files.get(name);
    return file != null;
  }

  
  public final long fileModified(String name) {
    RAMFile file = (RAMFile)files.get(name);
    return file.lastModified;
  }

  
  public void touchFile(String name) {

    
    RAMFile file = (RAMFile)files.get(name);
    long ts2, ts1 = System.currentTimeMillis();
    do {
      try {
        Thread.sleep(0, 1);
      } catch (InterruptedException e) {}
      ts2 = System.currentTimeMillis();



    } while(ts1 == ts2);

    file.lastModified = ts2;



  }

  
  public final long fileLength(String name) {
    RAMFile file = (RAMFile)files.get(name);
    return file.length;
  }

  
  public final void deleteFile(String name) {
    files.remove(name);
  }

  
  public final void renameFile(String from, String to) {
    RAMFile file = (RAMFile)files.get(from);
    files.remove(from);
    files.put(to, file);
  }

  
  public final IndexOutput createOutput(String name) {
    RAMFile file = new RAMFile();
    files.put(name, file);
    return new RAMOutputStream(file);
  }

  
  public final IndexInput openInput(String name) {
    RAMFile file = (RAMFile)files.get(name);
    return new RAMInputStream(file);
  }

  
  public final Lock makeLock(final String name) {
    return new Lock() {
      public boolean obtain() throws IOException {
        synchronized (files) {
          if (!fileExists(name)) {
            createOutput(name).close();
            return true;
          }
          return false;
        }
      }
      public void release() {
        deleteFile(name);
      }
      public boolean isLocked() {
        return fileExists(name);
      }
    };
  }

  
  public final void close() {
  }
}
"
lucene,2,org.apache.lucene.search.spans.SpanQuery,5,2,5,15,7,10,10,6,4,2.0,14,0.0,0,0.75,0.466666667,1,1,1.8,1,0.8,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.Weight;
import org.apache.lucene.search.Searcher;


public abstract class SpanQuery extends Query {
  
  public abstract Spans getSpans(IndexReader reader) throws IOException;

  
  public abstract String getField();

  
  public abstract Collection getTerms();

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new SpanWeight(this, searcher);
  }

}

"
lucene,2,org.apache.lucene.index.MultipleTermPositions,10,1,0,8,33,25,1,7,10,0.722222222,178,1.0,2,0.0,0.228571429,0,0,16.4,1,0.9,2,"package org.apache.lucene.index;



import java.io.IOException;
import java.util.Arrays;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;

import org.apache.lucene.util.PriorityQueue;


public class MultipleTermPositions implements TermPositions {

  private static final class TermPositionsQueue extends PriorityQueue {
    TermPositionsQueue(List termPositions) throws IOException {
      initialize(termPositions.size());

      Iterator i = termPositions.iterator();
      while (i.hasNext()) {
        TermPositions tp = (TermPositions) i.next();
        if (tp.next())
          put(tp);
      }
    }

    final TermPositions peek() {
      return (TermPositions) top();
    }

    public final boolean lessThan(Object a, Object b) {
      return ((TermPositions) a).doc() < ((TermPositions) b).doc();
    }
  }

  private static final class IntQueue {
    private int _arraySize = 16;
    private int _index = 0;
    private int _lastIndex = 0;
    private int[] _array = new int[_arraySize];

    final void add(int i) {
      if (_lastIndex == _arraySize)
        growArray();

      _array[_lastIndex++] = i;
    }

    final int next() {
      return _array[_index++];
    }

    final void sort() {
      Arrays.sort(_array, _index, _lastIndex);
    }

    final void clear() {
      _index = 0;
      _lastIndex = 0;
    }

    final int size() {
      return (_lastIndex - _index);
    }

    private void growArray() {
      int[] newArray = new int[_arraySize * 2];
      System.arraycopy(_array, 0, newArray, 0, _arraySize);
      _array = newArray;
      _arraySize *= 2;
    }
  }

  private int _doc;
  private int _freq;
  private TermPositionsQueue _termPositionsQueue;
  private IntQueue _posList;

  
  public MultipleTermPositions(IndexReader indexReader, Term[] terms) throws IOException {
    List termPositions = new LinkedList();

    for (int i = 0; i < terms.length; i++)
      termPositions.add(indexReader.termPositions(terms[i]));

    _termPositionsQueue = new TermPositionsQueue(termPositions);
    _posList = new IntQueue();
  }

  public final boolean next() throws IOException {
    if (_termPositionsQueue.size() == 0)
      return false;

    _posList.clear();
    _doc = _termPositionsQueue.peek().doc();

    TermPositions tp;
    do {
      tp = _termPositionsQueue.peek();

      for (int i = 0; i < tp.freq(); i++)
        _posList.add(tp.nextPosition());

      if (tp.next())
        _termPositionsQueue.adjustTop();
      else {
        _termPositionsQueue.pop();
        tp.close();
      }
    } while (_termPositionsQueue.size() > 0 && _termPositionsQueue.peek().doc() == _doc);

    _posList.sort();
    _freq = _posList.size();

    return true;
  }

  public final int nextPosition() {
    return _posList.next();
  }

  public final boolean skipTo(int target) throws IOException {
    while (_termPositionsQueue.peek() != null && target > _termPositionsQueue.peek().doc()) {
      TermPositions tp = (TermPositions) _termPositionsQueue.pop();
      if (tp.skipTo(target))
        _termPositionsQueue.put(tp);
      else
        tp.close();
    }
    return next();
  }

  public final int doc() {
    return _doc;
  }

  public final int freq() {
    return _freq;
  }

  public final void close() throws IOException {
    while (_termPositionsQueue.size() > 0)
      ((TermPositions) _termPositionsQueue.pop()).close();
  }

  
  public void seek(Term arg0) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  public void seek(TermEnum termEnum) throws IOException {
    throw new UnsupportedOperationException();
  }

  
  public int read(int[] arg0, int[] arg1) throws IOException {
    throw new UnsupportedOperationException();
  }

}
"
lucene,2,org.apache.lucene.queryParser.QueryParser,52,1,1,30,129,888,1,29,32,0.873873874,2830,0.648648649,11,0.0,0.132730015,0,0,52.71153846,23,2.6731,7,"
package org.apache.lucene.queryParser;

import java.util.Vector;
import java.io.*;
import java.text.*;
import java.util.*;
import org.apache.lucene.index.Term;
import org.apache.lucene.analysis.*;
import org.apache.lucene.document.*;
import org.apache.lucene.search.*;
import org.apache.lucene.util.Parameter;



public class QueryParser implements QueryParserConstants {

  private static final int CONJ_NONE   = 0;
  private static final int CONJ_AND    = 1;
  private static final int CONJ_OR     = 2;

  private static final int MOD_NONE    = 0;
  private static final int MOD_NOT     = 10;
  private static final int MOD_REQ     = 11;

  
  
  
  public static final Operator AND_OPERATOR = Operator.AND;
  
  public static final Operator OR_OPERATOR = Operator.OR;

  
  private Operator operator = OR_OPERATOR;

  boolean lowercaseExpandedTerms = true;

  Analyzer analyzer;
  String field;
  int phraseSlop = 0;
  float fuzzyMinSim = FuzzyQuery.defaultMinSimilarity;
  int fuzzyPrefixLength = FuzzyQuery.defaultPrefixLength;
  Locale locale = Locale.getDefault();

  
  static public final class Operator extends Parameter {
    private Operator(String name) {
      super(name);
    }
    static public final Operator OR = new Operator(""OR"");
    static public final Operator AND = new Operator(""AND"");
  }


  
  public QueryParser(String f, Analyzer a) {
    this(new FastCharStream(new StringReader("""")));
    analyzer = a;
    field = f;
  }

  
  public Query parse(String query) throws ParseException {
    ReInit(new FastCharStream(new StringReader(query)));
    try {
      return Query(field);
    }
    catch (TokenMgrError tme) {
      throw new ParseException(tme.getMessage());
    }
    catch (BooleanQuery.TooManyClauses tmc) {
      throw new ParseException(""Too many boolean clauses"");
    }
  }

   
  public Analyzer getAnalyzer() {
    return analyzer;
  }

  
  public String getField() {
    return field;
  }

   
  public float getFuzzyMinSim() {
      return fuzzyMinSim;
  }

  
  public void setFuzzyMinSim(float fuzzyMinSim) {
      this.fuzzyMinSim = fuzzyMinSim;
  }

   
  public int getFuzzyPrefixLength() {
    return fuzzyPrefixLength;
  }

  
  public void setFuzzyPrefixLength(int fuzzyPrefixLength) {
    this.fuzzyPrefixLength = fuzzyPrefixLength;
  }

  
  public void setPhraseSlop(int phraseSlop) {
    this.phraseSlop = phraseSlop;
  }

  
  public int getPhraseSlop() {
    return phraseSlop;
  }


  
  public void setDefaultOperator(Operator op) {
    this.operator = op;
  }


  
  public Operator getDefaultOperator() {
    return operator;
  }


  
  public void setLowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
    this.lowercaseExpandedTerms = lowercaseExpandedTerms;
  }


  
  public boolean getLowercaseExpandedTerms() {
    return lowercaseExpandedTerms;
  }

  
  public void setLocale(Locale locale) {
    this.locale = locale;
  }

  
  public Locale getLocale() {
    return locale;
  }

  protected void addClause(Vector clauses, int conj, int mods, Query q) {
    boolean required, prohibited;

    
    
    if (clauses.size() > 0 && conj == CONJ_AND) {
      BooleanClause c = (BooleanClause) clauses.elementAt(clauses.size()-1);
      if (!c.isProhibited())
        c.setOccur(BooleanClause.Occur.MUST);
    }

    if (clauses.size() > 0 && operator == AND_OPERATOR && conj == CONJ_OR) {
      
      
      
      
      BooleanClause c = (BooleanClause) clauses.elementAt(clauses.size()-1);
      if (!c.isProhibited())
        c.setOccur(BooleanClause.Occur.SHOULD);
    }

    
    
    if (q == null)
      return;

    if (operator == OR_OPERATOR) {
      
      
      prohibited = (mods == MOD_NOT);
      required = (mods == MOD_REQ);
      if (conj == CONJ_AND && !prohibited) {
        required = true;
      }
    } else {
      
      
      prohibited = (mods == MOD_NOT);
      required   = (!prohibited && conj != CONJ_OR);
    }
    if (required && !prohibited)
      clauses.addElement(new BooleanClause(q, BooleanClause.Occur.MUST));
    else if (!required && !prohibited)
      clauses.addElement(new BooleanClause(q, BooleanClause.Occur.SHOULD));
    else if (!required && prohibited)
      clauses.addElement(new BooleanClause(q, BooleanClause.Occur.MUST_NOT));
    else
      throw new RuntimeException(""Clause cannot be both required and prohibited"");
  }


  
  protected Query getFieldQuery(String field, String queryText)  throws ParseException {
    
    

    TokenStream source = analyzer.tokenStream(field, new StringReader(queryText));
    Vector v = new Vector();
    org.apache.lucene.analysis.Token t;
    int positionCount = 0;
    boolean severalTokensAtSamePosition = false;

    while (true) {
      try {
        t = source.next();
      }
      catch (IOException e) {
        t = null;
      }
      if (t == null)
        break;
      v.addElement(t);
      if (t.getPositionIncrement() != 0)
        positionCount += t.getPositionIncrement();
      else
        severalTokensAtSamePosition = true;
    }
    try {
      source.close();
    }
    catch (IOException e) {
      
    }

    if (v.size() == 0)
      return null;
    else if (v.size() == 1) {
      t = (org.apache.lucene.analysis.Token) v.elementAt(0);
      return new TermQuery(new Term(field, t.termText()));
    } else {
      if (severalTokensAtSamePosition) {
        if (positionCount == 1) {
          
          BooleanQuery q = new BooleanQuery(true);
          for (int i = 0; i < v.size(); i++) {
            t = (org.apache.lucene.analysis.Token) v.elementAt(i);
            TermQuery currentQuery = new TermQuery(
                new Term(field, t.termText()));
            q.add(currentQuery, BooleanClause.Occur.SHOULD);
          }
          return q;
        }
        else {
          
          MultiPhraseQuery mpq = new MultiPhraseQuery();
          mpq.setSlop(phraseSlop);
          List multiTerms = new ArrayList();
          for (int i = 0; i < v.size(); i++) {
            t = (org.apache.lucene.analysis.Token) v.elementAt(i);
            if (t.getPositionIncrement() == 1 && multiTerms.size() > 0) {
              mpq.add((Term[])multiTerms.toArray(new Term[0]));
              multiTerms.clear();
            }
            multiTerms.add(new Term(field, t.termText()));
          }
          mpq.add((Term[])multiTerms.toArray(new Term[0]));
          return mpq;
        }
      }
      else {
        PhraseQuery q = new PhraseQuery();
        q.setSlop(phraseSlop);
        for (int i = 0; i < v.size(); i++) {
          q.add(new Term(field, ((org.apache.lucene.analysis.Token)
              v.elementAt(i)).termText()));

        }
        return q;
      }
    }
  }


  
  protected Query getFieldQuery(String field, String queryText, int slop)
        throws ParseException {
    Query query = getFieldQuery(field, queryText);

    if (query instanceof PhraseQuery) {
      ((PhraseQuery) query).setSlop(slop);
    }
    if (query instanceof MultiPhraseQuery) {
      ((MultiPhraseQuery) query).setSlop(slop);
    }

    return query;
  }


  
  protected Query getRangeQuery(String field,
                                String part1,
                                String part2,
                                boolean inclusive) throws ParseException
  {
    if (lowercaseExpandedTerms) {
      part1 = part1.toLowerCase();
      part2 = part2.toLowerCase();
    }
    try {
      DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT, locale);
      df.setLenient(true);
      Date d1 = df.parse(part1);
      Date d2 = df.parse(part2);
      if (inclusive) {
        
        
        
        Calendar cal = Calendar.getInstance(locale);
        cal.setTime(d2);
        cal.set(Calendar.HOUR_OF_DAY, 23);
        cal.set(Calendar.MINUTE, 59);
        cal.set(Calendar.SECOND, 59);
        cal.set(Calendar.MILLISECOND, 999);
        d2 = cal.getTime();
      }
      part1 = DateField.dateToString(d1);
      part2 = DateField.dateToString(d2);
    }
    catch (Exception e) { }

    return new RangeQuery(new Term(field, part1),
                          new Term(field, part2),
                          inclusive);
  }

  
  protected Query getBooleanQuery(Vector clauses) throws ParseException {
    return getBooleanQuery(clauses, false);
  }

  
  protected Query getBooleanQuery(Vector clauses, boolean disableCoord)
    throws ParseException
  {
    BooleanQuery query = new BooleanQuery(disableCoord);
    for (int i = 0; i < clauses.size(); i++) {
  query.add((BooleanClause)clauses.elementAt(i));
    }
    return query;
  }

  
  protected Query getWildcardQuery(String field, String termStr) throws ParseException
  {
    if (lowercaseExpandedTerms) {
      termStr = termStr.toLowerCase();
    }
    Term t = new Term(field, termStr);
    return new WildcardQuery(t);
  }

  
  protected Query getPrefixQuery(String field, String termStr) throws ParseException
  {
    if (lowercaseExpandedTerms) {
      termStr = termStr.toLowerCase();
    }
    Term t = new Term(field, termStr);
    return new PrefixQuery(t);
  }


   
  protected Query getFuzzyQuery(String field, String termStr, float minSimilarity) throws ParseException
  {
    if (lowercaseExpandedTerms) {
      termStr = termStr.toLowerCase();
    }
    Term t = new Term(field, termStr);
    return new FuzzyQuery(t, minSimilarity, fuzzyPrefixLength);
  }

  
  private String discardEscapeChar(String input) {
    char[] caSource = input.toCharArray();
    char[] caDest = new char[caSource.length];
    int j = 0;
    for (int i = 0; i < caSource.length; i++) {
      if ((caSource[i] != '\\') || (i > 0 && caSource[i-1] == '\\')) {
        caDest[j++]=caSource[i];
      }
    }
    return new String(caDest, 0, j);
  }

  
  public static String escape(String s) {
    StringBuffer sb = new StringBuffer();
    for (int i = 0; i < s.length(); i++) {
      char c = s.charAt(i);
      
      if (c == '\\' || c == '+' || c == '-' || c == '!' || c == '(' || c == ')' || c == ':'
        || c == '^' || c == '[' || c == ']' || c == '\""' || c == '{' || c == '}' || c == '~'
        || c == '*' || c == '?') {
        sb.append('\\');
      }
      sb.append(c);
    }
    return sb.toString();
  }

  
  public static void main(String[] args) throws Exception {
    if (args.length == 0) {
      System.out.println(""Usage: java org.apache.lucene.queryParser.QueryParser <input>"");
      System.exit(0);
    }
    QueryParser qp = new QueryParser(""field"",
                           new org.apache.lucene.analysis.SimpleAnalyzer());
    Query q = qp.parse(args[0]);
    System.out.println(q.toString(""field""));
  }



  final public int Conjunction() throws ParseException {
  int ret = CONJ_NONE;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case AND:
    case OR:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case AND:
        jj_consume_token(AND);
            ret = CONJ_AND;
        break;
      case OR:
        jj_consume_token(OR);
              ret = CONJ_OR;
        break;
      default:
        jj_la1[0] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      break;
    default:
      jj_la1[1] = jj_gen;
      ;
    }
    {if (true) return ret;}
    throw new Error(""Missing return statement in function"");
  }

  final public int Modifiers() throws ParseException {
  int ret = MOD_NONE;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case NOT:
    case PLUS:
    case MINUS:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case PLUS:
        jj_consume_token(PLUS);
              ret = MOD_REQ;
        break;
      case MINUS:
        jj_consume_token(MINUS);
                 ret = MOD_NOT;
        break;
      case NOT:
        jj_consume_token(NOT);
               ret = MOD_NOT;
        break;
      default:
        jj_la1[2] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      break;
    default:
      jj_la1[3] = jj_gen;
      ;
    }
    {if (true) return ret;}
    throw new Error(""Missing return statement in function"");
  }

  final public Query Query(String field) throws ParseException {
  Vector clauses = new Vector();
  Query q, firstQuery=null;
  int conj, mods;
    mods = Modifiers();
    q = Clause(field);
    addClause(clauses, CONJ_NONE, mods, q);
    if (mods == MOD_NONE)
        firstQuery=q;
    label_1:
    while (true) {
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case AND:
      case OR:
      case NOT:
      case PLUS:
      case MINUS:
      case LPAREN:
      case QUOTED:
      case TERM:
      case PREFIXTERM:
      case WILDTERM:
      case RANGEIN_START:
      case RANGEEX_START:
      case NUMBER:
        ;
        break;
      default:
        jj_la1[4] = jj_gen;
        break label_1;
      }
      conj = Conjunction();
      mods = Modifiers();
      q = Clause(field);
      addClause(clauses, conj, mods, q);
    }
      if (clauses.size() == 1 && firstQuery != null)
        {if (true) return firstQuery;}
      else {
  {if (true) return getBooleanQuery(clauses);}
      }
    throw new Error(""Missing return statement in function"");
  }

  final public Query Clause(String field) throws ParseException {
  Query q;
  Token fieldToken=null, boost=null;
    if (jj_2_1(2)) {
      fieldToken = jj_consume_token(TERM);
      jj_consume_token(COLON);
      field=discardEscapeChar(fieldToken.image);
    } else {
      ;
    }
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case QUOTED:
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case RANGEIN_START:
    case RANGEEX_START:
    case NUMBER:
      q = Term(field);
      break;
    case LPAREN:
      jj_consume_token(LPAREN);
      q = Query(field);
      jj_consume_token(RPAREN);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[5] = jj_gen;
        ;
      }
      break;
    default:
      jj_la1[6] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
      if (boost != null) {
        float f = (float)1.0;
  try {
    f = Float.valueOf(boost.image).floatValue();
          q.setBoost(f);
  } catch (Exception ignored) { }
      }
      {if (true) return q;}
    throw new Error(""Missing return statement in function"");
  }

  final public Query Term(String field) throws ParseException {
  Token term, boost=null, fuzzySlop=null, goop1, goop2;
  boolean prefix = false;
  boolean wildcard = false;
  boolean fuzzy = false;
  boolean rangein = false;
  Query q;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case TERM:
    case PREFIXTERM:
    case WILDTERM:
    case NUMBER:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case TERM:
        term = jj_consume_token(TERM);
        break;
      case PREFIXTERM:
        term = jj_consume_token(PREFIXTERM);
                             prefix=true;
        break;
      case WILDTERM:
        term = jj_consume_token(WILDTERM);
                           wildcard=true;
        break;
      case NUMBER:
        term = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[7] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                fuzzy=true;
        break;
      default:
        jj_la1[8] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case FUZZY_SLOP:
          fuzzySlop = jj_consume_token(FUZZY_SLOP);
                                                         fuzzy=true;
          break;
        default:
          jj_la1[9] = jj_gen;
          ;
        }
        break;
      default:
        jj_la1[10] = jj_gen;
        ;
      }
       String termImage=discardEscapeChar(term.image);
       if (wildcard) {
       q = getWildcardQuery(field, termImage);
       } else if (prefix) {
         q = getPrefixQuery(field,
           discardEscapeChar(term.image.substring
          (0, term.image.length()-1)));
       } else if (fuzzy) {
          float fms = fuzzyMinSim;
          try {
            fms = Float.valueOf(fuzzySlop.image.substring(1)).floatValue();
          } catch (Exception ignored) { }
         if(fms < 0.0f || fms > 1.0f){
           {if (true) throw new ParseException(""Minimum similarity for a FuzzyQuery has to be between 0.0f and 1.0f !"");}
         }
         q = getFuzzyQuery(field, termImage,fms);
       } else {
         q = getFieldQuery(field, termImage);
       }
      break;
    case RANGEIN_START:
      jj_consume_token(RANGEIN_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop1 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop1 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[11] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_TO:
        jj_consume_token(RANGEIN_TO);
        break;
      default:
        jj_la1[12] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEIN_GOOP:
        goop2 = jj_consume_token(RANGEIN_GOOP);
        break;
      case RANGEIN_QUOTED:
        goop2 = jj_consume_token(RANGEIN_QUOTED);
        break;
      default:
        jj_la1[13] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEIN_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[14] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEIN_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else {
            goop1.image = discardEscapeChar(goop1.image);
          }
          if (goop2.kind == RANGEIN_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
      } else {
        goop2.image = discardEscapeChar(goop2.image);
      }
          q = getRangeQuery(field, goop1.image, goop2.image, true);
      break;
    case RANGEEX_START:
      jj_consume_token(RANGEEX_START);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop1 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop1 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[15] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_TO:
        jj_consume_token(RANGEEX_TO);
        break;
      default:
        jj_la1[16] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case RANGEEX_GOOP:
        goop2 = jj_consume_token(RANGEEX_GOOP);
        break;
      case RANGEEX_QUOTED:
        goop2 = jj_consume_token(RANGEEX_QUOTED);
        break;
      default:
        jj_la1[17] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      jj_consume_token(RANGEEX_END);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[18] = jj_gen;
        ;
      }
          if (goop1.kind == RANGEEX_QUOTED) {
            goop1.image = goop1.image.substring(1, goop1.image.length()-1);
          } else {
            goop1.image = discardEscapeChar(goop1.image);
          }
          if (goop2.kind == RANGEEX_QUOTED) {
            goop2.image = goop2.image.substring(1, goop2.image.length()-1);
      } else {
        goop2.image = discardEscapeChar(goop2.image);
      }

          q = getRangeQuery(field, goop1.image, goop2.image, false);
      break;
    case QUOTED:
      term = jj_consume_token(QUOTED);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case FUZZY_SLOP:
        fuzzySlop = jj_consume_token(FUZZY_SLOP);
        break;
      default:
        jj_la1[19] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case CARAT:
        jj_consume_token(CARAT);
        boost = jj_consume_token(NUMBER);
        break;
      default:
        jj_la1[20] = jj_gen;
        ;
      }
         int s = phraseSlop;

         if (fuzzySlop != null) {
           try {
             s = Float.valueOf(fuzzySlop.image.substring(1)).intValue();
           }
           catch (Exception ignored) { }
         }
         q = getFieldQuery(field, term.image.substring(1, term.image.length()-1), s);
      break;
    default:
      jj_la1[21] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
    if (boost != null) {
      float f = (float) 1.0;
      try {
        f = Float.valueOf(boost.image).floatValue();
      }
      catch (Exception ignored) {
    
      }

      
      if (q != null) {
        q.setBoost(f);
      }
    }
    {if (true) return q;}
    throw new Error(""Missing return statement in function"");
  }

  final private boolean jj_2_1(int xla) {
    jj_la = xla; jj_lastpos = jj_scanpos = token;
    try { return !jj_3_1(); }
    catch(LookaheadSuccess ls) { return true; }
    finally { jj_save(0, xla); }
  }

  final private boolean jj_3_1() {
    if (jj_scan_token(TERM)) return true;
    if (jj_scan_token(COLON)) return true;
    return false;
  }

  public QueryParserTokenManager token_source;
  public Token token, jj_nt;
  private int jj_ntk;
  private Token jj_scanpos, jj_lastpos;
  private int jj_la;
  public boolean lookingAhead = false;
  private boolean jj_semLA;
  private int jj_gen;
  final private int[] jj_la1 = new int[22];
  static private int[] jj_la1_0;
  static {
      jj_la1_0();
   }
   private static void jj_la1_0() {
      jj_la1_0 = new int[] {0x180,0x180,0xe00,0xe00,0xfb1f80,0x8000,0xfb1000,0x9a0000,0x40000,0x40000,0x8000,0xc000000,0x1000000,0xc000000,0x8000,0xc0000000,0x10000000,0xc0000000,0x8000,0x40000,0x8000,0xfb0000,};
   }
  final private JJCalls[] jj_2_rtns = new JJCalls[1];
  private boolean jj_rescan = false;
  private int jj_gc = 0;

  public QueryParser(CharStream stream) {
    token_source = new QueryParserTokenManager(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 22; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  public void ReInit(CharStream stream) {
    token_source.ReInit(stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 22; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  public QueryParser(QueryParserTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 22; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  public void ReInit(QueryParserTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 22; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  final private Token jj_consume_token(int kind) throws ParseException {
    Token oldToken;
    if ((oldToken = token).next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    if (token.kind == kind) {
      jj_gen++;
      if (++jj_gc > 100) {
        jj_gc = 0;
        for (int i = 0; i < jj_2_rtns.length; i++) {
          JJCalls c = jj_2_rtns[i];
          while (c != null) {
            if (c.gen < jj_gen) c.first = null;
            c = c.next;
          }
        }
      }
      return token;
    }
    token = oldToken;
    jj_kind = kind;
    throw generateParseException();
  }

  static private final class LookaheadSuccess extends java.lang.Error { }
  final private LookaheadSuccess jj_ls = new LookaheadSuccess();
  final private boolean jj_scan_token(int kind) {
    if (jj_scanpos == jj_lastpos) {
      jj_la--;
      if (jj_scanpos.next == null) {
        jj_lastpos = jj_scanpos = jj_scanpos.next = token_source.getNextToken();
      } else {
        jj_lastpos = jj_scanpos = jj_scanpos.next;
      }
    } else {
      jj_scanpos = jj_scanpos.next;
    }
    if (jj_rescan) {
      int i = 0; Token tok = token;
      while (tok != null && tok != jj_scanpos) { i++; tok = tok.next; }
      if (tok != null) jj_add_error_token(kind, i);
    }
    if (jj_scanpos.kind != kind) return true;
    if (jj_la == 0 && jj_scanpos == jj_lastpos) throw jj_ls;
    return false;
  }

  final public Token getNextToken() {
    if (token.next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    jj_gen++;
    return token;
  }

  final public Token getToken(int index) {
    Token t = lookingAhead ? jj_scanpos : token;
    for (int i = 0; i < index; i++) {
      if (t.next != null) t = t.next;
      else t = t.next = token_source.getNextToken();
    }
    return t;
  }

  final private int jj_ntk() {
    if ((jj_nt=token.next) == null)
      return (jj_ntk = (token.next=token_source.getNextToken()).kind);
    else
      return (jj_ntk = jj_nt.kind);
  }

  private java.util.Vector jj_expentries = new java.util.Vector();
  private int[] jj_expentry;
  private int jj_kind = -1;
  private int[] jj_lasttokens = new int[100];
  private int jj_endpos;

  private void jj_add_error_token(int kind, int pos) {
    if (pos >= 100) return;
    if (pos == jj_endpos + 1) {
      jj_lasttokens[jj_endpos++] = kind;
    } else if (jj_endpos != 0) {
      jj_expentry = new int[jj_endpos];
      for (int i = 0; i < jj_endpos; i++) {
        jj_expentry[i] = jj_lasttokens[i];
      }
      boolean exists = false;
      for (java.util.Enumeration e = jj_expentries.elements(); e.hasMoreElements();) {
        int[] oldentry = (int[])(e.nextElement());
        if (oldentry.length == jj_expentry.length) {
          exists = true;
          for (int i = 0; i < jj_expentry.length; i++) {
            if (oldentry[i] != jj_expentry[i]) {
              exists = false;
              break;
            }
          }
          if (exists) break;
        }
      }
      if (!exists) jj_expentries.addElement(jj_expentry);
      if (pos != 0) jj_lasttokens[(jj_endpos = pos) - 1] = kind;
    }
  }

  public ParseException generateParseException() {
    jj_expentries.removeAllElements();
    boolean[] la1tokens = new boolean[32];
    for (int i = 0; i < 32; i++) {
      la1tokens[i] = false;
    }
    if (jj_kind >= 0) {
      la1tokens[jj_kind] = true;
      jj_kind = -1;
    }
    for (int i = 0; i < 22; i++) {
      if (jj_la1[i] == jj_gen) {
        for (int j = 0; j < 32; j++) {
          if ((jj_la1_0[i] & (1<<j)) != 0) {
            la1tokens[j] = true;
          }
        }
      }
    }
    for (int i = 0; i < 32; i++) {
      if (la1tokens[i]) {
        jj_expentry = new int[1];
        jj_expentry[0] = i;
        jj_expentries.addElement(jj_expentry);
      }
    }
    jj_endpos = 0;
    jj_rescan_token();
    jj_add_error_token(0, 0);
    int[][] exptokseq = new int[jj_expentries.size()][];
    for (int i = 0; i < jj_expentries.size(); i++) {
      exptokseq[i] = (int[])jj_expentries.elementAt(i);
    }
    return new ParseException(token, exptokseq, tokenImage);
  }

  final public void enable_tracing() {
  }

  final public void disable_tracing() {
  }

  final private void jj_rescan_token() {
    jj_rescan = true;
    for (int i = 0; i < 1; i++) {
      JJCalls p = jj_2_rtns[i];
      do {
        if (p.gen > jj_gen) {
          jj_la = p.arg; jj_lastpos = jj_scanpos = p.first;
          switch (i) {
            case 0: jj_3_1(); break;
          }
        }
        p = p.next;
      } while (p != null);
    }
    jj_rescan = false;
  }

  final private void jj_save(int index, int xla) {
    JJCalls p = jj_2_rtns[index];
    while (p.gen > jj_gen) {
      if (p.next == null) { p = p.next = new JJCalls(); break; }
      p = p.next;
    }
    p.gen = jj_gen + xla - jj_la; p.first = token; p.arg = xla;
  }

  static final class JJCalls {
    int gen;
    Token first;
    int arg;
    JJCalls next;
  }

}
"
lucene,2,org.apache.lucene.analysis.SimpleAnalyzer,2,2,0,4,4,1,1,3,2,2.0,10,0.0,0,0.666666667,0.666666667,0,0,4.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public final class SimpleAnalyzer extends Analyzer {
  public TokenStream tokenStream(String fieldName, Reader reader) {
    return new LowerCaseTokenizer(reader);
  }
}
"
lucene,2,org.apache.lucene.search.FieldDocSortedHitQueue,5,2,0,6,21,0,3,3,0,0.375,274,0.0,1,0.733333333,0.5,1,3,53.4,18,5.0,0,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;

import java.text.Collator;
import java.util.Locale;


class FieldDocSortedHitQueue
extends PriorityQueue {

	
	
	volatile SortField[] fields;

	
	
	volatile Collator[] collators;


	
	FieldDocSortedHitQueue (SortField[] fields, int size) {
		this.fields = fields;
		this.collators = hasCollators (fields);
		initialize (size);
	}


	
	synchronized void setFields (SortField[] fields) {
		if (this.fields == null) {
			this.fields = fields;
			this.collators = hasCollators (fields);
		}
	}


	
	SortField[] getFields() {
		return fields;
	}


	
	private Collator[] hasCollators (final SortField[] fields) {
		if (fields == null) return null;
		Collator[] ret = new Collator[fields.length];
		for (int i=0; i<fields.length; ++i) {
			Locale locale = fields[i].getLocale();
			if (locale != null)
				ret[i] = Collator.getInstance (locale);
		}
		return ret;
	}


	
	protected final boolean lessThan (final Object a, final Object b) {
		final FieldDoc docA = (FieldDoc) a;
		final FieldDoc docB = (FieldDoc) b;
		final int n = fields.length;
		int c = 0;
		for (int i=0; i<n && c==0; ++i) {
			final int type = fields[i].getType();
			switch (type) {
				case SortField.SCORE:
					float r1 = ((Float)docA.fields[i]).floatValue();
					float r2 = ((Float)docB.fields[i]).floatValue();
					if (r1 > r2) c = -1;
					if (r1 < r2) c = 1;
					break;
				case SortField.DOC:
				case SortField.INT:
					int i1 = ((Integer)docA.fields[i]).intValue();
					int i2 = ((Integer)docB.fields[i]).intValue();
					if (i1 < i2) c = -1;
					if (i1 > i2) c = 1;
					break;
				case SortField.STRING:
					String s1 = (String) docA.fields[i];
					String s2 = (String) docB.fields[i];
					
					
					
					if (s1 == null) c = (s2==null) ? 0 : -1;
					else if (s2 == null) c = 1;  
					else if (fields[i].getLocale() == null) {
						c = s1.compareTo(s2);
					} else {
						c = collators[i].compare (s1, s2);
					}
					break;
				case SortField.FLOAT:
					float f1 = ((Float)docA.fields[i]).floatValue();
					float f2 = ((Float)docB.fields[i]).floatValue();
					if (f1 < f2) c = -1;
					if (f1 > f2) c = 1;
					break;
				case SortField.CUSTOM:
					c = docA.fields[i].compareTo (docB.fields[i]);
					break;
				case SortField.AUTO:
					
					
					
					
					throw new RuntimeException (""FieldDocSortedHitQueue cannot use an AUTO SortField"");
				default:
					throw new RuntimeException (""invalid SortField type: ""+type);
			}
			if (fields[i].getReverse()) {
				c = -c;
			}
		}

    
    if (c == 0)
      return docA.doc > docB.doc;

    return c > 0;
	}
}
"
lucene,2,org.apache.lucene.search.HitCollector,2,1,6,21,3,1,21,0,2,2.0,5,0.0,0,0.0,0.666666667,0,0,1.5,1,0.5,0,"package org.apache.lucene.search;




public abstract class HitCollector {
  
  public abstract void collect(int doc, float score);
}
"
lucene,2,org.apache.lucene.analysis.WhitespaceTokenizer,2,4,0,2,4,1,1,1,1,2.0,13,0.0,0,0.857142857,0.666666667,1,1,5.5,2,1.0,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public class WhitespaceTokenizer extends CharTokenizer {
  
  public WhitespaceTokenizer(Reader in) {
    super(in);
  }

  
  protected boolean isTokenChar(char c) {
    return !Character.isWhitespace(c);
  }
}
"
lucene,2,org.apache.lucene.search.spans.SpanNotQuery,13,3,0,6,31,0,1,6,11,0.375,218,1.0,2,0.571428571,0.208791209,2,2,15.61538462,6,1.3077,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class SpanNotQuery extends SpanQuery {
  private SpanQuery include;
  private SpanQuery exclude;

  
  public SpanNotQuery(SpanQuery include, SpanQuery exclude) {
    this.include = include;
    this.exclude = exclude;

    if (!include.getField().equals(exclude.getField()))
      throw new IllegalArgumentException(""Clauses must have same field."");
  }

  
  public SpanQuery getInclude() { return include; }

  
  public SpanQuery getExclude() { return exclude; }

  public String getField() { return include.getField(); }

  
  public Collection getTerms() { return include.getTerms(); }
  
  public void extractTerms(Set terms) { include.extractTerms(terms); }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanNot("");
    buffer.append(include.toString(field));
    buffer.append("", "");
    buffer.append(exclude.toString(field));
    buffer.append("")"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }


  public Spans getSpans(final IndexReader reader) throws IOException {
    return new Spans() {
        private Spans includeSpans = include.getSpans(reader);
        private boolean moreInclude = true;

        private Spans excludeSpans = exclude.getSpans(reader);
        private boolean moreExclude = excludeSpans.next();

        public boolean next() throws IOException {
          if (moreInclude)                        
            moreInclude = includeSpans.next();

          while (moreInclude && moreExclude) {

            if (includeSpans.doc() > excludeSpans.doc()) 
              moreExclude = excludeSpans.skipTo(includeSpans.doc());

            while (moreExclude                    
                   && includeSpans.doc() == excludeSpans.doc()
                   && excludeSpans.end() <= includeSpans.start()) {
              moreExclude = excludeSpans.next();  
            }

            if (!moreExclude                      
                || includeSpans.doc() != excludeSpans.doc()
                || includeSpans.end() <= excludeSpans.start())
              break;                              

            moreInclude = includeSpans.next();    
          }
          return moreInclude;
        }

        public boolean skipTo(int target) throws IOException {
          if (moreInclude)                        
            moreInclude = includeSpans.skipTo(target);

          if (!moreInclude)
            return false;

          if (moreExclude                         
              && includeSpans.doc() > excludeSpans.doc())
            moreExclude = excludeSpans.skipTo(includeSpans.doc());

          while (moreExclude                      
                 && includeSpans.doc() == excludeSpans.doc()
                 && excludeSpans.end() <= includeSpans.start()) {
            moreExclude = excludeSpans.next();    
          }

          if (!moreExclude                      
                || includeSpans.doc() != excludeSpans.doc()
                || includeSpans.end() <= excludeSpans.start())
            return true;                          

          return next();                          
        }

        public int doc() { return includeSpans.doc(); }
        public int start() { return includeSpans.start(); }
        public int end() { return includeSpans.end(); }

        public String toString() {
          return ""spans("" + SpanNotQuery.this.toString() + "")"";
        }

      };
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanNotQuery clone = null;

    SpanQuery rewrittenInclude = (SpanQuery) include.rewrite(reader);
    if (rewrittenInclude != include) {
      clone = (SpanNotQuery) this.clone();
      clone.include = rewrittenInclude;
    }
    SpanQuery rewrittenExclude = (SpanQuery) exclude.rewrite(reader);
    if (rewrittenExclude != exclude) {
      if (clone == null) clone = (SpanNotQuery) this.clone();
      clone.exclude = rewrittenExclude;
    }

    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

    
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof SpanNotQuery)) return false;

    SpanNotQuery other = (SpanNotQuery)o;
    return this.include.equals(other.include)
            && this.exclude.equals(other.exclude)
            && this.getBoost() == other.getBoost();
  }

  public int hashCode() {
    int h = include.hashCode();
    h = (h<<1) | (h >>> 31);  
    h ^= exclude.hashCode();
    h = (h<<1) | (h >>> 31);  
    h ^= Float.floatToRawIntBits(getBoost());
    return h;
  }

}
"
lucene,2,org.apache.lucene.analysis.standard.StandardFilter,3,3,0,5,17,1,1,4,2,0.5,98,1.0,0,0.75,0.75,0,0,31.0,1,0.3333,0,"package org.apache.lucene.analysis.standard;



import org.apache.lucene.analysis.*;



public final class StandardFilter extends TokenFilter
  implements StandardTokenizerConstants  {


  
  public StandardFilter(TokenStream in) {
    super(in);
  }

  private static final String APOSTROPHE_TYPE = tokenImage[APOSTROPHE];
  private static final String ACRONYM_TYPE = tokenImage[ACRONYM];
  
  
  public final org.apache.lucene.analysis.Token next() throws java.io.IOException {
    org.apache.lucene.analysis.Token t = input.next();

    if (t == null)
      return null;

    String text = t.termText();
    String type = t.type();

    if (type == APOSTROPHE_TYPE &&		  
	(text.endsWith(""'s"") || text.endsWith(""'S""))) {
      return new org.apache.lucene.analysis.Token
	(text.substring(0,text.length()-2),
	 t.startOffset(), t.endOffset(), type);

    } else if (type == ACRONYM_TYPE) {		  
      StringBuffer trimmed = new StringBuffer();
      for (int i = 0; i < text.length(); i++) {
	char c = text.charAt(i);
	if (c != '.')
	  trimmed.append(c);
      }
      return new org.apache.lucene.analysis.Token
	(trimmed.toString(), t.startOffset(), t.endOffset(), type);

    } else {
      return t;
    }
  }
}
"
lucene,2,org.apache.lucene.search.TermQuery,8,2,0,14,22,0,9,6,6,0.142857143,100,1.0,1,0.631578947,0.232142857,2,2,11.375,4,1.375,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Set;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermDocs;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class TermQuery extends Query {
  private Term term;

  private class TermWeight implements Weight {
    private Similarity similarity;
    private float value;
    private float idf;
    private float queryNorm;
    private float queryWeight;

    public TermWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);
      idf = similarity.idf(term, searcher); 
    }

    public String toString() { return ""weight("" + TermQuery.this + "")""; }

    public Query getQuery() { return TermQuery.this; }
    public float getValue() { return value; }

    public float sumOfSquaredWeights() {
      queryWeight = idf * getBoost();             
      return queryWeight * queryWeight;           
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= queryNorm;                   
      value = queryWeight * idf;                  
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      TermDocs termDocs = reader.termDocs(term);

      if (termDocs == null)
        return null;

      return new TermScorer(this, termDocs, similarity,
                            reader.norms(term.field()));
    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {

      Explanation result = new Explanation();
      result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");

      Explanation idfExpl =
        new Explanation(idf, ""idf(docFreq="" + reader.docFreq(term) + "")"");

      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

      Explanation boostExpl = new Explanation(getBoost(), ""boost"");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);
      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      
      String field = term.field();
      Explanation fieldExpl = new Explanation();
      fieldExpl.setDescription(""fieldWeight(""+term+"" in ""+doc+
                               ""), product of:"");

      Explanation tfExpl = scorer(reader).explain(doc);
      fieldExpl.addDetail(tfExpl);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setValue(tfExpl.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);

      
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }
  }

  
  public TermQuery(Term t) {
    term = t;
  }

  
  public Term getTerm() { return term; }

  protected Weight createWeight(Searcher searcher) throws IOException {
    return new TermWeight(searcher);
  }

  public void extractTerms(Set terms) {
    terms.add(getTerm());
  }

  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    if (!term.field().equals(field)) {
      buffer.append(term.field());
      buffer.append("":"");
    }
    buffer.append(term.text());
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof TermQuery))
      return false;
    TermQuery other = (TermQuery)o;
    return (this.getBoost() == other.getBoost())
      && this.term.equals(other.term);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ term.hashCode();
  }

}
"
lucene,2,org.apache.lucene.analysis.CharTokenizer,4,3,2,4,8,4,2,2,2,0.857142857,122,1.0,0,0.5,0.583333333,0,0,27.75,1,0.75,0,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.io.Reader;


public abstract class CharTokenizer extends Tokenizer {
  public CharTokenizer(Reader input) {
    super(input);
  }

  private int offset = 0, bufferIndex = 0, dataLen = 0;
  private static final int MAX_WORD_LEN = 255;
  private static final int IO_BUFFER_SIZE = 1024;
  private final char[] buffer = new char[MAX_WORD_LEN];
  private final char[] ioBuffer = new char[IO_BUFFER_SIZE];

  
  protected abstract boolean isTokenChar(char c);

  
  protected char normalize(char c) {
    return c;
  }

  
  public final Token next() throws IOException {
    int length = 0;
    int start = offset;
    while (true) {
      final char c;

      offset++;
      if (bufferIndex >= dataLen) {
        dataLen = input.read(ioBuffer);
        bufferIndex = 0;
      }
      ;
      if (dataLen == -1) {
        if (length > 0)
          break;
        else
          return null;
      } else
        c = ioBuffer[bufferIndex++];

      if (isTokenChar(c)) {               

        if (length == 0)			           
          start = offset - 1;

        buffer[length++] = normalize(c); 

        if (length == MAX_WORD_LEN)		   
          break;

      } else if (length > 0)             
        break;                           

    }

    return new Token(new String(buffer, 0, length), start, start + length);
  }
}
"
lucene,2,org.apache.lucene.document.DateTools,8,1,0,1,29,16,0,1,6,0.142857143,330,1.0,0,0.0,0.314285714,0,0,40.125,8,2.5,0,"package org.apache.lucene.document;



import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Date;
import java.util.TimeZone;


public class DateTools {
  
  private final static TimeZone GMT = TimeZone.getTimeZone(""GMT"");

  private DateTools() {}

  
  public static String dateToString(Date date, Resolution resolution) {
    return timeToString(date.getTime(), resolution);
  }
  
  
  public static String timeToString(long time, Resolution resolution) {
    Calendar cal = Calendar.getInstance(GMT);

    
    
    
    cal.setTime(new Date(round(time, resolution)));

    SimpleDateFormat sdf = new SimpleDateFormat();
    sdf.setTimeZone(GMT);
    String pattern = null;
    if (resolution == Resolution.YEAR) {
      pattern = ""yyyy"";
    } else if (resolution == Resolution.MONTH) {
      pattern = ""yyyyMM"";
    } else if (resolution == Resolution.DAY) {
      pattern = ""yyyyMMdd"";
    } else if (resolution == Resolution.HOUR) {
      pattern = ""yyyyMMddHH"";
    } else if (resolution == Resolution.MINUTE) {
      pattern = ""yyyyMMddHHmm"";
    } else if (resolution == Resolution.SECOND) {
      pattern = ""yyyyMMddHHmmss"";
    } else if (resolution == Resolution.MILLISECOND) {
      pattern = ""yyyyMMddHHmmssSSS"";
    } else {
      throw new IllegalArgumentException(""unknown resolution "" + resolution);
    }
    sdf.applyPattern(pattern);
    return sdf.format(cal.getTime());
  }

  
  public static long stringToTime(String dateString) throws ParseException {
    return stringToDate(dateString).getTime();
  }

  
  public static Date stringToDate(String dateString) throws ParseException {
    String pattern = null;
    if (dateString.length() == 4 )
      pattern = ""yyyy"";
    else if (dateString.length() == 6 )
      pattern = ""yyyyMM"";
    else if (dateString.length() == 8 )
      pattern = ""yyyyMMdd"";
    else if (dateString.length() == 10 )
      pattern = ""yyyyMMddHH"";
    else if (dateString.length() == 12 )
      pattern = ""yyyyMMddHHmm"";
    else if (dateString.length() == 14 )
      pattern = ""yyyyMMddHHmmss"";
    else if (dateString.length() == 17 )
      pattern = ""yyyyMMddHHmmssSSS"";
    else
      throw new ParseException(""Input is not valid date string: "" + dateString, 0);
    SimpleDateFormat sdf = new SimpleDateFormat(pattern);
    sdf.setTimeZone(GMT);
    Date date = sdf.parse(dateString);
    return date;
  }
  
  
  public static Date round(Date date, Resolution resolution) {
    return new Date(round(date.getTime(), resolution));
  }
  
  
  public static long round(long time, Resolution resolution) {
    Calendar cal = Calendar.getInstance(GMT);

    
    
    
    cal.setTime(new Date(time));
    
    if (resolution == Resolution.YEAR) {
      cal.set(Calendar.MONTH, 0);
      cal.set(Calendar.DAY_OF_MONTH, 1);
      cal.set(Calendar.HOUR_OF_DAY, 0);
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.MONTH) {
      cal.set(Calendar.DAY_OF_MONTH, 1);
      cal.set(Calendar.HOUR_OF_DAY, 0);
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.DAY) {
      cal.set(Calendar.HOUR_OF_DAY, 0);
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.HOUR) {
      cal.set(Calendar.MINUTE, 0);
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.MINUTE) {
      cal.set(Calendar.SECOND, 0);
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.SECOND) {
      cal.set(Calendar.MILLISECOND, 0);
    } else if (resolution == Resolution.MILLISECOND) {
      
    } else {
      throw new IllegalArgumentException(""unknown resolution "" + resolution);
    }
    return cal.getTime().getTime();
  }

  
  public static class Resolution {
    
    public static final Resolution YEAR = new Resolution(""year"");
    public static final Resolution MONTH = new Resolution(""month"");
    public static final Resolution DAY = new Resolution(""day"");
    public static final Resolution HOUR = new Resolution(""hour"");
    public static final Resolution MINUTE = new Resolution(""minute"");
    public static final Resolution SECOND = new Resolution(""second"");
    public static final Resolution MILLISECOND = new Resolution(""millisecond"");

    private String resolution;

    private Resolution() {
    }
    
    private Resolution(String resolution) {
      this.resolution = resolution;
    }
    
    public String toString() {
      return resolution;
    }

  }

}
"
lucene,2,org.apache.lucene.search.ScoreDocComparator,4,1,0,11,6,6,10,3,3,1.0,15,0.0,2,0.0,0.833333333,0,0,2.25,1,0.75,0,"package org.apache.lucene.search;





public interface ScoreDocComparator {

	
	static final ScoreDocComparator RELEVANCE = new ScoreDocComparator() {
		public int compare (ScoreDoc i, ScoreDoc j) {
			if (i.score > j.score) return -1;
			if (i.score < j.score) return 1;
			return 0;
		}
		public Comparable sortValue (ScoreDoc i) {
			return new Float (i.score);
		}
		public int sortType() {
			return SortField.SCORE;
		}
	};


	
	static final ScoreDocComparator INDEXORDER = new ScoreDocComparator() {
		public int compare (ScoreDoc i, ScoreDoc j) {
			if (i.doc < j.doc) return -1;
			if (i.doc > j.doc) return 1;
			return 0;
		}
		public Comparable sortValue (ScoreDoc i) {
			return new Integer (i.doc);
		}
		public int sortType() {
			return SortField.DOC;
		}
	};


	
	int compare (ScoreDoc i, ScoreDoc j);


	
	Comparable sortValue (ScoreDoc i);


	
	int sortType();
}"
lucene,2,org.apache.lucene.store.Directory,12,1,3,35,13,66,32,3,12,2.0,15,0.0,0,0.0,0.875,0,0,0.25,1,0.9167,6,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class Directory {
  
  public abstract String[] list()
       throws IOException;

  
  public abstract boolean fileExists(String name)
       throws IOException;

  
  public abstract long fileModified(String name)
       throws IOException;

  
  public abstract void touchFile(String name)
       throws IOException;

  
  public abstract void deleteFile(String name)
       throws IOException;

  
  public abstract void renameFile(String from, String to)
       throws IOException;

  
  public abstract long fileLength(String name)
       throws IOException;


  
  public abstract IndexOutput createOutput(String name) throws IOException;


  
  public abstract IndexInput openInput(String name)
    throws IOException;

  
  public abstract Lock makeLock(String name);

  
  public abstract void close()
       throws IOException;
}
"
lucene,2,org.apache.lucene.search.spans.SpanOrQuery,11,3,0,8,42,0,3,6,10,0.45,285,1.0,0,0.615384615,0.220779221,2,2,24.72727273,7,1.7273,1,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.List;
import java.util.Collection;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.PriorityQueue;
import org.apache.lucene.util.ToStringUtils;
import org.apache.lucene.search.Query;


public class SpanOrQuery extends SpanQuery {
  private List clauses;
  private String field;

  
  public SpanOrQuery(SpanQuery[] clauses) {

    
    this.clauses = new ArrayList(clauses.length);
    for (int i = 0; i < clauses.length; i++) {
      SpanQuery clause = clauses[i];
      if (i == 0) {                               
        field = clause.getField();
      } else if (!clause.getField().equals(field)) {
        throw new IllegalArgumentException(""Clauses must have same field."");
      }
      this.clauses.add(clause);
    }
  }

  
  public SpanQuery[] getClauses() {
    return (SpanQuery[])clauses.toArray(new SpanQuery[clauses.size()]);
  }

  public String getField() { return field; }

  
  public Collection getTerms() {
    Collection terms = new ArrayList();
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      terms.addAll(clause.getTerms());
    }
    return terms;
  }
  
  public void extractTerms(Set terms) {
	    Iterator i = clauses.iterator();
	    while (i.hasNext()) {
	      SpanQuery clause = (SpanQuery)i.next();
	      clause.extractTerms(terms);
	    }
  }
  

  public Query rewrite(IndexReader reader) throws IOException {
    SpanOrQuery clone = null;
    for (int i = 0 ; i < clauses.size(); i++) {
      SpanQuery c = (SpanQuery)clauses.get(i);
      SpanQuery query = (SpanQuery) c.rewrite(reader);
      if (query != c) {                     
        if (clone == null)
          clone = (SpanOrQuery) this.clone();
        clone.clauses.set(i,query);
      }
    }
    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanOr(["");
    Iterator i = clauses.iterator();
    while (i.hasNext()) {
      SpanQuery clause = (SpanQuery)i.next();
      buffer.append(clause.toString(field));
      if (i.hasNext()) {
        buffer.append("", "");
      }
    }
    buffer.append(""])"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    final SpanOrQuery that = (SpanOrQuery) o;

    if (!clauses.equals(that.clauses)) return false;
    if (!field.equals(that.field)) return false;

    return getBoost() == that.getBoost();
  }

  public int hashCode() {
    int h = clauses.hashCode();
    h ^= (h << 10) | (h >>> 23);
    h ^= Float.floatToRawIntBits(getBoost());
    return h;
  }

  private class SpanQueue extends PriorityQueue {
    public SpanQueue(int size) {
      initialize(size);
    }

    protected final boolean lessThan(Object o1, Object o2) {
      Spans spans1 = (Spans)o1;
      Spans spans2 = (Spans)o2;
      if (spans1.doc() == spans2.doc()) {
        if (spans1.start() == spans2.start()) {
          return spans1.end() < spans2.end();
        } else {
          return spans1.start() < spans2.start();
        }
      } else {
        return spans1.doc() < spans2.doc();
      }
    }
  }


  public Spans getSpans(final IndexReader reader) throws IOException {
    if (clauses.size() == 1)                      
      return ((SpanQuery)clauses.get(0)).getSpans(reader);

    return new Spans() {
        private List all = new ArrayList(clauses.size());
        private SpanQueue queue = new SpanQueue(clauses.size());

        {
          Iterator i = clauses.iterator();
          while (i.hasNext()) {                   
            all.add(((SpanQuery)i.next()).getSpans(reader));
          }
        }

        private boolean firstTime = true;

        public boolean next() throws IOException {
          if (firstTime) {                        
            for (int i = 0; i < all.size(); i++) {
              Spans spans = (Spans)all.get(i);
              if (spans.next()) {                 
                queue.put(spans);                 
              } else {
                all.remove(i--);
              }
            }
            firstTime = false;
            return queue.size() != 0;
          }

          if (queue.size() == 0) {                
            return false;
          }

          if (top().next()) {                     
            queue.adjustTop();
            return true;
          }

          all.remove(queue.pop());                

          return queue.size() != 0;
        }

        private Spans top() { return (Spans)queue.top(); }

        public boolean skipTo(int target) throws IOException {
          if (firstTime) {
            for (int i = 0; i < all.size(); i++) {
              Spans spans = (Spans)all.get(i);
              if (spans.skipTo(target)) {         
                queue.put(spans);                 
              } else {
                all.remove(i--);
              }
            }
            firstTime = false;
          } else {
            while (queue.size() != 0 && top().doc() < target) {
              if (top().skipTo(target)) {
                queue.adjustTop();
              } else {
                all.remove(queue.pop());
              }
            }
          }

          return queue.size() != 0;
        }

        public int doc() { return top().doc(); }
        public int start() { return top().start(); }
        public int end() { return top().end(); }

        public String toString() {
          return ""spans(""+SpanOrQuery.this+"")@""+
            (firstTime?""START""
             :(queue.size()>0?(doc()+"":""+start()+""-""+end()):""END""));
        }

      };
  }

}
"
lucene,2,org.apache.lucene.search.WildcardQuery,3,3,0,6,7,3,1,5,2,2.0,23,0.0,0,0.9,0.5,1,1,6.666666667,2,1.0,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import java.io.IOException;


public class WildcardQuery extends MultiTermQuery {
  public WildcardQuery(Term term) {
    super(term);
  }

  protected FilteredTermEnum getEnum(IndexReader reader) throws IOException {
    return new WildcardTermEnum(reader, getTerm());
  }

  public boolean equals(Object o) {
    if (o instanceof WildcardQuery)
      return super.equals(o);

    return false;
  }
}
"
lucene,2,org.apache.lucene.index.SegmentTermVector,8,1,1,3,15,0,2,1,7,0.571428571,133,1.0,0,0.0,0.35,0,0,15.25,4,1.75,0,"package org.apache.lucene.index;



import java.util.*;


class SegmentTermVector implements TermFreqVector {
  private String field;
  private String terms[];
  private int termFreqs[];
  
  SegmentTermVector(String field, String terms[], int termFreqs[]) {
    this.field = field;
    this.terms = terms;
    this.termFreqs = termFreqs;
  }

  
  public String getField() {
    return field;
  }

  public String toString() {
    StringBuffer sb = new StringBuffer();
    sb.append('{');
    sb.append(field).append("": "");
    if(terms != null){
      for (int i=0; i<terms.length; i++) {
        if (i>0) sb.append("", "");
        sb.append(terms[i]).append('/').append(termFreqs[i]);
      }
    }
    sb.append('}');
    
    return sb.toString();
  }

  public int size() {
    return terms == null ? 0 : terms.length;
  }

  public String [] getTerms() {
    return terms;
  }

  public int[] getTermFrequencies() {
    return termFreqs;
  }

  public int indexOf(String termText) {
    if(terms == null)
      return -1;
    int res = Arrays.binarySearch(terms, termText);
    return res >= 0 ? res : -1;
  }

  public int[] indexesOf(String [] termNumbers, int start, int len) {
    
    
    
    
    
    int res[] = new int[len];

    for (int i=0; i < len; i++) {
      res[i] = indexOf(termNumbers[start+ i]);
    }
    return res;
  }
}
"
lucene,2,org.apache.lucene.document.DateField,8,1,0,1,25,22,1,0,6,0.428571429,126,1.0,0,0.0,0.178571429,0,0,14.625,5,1.375,0,"package org.apache.lucene.document;



import org.apache.lucene.search.PrefixQuery;
import org.apache.lucene.search.RangeQuery;

import java.util.Date;   


public class DateField {
  
  private DateField() {}

  
  private static int DATE_LEN = Long.toString(1000L*365*24*60*60*1000,
					       Character.MAX_RADIX).length();

  public static String MIN_DATE_STRING() {
    return timeToString(0);
  }

  public static String MAX_DATE_STRING() {
    char[] buffer = new char[DATE_LEN];
    char c = Character.forDigit(Character.MAX_RADIX-1, Character.MAX_RADIX);
    for (int i = 0 ; i < DATE_LEN; i++)
      buffer[i] = c;
    return new String(buffer);
  }

  
  public static String dateToString(Date date) {
    return timeToString(date.getTime());
  }
  
  public static String timeToString(long time) {
    if (time < 0)
      throw new RuntimeException(""time '"" + time + ""' is too early, must be >= 0"");

    String s = Long.toString(time, Character.MAX_RADIX);

    if (s.length() > DATE_LEN)
      throw new RuntimeException(""time '"" + time + ""' is too late, length of string "" +
          ""representation must be <= "" + DATE_LEN);

    
    if (s.length() < DATE_LEN) {
      StringBuffer sb = new StringBuffer(s);
      while (sb.length() < DATE_LEN)
        sb.insert(0, 0);
      s = sb.toString();
    }

    return s;
  }

  
  public static long stringToTime(String s) {
    return Long.parseLong(s, Character.MAX_RADIX);
  }
  
  public static Date stringToDate(String s) {
    return new Date(stringToTime(s));
  }
}
"
lucene,2,org.apache.lucene.search.FieldDoc,2,2,0,4,3,1,3,1,2,1.0,16,0.0,0,0.0,0.875,0,0,6.5,0,0.0,0,"package org.apache.lucene.search;





public class FieldDoc
extends ScoreDoc {

	
	public Comparable[] fields;

	
	public FieldDoc (int doc, float score) {
		super (doc, score);
	}

	
	public FieldDoc (int doc, float score, Comparable[] fields) {
		super (doc, score);
		this.fields = fields;
	}
}"
lucene,2,org.apache.lucene.queryParser.TokenMgrError,6,3,0,2,19,15,2,0,4,1.12,184,0.0,0,0.8125,0.5,1,1,28.83333333,14,2.8333,0,"
package org.apache.lucene.queryParser;

public class TokenMgrError extends Error
{
   

   
   static final int LEXICAL_ERROR = 0;

   
   static final int STATIC_LEXER_ERROR = 1;

   
   static final int INVALID_LEXICAL_STATE = 2;

   
   static final int LOOP_DETECTED = 3;

   
   int errorCode;

   
   protected static final String addEscapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

   
   protected static String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar) {
      return(""Lexical error at line "" +
           errorLine + "", column "" +
           errorColumn + "".  Encountered: "" +
           (EOFSeen ? ""<EOF> "" : (""\"""" + addEscapes(String.valueOf(curChar)) + ""\"""") + "" ("" + (int)curChar + ""), "") +
           ""after : \"""" + addEscapes(errorAfter) + ""\"""");
   }

   
   public String getMessage() {
      return super.getMessage();
   }

   

   public TokenMgrError() {
   }

   public TokenMgrError(String message, int reason) {
      super(message);
      errorCode = reason;
   }

   public TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason) {
      this(LexicalError(EOFSeen, lexState, errorLine, errorColumn, errorAfter, curChar), reason);
   }
}
"
lucene,2,org.apache.lucene.index.SegmentMerger,18,1,0,21,93,0,1,21,0,0.701960784,1039,1.0,8,0.0,0.188888889,0,0,55.88888889,1,0.8889,8,"package org.apache.lucene.index;



import java.util.Vector;
import java.util.Iterator;
import java.util.Collection;
import java.io.IOException;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.RAMOutputStream;


final class SegmentMerger {
  private Directory directory;
  private String segment;
  private int termIndexInterval = IndexWriter.DEFAULT_TERM_INDEX_INTERVAL;

  private Vector readers = new Vector();
  private FieldInfos fieldInfos;

  
  SegmentMerger(Directory dir, String name) {
    directory = dir;
    segment = name;
  }

  SegmentMerger(IndexWriter writer, String name) {
    directory = writer.getDirectory();
    segment = name;
    termIndexInterval = writer.getTermIndexInterval();
  }

  
  final void add(IndexReader reader) {
    readers.addElement(reader);
  }

  
  final IndexReader segmentReader(int i) {
    return (IndexReader) readers.elementAt(i);
  }

  
  final int merge() throws IOException {
    int value;
    
    value = mergeFields();
    mergeTerms();
    mergeNorms();

    if (fieldInfos.hasVectors())
      mergeVectors();

    return value;
  }
  
  
  final void closeReaders() throws IOException {
    for (int i = 0; i < readers.size(); i++) {  
      IndexReader reader = (IndexReader) readers.elementAt(i);
      reader.close();
    }
  }

  final Vector createCompoundFile(String fileName)
          throws IOException {
    CompoundFileWriter cfsWriter =
            new CompoundFileWriter(directory, fileName);

    Vector files =
      new Vector(IndexFileNames.COMPOUND_EXTENSIONS.length + fieldInfos.size());    
    
    
    for (int i = 0; i < IndexFileNames.COMPOUND_EXTENSIONS.length; i++) {
      files.add(segment + ""."" + IndexFileNames.COMPOUND_EXTENSIONS[i]);
    }

    
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        files.add(segment + "".f"" + i);
      }
    }

    
    if (fieldInfos.hasVectors()) {
      for (int i = 0; i < IndexFileNames.VECTOR_EXTENSIONS.length; i++) {
        files.add(segment + ""."" + IndexFileNames.VECTOR_EXTENSIONS[i]);
      }
    }

    
    Iterator it = files.iterator();
    while (it.hasNext()) {
      cfsWriter.addFile((String) it.next());
    }
    
    
    cfsWriter.close();
   
    return files;
  }

  private void addIndexed(IndexReader reader, FieldInfos fieldInfos, Collection names, boolean storeTermVectors, boolean storePositionWithTermVector,
                         boolean storeOffsetWithTermVector) throws IOException {
    Iterator i = names.iterator();
    while (i.hasNext()) {
      String field = (String)i.next();
      fieldInfos.add(field, true, storeTermVectors, storePositionWithTermVector, storeOffsetWithTermVector, !reader.hasNorms(field));
    }
  }

  
  private final int mergeFields() throws IOException {
    fieldInfos = new FieldInfos();		  
    int docCount = 0;
    for (int i = 0; i < readers.size(); i++) {
      IndexReader reader = (IndexReader) readers.elementAt(i);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET), true, true, true);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_POSITION), true, true, false);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET), true, false, true);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.TERMVECTOR), true, false, false);
      addIndexed(reader, fieldInfos, reader.getFieldNames(IndexReader.FieldOption.INDEXED), false, false, false);
      fieldInfos.add(reader.getFieldNames(IndexReader.FieldOption.UNINDEXED), false);
    }
    fieldInfos.write(directory, segment + "".fnm"");

    FieldsWriter fieldsWriter = 
            new FieldsWriter(directory, segment, fieldInfos);
    try {
      for (int i = 0; i < readers.size(); i++) {
        IndexReader reader = (IndexReader) readers.elementAt(i);
        int maxDoc = reader.maxDoc();
        for (int j = 0; j < maxDoc; j++)
          if (!reader.isDeleted(j)) {               
            fieldsWriter.addDocument(reader.document(j));
            docCount++;
          }
      }
    } finally {
      fieldsWriter.close();
    }
    return docCount;
  }

  
  private final void mergeVectors() throws IOException {
    TermVectorsWriter termVectorsWriter = 
      new TermVectorsWriter(directory, segment, fieldInfos);

    try {
      for (int r = 0; r < readers.size(); r++) {
        IndexReader reader = (IndexReader) readers.elementAt(r);
        int maxDoc = reader.maxDoc();
        for (int docNum = 0; docNum < maxDoc; docNum++) {
          
          if (reader.isDeleted(docNum)) 
            continue;
          termVectorsWriter.addAllDocVectors(reader.getTermFreqVectors(docNum));
        }
      }
    } finally {
      termVectorsWriter.close();
    }
  }

  private IndexOutput freqOutput = null;
  private IndexOutput proxOutput = null;
  private TermInfosWriter termInfosWriter = null;
  private int skipInterval;
  private SegmentMergeQueue queue = null;

  private final void mergeTerms() throws IOException {
    try {
      freqOutput = directory.createOutput(segment + "".frq"");
      proxOutput = directory.createOutput(segment + "".prx"");
      termInfosWriter =
              new TermInfosWriter(directory, segment, fieldInfos,
                                  termIndexInterval);
      skipInterval = termInfosWriter.skipInterval;
      queue = new SegmentMergeQueue(readers.size());

      mergeTermInfos();

    } finally {
      if (freqOutput != null) freqOutput.close();
      if (proxOutput != null) proxOutput.close();
      if (termInfosWriter != null) termInfosWriter.close();
      if (queue != null) queue.close();
    }
  }

  private final void mergeTermInfos() throws IOException {
    int base = 0;
    for (int i = 0; i < readers.size(); i++) {
      IndexReader reader = (IndexReader) readers.elementAt(i);
      TermEnum termEnum = reader.terms();
      SegmentMergeInfo smi = new SegmentMergeInfo(base, termEnum, reader);
      base += reader.numDocs();
      if (smi.next())
        queue.put(smi);				  
      else
        smi.close();
    }

    SegmentMergeInfo[] match = new SegmentMergeInfo[readers.size()];

    while (queue.size() > 0) {
      int matchSize = 0;			  
      match[matchSize++] = (SegmentMergeInfo) queue.pop();
      Term term = match[0].term;
      SegmentMergeInfo top = (SegmentMergeInfo) queue.top();

      while (top != null && term.compareTo(top.term) == 0) {
        match[matchSize++] = (SegmentMergeInfo) queue.pop();
        top = (SegmentMergeInfo) queue.top();
      }

      mergeTermInfo(match, matchSize);		  

      while (matchSize > 0) {
        SegmentMergeInfo smi = match[--matchSize];
        if (smi.next())
          queue.put(smi);			  
        else
          smi.close();				  
      }
    }
  }

  private final TermInfo termInfo = new TermInfo(); 

  
  private final void mergeTermInfo(SegmentMergeInfo[] smis, int n)
          throws IOException {
    long freqPointer = freqOutput.getFilePointer();
    long proxPointer = proxOutput.getFilePointer();

    int df = appendPostings(smis, n);		  

    long skipPointer = writeSkip();

    if (df > 0) {
      
      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));
      termInfosWriter.add(smis[0].term, termInfo);
    }
  }

  
  private final int appendPostings(SegmentMergeInfo[] smis, int n)
          throws IOException {
    int lastDoc = 0;
    int df = 0;					  
    resetSkip();
    for (int i = 0; i < n; i++) {
      SegmentMergeInfo smi = smis[i];
      TermPositions postings = smi.getPositions();
      int base = smi.base;
      int[] docMap = smi.getDocMap();
      postings.seek(smi.termEnum);
      while (postings.next()) {
        int doc = postings.doc();
        if (docMap != null)
          doc = docMap[doc];                      
        doc += base;                              

        if (doc < lastDoc)
          throw new IllegalStateException(""docs out of order ("" + doc +
              "" < "" + lastDoc + "" )"");

        df++;

        if ((df % skipInterval) == 0) {
          bufferSkip(lastDoc);
        }

        int docCode = (doc - lastDoc) << 1;	  
        lastDoc = doc;

        int freq = postings.freq();
        if (freq == 1) {
          freqOutput.writeVInt(docCode | 1);	  
        } else {
          freqOutput.writeVInt(docCode);	  
          freqOutput.writeVInt(freq);		  
        }

        int lastPosition = 0;			  
        for (int j = 0; j < freq; j++) {
          int position = postings.nextPosition();
          proxOutput.writeVInt(position - lastPosition);
          lastPosition = position;
        }
      }
    }
    return df;
  }

  private RAMOutputStream skipBuffer = new RAMOutputStream();
  private int lastSkipDoc;
  private long lastSkipFreqPointer;
  private long lastSkipProxPointer;

  private void resetSkip() {
    skipBuffer.reset();
    lastSkipDoc = 0;
    lastSkipFreqPointer = freqOutput.getFilePointer();
    lastSkipProxPointer = proxOutput.getFilePointer();
  }

  private void bufferSkip(int doc) throws IOException {
    long freqPointer = freqOutput.getFilePointer();
    long proxPointer = proxOutput.getFilePointer();

    skipBuffer.writeVInt(doc - lastSkipDoc);
    skipBuffer.writeVInt((int) (freqPointer - lastSkipFreqPointer));
    skipBuffer.writeVInt((int) (proxPointer - lastSkipProxPointer));

    lastSkipDoc = doc;
    lastSkipFreqPointer = freqPointer;
    lastSkipProxPointer = proxPointer;
  }

  private long writeSkip() throws IOException {
    long skipPointer = freqOutput.getFilePointer();
    skipBuffer.writeTo(freqOutput);
    return skipPointer;
  }

  private void mergeNorms() throws IOException {
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        IndexOutput output = directory.createOutput(segment + "".f"" + i);
        try {
          for (int j = 0; j < readers.size(); j++) {
            IndexReader reader = (IndexReader) readers.elementAt(j);
            int maxDoc = reader.maxDoc();
            byte[] input = new byte[maxDoc];
            reader.norms(fi.name, input, 0);
            for (int k = 0; k < maxDoc; k++) {
              if (!reader.isDeleted(k)) {
                output.writeByte(input[k]);
              }
            }
          }
        } finally {
          output.close();
        }
      }
    }
  }

}
"
lucene,2,org.apache.lucene.search.SortComparatorSource,1,1,0,5,1,0,3,2,1,2.0,1,0.0,0,0.0,1.0,0,0,0.0,1,1.0,0,"package org.apache.lucene.search;

import org.apache.lucene.index.IndexReader;
import java.io.IOException;
import java.io.Serializable;


public interface SortComparatorSource
extends Serializable {

  
  ScoreDocComparator newComparator (IndexReader reader, String fieldname)
  throws IOException;
}"
lucene,2,org.apache.lucene.search.ReqOptSumScorer,6,2,0,4,15,0,1,3,6,0.466666667,113,1.0,2,0.615384615,0.5,1,3,17.33333333,1,0.8333,0,"package org.apache.lucene.search;


import java.io.IOException;


public class ReqOptSumScorer extends Scorer {
  
  private Scorer reqScorer;
  private Scorer optScorer;

  
  public ReqOptSumScorer(
      Scorer reqScorer,
      Scorer optScorer)
  {
    super(null); 
    this.reqScorer = reqScorer;
    this.optScorer = optScorer;
  }

  private boolean firstTimeOptScorer = true;

  public boolean next() throws IOException {
    return reqScorer.next();
  }

  public boolean skipTo(int target) throws IOException {
    return reqScorer.skipTo(target);
  }

  public int doc() {
    return reqScorer.doc();
  }

  
  public float score() throws IOException {
    int curDoc = reqScorer.doc();
    float reqScore = reqScorer.score();
    if (firstTimeOptScorer) {
      firstTimeOptScorer = false;
      if (! optScorer.skipTo(curDoc)) {
        optScorer = null;
        return reqScore;
      }
    } else if (optScorer == null) {
      return reqScore;
    } else if ((optScorer.doc() < curDoc) && (! optScorer.skipTo(curDoc))) {
      optScorer = null;
      return reqScore;
    }
    
    return (optScorer.doc() == curDoc)
       ? reqScore + optScorer.score()
       : reqScore;
  }

  
  public Explanation explain(int doc) throws IOException {
    Explanation res = new Explanation();
    res.setDescription(""required, optional"");
    res.addDetail(reqScorer.explain(doc));
    res.addDetail(optScorer.explain(doc));
    return res;
  }
}

"
lucene,2,org.apache.lucene.search.DisjunctionMaxScorer,11,2,0,4,25,0,1,3,7,0.65,434,1.0,0,0.444444444,0.287878788,1,3,38.09090909,6,1.5455,2,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.ArrayList;


class DisjunctionMaxScorer extends Scorer {

    
    private ArrayList subScorers = new ArrayList();

    
    private float tieBreakerMultiplier;

    private boolean more = false;          
    private boolean firstTime = true;      

    
    public DisjunctionMaxScorer(float tieBreakerMultiplier, Similarity similarity) {
        super(similarity);
        this.tieBreakerMultiplier = tieBreakerMultiplier;
    }

    
    public void add(Scorer scorer) throws IOException {
        if (scorer.next()) {       
            subScorers.add(scorer);
            more = true;
        }
    }

    
    public boolean next() throws IOException {
        if (!more) return false;
        if (firstTime) {
            heapify();
            firstTime = false;
            return true;   
        }
        
        int lastdoc = ((Scorer) subScorers.get(0)).doc();
        do {
            if (((Scorer) subScorers.get(0)).next())
                heapAdjust(0);
            else {
                heapRemoveRoot();
                if (subScorers.isEmpty()) return (more = false);
            }
        } while ( ((Scorer) subScorers.get(0)).doc()==lastdoc );
        return true;
    }

    
    public int doc() {
        return ((Scorer) subScorers.get(0)).doc();
    }

    
    public float score() throws IOException {
        int doc = ((Scorer) subScorers.get(0)).doc();
        float[] sum = {((Scorer) subScorers.get(0)).score()}, max = {sum[0]};
        int size = subScorers.size();
        scoreAll(1, size, doc, sum, max);
        scoreAll(2, size, doc, sum, max);
        return max[0] + (sum[0] - max[0])*tieBreakerMultiplier;
    }

    
    private void scoreAll(int root, int size, int doc, float[] sum, float[] max) throws IOException {
        if (root<size && ((Scorer) subScorers.get(root)).doc() == doc) {
            float sub = ((Scorer) subScorers.get(root)).score();
            sum[0] += sub;
            max[0] = Math.max(max[0], sub);
            scoreAll((root<<1)+1, size, doc, sum, max);
            scoreAll((root<<1)+2, size, doc, sum, max);
        }
    }

    
    public boolean skipTo(int target) throws IOException {
        while (subScorers.size()>0 && ((Scorer)subScorers.get(0)).doc()<target) {
            if (((Scorer)subScorers.get(0)).skipTo(target))
                heapAdjust(0);
            else
                heapRemoveRoot();
        }
        if ((subScorers.size()==0))
            return (more = false);
        return true;
    }

    
    public Explanation explain(int doc) throws IOException {
        throw new UnsupportedOperationException();
    }

    
    private void heapify() {
        int size = subScorers.size();
        for (int i=(size>>1)-1; i>=0; i--)
            heapAdjust(i);
    }

    
    private void heapAdjust(int root) {
        Scorer scorer=(Scorer)subScorers.get(root);
        int doc=scorer.doc();
        int i=root, size=subScorers.size();
        while (i<=(size>>1)-1) {
            int lchild=(i<<1)+1;
            Scorer lscorer=(Scorer)subScorers.get(lchild);
            int ldoc=lscorer.doc();
            int rdoc=Integer.MAX_VALUE, rchild=(i<<1)+2;
            Scorer rscorer=null;
            if (rchild<size) {
                rscorer=(Scorer)subScorers.get(rchild);
                rdoc=rscorer.doc();
            }
            if (ldoc<doc) {
                if (rdoc<ldoc) {
                    subScorers.set(i, rscorer);
                    subScorers.set(rchild, scorer);
                    i=rchild;
                } else {
                    subScorers.set(i, lscorer);
                    subScorers.set(lchild, scorer);
                    i=lchild;
                }
            } else if (rdoc<doc) {
                subScorers.set(i, rscorer);
                subScorers.set(rchild, scorer);
                i=rchild;
            } else return;
        }
    }

    
    private void heapRemoveRoot() {
        int size=subScorers.size();
        if (size==1)
            subScorers.remove(0);
        else {
            subScorers.set(0, subScorers.get(size-1));
            subScorers.remove(size-1);
            heapAdjust(0);
        }
    }

}
"
lucene,2,org.apache.lucene.document.NumberTools,4,1,0,0,18,0,0,0,3,1.166666667,130,0.5,0,0.0,0.333333333,0,0,30.0,6,2.5,0,"package org.apache.lucene.document;





public class NumberTools {

    private static final int RADIX = 36;

    private static final char NEGATIVE_PREFIX = '-';

    
    private static final char POSITIVE_PREFIX = '0';

    
    
    public static final String MIN_STRING_VALUE = NEGATIVE_PREFIX
            + ""0000000000000"";

    
    public static final String MAX_STRING_VALUE = POSITIVE_PREFIX
            + ""1y2p0ij32e8e7"";

    
    public static final int STR_SIZE = MIN_STRING_VALUE.length();

    
    public static String longToString(long l) {

        if (l == Long.MIN_VALUE) {
            
            return MIN_STRING_VALUE;
        }

        StringBuffer buf = new StringBuffer(STR_SIZE);

        if (l < 0) {
            buf.append(NEGATIVE_PREFIX);
            l = Long.MAX_VALUE + l + 1;
        } else {
            buf.append(POSITIVE_PREFIX);
        }
        String num = Long.toString(l, RADIX);

        int padLen = STR_SIZE - num.length() - buf.length();
        while (padLen-- > 0) {
            buf.append('0');
        }
        buf.append(num);

        return buf.toString();
    }

    
    public static long stringToLong(String str) {
        if (str == null) {
            throw new NullPointerException(""string cannot be null"");
        }
        if (str.length() != STR_SIZE) {
            throw new NumberFormatException(""string is the wrong size"");
        }

        if (str.equals(MIN_STRING_VALUE)) {
            return Long.MIN_VALUE;
        }

        char prefix = str.charAt(0);
        long l = Long.parseLong(str.substring(1), RADIX);

        if (prefix == POSITIVE_PREFIX) {
            
        } else if (prefix == NEGATIVE_PREFIX) {
            l = l - Long.MAX_VALUE - 1;
        } else {
            throw new NumberFormatException(
                    ""string does not begin with the correct prefix"");
        }

        return l;
    }
}"
lucene,2,org.apache.lucene.search.SimilarityDelegator,7,2,1,2,14,0,1,1,7,0.0,47,1.0,1,0.7,0.428571429,1,2,5.571428571,1,0.8571,0,"package org.apache.lucene.search;




public class SimilarityDelegator extends Similarity {

  private Similarity delegee;

  
  public SimilarityDelegator(Similarity delegee) {
    this.delegee = delegee;
  }

  public float lengthNorm(String fieldName, int numTerms) {
    return delegee.lengthNorm(fieldName, numTerms);
  }
  
  public float queryNorm(float sumOfSquaredWeights) {
    return delegee.queryNorm(sumOfSquaredWeights);
  }

  public float tf(float freq) {
    return delegee.tf(freq);
  }
    
  public float sloppyFreq(int distance) {
    return delegee.sloppyFreq(distance);
  }
    
  public float idf(int docFreq, int numDocs) {
    return delegee.idf(docFreq, numDocs);
  }
    
  public float coord(int overlap, int maxOverlap) {
    return delegee.coord(overlap, maxOverlap);
  }

}
"
lucene,2,org.apache.lucene.analysis.standard.Token,3,1,0,3,4,3,3,0,3,1.4375,23,0.0,2,0.0,0.5,0,0,4.0,2,1.0,0,"
package org.apache.lucene.analysis.standard;



public class Token {

  
  public int kind;

  
  public int beginLine, beginColumn, endLine, endColumn;

  
  public String image;

  
  public Token next;

  
  public Token specialToken;

  
  public String toString()
  {
     return image;
  }

  
  public static final Token newToken(int ofKind)
  {
     switch(ofKind)
     {
       default : return new Token();
     }
  }

}
"
lucene,2,org.apache.lucene.search.CachingWrapperFilter,5,2,0,2,16,0,0,2,5,0.5,102,1.0,1,0.2,0.4,1,1,19.0,2,1.0,3,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import java.util.BitSet;
import java.util.WeakHashMap;
import java.util.Map;
import java.io.IOException;


public class CachingWrapperFilter extends Filter {
  private Filter filter;

  
  private transient Map cache;

  
  public CachingWrapperFilter(Filter filter) {
    this.filter = filter;
  }

  public BitSet bits(IndexReader reader) throws IOException {
    if (cache == null) {
      cache = new WeakHashMap();
    }

    synchronized (cache) {  
      BitSet cached = (BitSet) cache.get(reader);
      if (cached != null) {
        return cached;
      }
    }

    final BitSet bits = filter.bits(reader);

    synchronized (cache) {  
      cache.put(reader, bits);
    }

    return bits;
  }

  public String toString() {
    return ""CachingWrapperFilter(""+filter+"")"";
  }

  public boolean equals(Object o) {
    if (!(o instanceof CachingWrapperFilter)) return false;
    return this.filter.equals(((CachingWrapperFilter)o).filter);
  }

  public int hashCode() {
    return filter.hashCode() ^ 0x1117BF25;  
  }
}
"
lucene,2,org.apache.lucene.index.TermPositionVector,2,1,0,4,2,1,2,2,2,2.0,2,0.0,0,0.0,1.0,0,0,0.0,1,1.0,0,"package org.apache.lucene.index;




public interface TermPositionVector extends TermFreqVector {
  
    
    public int[] getTermPositions(int index);
  
     
    public TermVectorOffsetInfo [] getOffsets(int index);
}"
lucene,2,org.apache.lucene.store.RAMFile,1,1,0,3,4,0,3,0,0,2.0,15,0.0,0,0.0,1.0,0,0,11.0,0,0.0,1,"package org.apache.lucene.store;



import java.util.Vector;

class RAMFile {
  Vector buffers = new Vector();
  long length;
  long lastModified = System.currentTimeMillis();
}
"
lucene,2,org.apache.lucene.analysis.StopFilter,7,3,0,5,13,15,2,3,7,0.333333333,106,1.0,0,0.5,0.514285714,0,0,13.85714286,3,0.7143,0,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.util.HashSet;
import java.util.Set;



public final class StopFilter extends TokenFilter {

  private final Set stopWords;
  private final boolean ignoreCase;

    
    public StopFilter(TokenStream input, String [] stopWords)
    {
        this(input, stopWords, false);
    }

  
  public StopFilter(TokenStream in, String[] stopWords, boolean ignoreCase) {
    super(in);
    this.ignoreCase = ignoreCase;
    this.stopWords = makeStopSet(stopWords, ignoreCase);
  }


    
    public StopFilter(TokenStream input, Set stopWords, boolean ignoreCase)
    {
        super(input);
        this.ignoreCase = ignoreCase;
        this.stopWords = stopWords;
    }

  
  public StopFilter(TokenStream in, Set stopWords) {
    this(in, stopWords, false);
  }

  
  public static final Set makeStopSet(String[] stopWords) {
    return makeStopSet(stopWords, false);
  }
    
      
  public static final Set makeStopSet(String[] stopWords, boolean ignoreCase) {
    HashSet stopTable = new HashSet(stopWords.length);
    for (int i = 0; i < stopWords.length; i++)
      stopTable.add(ignoreCase ? stopWords[i].toLowerCase() : stopWords[i]);
    return stopTable;
  }    

  
  public final Token next() throws IOException {
    
    for (Token token = input.next(); token != null; token = input.next())
    {
        String termText = ignoreCase ? token.termText.toLowerCase() : token.termText;
        if (!stopWords.contains(termText))
          return token;
    }
    
    return null;
  }
}
"
lucene,2,org.apache.lucene.index.IndexWriter,48,1,0,21,119,742,8,20,32,0.89106383,1211,0.64,6,0.0,0.115277778,0,0,23.70833333,2,0.9792,22,"package org.apache.lucene.index;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.Lock;
import org.apache.lucene.store.RAMDirectory;

import java.io.File;
import java.io.IOException;
import java.io.PrintStream;
import java.util.Vector;




public class IndexWriter {

  
  public final static long WRITE_LOCK_TIMEOUT = 1000;

  private long writeLockTimeout = WRITE_LOCK_TIMEOUT;

  
  public final static long COMMIT_LOCK_TIMEOUT = 10000;

  private long commitLockTimeout = COMMIT_LOCK_TIMEOUT;

  public static final String WRITE_LOCK_NAME = ""write.lock"";
  public static final String COMMIT_LOCK_NAME = ""commit.lock"";

  
  public final static int DEFAULT_MERGE_FACTOR = 10;

  
  public final static int DEFAULT_MAX_BUFFERED_DOCS = 10;

  
  public final static int DEFAULT_MAX_MERGE_DOCS = Integer.MAX_VALUE;

  
  public final static int DEFAULT_MAX_FIELD_LENGTH = 10000;

  
  public final static int DEFAULT_TERM_INDEX_INTERVAL = 128;
  
  private Directory directory;  
  private Analyzer analyzer;    

  private Similarity similarity = Similarity.getDefault(); 

  private SegmentInfos segmentInfos = new SegmentInfos(); 
  private final Directory ramDirectory = new RAMDirectory(); 

  private Lock writeLock;

  private int termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL;

  
  private boolean useCompoundFile = true;
  
  private boolean closeDir;

  
  public boolean getUseCompoundFile() {
    return useCompoundFile;
  }

  
  public void setUseCompoundFile(boolean value) {
    useCompoundFile = value;
  }

  
  public void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
  }

  
  public Similarity getSimilarity() {
    return this.similarity;
  }

  
  public void setTermIndexInterval(int interval) {
    this.termIndexInterval = interval;
  }

  
  public int getTermIndexInterval() { return termIndexInterval; }

  
  public IndexWriter(String path, Analyzer a, boolean create)
       throws IOException {
    this(FSDirectory.getDirectory(path, create), a, create, true);
  }

  
  public IndexWriter(File path, Analyzer a, boolean create)
       throws IOException {
    this(FSDirectory.getDirectory(path, create), a, create, true);
  }

  
  public IndexWriter(Directory d, Analyzer a, boolean create)
       throws IOException {
    this(d, a, create, false);
  }
  
  private IndexWriter(Directory d, Analyzer a, final boolean create, boolean closeDir)
    throws IOException {
      this.closeDir = closeDir;
      directory = d;
      analyzer = a;

      Lock writeLock = directory.makeLock(IndexWriter.WRITE_LOCK_NAME);
      if (!writeLock.obtain(writeLockTimeout)) 
        throw new IOException(""Index locked for write: "" + writeLock);
      this.writeLock = writeLock;                   

      synchronized (directory) {        
        new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), commitLockTimeout) {
            public Object doBody() throws IOException {
              if (create)
                segmentInfos.write(directory);
              else
                segmentInfos.read(directory);
              return null;
            }
          }.run();
      }
  }

  
  public void setMaxMergeDocs(int maxMergeDocs) {
    this.maxMergeDocs = maxMergeDocs;
  }

  
  public int getMaxMergeDocs() {
    return maxMergeDocs;
  }

  
  public void setMaxFieldLength(int maxFieldLength) {
    this.maxFieldLength = maxFieldLength;
  }
  
  
  public int getMaxFieldLength() {
    return maxFieldLength;
  }

  
  public void setMaxBufferedDocs(int maxBufferedDocs) {
    if (maxBufferedDocs < 2)
      throw new IllegalArgumentException(""maxBufferedDocs must at least be 2"");
    this.minMergeDocs = maxBufferedDocs;
  }

  
  public int getMaxBufferedDocs() {
    return minMergeDocs;
  }

  
  public void setMergeFactor(int mergeFactor) {
    if (mergeFactor < 2)
      throw new IllegalArgumentException(""mergeFactor cannot be less than 2"");
    this.mergeFactor = mergeFactor;
  }

  
  public int getMergeFactor() {
    return mergeFactor;
  }

  
  public void setInfoStream(PrintStream infoStream) {
    this.infoStream = infoStream;
  }

  
  public PrintStream getInfoStream() {
    return infoStream;
  }

  
  public void setCommitLockTimeout(long commitLockTimeout) {
    this.commitLockTimeout = commitLockTimeout;
  }

  
  public long getCommitLockTimeout() {
    return commitLockTimeout;
  }

  
  public void setWriteLockTimeout(long writeLockTimeout) {
    this.writeLockTimeout = writeLockTimeout;
  }

  
  public long getWriteLockTimeout() {
    return writeLockTimeout;
  }

  
  public synchronized void close() throws IOException {
    flushRamSegments();
    ramDirectory.close();
    if (writeLock != null) {
      writeLock.release();                          
      writeLock = null;
    }
    if(closeDir)
      directory.close();
  }

  
  protected void finalize() throws IOException {
    if (writeLock != null) {
      writeLock.release();                        
      writeLock = null;
    }
  }

  
  public Directory getDirectory() {
      return directory;
  }

  
  public Analyzer getAnalyzer() {
      return analyzer;
  }


  
  public synchronized int docCount() {
    int count = 0;
    for (int i = 0; i < segmentInfos.size(); i++) {
      SegmentInfo si = segmentInfos.info(i);
      count += si.docCount;
    }
    return count;
  }

  
  private int maxFieldLength = DEFAULT_MAX_FIELD_LENGTH;

  
  public void addDocument(Document doc) throws IOException {
    addDocument(doc, analyzer);
  }

  
  public void addDocument(Document doc, Analyzer analyzer) throws IOException {
    DocumentWriter dw =
      new DocumentWriter(ramDirectory, analyzer, this);
    dw.setInfoStream(infoStream);
    String segmentName = newSegmentName();
    dw.addDocument(segmentName, doc);
    synchronized (this) {
      segmentInfos.addElement(new SegmentInfo(segmentName, 1, ramDirectory));
      maybeMergeSegments();
    }
  }

  final int getSegmentsCounter(){
    return segmentInfos.counter;
  }
  
  private final synchronized String newSegmentName() {
    return ""_"" + Integer.toString(segmentInfos.counter++, Character.MAX_RADIX);
  }

  
  private int mergeFactor = DEFAULT_MERGE_FACTOR;

  
  private int minMergeDocs = DEFAULT_MAX_BUFFERED_DOCS;


  
  private int maxMergeDocs = DEFAULT_MAX_MERGE_DOCS;

  
  private PrintStream infoStream = null;

  
  public synchronized void optimize() throws IOException {
    flushRamSegments();
    while (segmentInfos.size() > 1 ||
           (segmentInfos.size() == 1 &&
            (SegmentReader.hasDeletions(segmentInfos.info(0)) ||
             segmentInfos.info(0).dir != directory ||
             (useCompoundFile &&
              (!SegmentReader.usesCompoundFile(segmentInfos.info(0)) ||
                SegmentReader.hasSeparateNorms(segmentInfos.info(0))))))) {
      int minSegment = segmentInfos.size() - mergeFactor;
      mergeSegments(minSegment < 0 ? 0 : minSegment);
    }
  }

  
  public synchronized void addIndexes(Directory[] dirs)
      throws IOException {
    optimize();					  

    int start = segmentInfos.size();

    for (int i = 0; i < dirs.length; i++) {
      SegmentInfos sis = new SegmentInfos();	  
      sis.read(dirs[i]);
      for (int j = 0; j < sis.size(); j++) {
        segmentInfos.addElement(sis.info(j));	  
      }
    }
    
    
    while (segmentInfos.size() > start+mergeFactor) {
      for (int base = start; base < segmentInfos.size(); base++) {
        int end = Math.min(segmentInfos.size(), base+mergeFactor);
        if (end-base > 1)
          mergeSegments(base, end);
      }
    }

    optimize();					  
  }

  
  public synchronized void addIndexes(IndexReader[] readers)
    throws IOException {

    optimize();					  

    final String mergedName = newSegmentName();
    SegmentMerger merger = new SegmentMerger(this, mergedName);

    final Vector segmentsToDelete = new Vector();
    IndexReader sReader = null;
    if (segmentInfos.size() == 1){ 
        sReader = SegmentReader.get(segmentInfos.info(0));
        merger.add(sReader);
        segmentsToDelete.addElement(sReader);   
    }
      
    for (int i = 0; i < readers.length; i++)      
      merger.add(readers[i]);

    int docCount = merger.merge();                

    segmentInfos.setSize(0);                      
    segmentInfos.addElement(new SegmentInfo(mergedName, docCount, directory));
    
    if(sReader != null)
        sReader.close();

    synchronized (directory) {			  
      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), commitLockTimeout) {
	  public Object doBody() throws IOException {
	    segmentInfos.write(directory);	  
	    return null;
	  }
	}.run();
    }
    
    deleteSegments(segmentsToDelete);  

    if (useCompoundFile) {
      final Vector filesToDelete = merger.createCompoundFile(mergedName + "".tmp"");
      synchronized (directory) { 
        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), commitLockTimeout) {
          public Object doBody() throws IOException {
            
            directory.renameFile(mergedName + "".tmp"", mergedName + "".cfs"");
            return null;
          }
        }.run();
      }

      
      deleteFiles(filesToDelete);   
    }
  }

  
  private final void flushRamSegments() throws IOException {
    int minSegment = segmentInfos.size()-1;
    int docCount = 0;
    while (minSegment >= 0 &&
           (segmentInfos.info(minSegment)).dir == ramDirectory) {
      docCount += segmentInfos.info(minSegment).docCount;
      minSegment--;
    }
    if (minSegment < 0 ||			  
        (docCount + segmentInfos.info(minSegment).docCount) > mergeFactor ||
        !(segmentInfos.info(segmentInfos.size()-1).dir == ramDirectory))
      minSegment++;
    if (minSegment >= segmentInfos.size())
      return;					  
    mergeSegments(minSegment);
  }

  
  private final void maybeMergeSegments() throws IOException {
    long targetMergeDocs = minMergeDocs;
    while (targetMergeDocs <= maxMergeDocs) {
      
      int minSegment = segmentInfos.size();
      int mergeDocs = 0;
      while (--minSegment >= 0) {
        SegmentInfo si = segmentInfos.info(minSegment);
        if (si.docCount >= targetMergeDocs)
          break;
        mergeDocs += si.docCount;
      }

      if (mergeDocs >= targetMergeDocs)		  
        mergeSegments(minSegment+1);
      else
        break;

      targetMergeDocs *= mergeFactor;		  
    }
  }

  
  private final void mergeSegments(int minSegment)
      throws IOException {
    mergeSegments(minSegment, segmentInfos.size());
  }

  
  private final void mergeSegments(int minSegment, int end)
    throws IOException {
    final String mergedName = newSegmentName();
    if (infoStream != null) infoStream.print(""merging segments"");
    SegmentMerger merger = new SegmentMerger(this, mergedName);

    final Vector segmentsToDelete = new Vector();
    for (int i = minSegment; i < end; i++) {
      SegmentInfo si = segmentInfos.info(i);
      if (infoStream != null)
        infoStream.print("" "" + si.name + "" ("" + si.docCount + "" docs)"");
      IndexReader reader = SegmentReader.get(si);
      merger.add(reader);
      if ((reader.directory() == this.directory) || 
          (reader.directory() == this.ramDirectory))
        segmentsToDelete.addElement(reader);   
    }

    int mergedDocCount = merger.merge();

    if (infoStream != null) {
      infoStream.println("" into ""+mergedName+"" (""+mergedDocCount+"" docs)"");
    }

    for (int i = end-1; i > minSegment; i--)     
      segmentInfos.remove(i);
    segmentInfos.set(minSegment, new SegmentInfo(mergedName, mergedDocCount,
                                            directory));

    
    merger.closeReaders();

    synchronized (directory) {                 
      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), commitLockTimeout) {
          public Object doBody() throws IOException {
            segmentInfos.write(directory);     
            return null;
          }
        }.run();
    }
    
    deleteSegments(segmentsToDelete);  

    if (useCompoundFile) {
      final Vector filesToDelete = merger.createCompoundFile(mergedName + "".tmp"");
      synchronized (directory) { 
        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), commitLockTimeout) {
          public Object doBody() throws IOException {
            
            directory.renameFile(mergedName + "".tmp"", mergedName + "".cfs"");
            return null;
          }
        }.run();
      }

      
      deleteFiles(filesToDelete);   
    }
  }

  

  private final void deleteSegments(Vector segments) throws IOException {
    Vector deletable = new Vector();

    deleteFiles(readDeleteableFiles(), deletable); 

    for (int i = 0; i < segments.size(); i++) {
      SegmentReader reader = (SegmentReader)segments.elementAt(i);
      if (reader.directory() == this.directory)
        deleteFiles(reader.files(), deletable);	  
      else
        deleteFiles(reader.files(), reader.directory()); 
    }

    writeDeleteableFiles(deletable);		  
  }
  
  private final void deleteFiles(Vector files) throws IOException {
    Vector deletable = new Vector();
    deleteFiles(readDeleteableFiles(), deletable); 
    deleteFiles(files, deletable);     
    writeDeleteableFiles(deletable);        
  }

  private final void deleteFiles(Vector files, Directory directory)
       throws IOException {
    for (int i = 0; i < files.size(); i++)
      directory.deleteFile((String)files.elementAt(i));
  }

  private final void deleteFiles(Vector files, Vector deletable)
       throws IOException {
    for (int i = 0; i < files.size(); i++) {
      String file = (String)files.elementAt(i);
      try {
        directory.deleteFile(file);		  
      } catch (IOException e) {			  
        if (directory.fileExists(file)) {
          if (infoStream != null)
            infoStream.println(e.toString() + ""; Will re-try later."");
          deletable.addElement(file);		  
        }
      }
    }
  }

  private final Vector readDeleteableFiles() throws IOException {
    Vector result = new Vector();
    if (!directory.fileExists(IndexFileNames.DELETABLE))
      return result;

    IndexInput input = directory.openInput(IndexFileNames.DELETABLE);
    try {
      for (int i = input.readInt(); i > 0; i--)	  
        result.addElement(input.readString());
    } finally {
      input.close();
    }
    return result;
  }

  private final void writeDeleteableFiles(Vector files) throws IOException {
    IndexOutput output = directory.createOutput(""deleteable.new"");
    try {
      output.writeInt(files.size());
      for (int i = 0; i < files.size(); i++)
        output.writeString((String)files.elementAt(i));
    } finally {
      output.close();
    }
    directory.renameFile(""deleteable.new"", IndexFileNames.DELETABLE);
  }
}
"
lucene,2,org.apache.lucene.index.TermInfosReader,16,1,0,8,34,62,2,6,3,0.686666667,461,1.0,6,0.0,0.28125,0,0,27.1875,4,1.1875,4,"package org.apache.lucene.index;



import java.io.IOException;

import org.apache.lucene.store.Directory;



final class TermInfosReader {
  private Directory directory;
  private String segment;
  private FieldInfos fieldInfos;

  private ThreadLocal enumerators = new ThreadLocal();
  private SegmentTermEnum origEnum;
  private long size;

  private Term[] indexTerms = null;
  private TermInfo[] indexInfos;
  private long[] indexPointers;
  
  private SegmentTermEnum indexEnum;

  TermInfosReader(Directory dir, String seg, FieldInfos fis)
       throws IOException {
    directory = dir;
    segment = seg;
    fieldInfos = fis;

    origEnum = new SegmentTermEnum(directory.openInput(segment + "".tis""),
                                   fieldInfos, false);
    size = origEnum.size;

    indexEnum =
      new SegmentTermEnum(directory.openInput(segment + "".tii""),
			  fieldInfos, true);
  }

  protected void finalize() {
    
    enumerators.set(null);
  }

  public int getSkipInterval() {
    return origEnum.skipInterval;
  }

  final void close() throws IOException {
    if (origEnum != null)
      origEnum.close();
    if (indexEnum != null)
      indexEnum.close();
  }

  
  final long size() {
    return size;
  }

  private SegmentTermEnum getEnum() {
    SegmentTermEnum termEnum = (SegmentTermEnum)enumerators.get();
    if (termEnum == null) {
      termEnum = terms();
      enumerators.set(termEnum);
    }
    return termEnum;
  }

  private synchronized void ensureIndexIsRead() throws IOException {
    if (indexTerms != null)                       
      return;                                     
    try {
      int indexSize = (int)indexEnum.size;        

      indexTerms = new Term[indexSize];
      indexInfos = new TermInfo[indexSize];
      indexPointers = new long[indexSize];
        
      for (int i = 0; indexEnum.next(); i++) {
        indexTerms[i] = indexEnum.term();
        indexInfos[i] = indexEnum.termInfo();
        indexPointers[i] = indexEnum.indexPointer;
      }
    } finally {
        indexEnum.close();
        indexEnum = null;
    }
  }

  
  private final int getIndexOffset(Term term) {
    int lo = 0;					  
    int hi = indexTerms.length - 1;

    while (hi >= lo) {
      int mid = (lo + hi) >> 1;
      int delta = term.compareTo(indexTerms[mid]);
      if (delta < 0)
	hi = mid - 1;
      else if (delta > 0)
	lo = mid + 1;
      else
	return mid;
    }
    return hi;
  }

  private final void seekEnum(int indexOffset) throws IOException {
    getEnum().seek(indexPointers[indexOffset],
	      (indexOffset * getEnum().indexInterval) - 1,
	      indexTerms[indexOffset], indexInfos[indexOffset]);
  }

  
  TermInfo get(Term term) throws IOException {
    if (size == 0) return null;

    ensureIndexIsRead();

    
    SegmentTermEnum enumerator = getEnum();
    if (enumerator.term() != null                 
	&& ((enumerator.prev() != null && term.compareTo(enumerator.prev())> 0)
	    || term.compareTo(enumerator.term()) >= 0)) {
      int enumOffset = (int)(enumerator.position/enumerator.indexInterval)+1;
      if (indexTerms.length == enumOffset	  
	  || term.compareTo(indexTerms[enumOffset]) < 0)
	return scanEnum(term);			  
    }

    
    seekEnum(getIndexOffset(term));
    return scanEnum(term);
  }

  
  private final TermInfo scanEnum(Term term) throws IOException {
    SegmentTermEnum enumerator = getEnum();
    enumerator.scanTo(term);
    if (enumerator.term() != null && term.compareTo(enumerator.term()) == 0)
      return enumerator.termInfo();
    else
      return null;
  }

  
  final Term get(int position) throws IOException {
    if (size == 0) return null;

    SegmentTermEnum enumerator = getEnum();
    if (enumerator != null && enumerator.term() != null &&
        position >= enumerator.position &&
	position < (enumerator.position + enumerator.indexInterval))
      return scanEnum(position);		  

    seekEnum(position / enumerator.indexInterval); 
    return scanEnum(position);
  }

  private final Term scanEnum(int position) throws IOException {
    SegmentTermEnum enumerator = getEnum();
    while(enumerator.position < position)
      if (!enumerator.next())
	return null;

    return enumerator.term();
  }

  
  final long getPosition(Term term) throws IOException {
    if (size == 0) return -1;

    ensureIndexIsRead();
    int indexOffset = getIndexOffset(term);
    seekEnum(indexOffset);

    SegmentTermEnum enumerator = getEnum();
    while(term.compareTo(enumerator.term()) > 0 && enumerator.next()) {}

    if (term.compareTo(enumerator.term()) == 0)
      return enumerator.position;
    else
      return -1;
  }

  
  public SegmentTermEnum terms() {
    return (SegmentTermEnum)origEnum.clone();
  }

  
  public SegmentTermEnum terms(Term term) throws IOException {
    get(term);
    return (SegmentTermEnum)getEnum().clone();
  }
}
"
lucene,2,org.apache.lucene.search.PhraseScorer,13,2,2,9,34,0,2,7,6,0.675925926,342,1.0,4,0.4,0.21978022,1,3,24.61538462,3,1.1538,1,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.*;

abstract class PhraseScorer extends Scorer {
  private Weight weight;
  protected byte[] norms;
  protected float value;

  private boolean firstTime = true;
  private boolean more = true;
  protected PhraseQueue pq;
  protected PhrasePositions first, last;

  private float freq;


  PhraseScorer(Weight weight, TermPositions[] tps, int[] positions, Similarity similarity,
               byte[] norms) {
    super(similarity);
    this.norms = norms;
    this.weight = weight;
    this.value = weight.getValue();

    
    for (int i = 0; i < tps.length; i++) {
      PhrasePositions pp = new PhrasePositions(tps[i], positions[i]);
      if (last != null) {			  
        last.next = pp;
      } else
        first = pp;
      last = pp;
    }

    pq = new PhraseQueue(tps.length);             

  }

  public int doc() { return first.doc; }

  public boolean next() throws IOException {
    if (firstTime) {
      init();
      firstTime = false;
    } else if (more) {
      more = last.next();                         
    }
    return doNext();
  }
  
  
  private boolean doNext() throws IOException {
    while (more) {
      while (more && first.doc < last.doc) {      
        more = first.skipTo(last.doc);            
        firstToLast();                            
      }

      if (more) {
        
        freq = phraseFreq();                      
        if (freq == 0.0f)                         
          more = last.next();                     
        else
          return true;                            
      }
    }
    return false;                                 
  }

  public float score() throws IOException {
    
    float raw = getSimilarity().tf(freq) * value; 
    return raw * Similarity.decodeNorm(norms[first.doc]); 
  }

  public boolean skipTo(int target) throws IOException {
    for (PhrasePositions pp = first; more && pp != null; pp = pp.next) {
      more = pp.skipTo(target);
    }
    if (more)
      sort();                                     
    return doNext();
  }

  protected abstract float phraseFreq() throws IOException;

  private void init() throws IOException {
    for (PhrasePositions pp = first; more && pp != null; pp = pp.next) 
      more = pp.next();
    if(more)
      sort();
  }
  
  private void sort() {
    pq.clear();
    for (PhrasePositions pp = first; pp != null; pp = pp.next)
      pq.put(pp);
    pqToList();
  }

  protected final void pqToList() {
    last = first = null;
    while (pq.top() != null) {
      PhrasePositions pp = (PhrasePositions) pq.pop();
      if (last != null) {			  
        last.next = pp;
      } else
        first = pp;
      last = pp;
      pp.next = null;
    }
  }

  protected final void firstToLast() {
    last.next = first;			  
    last = first;
    first = first.next;
    last.next = null;
  }

  public Explanation explain(final int doc) throws IOException {
    Explanation tfExplanation = new Explanation();

    while (next() && doc() < doc) {}

    float phraseFreq = (doc() == doc) ? freq : 0.0f;
    tfExplanation.setValue(getSimilarity().tf(phraseFreq));
    tfExplanation.setDescription(""tf(phraseFreq="" + phraseFreq + "")"");

    return tfExplanation;
  }

  public String toString() { return ""scorer("" + weight + "")""; }

}
"
lucene,2,org.apache.lucene.analysis.standard.StandardAnalyzer,7,2,0,8,15,0,0,8,6,0.5,67,0.5,0,0.666666667,0.333333333,0,0,8.285714286,1,0.1429,0,"package org.apache.lucene.analysis.standard;



import org.apache.lucene.analysis.*;

import java.io.File;
import java.io.IOException;
import java.io.Reader;
import java.util.Set;


public class StandardAnalyzer extends Analyzer {
  private Set stopSet;

  
  public static final String[] STOP_WORDS = StopAnalyzer.ENGLISH_STOP_WORDS;

  
  public StandardAnalyzer() {
    this(STOP_WORDS);
  }

  
  public StandardAnalyzer(Set stopWords) {
    stopSet = stopWords;
  }

  
  public StandardAnalyzer(String[] stopWords) {
    stopSet = StopFilter.makeStopSet(stopWords);
  }

  
  public StandardAnalyzer(File stopwords) throws IOException {
    stopSet = WordlistLoader.getWordSet(stopwords);
  }

  
  public StandardAnalyzer(Reader stopwords) throws IOException {
    stopSet = WordlistLoader.getWordSet(stopwords);
  }

  
  public TokenStream tokenStream(String fieldName, Reader reader) {
    TokenStream result = new StandardTokenizer(reader);
    result = new StandardFilter(result);
    result = new LowerCaseFilter(result);
    result = new StopFilter(result, stopSet);
    return result;
  }
}
"
lucene,2,org.apache.lucene.store.RAMOutputStream,8,3,0,5,21,4,2,3,7,0.357142857,188,1.0,1,0.777777778,0.270833333,1,2,22.25,5,1.25,4,"package org.apache.lucene.store;



import java.io.IOException;



public class RAMOutputStream extends BufferedIndexOutput {
  private RAMFile file;
  private long pointer = 0;

  
  public RAMOutputStream() {
    this(new RAMFile());
  }

  RAMOutputStream(RAMFile f) {
    file = f;
  }

  
  public void writeTo(IndexOutput out) throws IOException {
    flush();
    final long end = file.length;
    long pos = 0;
    int buffer = 0;
    while (pos < end) {
      int length = BUFFER_SIZE;
      long nextPos = pos + length;
      if (nextPos > end) {                        
        length = (int)(end - pos);
      }
      out.writeBytes((byte[])file.buffers.elementAt(buffer++), length);
      pos = nextPos;
    }
  }

  
  public void reset() {
    try {
      seek(0);
    } catch (IOException e) {                     
      throw new RuntimeException(e.toString());
    }

    file.length = 0;
  }

  public void flushBuffer(byte[] src, int len) {
    byte[] buffer;
    int bufferPos = 0;
    while (bufferPos != len) {
      int bufferNumber = (int)(pointer/BUFFER_SIZE);
      int bufferOffset = (int)(pointer%BUFFER_SIZE);
      int bytesInBuffer = BUFFER_SIZE - bufferOffset;
      int remainInSrcBuffer = len - bufferPos;
      int bytesToCopy = bytesInBuffer >= remainInSrcBuffer ? remainInSrcBuffer : bytesInBuffer;

      if (bufferNumber == file.buffers.size()) {
        buffer = new byte[BUFFER_SIZE];
        file.buffers.addElement(buffer);
      } else {
        buffer = (byte[]) file.buffers.elementAt(bufferNumber);
      }

      System.arraycopy(src, bufferPos, buffer, bufferOffset, bytesToCopy);
      bufferPos += bytesToCopy;
      pointer += bytesToCopy;
    }

    if (pointer > file.length)
      file.length = pointer;

    file.lastModified = System.currentTimeMillis();
  }

  public void close() throws IOException {
    super.close();
  }

  public void seek(long pos) throws IOException {
    super.seek(pos);
    pointer = pos;
  }
  public long length() {
    return file.length;
  }
}
"
lucene,2,org.apache.lucene.search.spans.Spans,5,1,0,15,5,10,15,0,5,2.0,5,0.0,0,0.0,0.6,0,0,0.0,1,1.0,0,"package org.apache.lucene.search.spans;



import java.io.IOException;


public interface Spans {
  
  boolean next() throws IOException;

  
  boolean skipTo(int target) throws IOException;

  
  int doc();

  
  int start();

  
  int end();

}
"
lucene,2,org.apache.lucene.index.FieldInfo,1,1,0,6,2,0,6,0,0,2.0,32,0.0,0,0.0,1.0,0,0,24.0,0,0.0,1,"package org.apache.lucene.index;



final class FieldInfo {
  String name;
  boolean isIndexed;
  int number;

  
  boolean storeTermVector;
  boolean storeOffsetWithTermVector;
  boolean storePositionWithTermVector;

  boolean omitNorms; 

  FieldInfo(String na, boolean tk, int nu, boolean storeTermVector, 
            boolean storePositionWithTermVector,  boolean storeOffsetWithTermVector, boolean omitNorms) {
    name = na;
    isIndexed = tk;
    number = nu;
    this.storeTermVector = storeTermVector;
    this.storeOffsetWithTermVector = storeOffsetWithTermVector;
    this.storePositionWithTermVector = storePositionWithTermVector;
    this.omitNorms = omitNorms;
  }
}
"
lucene,2,org.apache.lucene.search.HitIterator,5,1,0,2,10,0,1,2,4,0.375,60,1.0,1,0.0,0.6,0,0,10.6,2,1.2,0,"

package org.apache.lucene.search;

import java.util.Iterator;
import java.util.NoSuchElementException;


public class HitIterator implements Iterator {
  private Hits hits;
  private int hitNumber = 0;

  
  HitIterator(Hits hits) {
    this.hits = hits;
  }

  
  public boolean hasNext() {
    return hitNumber < hits.length();
  }

  
  public Object next() {
    if (hitNumber == hits.length())
      throw new NoSuchElementException();

    Object next = new Hit(hits, hitNumber);
    hitNumber++;
    return next;
  }

  
  public void remove() {
    throw new UnsupportedOperationException();
  }

  
  public int length() {
    return hits.length();
  }
}

"
lucene,2,org.apache.lucene.search.BooleanScorer2,20,2,0,15,52,86,5,14,9,0.669172932,449,1.0,3,0.32,0.223684211,1,3,21.1,6,1.75,4,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Iterator;


class BooleanScorer2 extends Scorer {
  private ArrayList requiredScorers = new ArrayList();
  private ArrayList optionalScorers = new ArrayList();
  private ArrayList prohibitedScorers = new ArrayList();


  private class Coordinator {
    int maxCoord = 0; 
    
    private float[] coordFactors = null;
    
    void init() { 
      coordFactors = new float[maxCoord + 1];
      Similarity sim = getSimilarity();
      for (int i = 0; i <= maxCoord; i++) {
        coordFactors[i] = sim.coord(i, maxCoord);
      }
    }
    
    int nrMatchers; 

    void initDoc() {
      nrMatchers = 0;
    }
    
    float coordFactor() {
      return coordFactors[nrMatchers];
    }
  }

  private final Coordinator coordinator;

  
  private Scorer countingSumScorer = null;

  
  private final int minNrShouldMatch;

  
  public BooleanScorer2(Similarity similarity, int minNrShouldMatch) {
    super(similarity);
    if (minNrShouldMatch < 0) {
      throw new IllegalArgumentException(""Minimum number of optional scorers should not be negative"");
    }
    coordinator = new Coordinator();
    this.minNrShouldMatch = minNrShouldMatch;
  }

  
  public BooleanScorer2(Similarity similarity) {
    this(similarity, 0);
  }

  public void add(final Scorer scorer, boolean required, boolean prohibited) {
    if (!prohibited) {
      coordinator.maxCoord++;
    }

    if (required) {
      if (prohibited) {
        throw new IllegalArgumentException(""scorer cannot be required and prohibited"");
      }
      requiredScorers.add(scorer);
    } else if (prohibited) {
      prohibitedScorers.add(scorer);
    } else {
      optionalScorers.add(scorer);
    }
  }

  
  private void initCountingSumScorer() {
    coordinator.init();
    countingSumScorer = makeCountingSumScorer();
  }

  
  private class SingleMatchScorer extends Scorer {
    private Scorer scorer;
    private int lastScoredDoc = -1;

    SingleMatchScorer(Scorer scorer) {
      super(scorer.getSimilarity());
      this.scorer = scorer;
    }
    public float score() throws IOException {
      if (doc() > lastScoredDoc) {
        lastScoredDoc = doc();
        coordinator.nrMatchers++;
      }
      return scorer.score();
    }
    public int doc() {
      return scorer.doc();
    }
    public boolean next() throws IOException {
      return scorer.next();
    }
    public boolean skipTo(int docNr) throws IOException {
      return scorer.skipTo(docNr);
    }
    public Explanation explain(int docNr) throws IOException {
      return scorer.explain(docNr);
    }
  }

  private Scorer countingDisjunctionSumScorer(List scorers,
                                              int minMrShouldMatch)
  
  {
    return new DisjunctionSumScorer(scorers, minMrShouldMatch) {
      private int lastScoredDoc = -1;
      public float score() throws IOException {
        if (doc() > lastScoredDoc) {
          lastScoredDoc = doc();
          coordinator.nrMatchers += super.nrMatchers;
        }
        return super.score();
      }
    };
  }

  private static Similarity defaultSimilarity = new DefaultSimilarity();

  private Scorer countingConjunctionSumScorer(List requiredScorers) {
    
    final int requiredNrMatchers = requiredScorers.size();
    ConjunctionScorer cs = new ConjunctionScorer(defaultSimilarity) {
      private int lastScoredDoc = -1;

      public float score() throws IOException {
        if (doc() > lastScoredDoc) {
          lastScoredDoc = doc();
          coordinator.nrMatchers += requiredNrMatchers;
        }
        
        
        
        
        return super.score();
      }
    };
    Iterator rsi = requiredScorers.iterator();
    while (rsi.hasNext()) {
      cs.add((Scorer) rsi.next());
    }
    return cs;
  }

  private Scorer dualConjunctionSumScorer(Scorer req1, Scorer req2) { 
    final int requiredNrMatchers = requiredScorers.size();
    ConjunctionScorer cs = new ConjunctionScorer(defaultSimilarity);
    
    
    
    
    cs.add(req1);
    cs.add(req2);
    return cs;
  }

  
  private Scorer makeCountingSumScorer() { 
    return (requiredScorers.size() == 0)
          ? makeCountingSumScorerNoReq()
          : makeCountingSumScorerSomeReq();
  }

  private Scorer makeCountingSumScorerNoReq() { 
    if (optionalScorers.size() == 0) {
      return new NonMatchingScorer(); 
    } else { 
      
      int nrOptRequired = (minNrShouldMatch < 1) ? 1 : minNrShouldMatch;
      if (optionalScorers.size() < nrOptRequired) { 
        return new NonMatchingScorer(); 
      } else { 
        Scorer requiredCountingSumScorer =
              (optionalScorers.size() > nrOptRequired)
              ? countingDisjunctionSumScorer(optionalScorers, nrOptRequired)
              : 
              (optionalScorers.size() == 1)
              ? new SingleMatchScorer((Scorer) optionalScorers.get(0))
              : countingConjunctionSumScorer(optionalScorers);
        return addProhibitedScorers( requiredCountingSumScorer);
      }
    }
  }

  private Scorer makeCountingSumScorerSomeReq() { 
    if (optionalScorers.size() < minNrShouldMatch) {
      return new NonMatchingScorer(); 
    } else if (optionalScorers.size() == minNrShouldMatch) { 
      ArrayList allReq = new ArrayList(requiredScorers);
      allReq.addAll(optionalScorers);
      return addProhibitedScorers( countingConjunctionSumScorer(allReq));
    } else { 
      Scorer requiredCountingSumScorer =
            (requiredScorers.size() == 1)
            ? new SingleMatchScorer((Scorer) requiredScorers.get(0))
            : countingConjunctionSumScorer(requiredScorers);
      if (minNrShouldMatch > 0) { 
        return addProhibitedScorers( 
                      dualConjunctionSumScorer( 
                              requiredCountingSumScorer,
                              countingDisjunctionSumScorer(
                                      optionalScorers,
                                      minNrShouldMatch)));
      } else { 
        return new ReqOptSumScorer(
                      addProhibitedScorers(requiredCountingSumScorer),
                      ((optionalScorers.size() == 1)
                        ? new SingleMatchScorer((Scorer) optionalScorers.get(0))
                        : countingDisjunctionSumScorer(optionalScorers, 1))); 
      }
    }
  }
  
  
  private Scorer addProhibitedScorers(Scorer requiredCountingSumScorer)
  {
    return (prohibitedScorers.size() == 0)
          ? requiredCountingSumScorer 
          : new ReqExclScorer(requiredCountingSumScorer,
                              ((prohibitedScorers.size() == 1)
                                ? (Scorer) prohibitedScorers.get(0)
                                : new DisjunctionSumScorer(prohibitedScorers)));
  }

  
  public void score(HitCollector hc) throws IOException {
    if (countingSumScorer == null) {
      initCountingSumScorer();
    }
    while (countingSumScorer.next()) {
      hc.collect(countingSumScorer.doc(), score());
    }
  }

  
  protected boolean score(HitCollector hc, int max) throws IOException {
    
    int docNr = countingSumScorer.doc();
    while (docNr < max) {
      hc.collect(docNr, score());
      if (! countingSumScorer.next()) {
        return false;
      }
      docNr = countingSumScorer.doc();
    }
    return true;
  }

  public int doc() { return countingSumScorer.doc(); }

  public boolean next() throws IOException {
    if (countingSumScorer == null) {
      initCountingSumScorer();
    }
    return countingSumScorer.next();
  }

  public float score() throws IOException {
    coordinator.initDoc();
    float sum = countingSumScorer.score();
    return sum * coordinator.coordFactor();
  }

  
  public boolean skipTo(int target) throws IOException {
    if (countingSumScorer == null) {
      initCountingSumScorer();
    }
    return countingSumScorer.skipTo(target);
  }

  
  public Explanation explain(int doc) {
    throw new UnsupportedOperationException();
 
  }
}

"
lucene,2,org.apache.lucene.analysis.Token,9,1,0,13,16,0,13,0,9,0.6,152,0.2,0,0.0,0.518518519,1,1,15.33333333,3,1.1111,2,"package org.apache.lucene.analysis;





public final class Token {
  String termText;				  
  int startOffset;				  
  int endOffset;				  
  String type = ""word"";				  

  private int positionIncrement = 1;

  
  public Token(String text, int start, int end) {
    termText = text;
    startOffset = start;
    endOffset = end;
  }

  
  public Token(String text, int start, int end, String typ) {
    termText = text;
    startOffset = start;
    endOffset = end;
    type = typ;
  }

  
  public void setPositionIncrement(int positionIncrement) {
    if (positionIncrement < 0)
      throw new IllegalArgumentException
        (""Increment must be zero or greater: "" + positionIncrement);
    this.positionIncrement = positionIncrement;
  }

  
  public int getPositionIncrement() { return positionIncrement; }

  
  public final String termText() { return termText; }

  
  public final int startOffset() { return startOffset; }

  
  public final int endOffset() { return endOffset; }

  
  public final String type() { return type; }

  public final String toString() {
    StringBuffer sb = new StringBuffer();
    sb.append(""("" + termText + "","" + startOffset + "","" + endOffset);
    if (!type.equals(""word""))
      sb.append("",type=""+type);
    if (positionIncrement != 1)
      sb.append("",posIncr=""+positionIncrement);
    sb.append("")"");
    return sb.toString();
  }
}
"
lucene,2,org.apache.lucene.index.DocumentWriter,10,1,0,18,87,0,1,18,0,0.700854701,990,1.0,5,0.0,0.254545455,0,0,96.7,10,2.4,6,"package org.apache.lucene.index;



import java.io.IOException;
import java.io.PrintStream;
import java.io.Reader;
import java.io.StringReader;
import java.util.Hashtable;
import java.util.Enumeration;
import java.util.Arrays;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.Token;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.search.Similarity;

final class DocumentWriter {
  private Analyzer analyzer;
  private Directory directory;
  private Similarity similarity;
  private FieldInfos fieldInfos;
  private int maxFieldLength;
  private int termIndexInterval = IndexWriter.DEFAULT_TERM_INDEX_INTERVAL;
  private PrintStream infoStream;

   
  DocumentWriter(Directory directory, Analyzer analyzer,
                 Similarity similarity, int maxFieldLength) {
    this.directory = directory;
    this.analyzer = analyzer;
    this.similarity = similarity;
    this.maxFieldLength = maxFieldLength;
  }

  DocumentWriter(Directory directory, Analyzer analyzer, IndexWriter writer) {
    this.directory = directory;
    this.analyzer = analyzer;
    this.similarity = writer.getSimilarity();
    this.maxFieldLength = writer.getMaxFieldLength();
    this.termIndexInterval = writer.getTermIndexInterval();
  }

  final void addDocument(String segment, Document doc)
          throws IOException {
    
    fieldInfos = new FieldInfos();
    fieldInfos.add(doc);
    fieldInfos.write(directory, segment + "".fnm"");

    
    FieldsWriter fieldsWriter =
            new FieldsWriter(directory, segment, fieldInfos);
    try {
      fieldsWriter.addDocument(doc);
    } finally {
      fieldsWriter.close();
    }

    
    postingTable.clear();			  
    fieldLengths = new int[fieldInfos.size()];    
    fieldPositions = new int[fieldInfos.size()];  
    fieldOffsets = new int[fieldInfos.size()];    

    fieldBoosts = new float[fieldInfos.size()];	  
    Arrays.fill(fieldBoosts, doc.getBoost());

    invertDocument(doc);

    
    Posting[] postings = sortPostingTable();

    

    
    writePostings(postings, segment);

    
    writeNorms(segment);

  }

  
  
  private final Hashtable postingTable = new Hashtable();
  private int[] fieldLengths;
  private int[] fieldPositions;
  private int[] fieldOffsets;
  private float[] fieldBoosts;

  
  private final void invertDocument(Document doc)
          throws IOException {
    Enumeration fields = doc.fields();
    while (fields.hasMoreElements()) {
      Field field = (Field) fields.nextElement();
      String fieldName = field.name();
      int fieldNumber = fieldInfos.fieldNumber(fieldName);

      int length = fieldLengths[fieldNumber];     
      int position = fieldPositions[fieldNumber]; 
      if (length>0) position+=analyzer.getPositionIncrementGap(fieldName);
      int offset = fieldOffsets[fieldNumber];       

      if (field.isIndexed()) {
        if (!field.isTokenized()) {		  
          String stringValue = field.stringValue();
          if(field.isStoreOffsetWithTermVector())
            addPosition(fieldName, stringValue, position++, new TermVectorOffsetInfo(offset, offset + stringValue.length()));
          else
            addPosition(fieldName, stringValue, position++, null);
          offset += stringValue.length();
          length++;
        } else 
        {
          Reader reader;			  
          if (field.readerValue() != null)
            reader = field.readerValue();
          else if (field.stringValue() != null)
            reader = new StringReader(field.stringValue());
          else
            throw new IllegalArgumentException
                    (""field must have either String or Reader value"");

          
          TokenStream stream = analyzer.tokenStream(fieldName, reader);
          try {
            Token lastToken = null;
            for (Token t = stream.next(); t != null; t = stream.next()) {
              position += (t.getPositionIncrement() - 1);
              
              if(field.isStoreOffsetWithTermVector())
                addPosition(fieldName, t.termText(), position++, new TermVectorOffsetInfo(offset + t.startOffset(), offset + t.endOffset()));
              else
                addPosition(fieldName, t.termText(), position++, null);
              
              lastToken = t;
              if (++length > maxFieldLength) {
                if (infoStream != null)
                  infoStream.println(""maxFieldLength "" +maxFieldLength+ "" reached, ignoring following tokens"");
                break;
              }
            }
            
            if(lastToken != null)
              offset += lastToken.endOffset() + 1;
            
          } finally {
            stream.close();
          }
        }

        fieldLengths[fieldNumber] = length;	  
        fieldPositions[fieldNumber] = position;	  
        fieldBoosts[fieldNumber] *= field.getBoost();
        fieldOffsets[fieldNumber] = offset;
      }
    }
  }

  private final Term termBuffer = new Term("""", """"); 

  private final void addPosition(String field, String text, int position, TermVectorOffsetInfo offset) {
    termBuffer.set(field, text);
    
    Posting ti = (Posting) postingTable.get(termBuffer);
    if (ti != null) {				  
      int freq = ti.freq;
      if (ti.positions.length == freq) {	  
        int[] newPositions = new int[freq * 2];	  
        int[] positions = ti.positions;
        for (int i = 0; i < freq; i++)		  
          newPositions[i] = positions[i];
        ti.positions = newPositions;
      }
      ti.positions[freq] = position;		  

      if (offset != null) {
        if (ti.offsets.length == freq){
          TermVectorOffsetInfo [] newOffsets = new TermVectorOffsetInfo[freq*2];
          TermVectorOffsetInfo [] offsets = ti.offsets;
          for (int i = 0; i < freq; i++)
          {
            newOffsets[i] = offsets[i];
          }
          ti.offsets = newOffsets;
        }
        ti.offsets[freq] = offset;
      }
      ti.freq = freq + 1;			  
    } else {					  
      Term term = new Term(field, text, false);
      postingTable.put(term, new Posting(term, position, offset));
    }
  }

  private final Posting[] sortPostingTable() {
    
    Posting[] array = new Posting[postingTable.size()];
    Enumeration postings = postingTable.elements();
    for (int i = 0; postings.hasMoreElements(); i++)
      array[i] = (Posting) postings.nextElement();

    
    quickSort(array, 0, array.length - 1);

    return array;
  }

  private static final void quickSort(Posting[] postings, int lo, int hi) {
    if (lo >= hi)
      return;

    int mid = (lo + hi) / 2;

    if (postings[lo].term.compareTo(postings[mid].term) > 0) {
      Posting tmp = postings[lo];
      postings[lo] = postings[mid];
      postings[mid] = tmp;
    }

    if (postings[mid].term.compareTo(postings[hi].term) > 0) {
      Posting tmp = postings[mid];
      postings[mid] = postings[hi];
      postings[hi] = tmp;

      if (postings[lo].term.compareTo(postings[mid].term) > 0) {
        Posting tmp2 = postings[lo];
        postings[lo] = postings[mid];
        postings[mid] = tmp2;
      }
    }

    int left = lo + 1;
    int right = hi - 1;

    if (left >= right)
      return;

    Term partition = postings[mid].term;

    for (; ;) {
      while (postings[right].term.compareTo(partition) > 0)
        --right;

      while (left < right && postings[left].term.compareTo(partition) <= 0)
        ++left;

      if (left < right) {
        Posting tmp = postings[left];
        postings[left] = postings[right];
        postings[right] = tmp;
        --right;
      } else {
        break;
      }
    }

    quickSort(postings, lo, left);
    quickSort(postings, left + 1, hi);
  }

  private final void writePostings(Posting[] postings, String segment)
          throws IOException {
    IndexOutput freq = null, prox = null;
    TermInfosWriter tis = null;
    TermVectorsWriter termVectorWriter = null;
    try {
      
      freq = directory.createOutput(segment + "".frq"");
      prox = directory.createOutput(segment + "".prx"");
      tis = new TermInfosWriter(directory, segment, fieldInfos,
                                termIndexInterval);
      TermInfo ti = new TermInfo();
      String currentField = null;

      for (int i = 0; i < postings.length; i++) {
        Posting posting = postings[i];

        
        ti.set(1, freq.getFilePointer(), prox.getFilePointer(), -1);
        tis.add(posting.term, ti);

        
        int postingFreq = posting.freq;
        if (postingFreq == 1)				  
          freq.writeVInt(1);			  
        else {
          freq.writeVInt(0);			  
          freq.writeVInt(postingFreq);			  
        }

        int lastPosition = 0;			  
        int[] positions = posting.positions;
        for (int j = 0; j < postingFreq; j++) {		  
          int position = positions[j];
          prox.writeVInt(position - lastPosition);
          lastPosition = position;
        }
        
        String termField = posting.term.field();
        if (currentField != termField) {
          
          currentField = termField;
          FieldInfo fi = fieldInfos.fieldInfo(currentField);
          if (fi.storeTermVector) {
            if (termVectorWriter == null) {
              termVectorWriter =
                new TermVectorsWriter(directory, segment, fieldInfos);
              termVectorWriter.openDocument();
            }
            termVectorWriter.openField(currentField);

          } else if (termVectorWriter != null) {
            termVectorWriter.closeField();
          }
        }
        if (termVectorWriter != null && termVectorWriter.isFieldOpen()) {
            termVectorWriter.addTerm(posting.term.text(), postingFreq, posting.positions, posting.offsets);
        }
      }
      if (termVectorWriter != null)
        termVectorWriter.closeDocument();
    } finally {
      
      
      IOException keep = null;
      if (freq != null) try { freq.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (prox != null) try { prox.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (tis  != null) try {  tis.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (termVectorWriter  != null) try {  termVectorWriter.close(); } catch (IOException e) { if (keep == null) keep = e; }
      if (keep != null) throw (IOException) keep.fillInStackTrace();
    }
  }

  private final void writeNorms(String segment) throws IOException { 
    for(int n = 0; n < fieldInfos.size(); n++){
      FieldInfo fi = fieldInfos.fieldInfo(n);
      if(fi.isIndexed && !fi.omitNorms){
        float norm = fieldBoosts[n] * similarity.lengthNorm(fi.name, fieldLengths[n]);
        IndexOutput norms = directory.createOutput(segment + "".f"" + n);
        try {
          norms.writeByte(Similarity.encodeNorm(norm));
        } finally {
          norms.close();
        }
      }
    }
  }
  
  
  void setInfoStream(PrintStream infoStream) {
    this.infoStream = infoStream;
  }

}

final class Posting {				  
  Term term;					  
  int freq;					  
  int[] positions;				  
  TermVectorOffsetInfo [] offsets;

  Posting(Term t, int position, TermVectorOffsetInfo offset) {
    term = t;
    freq = 1;
    positions = new int[1];
    positions[0] = position;
    if(offset != null){
    offsets = new TermVectorOffsetInfo[1];
    offsets[0] = offset;
    }
    else
      offsets = null;
  }
}
"
lucene,2,org.apache.lucene.util.Constants,2,1,0,0,5,1,0,0,0,1.0,44,0.0,0,0.0,1.0,0,0,17.0,0,0.0,0,"package org.apache.lucene.util;





public final class Constants {
  private Constants() {}			  

  
  public static final String JAVA_VERSION = System.getProperty(""java.version"");
  
  public static final boolean JAVA_1_1 = JAVA_VERSION.startsWith(""1.1."");
  
  public static final boolean JAVA_1_2 = JAVA_VERSION.startsWith(""1.2."");
  
  public static final boolean JAVA_1_3 = JAVA_VERSION.startsWith(""1.3."");
 
  
  public static final String OS_NAME = System.getProperty(""os.name"");
  
  public static final boolean LINUX = OS_NAME.startsWith(""Linux"");
  
  public static final boolean WINDOWS = OS_NAME.startsWith(""Windows"");
  
  public static final boolean SUN_OS = OS_NAME.startsWith(""SunOS"");
}
"
lucene,2,org.apache.lucene.search.MultiTermQuery,7,2,2,10,27,1,2,8,6,0.333333333,134,1.0,1,0.666666667,0.342857143,2,3,18.0,5,1.5714,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.util.ToStringUtils;


public abstract class MultiTermQuery extends Query {
    private Term term;

    
    public MultiTermQuery(Term term) {
        this.term = term;
    }

    
    public Term getTerm() { return term; }

    
    protected abstract FilteredTermEnum getEnum(IndexReader reader)
      throws IOException;

    public Query rewrite(IndexReader reader) throws IOException {
      FilteredTermEnum enumerator = getEnum(reader);
      BooleanQuery query = new BooleanQuery(true);
      try {
        do {
          Term t = enumerator.term();
          if (t != null) {
            TermQuery tq = new TermQuery(t);      
            tq.setBoost(getBoost() * enumerator.difference()); 
            query.add(tq, BooleanClause.Occur.SHOULD);          
          }
        } while (enumerator.next());
      } finally {
        enumerator.close();
      }
      return query;
    }

    
    public String toString(String field) {
        StringBuffer buffer = new StringBuffer();
        if (!term.field().equals(field)) {
            buffer.append(term.field());
            buffer.append("":"");
        }
        buffer.append(term.text());
        buffer.append(ToStringUtils.boost(getBoost()));
        return buffer.toString();
    }

    public boolean equals(Object o) {
      if (this == o) return true;
      if (!(o instanceof MultiTermQuery)) return false;

      final MultiTermQuery multiTermQuery = (MultiTermQuery) o;

      if (!term.equals(multiTermQuery.term)) return false;

      return getBoost() == multiTermQuery.getBoost();
    }

    public int hashCode() {
      return term.hashCode() + Float.floatToRawIntBits(getBoost());
    }
}
"
lucene,2,org.apache.lucene.search.BooleanScorer,11,2,0,8,28,15,2,7,7,0.644444444,440,1.0,3,0.444444444,0.287878788,1,3,38.18181818,2,1.1818,1,"package org.apache.lucene.search;



import java.io.IOException;

final class BooleanScorer extends Scorer {
  private SubScorer scorers = null;
  private BucketTable bucketTable = new BucketTable(this);

  private int maxCoord = 1;
  private float[] coordFactors = null;

  private int requiredMask = 0;
  private int prohibitedMask = 0;
  private int nextMask = 1;

  BooleanScorer(Similarity similarity) {
    super(similarity);
  }

  static final class SubScorer {
    public Scorer scorer;
    public boolean done;
    public boolean required = false;
    public boolean prohibited = false;
    public HitCollector collector;
    public SubScorer next;

    public SubScorer(Scorer scorer, boolean required, boolean prohibited,
                     HitCollector collector, SubScorer next)
      throws IOException {
      this.scorer = scorer;
      this.done = !scorer.next();
      this.required = required;
      this.prohibited = prohibited;
      this.collector = collector;
      this.next = next;
    }
  }

  final void add(Scorer scorer, boolean required, boolean prohibited)
    throws IOException {
    int mask = 0;
    if (required || prohibited) {
      if (nextMask == 0)
        throw new IndexOutOfBoundsException
          (""More than 32 required/prohibited clauses in query."");
      mask = nextMask;
      nextMask = nextMask << 1;
    } else
      mask = 0;

    if (!prohibited)
      maxCoord++;

    if (prohibited)
      prohibitedMask |= mask;                     
    else if (required)
      requiredMask |= mask;                       

    scorers = new SubScorer(scorer, required, prohibited,
                            bucketTable.newCollector(mask), scorers);
  }

  private final void computeCoordFactors() {
    coordFactors = new float[maxCoord];
    for (int i = 0; i < maxCoord; i++)
      coordFactors[i] = getSimilarity().coord(i, maxCoord-1);
  }

  private int end;
  private Bucket current;

  public void score(HitCollector hc) throws IOException {
    next();
    score(hc, Integer.MAX_VALUE);
  }

  protected boolean score(HitCollector hc, int max) throws IOException {
    if (coordFactors == null)
      computeCoordFactors();

    boolean more;
    Bucket tmp;
    
    do {
      bucketTable.first = null;
      
      while (current != null) {         

        
        if ((current.bits & prohibitedMask) == 0 && 
            (current.bits & requiredMask) == requiredMask) {
          
          if (current.doc >= max){
            tmp = current;
            current = current.next;
            tmp.next = bucketTable.first;
            bucketTable.first = tmp;
            continue;
          }
          
          hc.collect(current.doc, current.score * coordFactors[current.coord]);
        }
        
        current = current.next;         
      }
      
      if( bucketTable.first != null){
        current = bucketTable.first;
        bucketTable.first = current.next;
        return true;
      }

      
      more = false;
      end += BucketTable.SIZE;
      for (SubScorer sub = scorers; sub != null; sub = sub.next) {
        if (!sub.done) {
          sub.done = !sub.scorer.score(sub.collector, end);
          if (!sub.done)
            more = true;
        }
      }
      current = bucketTable.first;
      
    } while (current != null || more);

    return false;
  }

  public int doc() { return current.doc; }

  public boolean next() throws IOException {
    boolean more;
    do {
      while (bucketTable.first != null) {         
        current = bucketTable.first;
        bucketTable.first = current.next;         

        
        if ((current.bits & prohibitedMask) == 0 && 
            (current.bits & requiredMask) == requiredMask) {
          return true;
        }
      }

      
      more = false;
      end += BucketTable.SIZE;
      for (SubScorer sub = scorers; sub != null; sub = sub.next) {
        Scorer scorer = sub.scorer;
        while (!sub.done && scorer.doc() < end) {
          sub.collector.collect(scorer.doc(), scorer.score());
          sub.done = !scorer.next();
        }
        if (!sub.done) {
          more = true;
        }
      }
    } while (bucketTable.first != null || more);

    return false;
  }

  public float score() {
    if (coordFactors == null)
      computeCoordFactors();
    return current.score * coordFactors[current.coord];
  }

  static final class Bucket {
    int doc = -1;                                 
    float       score;                            
    int bits;                                     
    int coord;                                    
    Bucket      next;                             
  }

  
  static final class BucketTable {
    public static final int SIZE = 1 << 11;
    public static final int MASK = SIZE - 1;

    final Bucket[] buckets = new Bucket[SIZE];
    Bucket first = null;                          
  
    private BooleanScorer scorer;

    public BucketTable(BooleanScorer scorer) {
      this.scorer = scorer;
    }

    public final int size() { return SIZE; }

    public HitCollector newCollector(int mask) {
      return new Collector(mask, this);
    }
  }

  static final class Collector extends HitCollector {
    private BucketTable bucketTable;
    private int mask;
    public Collector(int mask, BucketTable bucketTable) {
      this.mask = mask;
      this.bucketTable = bucketTable;
    }
    public final void collect(final int doc, final float score) {
      final BucketTable table = bucketTable;
      final int i = doc & BucketTable.MASK;
      Bucket bucket = table.buckets[i];
      if (bucket == null)
        table.buckets[i] = bucket = new Bucket();
      
      if (bucket.doc != doc) {                    
        bucket.doc = doc;                         
        bucket.score = score;                     
        bucket.bits = mask;                       
        bucket.coord = 1;                         

        bucket.next = table.first;                
        table.first = bucket;
      } else {                                    
        bucket.score += score;                    
        bucket.bits |= mask;                      
        bucket.coord++;                           
      }
    }
  }

  public boolean skipTo(int target) {
    throw new UnsupportedOperationException();
  }

  public Explanation explain(int doc) {
    throw new UnsupportedOperationException();
  }

  public String toString() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""boolean("");
    for (SubScorer sub = scorers; sub != null; sub = sub.next) {
      buffer.append(sub.scorer.toString());
      buffer.append("" "");
    }
    buffer.append("")"");
    return buffer.toString();
  }


}
"
lucene,2,org.apache.lucene.search.QueryFilter,5,2,0,6,20,0,1,6,5,0.375,118,1.0,1,0.2,0.4,1,1,22.2,2,1.0,2,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.WeakHashMap;
import java.util.BitSet;
import org.apache.lucene.index.IndexReader;


public class QueryFilter extends Filter {
  private Query query;
  private transient WeakHashMap cache = null;

  
  public QueryFilter(Query query) {
    this.query = query;
  }

  public BitSet bits(IndexReader reader) throws IOException {

    if (cache == null) {
      cache = new WeakHashMap();
    }

    synchronized (cache) {  
      BitSet cached = (BitSet) cache.get(reader);
      if (cached != null) {
        return cached;
      }
    }

    final BitSet bits = new BitSet(reader.maxDoc());

    new IndexSearcher(reader).search(query, new HitCollector() {
      public final void collect(int doc, float score) {
        bits.set(doc);  
      }
    });

    synchronized (cache) {  
      cache.put(reader, bits);
    }

    return bits;
  }

  public String toString() {
    return ""QueryFilter(""+query+"")"";
  }

  public boolean equals(Object o) {
    if (!(o instanceof QueryFilter)) return false;
    return this.query.equals(((QueryFilter)o).query);
  }

  public int hashCode() {
    return query.hashCode() ^ 0x923F64B9;  
  }
}
"
lucene,2,org.apache.lucene.search.ParallelMultiSearcher,6,3,0,16,33,3,1,16,6,0.4,297,1.0,1,0.87804878,0.351851852,2,3,48.16666667,1,0.8333,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.util.PriorityQueue;


public class ParallelMultiSearcher extends MultiSearcher {

  private Searchable[] searchables;
  private int[] starts;
	
  
  public ParallelMultiSearcher(Searchable[] searchables) throws IOException {
    super(searchables);
    this.searchables=searchables;
    this.starts=getStarts();
  }

  
  public int docFreq(Term term) throws IOException {
    return super.docFreq(term);
  }

  
  public TopDocs search(Weight weight, Filter filter, int nDocs)
    throws IOException {
    HitQueue hq = new HitQueue(nDocs);
    int totalHits = 0;
    MultiSearcherThread[] msta =
      new MultiSearcherThread[searchables.length];
    for (int i = 0; i < searchables.length; i++) { 
      
      msta[i] =
        new MultiSearcherThread(
                                searchables[i],
                                weight,
                                filter,
                                nDocs,
                                hq,
                                i,
                                starts,
                                ""MultiSearcher thread #"" + (i + 1));
      msta[i].start();
    }

    for (int i = 0; i < searchables.length; i++) {
      try {
        msta[i].join();
      } catch (InterruptedException ie) {
        ; 
      }
      IOException ioe = msta[i].getIOException();
      if (ioe == null) {
        totalHits += msta[i].hits();
      } else {
        
        throw ioe;
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size() - 1; i >= 0; i--) 
      scoreDocs[i] = (ScoreDoc) hq.pop();

    float maxScore = (totalHits==0) ? Float.NEGATIVE_INFINITY : scoreDocs[0].score;
    
    return new TopDocs(totalHits, scoreDocs, maxScore);
  }

  
  public TopFieldDocs search(Weight weight, Filter filter, int nDocs, Sort sort)
    throws IOException {
    
    FieldDocSortedHitQueue hq = new FieldDocSortedHitQueue (null, nDocs);
    int totalHits = 0;
    MultiSearcherThread[] msta = new MultiSearcherThread[searchables.length];
    for (int i = 0; i < searchables.length; i++) { 
      
      msta[i] =
        new MultiSearcherThread(
                                searchables[i],
                                weight,
                                filter,
                                nDocs,
                                hq,
                                sort,
                                i,
                                starts,
                                ""MultiSearcher thread #"" + (i + 1));
      msta[i].start();
    }

    float maxScore=Float.NEGATIVE_INFINITY;
    
    for (int i = 0; i < searchables.length; i++) {
      try {
        msta[i].join();
      } catch (InterruptedException ie) {
        ; 
      }
      IOException ioe = msta[i].getIOException();
      if (ioe == null) {
        totalHits += msta[i].hits();
        maxScore=Math.max(maxScore, msta[i].getMaxScore());
      } else {
        
        throw ioe;
      }
    }

    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size() - 1; i >= 0; i--) 
      scoreDocs[i] = (ScoreDoc) hq.pop();

    return new TopFieldDocs(totalHits, scoreDocs, hq.getFields(), maxScore);
  }

  
  public void search(Weight weight, Filter filter, final HitCollector results)
    throws IOException {
    for (int i = 0; i < searchables.length; i++) {

      final int start = starts[i];

      searchables[i].search(weight, filter, new HitCollector() {
          public void collect(int doc, float score) {
            results.collect(doc + start, score);
          }
        });

    }
  }

  
  public Query rewrite(Query original) throws IOException {
    return super.rewrite(original);
  }

}


class MultiSearcherThread extends Thread {

  private Searchable searchable;
  private Weight weight;
  private Filter filter;
  private int nDocs;
  private TopDocs docs;
  private int i;
  private PriorityQueue hq;
  private int[] starts;
  private IOException ioe;
  private Sort sort;

  public MultiSearcherThread(
                             Searchable searchable,
                             Weight weight,
                             Filter filter,
                             int nDocs,
                             HitQueue hq,
                             int i,
                             int[] starts,
                             String name) {
    super(name);
    this.searchable = searchable;
    this.weight = weight;
    this.filter = filter;
    this.nDocs = nDocs;
    this.hq = hq;
    this.i = i;
    this.starts = starts;
  }

  public MultiSearcherThread(
                             Searchable searchable,
                             Weight weight,
                             Filter filter,
                             int nDocs,
                             FieldDocSortedHitQueue hq,
                             Sort sort,
                             int i,
                             int[] starts,
                             String name) {
    super(name);
    this.searchable = searchable;
    this.weight = weight;
    this.filter = filter;
    this.nDocs = nDocs;
    this.hq = hq;
    this.i = i;
    this.starts = starts;
    this.sort = sort;
  }

  public void run() {
    try {
      docs = (sort == null) ? searchable.search (weight, filter, nDocs)
        : searchable.search (weight, filter, nDocs, sort);
    }
    
    catch (IOException ioe) {
      this.ioe = ioe;
    }
    if (ioe == null) {
      
      
      
      if (sort != null) {
        ((FieldDocSortedHitQueue)hq).setFields (((TopFieldDocs)docs).fields);
      }
      ScoreDoc[] scoreDocs = docs.scoreDocs;
      for (int j = 0;
           j < scoreDocs.length;
           j++) { 
        ScoreDoc scoreDoc = scoreDocs[j];
        scoreDoc.doc += starts[i]; 
        
        synchronized (hq) {
          if (!hq.insert(scoreDoc))
            break;
        } 
      }
    }
  }

  public int hits() {
    return docs.totalHits;
  }

  public float getMaxScore() {
      return docs.getMaxScore();
  }
  
  public IOException getIOException() {
    return ioe;
  }

}
"
lucene,2,org.apache.lucene.search.ConjunctionScorer,12,2,1,7,33,0,4,4,6,0.545454545,237,1.0,0,0.421052632,0.283333333,1,3,18.41666667,2,1.0,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Arrays;
import java.util.Comparator;
import java.util.Iterator;
import java.util.LinkedList;


class ConjunctionScorer extends Scorer {
  private LinkedList scorers = new LinkedList();
  private boolean firstTime = true;
  private boolean more = true;
  private float coord;

  public ConjunctionScorer(Similarity similarity) {
    super(similarity);
  }

  final void add(Scorer scorer) {
    scorers.addLast(scorer);
  }

  private Scorer first() { return (Scorer)scorers.getFirst(); }
  private Scorer last() { return (Scorer)scorers.getLast(); }

  public int doc() { return first().doc(); }

  public boolean next() throws IOException {
    if (firstTime) {
      init(true);
    } else if (more) {
      more = last().next();                       
    }
    return doNext();
  }
  
  private boolean doNext() throws IOException {
    while (more && first().doc() < last().doc()) { 
      more = first().skipTo(last().doc());      
      scorers.addLast(scorers.removeFirst());   
    }
    return more;                                
  }

  public boolean skipTo(int target) throws IOException {
    if(firstTime) {
      init(false);
    }
    
    Iterator i = scorers.iterator();
    while (more && i.hasNext()) {
      more = ((Scorer)i.next()).skipTo(target);
    }
    
    if (more)
      sortScorers();                              
    
    return doNext();
  }

  public float score() throws IOException {
    float score = 0.0f;                           
    Iterator i = scorers.iterator();
    while (i.hasNext())
      score += ((Scorer)i.next()).score();
    score *= coord;
    return score;
  }
  
  private void init(boolean initScorers) throws IOException {
    
    coord = getSimilarity().coord(scorers.size(), scorers.size());
   
    more = scorers.size() > 0;

    if(initScorers){
      
      Iterator i = scorers.iterator();
      while (more && i.hasNext()) {
        more = ((Scorer)i.next()).next();
      }
      if (more)
        sortScorers(); 
    }

    firstTime = false;
  }

  private void sortScorers() {
    
    Scorer[] array = (Scorer[])scorers.toArray(new Scorer[scorers.size()]);
    scorers.clear();                              

    
    Arrays.sort(array, new Comparator() {         
        public int compare(Object o1, Object o2) {
          return ((Scorer)o1).doc() - ((Scorer)o2).doc();
        }
      });
    
    for (int i = 0; i < array.length; i++) {
      scorers.addLast(array[i]);                  
    }
  }

  public Explanation explain(int doc) {
    throw new UnsupportedOperationException();
  }

}
"
lucene,2,org.apache.lucene.util.SmallFloat,7,1,0,1,10,21,1,0,7,2.0,155,0.0,0,0.0,0.321428571,0,0,21.14285714,4,2.5714,0,"package org.apache.lucene.util;




public class SmallFloat {

  
  public static byte floatToByte(float f, int numMantissaBits, int zeroExp) {
    
    
    int fzero = (63-zeroExp)<<numMantissaBits;
    int bits = Float.floatToRawIntBits(f);
    int smallfloat = bits >> (24-numMantissaBits);
    if (smallfloat < fzero) {
      return (bits<=0) ?
        (byte)0   
       :(byte)1;  
    } else if (smallfloat >= fzero + 0x100) {
      return -1;  
    } else {
      return (byte)(smallfloat - fzero);
    }
  }

  
  public static float byteToFloat(byte b, int numMantissaBits, int zeroExp) {
    
    
    if (b == 0) return 0.0f;
    int bits = (b&0xff) << (24-numMantissaBits);
    bits += (63-zeroExp) << 24;
    return Float.intBitsToFloat(bits);
  }


  
  
  
  
  

  
  public static byte floatToByte315(float f) {
    int bits = Float.floatToRawIntBits(f);
    int smallfloat = bits >> (24-3);
    if (smallfloat < (63-15)<<3) {
      return (bits<=0) ? (byte)0 : (byte)1;
    }
    if (smallfloat >= ((63-15)<<3) + 0x100) {
      return -1;
    }
    return (byte)(smallfloat - ((63-15)<<3));
 }

  
  public static float byte315ToFloat(byte b) {
    
    
    if (b == 0) return 0.0f;
    int bits = (b&0xff) << (24-3);
    bits += (63-15) << 24;
    return Float.intBitsToFloat(bits);
  }


  
  public static byte floatToByte52(float f) {
    int bits = Float.floatToRawIntBits(f);
    int smallfloat = bits >> (24-5);
    if (smallfloat < (63-2)<<5) {
      return (bits<=0) ? (byte)0 : (byte)1;
    }
    if (smallfloat >= ((63-2)<<5) + 0x100) {
      return -1;
    }
    return (byte)(smallfloat - ((63-2)<<5));
  }

  
  public static float byte52ToFloat(byte b) {
    
    
    if (b == 0) return 0.0f;
    int bits = (b&0xff) << (24-5);
    bits += (63-2) << 24;
    return Float.intBitsToFloat(bits);
  }
}
"
lucene,2,org.apache.lucene.analysis.KeywordTokenizer,3,3,0,3,10,1,1,2,3,0.5,63,1.0,0,0.75,0.666666667,0,0,19.0,1,0.3333,0,"package org.apache.lucene.analysis;



import java.io.IOException;
import java.io.Reader;


public class KeywordTokenizer extends Tokenizer {
  
  private static final int DEFAULT_BUFFER_SIZE = 256;

  private boolean done;
  private final char[] buffer;

  public KeywordTokenizer(Reader input) {
    this(input, DEFAULT_BUFFER_SIZE);
  }

  public KeywordTokenizer(Reader input, int bufferSize) {
    super(input);
    this.buffer = new char[bufferSize];
    this.done = false;
  }

  public Token next() throws IOException {
    if (!done) {
      done = true;
      StringBuffer buffer = new StringBuffer();
      int length;
      while (true) {
        length = input.read(this.buffer);
        if (length == -1) break;

        buffer.append(this.buffer, 0, length);
      }
      String text = buffer.toString();
      return new Token(text, 0, text.length());
    }
    return null;
  }
}
"
lucene,2,org.apache.lucene.queryParser.QueryParserConstants,1,1,0,2,1,0,2,0,0,2.0,169,0.0,0,0.0,0.0,0,0,132.0,0,0.0,1,"
package org.apache.lucene.queryParser;

public interface QueryParserConstants {

  int EOF = 0;
  int _NUM_CHAR = 1;
  int _ESCAPED_CHAR = 2;
  int _TERM_START_CHAR = 3;
  int _TERM_CHAR = 4;
  int _WHITESPACE = 5;
  int AND = 7;
  int OR = 8;
  int NOT = 9;
  int PLUS = 10;
  int MINUS = 11;
  int LPAREN = 12;
  int RPAREN = 13;
  int COLON = 14;
  int CARAT = 15;
  int QUOTED = 16;
  int TERM = 17;
  int FUZZY_SLOP = 18;
  int PREFIXTERM = 19;
  int WILDTERM = 20;
  int RANGEIN_START = 21;
  int RANGEEX_START = 22;
  int NUMBER = 23;
  int RANGEIN_TO = 24;
  int RANGEIN_END = 25;
  int RANGEIN_QUOTED = 26;
  int RANGEIN_GOOP = 27;
  int RANGEEX_TO = 28;
  int RANGEEX_END = 29;
  int RANGEEX_QUOTED = 30;
  int RANGEEX_GOOP = 31;

  int Boost = 0;
  int RangeEx = 1;
  int RangeIn = 2;
  int DEFAULT = 3;

  String[] tokenImage = {
    ""<EOF>"",
    ""<_NUM_CHAR>"",
    ""<_ESCAPED_CHAR>"",
    ""<_TERM_START_CHAR>"",
    ""<_TERM_CHAR>"",
    ""<_WHITESPACE>"",
    ""<token of kind 6>"",
    ""<AND>"",
    ""<OR>"",
    ""<NOT>"",
    ""\""+\"""",
    ""\""-\"""",
    ""\""(\"""",
    ""\"")\"""",
    ""\"":\"""",
    ""\""^\"""",
    ""<QUOTED>"",
    ""<TERM>"",
    ""<FUZZY_SLOP>"",
    ""<PREFIXTERM>"",
    ""<WILDTERM>"",
    ""\""[\"""",
    ""\""{\"""",
    ""<NUMBER>"",
    ""\""TO\"""",
    ""\""]\"""",
    ""<RANGEIN_QUOTED>"",
    ""<RANGEIN_GOOP>"",
    ""\""TO\"""",
    ""\""}\"""",
    ""<RANGEEX_QUOTED>"",
    ""<RANGEEX_GOOP>"",
  };

}
"
lucene,2,org.apache.lucene.index.TermFreqVector,6,1,0,11,6,15,11,0,6,2.0,6,0.0,0,0.0,0.375,0,0,0.0,1,1.0,0,"package org.apache.lucene.index;




public interface TermFreqVector {
   
  public String getField();
  
  
  public int size();

  
  public String[] getTerms();


  
  public int[] getTermFrequencies();
  

  
  public int indexOf(String term);


  
  public int[] indexesOf(String[] terms, int start, int len);

}
"
lucene,2,org.apache.lucene.index.IndexFileNames,2,1,0,3,3,1,3,0,0,1.4,112,0.0,0,0.0,1.0,0,0,52.5,0,0.0,2,"package org.apache.lucene.index;




final class IndexFileNames {

  
  static final String SEGMENTS = ""segments"";
  
  
  static final String DELETABLE = ""deletable"";
  
  
  static final String INDEX_EXTENSIONS[] = new String[] {
      ""cfs"", ""fnm"", ""fdx"", ""fdt"", ""tii"", ""tis"", ""frq"", ""prx"", ""del"",
      ""tvx"", ""tvd"", ""tvf"", ""tvp"" };
  
  
  static final String COMPOUND_EXTENSIONS[] = new String[] {
    ""fnm"", ""frq"", ""prx"", ""fdx"", ""fdt"", ""tii"", ""tis""
  };
  
  
  static final String VECTOR_EXTENSIONS[] = new String[] {
    ""tvx"", ""tvd"", ""tvf""
  };
  
}
"
lucene,2,org.apache.lucene.index.SegmentInfos,6,4,0,13,30,3,9,4,5,0.6,216,0.333333333,0,0.94047619,0.5,0,0,34.5,1,0.8333,7,"package org.apache.lucene.index;



import java.util.Vector;
import java.io.IOException;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.util.Constants;

final class SegmentInfos extends Vector {
  
  
  
  public static final int FORMAT = -1;
  
  public int counter = 0;    
  
  private long version = System.currentTimeMillis();

  public final SegmentInfo info(int i) {
    return (SegmentInfo) elementAt(i);
  }

  public final void read(Directory directory) throws IOException {
    
    IndexInput input = directory.openInput(IndexFileNames.SEGMENTS);
    try {
      int format = input.readInt();
      if(format < 0){     
        
        if (format < FORMAT)
          throw new IOException(""Unknown format version: "" + format);
        version = input.readLong(); 
        counter = input.readInt(); 
      }
      else{     
        counter = format;
      }
      
      for (int i = input.readInt(); i > 0; i--) { 
        SegmentInfo si =
          new SegmentInfo(input.readString(), input.readInt(), directory);
        addElement(si);
      }
      
      if(format >= 0){    
        if (input.getFilePointer() >= input.length())
          version = System.currentTimeMillis(); 
        else
          version = input.readLong(); 
      }
    }
    finally {
      input.close();
    }
  }

  public final void write(Directory directory) throws IOException {
    IndexOutput output = directory.createOutput(""segments.new"");
    try {
      output.writeInt(FORMAT); 
      output.writeLong(++version); 
      output.writeInt(counter); 
      output.writeInt(size()); 
      for (int i = 0; i < size(); i++) {
        SegmentInfo si = info(i);
        output.writeString(si.name);
        output.writeInt(si.docCount);
      }         
    }
    finally {
      output.close();
    }

    
    directory.renameFile(""segments.new"", IndexFileNames.SEGMENTS);
  }

  
  public long getVersion() {
    return version;
  }

  
  public static long readCurrentVersion(Directory directory)
    throws IOException {
      
    IndexInput input = directory.openInput(IndexFileNames.SEGMENTS);
    int format = 0;
    long version = 0;
    try {
      format = input.readInt();
      if(format < 0){
        if (format < FORMAT)
          throw new IOException(""Unknown format version: "" + format);
        version = input.readLong(); 
      }
    }
    finally {
      input.close();
    }
     
    if(format < 0)
      return version;

    
    

    SegmentInfos sis = new SegmentInfos();
    sis.read(directory);
    return sis.getVersion();
  }
}
"
lucene,2,org.apache.lucene.search.TopDocCollector,5,2,1,7,13,0,2,5,4,0.4375,110,0.5,1,0.25,0.5,0,0,20.2,4,1.6,0,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;


public class TopDocCollector extends HitCollector {
  private int numHits;
  private float minScore = 0.0f;

  int totalHits;
  PriorityQueue hq;
    
  
  public TopDocCollector(int numHits) {
    this(numHits, new HitQueue(numHits));
  }

  TopDocCollector(int numHits, PriorityQueue hq) {
    this.numHits = numHits;
    this.hq = hq;
  }

  
  public void collect(int doc, float score) {
    if (score > 0.0f) {
      totalHits++;
      if (hq.size() < numHits || score >= minScore) {
        hq.insert(new ScoreDoc(doc, score));
        minScore = ((ScoreDoc)hq.top()).score; 
      }
    }
  }

  
  public int getTotalHits() { return totalHits; }

  
  public TopDocs topDocs() {
    ScoreDoc[] scoreDocs = new ScoreDoc[hq.size()];
    for (int i = hq.size()-1; i >= 0; i--)      
      scoreDocs[i] = (ScoreDoc)hq.pop();
      
    float maxScore = (totalHits==0)
      ? Float.NEGATIVE_INFINITY
      : scoreDocs[0].score;
    
    return new TopDocs(totalHits, scoreDocs, maxScore);
  }
}
"
lucene,2,org.apache.lucene.analysis.LetterTokenizer,2,4,1,2,4,1,1,1,1,2.0,9,0.0,0,0.857142857,0.666666667,1,1,3.5,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;



public class LetterTokenizer extends CharTokenizer {
  
  public LetterTokenizer(Reader in) {
    super(in);
  }

  
  protected boolean isTokenChar(char c) {
    return Character.isLetter(c);
  }
}
"
lucene,2,org.apache.lucene.search.MatchAllDocsQuery,6,2,0,6,14,15,2,5,5,2.0,57,0.0,0,0.705882353,0.333333333,2,3,8.5,3,1.1667,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Explanation;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.Scorer;
import org.apache.lucene.search.Searcher;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.search.Weight;
import org.apache.lucene.util.ToStringUtils;

import java.util.Set;


public class MatchAllDocsQuery extends Query {

  public MatchAllDocsQuery() {
  }

  private class MatchAllScorer extends Scorer {

    final IndexReader reader;
    int id;
    final int maxId;
    final float score;

    MatchAllScorer(IndexReader reader, Similarity similarity, Weight w) {
      super(similarity);
      this.reader = reader;
      id = -1;
      maxId = reader.maxDoc() - 1;
      score = w.getValue();
    }

    public Explanation explain(int doc) {
      return null; 
    }

    public int doc() {
      return id;
    }

    public boolean next() {
      while (id < maxId) {
        id++;
        if (!reader.isDeleted(id)) {
          return true;
        }
      }
      return false;
    }

    public float score() {
      return score;
    }

    public boolean skipTo(int target) {
      id = target - 1;
      return next();
    }

  }

  private class MatchAllDocsWeight implements Weight {
    private Searcher searcher;
    private float queryWeight;
    private float queryNorm;

    public MatchAllDocsWeight(Searcher searcher) {
      this.searcher = searcher;
    }

    public String toString() {
      return ""weight("" + MatchAllDocsQuery.this + "")"";
    }

    public Query getQuery() {
      return MatchAllDocsQuery.this;
    }

    public float getValue() {
      return queryWeight;
    }

    public float sumOfSquaredWeights() {
      queryWeight = getBoost();
      return queryWeight * queryWeight;
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= this.queryNorm;
    }

    public Scorer scorer(IndexReader reader) {
      return new MatchAllScorer(reader, getSimilarity(searcher), this);
    }

    public Explanation explain(IndexReader reader, int doc) {
      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""MatchAllDocsQuery, product of:"");
      queryExpl.setValue(getValue());
      if (getBoost() != 1.0f) {
        queryExpl.addDetail(new Explanation(getBoost(),""boost""));
      }
      queryExpl.addDetail(new Explanation(queryNorm,""queryNorm""));

      return queryExpl;
    }
  }

  protected Weight createWeight(Searcher searcher) {
    return new MatchAllDocsWeight(searcher);
  }

  public void extractTerms(Set terms) {
  }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""MatchAllDocsQuery"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  public boolean equals(Object o) {
    if (!(o instanceof MatchAllDocsQuery))
      return false;
    MatchAllDocsQuery other = (MatchAllDocsQuery) o;
    return this.getBoost() == other.getBoost();
  }

  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ 0x1AA71190;
  }
}
"
lucene,2,org.apache.lucene.search.FuzzyQuery,10,3,0,13,42,7,1,12,9,0.638888889,280,0.5,0,0.72,0.285714286,3,4,26.6,6,1.4,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.util.PriorityQueue;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;


public final class FuzzyQuery extends MultiTermQuery {
  
  public final static float defaultMinSimilarity = 0.5f;
  public final static int defaultPrefixLength = 0;
  
  private float minimumSimilarity;
  private int prefixLength;
  
  
  public FuzzyQuery(Term term, float minimumSimilarity, int prefixLength) throws IllegalArgumentException {
    super(term);
    
    if (minimumSimilarity >= 1.0f)
      throw new IllegalArgumentException(""minimumSimilarity >= 1"");
    else if (minimumSimilarity < 0.0f)
      throw new IllegalArgumentException(""minimumSimilarity < 0"");
    if (prefixLength < 0)
      throw new IllegalArgumentException(""prefixLength < 0"");
    
    this.minimumSimilarity = minimumSimilarity;
    this.prefixLength = prefixLength;
  }
  
  
  public FuzzyQuery(Term term, float minimumSimilarity) throws IllegalArgumentException {
      this(term, minimumSimilarity, defaultPrefixLength);
  }

  
  public FuzzyQuery(Term term) {
    this(term, defaultMinSimilarity, defaultPrefixLength);
  }
  
  
  public float getMinSimilarity() {
    return minimumSimilarity;
  }
    
  
  public int getPrefixLength() {
    return prefixLength;
  }

  protected FilteredTermEnum getEnum(IndexReader reader) throws IOException {
    return new FuzzyTermEnum(reader, getTerm(), minimumSimilarity, prefixLength);
  }
  
  public Query rewrite(IndexReader reader) throws IOException {
    FilteredTermEnum enumerator = getEnum(reader);
    int maxClauseCount = BooleanQuery.getMaxClauseCount();
    ScoreTermQueue stQueue = new ScoreTermQueue(maxClauseCount);
    
    try {
      do {
        float minScore = 0.0f;
        float score = 0.0f;
        Term t = enumerator.term();
        if (t != null) {
          score = enumerator.difference();
          
          
          if(stQueue.size() < maxClauseCount || score > minScore){
            stQueue.insert(new ScoreTerm(t, score));
            minScore = ((ScoreTerm)stQueue.top()).score; 
          }
        }
      } while (enumerator.next());
    } finally {
      enumerator.close();
    }
    
    BooleanQuery query = new BooleanQuery(true);
    int size = stQueue.size();
    for(int i = 0; i < size; i++){
      ScoreTerm st = (ScoreTerm) stQueue.pop();
      TermQuery tq = new TermQuery(st.term);      
      tq.setBoost(getBoost() * st.score); 
      query.add(tq, BooleanClause.Occur.SHOULD);          
    }

    return query;
  }
    
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    Term term = getTerm();
    if (!term.field().equals(field)) {
        buffer.append(term.field());
        buffer.append("":"");
    }
    buffer.append(term.text());
    buffer.append('~');
    buffer.append(Float.toString(minimumSimilarity));
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }
  
  private static class ScoreTerm{
    public Term term;
    public float score;
    
    public ScoreTerm(Term term, float score){
      this.term = term;
      this.score = score;
    }
  }
  
  private static class ScoreTermQueue extends PriorityQueue {
    
    public ScoreTermQueue(int size){
      initialize(size);
    }
    
    
    protected boolean lessThan(Object a, Object b) {
      ScoreTerm termA = (ScoreTerm)a;
      ScoreTerm termB = (ScoreTerm)b;
      if (termA.score == termB.score)
        return termA.term.compareTo(termB.term) > 0;
      else
        return termA.score < termB.score;
    }
    
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof FuzzyQuery)) return false;
    if (!super.equals(o)) return false;

    final FuzzyQuery fuzzyQuery = (FuzzyQuery) o;

    if (minimumSimilarity != fuzzyQuery.minimumSimilarity) return false;
    if (prefixLength != fuzzyQuery.prefixLength) return false;

    return true;
  }

  public int hashCode() {
    int result = super.hashCode();
    result = 29 * result + minimumSimilarity != +0.0f ? Float.floatToIntBits(minimumSimilarity) : 0;
    result = 29 * result + prefixLength;
    return result;
  }
}
"
lucene,2,org.apache.lucene.analysis.standard.TokenMgrError,6,3,0,1,19,15,1,0,4,1.12,184,0.0,0,0.8125,0.5,1,1,28.83333333,14,2.8333,0,"
package org.apache.lucene.analysis.standard;

public class TokenMgrError extends Error
{
   

   
   static final int LEXICAL_ERROR = 0;

   
   static final int STATIC_LEXER_ERROR = 1;

   
   static final int INVALID_LEXICAL_STATE = 2;

   
   static final int LOOP_DETECTED = 3;

   
   int errorCode;

   
   protected static final String addEscapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

   
   protected static String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar) {
      return(""Lexical error at line "" +
           errorLine + "", column "" +
           errorColumn + "".  Encountered: "" +
           (EOFSeen ? ""<EOF> "" : (""\"""" + addEscapes(String.valueOf(curChar)) + ""\"""") + "" ("" + (int)curChar + ""), "") +
           ""after : \"""" + addEscapes(errorAfter) + ""\"""");
   }

   
   public String getMessage() {
      return super.getMessage();
   }

   

   public TokenMgrError() {
   }

   public TokenMgrError(String message, int reason) {
      super(message);
      errorCode = reason;
   }

   public TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason) {
      this(LexicalError(EOFSeen, lexState, errorLine, errorColumn, errorAfter, curChar), reason);
   }
}
"
lucene,2,org.apache.lucene.search.Filter,2,1,3,20,3,1,19,1,2,2.0,5,0.0,0,0.0,0.75,0,0,1.5,1,0.5,0,"package org.apache.lucene.search;



import java.util.BitSet;
import java.io.IOException;
import org.apache.lucene.index.IndexReader;


public abstract class Filter implements java.io.Serializable {
  
  public abstract BitSet bits(IndexReader reader) throws IOException;
}
"
lucene,2,org.apache.lucene.search.FieldCache,9,1,0,7,10,36,3,6,8,1.0625,16,0.0,1,0.0,0.5625,0,0,0.555555556,1,0.8889,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import java.io.IOException;


public interface FieldCache {

  
  
  
  public static final int STRING_INDEX = -1;


  
  public static class StringIndex {

    
    public final String[] lookup;

    
    public final int[] order;

    
    public StringIndex (int[] values, String[] lookup) {
      this.order = values;
      this.lookup = lookup;
    }
  }

  
  public interface IntParser {
    
    public int parseInt(String string);
  }


  
  public interface FloatParser {
    
    public float parseFloat(String string);
  }

  
  public static FieldCache DEFAULT = new FieldCacheImpl();


  
  public int[] getInts (IndexReader reader, String field)
  throws IOException;

  
  public int[] getInts (IndexReader reader, String field, IntParser parser)
  throws IOException;

  
  public float[] getFloats (IndexReader reader, String field)
  throws IOException;

  
  public float[] getFloats (IndexReader reader, String field,
                            FloatParser parser) throws IOException;

  
  public String[] getStrings (IndexReader reader, String field)
  throws IOException;

  
  public StringIndex getStringIndex (IndexReader reader, String field)
  throws IOException;

  
  public Object getAuto (IndexReader reader, String field)
  throws IOException;

  
  public Comparable[] getCustom (IndexReader reader, String field, SortComparator comparator)
  throws IOException;
}
"
lucene,2,org.apache.lucene.store.IndexInput,14,1,3,24,17,89,24,0,14,0.923076923,224,1.0,0,0.0,0.271428571,0,0,14.92857143,1,0.9286,0,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class IndexInput implements Cloneable {
  private char[] chars;                           

  
  public abstract byte readByte() throws IOException;

  
  public abstract void readBytes(byte[] b, int offset, int len)
    throws IOException;

  
  public int readInt() throws IOException {
    return ((readByte() & 0xFF) << 24) | ((readByte() & 0xFF) << 16)
         | ((readByte() & 0xFF) <<  8) |  (readByte() & 0xFF);
  }

  
  public int readVInt() throws IOException {
    byte b = readByte();
    int i = b & 0x7F;
    for (int shift = 7; (b & 0x80) != 0; shift += 7) {
      b = readByte();
      i |= (b & 0x7F) << shift;
    }
    return i;
  }

  
  public long readLong() throws IOException {
    return (((long)readInt()) << 32) | (readInt() & 0xFFFFFFFFL);
  }

  
  public long readVLong() throws IOException {
    byte b = readByte();
    long i = b & 0x7F;
    for (int shift = 7; (b & 0x80) != 0; shift += 7) {
      b = readByte();
      i |= (b & 0x7FL) << shift;
    }
    return i;
  }

  
  public String readString() throws IOException {
    int length = readVInt();
    if (chars == null || length > chars.length)
      chars = new char[length];
    readChars(chars, 0, length);
    return new String(chars, 0, length);
  }

  
  public void readChars(char[] buffer, int start, int length)
       throws IOException {
    final int end = start + length;
    for (int i = start; i < end; i++) {
      byte b = readByte();
      if ((b & 0x80) == 0)
	buffer[i] = (char)(b & 0x7F);
      else if ((b & 0xE0) != 0xE0) {
	buffer[i] = (char)(((b & 0x1F) << 6)
		 | (readByte() & 0x3F));
      } else
	buffer[i] = (char)(((b & 0x0F) << 12)
		| ((readByte() & 0x3F) << 6)
	        |  (readByte() & 0x3F));
    }
  }

  
  public abstract void close() throws IOException;

  
  public abstract long getFilePointer();

  
  public abstract void seek(long pos) throws IOException;

  
  public abstract long length();

  
  public Object clone() {
    IndexInput clone = null;
    try {
      clone = (IndexInput)super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.chars = null;

    return clone;
  }

}
"
lucene,2,org.apache.lucene.analysis.standard.CharStream,10,1,0,3,10,45,3,0,10,2.0,10,0.0,0,0.0,0.6,0,0,0.0,1,1.0,1,"
package org.apache.lucene.analysis.standard;



public interface CharStream {

  
  char readChar() throws java.io.IOException;

  
  int getEndColumn();

  
  int getEndLine();

  
  int getBeginColumn();

  
  int getBeginLine();

  
  void backup(int amount);

  
  char BeginToken() throws java.io.IOException;

  
  String GetImage();

  
  char[] GetSuffix(int len);

  
  void Done();

}
"
lucene,2,org.apache.lucene.analysis.standard.FastCharStream,14,1,0,2,25,3,1,1,13,0.602564103,237,0.0,0,0.0,0.404761905,0,0,15.5,1,0.9286,0,"
package org.apache.lucene.analysis.standard;



import java.io.*;


public final class FastCharStream implements CharStream {
  char[] buffer = null;

  int bufferLength = 0;				  
  int bufferPosition = 0;			  
  
  int tokenStart = 0;				  
  int bufferStart = 0;				  

  Reader input;					  

  
  public FastCharStream(Reader r) {
    input = r;
  }

  public final char readChar() throws IOException {
    if (bufferPosition >= bufferLength)
      refill();
    return buffer[bufferPosition++];
  }

  private final void refill() throws IOException {
    int newPosition = bufferLength - tokenStart;

    if (tokenStart == 0) {			  
      if (buffer == null) {			  
	buffer = new char[2048];		  
      } else if (bufferLength == buffer.length) { 
	char[] newBuffer = new char[buffer.length*2];
	System.arraycopy(buffer, 0, newBuffer, 0, bufferLength);
	buffer = newBuffer;
      }
    } else {					  
      System.arraycopy(buffer, tokenStart, buffer, 0, newPosition);
    }

    bufferLength = newPosition;			  
    bufferPosition = newPosition;
    bufferStart += tokenStart;
    tokenStart = 0;

    int charsRead =				  
      input.read(buffer, newPosition, buffer.length-newPosition);
    if (charsRead == -1)
      throw new IOException(""read past eof"");
    else
      bufferLength += charsRead;
  }

  public final char BeginToken() throws IOException {
    tokenStart = bufferPosition;
    return readChar();
  }

  public final void backup(int amount) {
    bufferPosition -= amount;
  }

  public final String GetImage() {
    return new String(buffer, tokenStart, bufferPosition - tokenStart);
  }

  public final char[] GetSuffix(int len) {
    char[] value = new char[len];
    System.arraycopy(buffer, bufferPosition - len, value, 0, len);
    return value;
  }

  public final void Done() {
    try {
      input.close();
    } catch (IOException e) {
      System.err.println(""Caught: "" + e + ""; ignoring."");
    }
  }

  public final int getColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getLine() {
    return 1;
  }
  public final int getEndColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getEndLine() {
    return 1;
  }
  public final int getBeginColumn() {
    return bufferStart + tokenStart;
  }
  public final int getBeginLine() {
    return 1;
  }
}
"
lucene,2,org.apache.lucene.search.FieldCacheImpl,14,1,0,12,51,67,1,12,8,0.641025641,764,0.666666667,2,0.0,0.401709402,0,0,53.35714286,2,1.1429,2,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermDocs;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.search.FieldCache.StringIndex; 

import java.io.IOException;
import java.util.Locale;
import java.util.Map;
import java.util.WeakHashMap;
import java.util.HashMap;


class FieldCacheImpl
implements FieldCache {

  
  static class Entry {
    final String field;        
    final int type;            
    final Object custom;       
    final Locale locale;       

    
    Entry (String field, int type, Locale locale) {
      this.field = field.intern();
      this.type = type;
      this.custom = null;
      this.locale = locale;
    }

    
    Entry (String field, Object custom) {
      this.field = field.intern();
      this.type = SortField.CUSTOM;
      this.custom = custom;
      this.locale = null;
    }

    
    public boolean equals (Object o) {
      if (o instanceof Entry) {
        Entry other = (Entry) o;
        if (other.field == field && other.type == type) {
          if (other.locale == null ? locale == null : other.locale.equals(locale)) {
            if (other.custom == null) {
              if (custom == null) return true;
            } else if (other.custom.equals (custom)) {
              return true;
            }
          }
        }
      }
      return false;
    }

    
    public int hashCode() {
      return field.hashCode() ^ type ^ (custom==null ? 0 : custom.hashCode()) ^ (locale==null ? 0 : locale.hashCode());
    }
  }

  private static final IntParser INT_PARSER = new IntParser() {
      public int parseInt(String value) {
        return Integer.parseInt(value);
      }
    };

  private static final FloatParser FLOAT_PARSER = new FloatParser() {
      public float parseFloat(String value) {
        return Float.parseFloat(value);
      }
    };

  
  final Map cache = new WeakHashMap();

  
  Object lookup (IndexReader reader, String field, int type, Locale locale) {
    Entry entry = new Entry (field, type, locale);
    synchronized (this) {
      HashMap readerCache = (HashMap)cache.get(reader);
      if (readerCache == null) return null;
      return readerCache.get (entry);
    }
  }

  
  Object lookup (IndexReader reader, String field, Object comparer) {
    Entry entry = new Entry (field, comparer);
    synchronized (this) {
      HashMap readerCache = (HashMap)cache.get(reader);
      if (readerCache == null) return null;
      return readerCache.get (entry);
    }
  }

  
  Object store (IndexReader reader, String field, int type, Locale locale, Object value) {
    Entry entry = new Entry (field, type, locale);
    synchronized (this) {
      HashMap readerCache = (HashMap)cache.get(reader);
      if (readerCache == null) {
        readerCache = new HashMap();
        cache.put(reader,readerCache);
      }
      return readerCache.put (entry, value);
    }
  }

  
  Object store (IndexReader reader, String field, Object comparer, Object value) {
    Entry entry = new Entry (field, comparer);
    synchronized (this) {
      HashMap readerCache = (HashMap)cache.get(reader);
      if (readerCache == null) {
        readerCache = new HashMap();
        cache.put(reader, readerCache);
      }
      return readerCache.put (entry, value);
    }
  }

  
  public int[] getInts (IndexReader reader, String field) throws IOException {
    return getInts(reader, field, INT_PARSER);
  }

  
  public int[] getInts (IndexReader reader, String field, IntParser parser)
  throws IOException {
    field = field.intern();
    Object ret = lookup (reader, field, parser);
    if (ret == null) {
      final int[] retArray = new int[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          int termval = parser.parseInt(term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      store (reader, field, parser, retArray);
      return retArray;
    }
    return (int[]) ret;
  }

  
  public float[] getFloats (IndexReader reader, String field)
    throws IOException {
    return getFloats(reader, field, FLOAT_PARSER);
  }

  
  public float[] getFloats (IndexReader reader, String field,
                            FloatParser parser) throws IOException {
    field = field.intern();
    Object ret = lookup (reader, field, parser);
    if (ret == null) {
      final float[] retArray = new float[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          float termval = parser.parseFloat(term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      store (reader, field, parser, retArray);
      return retArray;
    }
    return (float[]) ret;
  }

  
  public String[] getStrings (IndexReader reader, String field)
  throws IOException {
    field = field.intern();
    Object ret = lookup (reader, field, SortField.STRING, null);
    if (ret == null) {
      final String[] retArray = new String[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          String termval = term.text();
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      store (reader, field, SortField.STRING, null, retArray);
      return retArray;
    }
    return (String[]) ret;
  }

  
  public StringIndex getStringIndex (IndexReader reader, String field)
  throws IOException {
    field = field.intern();
    Object ret = lookup (reader, field, STRING_INDEX, null);
    if (ret == null) {
      final int[] retArray = new int[reader.maxDoc()];
      String[] mterms = new String[reader.maxDoc()+1];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      int t = 0;  

      
      
      
      
      mterms[t++] = null;

      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;

          
          
          if (t >= mterms.length) throw new RuntimeException (""there are more terms than "" +
                  ""documents in field \"""" + field + ""\"", but it's impossible to sort on "" +
                  ""tokenized fields"");
          mterms[t] = term.text();

          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = t;
          }

          t++;
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }

      if (t == 0) {
        
        
        mterms = new String[1];
      } else if (t < mterms.length) {
        
        
        String[] terms = new String[t];
        System.arraycopy (mterms, 0, terms, 0, t);
        mterms = terms;
      }

      StringIndex value = new StringIndex (retArray, mterms);
      store (reader, field, STRING_INDEX, null, value);
      return value;
    }
    return (StringIndex) ret;
  }

  
  

  
  

  
  public Object getAuto (IndexReader reader, String field)
  throws IOException {
    field = field.intern();
    Object ret = lookup (reader, field, SortField.AUTO, null);
    if (ret == null) {
      TermEnum enumerator = reader.terms (new Term (field, """"));
      try {
        Term term = enumerator.term();
        if (term == null) {
          throw new RuntimeException (""no terms in field "" + field + "" - cannot determine sort type"");
        }
        if (term.field() == field) {
          String termtext = term.text().trim();

          

          
          try {
            Integer.parseInt (termtext);
            ret = getInts (reader, field);
          } catch (NumberFormatException nfe1) {
            try {
              Float.parseFloat (termtext);
              ret = getFloats (reader, field);
            } catch (NumberFormatException nfe2) {
              ret = getStringIndex (reader, field);
            }
          }
          if (ret != null) {
            store (reader, field, SortField.AUTO, null, ret);
          }
        } else {
          throw new RuntimeException (""field \"""" + field + ""\"" does not appear to be indexed"");
        }
      } finally {
        enumerator.close();
      }

    }
    return ret;
  }

  
  public Comparable[] getCustom (IndexReader reader, String field, SortComparator comparator)
  throws IOException {
    field = field.intern();
    Object ret = lookup (reader, field, comparator);
    if (ret == null) {
      final Comparable[] retArray = new Comparable[reader.maxDoc()];
      TermDocs termDocs = reader.termDocs();
      TermEnum termEnum = reader.terms (new Term (field, """"));
      try {
        do {
          Term term = termEnum.term();
          if (term==null || term.field() != field) break;
          Comparable termval = comparator.getComparable (term.text());
          termDocs.seek (termEnum);
          while (termDocs.next()) {
            retArray[termDocs.doc()] = termval;
          }
        } while (termEnum.next());
      } finally {
        termDocs.close();
        termEnum.close();
      }
      store (reader, field, comparator, retArray);
      return retArray;
    }
    return (Comparable[]) ret;
  }

}

"
lucene,2,org.apache.lucene.search.ReqExclScorer,7,2,0,4,16,0,1,3,6,0.333333333,179,1.0,2,0.571428571,0.476190476,1,3,24.14285714,1,0.8571,0,"package org.apache.lucene.search;



import java.io.IOException;



public class ReqExclScorer extends Scorer {
  private Scorer reqScorer, exclScorer;

  
  public ReqExclScorer(
      Scorer reqScorer,
      Scorer exclScorer) {
    super(null); 
    this.reqScorer = reqScorer;
    this.exclScorer = exclScorer;
  }

  private boolean firstTime = true;
  
  public boolean next() throws IOException {
    if (firstTime) {
      if (! exclScorer.next()) {
        exclScorer = null; 
      }
      firstTime = false;
    }
    if (reqScorer == null) {
      return false;
    }
    if (! reqScorer.next()) {
      reqScorer = null; 
      return false;
    }
    if (exclScorer == null) {
      return true; 
    }
    return toNonExcluded();
  }
  
  
  private boolean toNonExcluded() throws IOException {
    int exclDoc = exclScorer.doc();
    do {  
      int reqDoc = reqScorer.doc(); 
      if (reqDoc < exclDoc) {
        return true; 
      } else if (reqDoc > exclDoc) {
        if (! exclScorer.skipTo(reqDoc)) {
          exclScorer = null; 
          return true;
        }
        exclDoc = exclScorer.doc();
        if (exclDoc > reqDoc) {
          return true; 
        }
      }
    } while (reqScorer.next());
    reqScorer = null; 
    return false;
  }

  public int doc() {
    return reqScorer.doc(); 
  }

  
  public float score() throws IOException {
    return reqScorer.score(); 
  }
  
  
  public boolean skipTo(int target) throws IOException {
    if (firstTime) {
      firstTime = false;
      if (! exclScorer.skipTo(target)) {
        exclScorer = null; 
      }
    }
    if (reqScorer == null) {
      return false;
    }
    if (exclScorer == null) {
      return reqScorer.skipTo(target);
    }
    if (! reqScorer.skipTo(target)) {
      reqScorer = null;
      return false;
    }
    return toNonExcluded();
  }

  public Explanation explain(int doc) throws IOException {
    Explanation res = new Explanation();
    if (exclScorer.skipTo(doc) && (exclScorer.doc() == doc)) {
      res.setDescription(""excluded"");
    } else {
      res.setDescription(""not excluded"");
      res.addDetail(reqScorer.explain(doc));
    }
    return res;
  }
}
"
lucene,2,org.apache.lucene.analysis.PorterStemFilter,2,3,0,4,6,0,0,4,2,0.0,35,1.0,1,0.75,0.75,0,0,16.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.IOException;


public final class PorterStemFilter extends TokenFilter {
  private PorterStemmer stemmer;

  public PorterStemFilter(TokenStream in) {
    super(in);
    stemmer = new PorterStemmer();
  }

  
  public final Token next() throws IOException {
    Token token = input.next();
    if (token == null)
      return null;
    else {
      String s = stemmer.stem(token.termText);
      if (s != token.termText) 
  	    token.termText = s;
      return token;
    }
  }
}
"
lucene,2,org.apache.lucene.index.IndexModifier,26,1,0,7,55,0,0,7,22,0.344,707,1.0,4,0.0,0.184615385,0,0,25.80769231,2,1.1538,2,"package org.apache.lucene.index;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;

import java.io.File;
import java.io.IOException;
import java.io.PrintStream;


public class IndexModifier {

  protected IndexWriter indexWriter = null;
  protected IndexReader indexReader = null;

  protected Directory directory = null;
  protected Analyzer analyzer = null;
  protected boolean open = false;

  
  protected PrintStream infoStream = null;
  protected boolean useCompoundFile = true;
  protected int maxBufferedDocs = IndexWriter.DEFAULT_MAX_BUFFERED_DOCS;
  protected int maxFieldLength = IndexWriter.DEFAULT_MAX_FIELD_LENGTH;
  protected int mergeFactor = IndexWriter.DEFAULT_MERGE_FACTOR;

  
  public IndexModifier(Directory directory, Analyzer analyzer, boolean create) throws IOException {
    init(directory, analyzer, create);
  }

  
  public IndexModifier(String dirName, Analyzer analyzer, boolean create) throws IOException {
    Directory dir = FSDirectory.getDirectory(dirName, create);
    init(dir, analyzer, create);
  }

  
  public IndexModifier(File file, Analyzer analyzer, boolean create) throws IOException {
    Directory dir = FSDirectory.getDirectory(file, create);
    init(dir, analyzer, create);
  }

  
  protected void init(Directory directory, Analyzer analyzer, boolean create) throws IOException {
    this.directory = directory;
    synchronized(this.directory) {
      this.analyzer = analyzer;
      indexWriter = new IndexWriter(directory, analyzer, create);
      open = true;
    }
  }

  
  protected void assureOpen() {
    if (!open) {
      throw new IllegalStateException(""Index is closed"");
    }
  }

  
  protected void createIndexWriter() throws IOException {
    if (indexWriter == null) {
      if (indexReader != null) {
        indexReader.close();
        indexReader = null;
      }
      indexWriter = new IndexWriter(directory, analyzer, false);
      indexWriter.setInfoStream(infoStream);
      indexWriter.setUseCompoundFile(useCompoundFile);
      indexWriter.setMaxBufferedDocs(maxBufferedDocs);
      indexWriter.setMaxFieldLength(maxFieldLength);
      indexWriter.setMergeFactor(mergeFactor);
    }
  }

  
  protected void createIndexReader() throws IOException {
    if (indexReader == null) {
      if (indexWriter != null) {
        indexWriter.close();
        indexWriter = null;
      }
      indexReader = IndexReader.open(directory);
    }
  }

  
  public void flush() throws IOException {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.close();
        indexWriter = null;
        createIndexWriter();
      } else {
        indexReader.close();
        indexReader = null;
        createIndexReader();
      }
    }
  }

  
  public void addDocument(Document doc, Analyzer docAnalyzer) throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      if (docAnalyzer != null)
        indexWriter.addDocument(doc, docAnalyzer);
      else
        indexWriter.addDocument(doc);
    }
  }

  
  public void addDocument(Document doc) throws IOException {
    addDocument(doc, null);
  }

  
  public int deleteDocuments(Term term) throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexReader();
      return indexReader.deleteDocuments(term);
    }
  }

  
  public void deleteDocument(int docNum) throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexReader();
      indexReader.deleteDocument(docNum);
    }
  }

  
  
  public int docCount() {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        return indexWriter.docCount();
      } else {
        return indexReader.numDocs();
      }
    }
  }

  
  public void optimize() throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      indexWriter.optimize();
    }
  }

  
  public void setInfoStream(PrintStream infoStream) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setInfoStream(infoStream);
      }
      this.infoStream = infoStream;
    }
  }

  
  public PrintStream getInfoStream() throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getInfoStream();
    }
  }

  
  public void setUseCompoundFile(boolean useCompoundFile) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setUseCompoundFile(useCompoundFile);
      }
      this.useCompoundFile = useCompoundFile;
    }
  }

  
  public boolean getUseCompoundFile() throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getUseCompoundFile();
    }
  }

  
  public void setMaxFieldLength(int maxFieldLength) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setMaxFieldLength(maxFieldLength);
      }
      this.maxFieldLength = maxFieldLength;
    }
  }

  
  public int getMaxFieldLength() throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getMaxFieldLength();
    }
  }

  
  public void setMaxBufferedDocs(int maxBufferedDocs) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setMaxBufferedDocs(maxBufferedDocs);
      }
      this.maxBufferedDocs = maxBufferedDocs;
    }
  }

  
  public int getMaxBufferedDocs() throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getMaxBufferedDocs();
    }
  }

  
  public void setMergeFactor(int mergeFactor) {
    synchronized(directory) {
      assureOpen();
      if (indexWriter != null) {
        indexWriter.setMergeFactor(mergeFactor);
      }
      this.mergeFactor = mergeFactor;
    }
  }

  
  public int getMergeFactor() throws IOException {
    synchronized(directory) {
      assureOpen();
      createIndexWriter();
      return indexWriter.getMergeFactor();
    }
  }

  
  public void close() throws IOException {
    synchronized(directory) {
      if (!open)
        throw new IllegalStateException(""Index is closed already"");
      if (indexWriter != null) {
        indexWriter.close();
        indexWriter = null;
      } else {
        indexReader.close();
        indexReader = null;
      }
      open = false;
    }
  }

  public String toString() {
    return ""Index@"" + directory;
  }

  
  
}
"
lucene,2,org.apache.lucene.index.SegmentTermEnum,13,2,0,9,38,0,3,6,4,0.75,354,0.571428571,6,0.294117647,0.211538462,1,2,25.15384615,1,0.9231,2,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.store.IndexInput;

final class SegmentTermEnum extends TermEnum implements Cloneable {
  private IndexInput input;
  FieldInfos fieldInfos;
  long size;
  long position = -1;

  private TermBuffer termBuffer = new TermBuffer();
  private TermBuffer prevBuffer = new TermBuffer();
  private TermBuffer scratch;                     

  private TermInfo termInfo = new TermInfo();

  private int format;
  private boolean isIndex = false;
  long indexPointer = 0;
  int indexInterval;
  int skipInterval;
  private int formatM1SkipInterval;

  SegmentTermEnum(IndexInput i, FieldInfos fis, boolean isi)
          throws IOException {
    input = i;
    fieldInfos = fis;
    isIndex = isi;

    int firstInt = input.readInt();
    if (firstInt >= 0) {
      
      format = 0;
      size = firstInt;

      
      indexInterval = 128;
      skipInterval = Integer.MAX_VALUE; 

    } else {
      
      format = firstInt;

      
      if (format < TermInfosWriter.FORMAT)
        throw new IOException(""Unknown format version:"" + format);

      size = input.readLong();                    
      
      if(format == -1){
        if (!isIndex) {
          indexInterval = input.readInt();
          formatM1SkipInterval = input.readInt();
        }
        
        
        skipInterval = Integer.MAX_VALUE;
      }
      else{
        indexInterval = input.readInt();
        skipInterval = input.readInt();
      }
    }

  }

  protected Object clone() {
    SegmentTermEnum clone = null;
    try {
      clone = (SegmentTermEnum) super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.input = (IndexInput) input.clone();
    clone.termInfo = new TermInfo(termInfo);

    clone.termBuffer = (TermBuffer)termBuffer.clone();
    clone.prevBuffer = (TermBuffer)prevBuffer.clone();
    clone.scratch = null;

    return clone;
  }

  final void seek(long pointer, int p, Term t, TermInfo ti)
          throws IOException {
    input.seek(pointer);
    position = p;
    termBuffer.set(t);
    prevBuffer.reset();
    termInfo.set(ti);
  }

  
  public final boolean next() throws IOException {
    if (position++ >= size - 1) {
      termBuffer.reset();
      return false;
    }

    prevBuffer.set(termBuffer);
    termBuffer.read(input, fieldInfos);

    termInfo.docFreq = input.readVInt();	  
    termInfo.freqPointer += input.readVLong();	  
    termInfo.proxPointer += input.readVLong();	  
    
    if(format == -1){
    
    
      if (!isIndex) {
        if (termInfo.docFreq > formatM1SkipInterval) {
          termInfo.skipOffset = input.readVInt(); 
        }
      }
    }
    else{
      if (termInfo.docFreq >= skipInterval) 
        termInfo.skipOffset = input.readVInt();
    }
    
    if (isIndex)
      indexPointer += input.readVLong();	  

    return true;
  }

  
  final void scanTo(Term term) throws IOException {
    if (scratch == null)
      scratch = new TermBuffer();
    scratch.set(term);
    while (scratch.compareTo(termBuffer) > 0 && next()) {}
  }

  
  public final Term term() {
    return termBuffer.toTerm();
  }

  
  final Term prev() {
    return prevBuffer.toTerm();
  }

  
  final TermInfo termInfo() {
    return new TermInfo(termInfo);
  }

  
  final void termInfo(TermInfo ti) {
    ti.set(termInfo);
  }

  
  public final int docFreq() {
    return termInfo.docFreq;
  }

  
  final long freqPointer() {
    return termInfo.freqPointer;
  }

  
  final long proxPointer() {
    return termInfo.proxPointer;
  }

  
  public final void close() throws IOException {
    input.close();
  }
}
"
lucene,2,org.apache.lucene.search.Searchable,10,1,0,16,10,45,6,10,10,2.0,10,0.0,0,0.0,0.288888889,0,0,0.0,1,1.0,2,"package org.apache.lucene.search;



import org.apache.lucene.document.Document;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;

import java.io.IOException;       


public interface Searchable extends java.rmi.Remote {
  
  void search(Weight weight, Filter filter, HitCollector results)
  throws IOException;


  
  void close() throws IOException;

  
  int docFreq(Term term) throws IOException;

  
  int[] docFreqs(Term[] terms) throws IOException;

  
  int maxDoc() throws IOException;

  
  TopDocs search(Weight weight, Filter filter, int n) throws IOException;

  
  Document doc(int i) throws IOException;

  
  Query rewrite(Query query) throws IOException;

  
  Explanation explain(Weight weight, int doc) throws IOException;

  
  TopFieldDocs search(Weight weight, Filter filter, int n, Sort sort)
  throws IOException;

}
"
lucene,2,org.apache.lucene.index.SegmentTermPositionVector,4,2,0,4,5,0,1,3,3,0.666666667,65,0.666666667,1,0.777777778,0.476190476,0,0,14.5,4,2.0,1,"package org.apache.lucene.index;



public class SegmentTermPositionVector extends SegmentTermVector implements TermPositionVector {
  protected int[][] positions;
  protected TermVectorOffsetInfo[][] offsets;
  public static final int[] EMPTY_TERM_POS = new int[0];
  
  public SegmentTermPositionVector(String field, String terms[], int termFreqs[], int[][] positions, TermVectorOffsetInfo[][] offsets) {
    super(field, terms, termFreqs);
    this.offsets = offsets;
    this.positions = positions;
  }

  
  public TermVectorOffsetInfo[] getOffsets(int index) {
    TermVectorOffsetInfo[] result = TermVectorOffsetInfo.EMPTY_OFFSET_INFO;
    if(offsets == null)
      return null;
    if (index >=0 && index < offsets.length)
    {
      result = offsets[index];
    }
    return result;
  }
  
  
  public int[] getTermPositions(int index) {
    int[] result = EMPTY_TERM_POS;
    if(positions == null)
      return null;
    if (index >=0 && index < positions.length)
    {
      result = positions[index];
    }
    
    return result;
  }
}"
lucene,2,org.apache.lucene.analysis.WordlistLoader,4,1,0,2,18,6,2,0,3,2.0,102,0.0,0,0.0,0.25,0,0,24.5,2,1.0,0,"package org.apache.lucene.analysis;



import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.io.Reader;
import java.io.BufferedReader;
import java.util.HashSet;
import java.util.Hashtable;
import java.util.Iterator;


public class WordlistLoader {

  
  public static HashSet getWordSet(File wordfile) throws IOException {
    HashSet result = new HashSet();
    FileReader reader = null;
    try {
      reader = new FileReader(wordfile);
      result = getWordSet(reader);
    }
    finally {
      if (reader != null)
        reader.close();
    }
    return result;
  }

  
  public static HashSet getWordSet(Reader reader) throws IOException {
    HashSet result = new HashSet();
    BufferedReader br = null;
    try {
      if (reader instanceof BufferedReader) {
        br = (BufferedReader) reader;
      } else {
        br = new BufferedReader(reader);
      }
      String word = null;
      while ((word = br.readLine()) != null) {
        result.add(word.trim());
      }
    }
    finally {
      if (br != null)
        br.close();
    }
    return result;
  }


  
  private static Hashtable makeWordTable(HashSet wordSet) {
    Hashtable table = new Hashtable();
    for (Iterator iter = wordSet.iterator(); iter.hasNext();) {
      String word = (String)iter.next();
      table.put(word, word);
    }
    return table;
  }
}
"
lucene,2,org.apache.lucene.analysis.LowerCaseFilter,2,3,0,4,5,1,1,3,2,2.0,21,0.0,0,0.75,0.75,0,0,9.5,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.IOException;


public final class LowerCaseFilter extends TokenFilter {
  public LowerCaseFilter(TokenStream in) {
    super(in);
  }

  public final Token next() throws IOException {
    Token t = input.next();

    if (t == null)
      return null;

    t.termText = t.termText.toLowerCase();

    return t;
  }
}
"
lucene,2,org.apache.lucene.index.MultiReader,26,2,0,15,56,0,1,14,17,0.668571429,601,1.0,1,0.696202532,0.174825175,1,5,21.84615385,6,1.3462,9,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.store.Directory;

import java.io.IOException;
import java.util.*;


public class MultiReader extends IndexReader {
  private IndexReader[] subReaders;
  private int[] starts;                           
  private Hashtable normsCache = new Hashtable();
  private int maxDoc = 0;
  private int numDocs = -1;
  private boolean hasDeletions = false;

 
  public MultiReader(IndexReader[] subReaders) throws IOException {
    super(subReaders.length == 0 ? null : subReaders[0].directory());
    initialize(subReaders);
  }

  
  MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders) {
    super(directory, sis, closeDirectory);
    initialize(subReaders);
  }

  private void initialize(IndexReader[] subReaders) {
    this.subReaders = subReaders;
    starts = new int[subReaders.length + 1];    
    for (int i = 0; i < subReaders.length; i++) {
      starts[i] = maxDoc;
      maxDoc += subReaders[i].maxDoc();      

      if (subReaders[i].hasDeletions())
        hasDeletions = true;
    }
    starts[subReaders.length] = maxDoc;
  }


  
  public TermFreqVector[] getTermFreqVectors(int n) throws IOException {
    int i = readerIndex(n);        
    return subReaders[i].getTermFreqVectors(n - starts[i]); 
  }

  public TermFreqVector getTermFreqVector(int n, String field)
      throws IOException {
    int i = readerIndex(n);        
    return subReaders[i].getTermFreqVector(n - starts[i], field);
  }

  public synchronized int numDocs() {
    if (numDocs == -1) {        
      int n = 0;                
      for (int i = 0; i < subReaders.length; i++)
        n += subReaders[i].numDocs();      
      numDocs = n;
    }
    return numDocs;
  }

  public int maxDoc() {
    return maxDoc;
  }

  public Document document(int n) throws IOException {
    int i = readerIndex(n);                          
    return subReaders[i].document(n - starts[i]);    
  }

  public boolean isDeleted(int n) {
    int i = readerIndex(n);                           
    return subReaders[i].isDeleted(n - starts[i]);    
  }

  public boolean hasDeletions() { return hasDeletions; }

  protected void doDelete(int n) throws IOException {
    numDocs = -1;                             
    int i = readerIndex(n);                   
    subReaders[i].deleteDocument(n - starts[i]);      
    hasDeletions = true;
  }

  protected void doUndeleteAll() throws IOException {
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].undeleteAll();
    hasDeletions = false;
    numDocs = -1;                                 
  }

  private int readerIndex(int n) {    
    int lo = 0;                                      
    int hi = subReaders.length - 1;                  

    while (hi >= lo) {
      int mid = (lo + hi) >> 1;
      int midValue = starts[mid];
      if (n < midValue)
        hi = mid - 1;
      else if (n > midValue)
        lo = mid + 1;
      else {                                      
        while (mid+1 < subReaders.length && starts[mid+1] == midValue) {
          mid++;                                  
        }
        return mid;
      }
    }
    return hi;
  }

  public boolean hasNorms(String field) throws IOException {
    for (int i = 0; i < subReaders.length; i++) {
      if (subReaders[i].hasNorms(field)) return true;
    }
    return false;
  }

  private byte[] ones;
  private byte[] fakeNorms() {
    if (ones==null) ones=SegmentReader.createFakeNorms(maxDoc());
    return ones;
  }

  public synchronized byte[] norms(String field) throws IOException {
    byte[] bytes = (byte[])normsCache.get(field);
    if (bytes != null)
      return bytes;          
    if (!hasNorms(field))
      return fakeNorms();

    bytes = new byte[maxDoc()];
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].norms(field, bytes, starts[i]);
    normsCache.put(field, bytes);      
    return bytes;
  }

  public synchronized void norms(String field, byte[] result, int offset)
    throws IOException {
    byte[] bytes = (byte[])normsCache.get(field);
    if (bytes==null && !hasNorms(field)) bytes=fakeNorms();
    if (bytes != null)                            
      System.arraycopy(bytes, 0, result, offset, maxDoc());

    for (int i = 0; i < subReaders.length; i++)      
      subReaders[i].norms(field, result, offset + starts[i]);
  }

  protected void doSetNorm(int n, String field, byte value)
    throws IOException {
    normsCache.remove(field);                         
    int i = readerIndex(n);                           
    subReaders[i].setNorm(n-starts[i], field, value); 
  }

  public TermEnum terms() throws IOException {
    return new MultiTermEnum(subReaders, starts, null);
  }

  public TermEnum terms(Term term) throws IOException {
    return new MultiTermEnum(subReaders, starts, term);
  }

  public int docFreq(Term t) throws IOException {
    int total = 0;          
    for (int i = 0; i < subReaders.length; i++)
      total += subReaders[i].docFreq(t);
    return total;
  }

  public TermDocs termDocs() throws IOException {
    return new MultiTermDocs(subReaders, starts);
  }

  public TermPositions termPositions() throws IOException {
    return new MultiTermPositions(subReaders, starts);
  }

  protected void doCommit() throws IOException {
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].commit();
  }

  protected synchronized void doClose() throws IOException {
    for (int i = 0; i < subReaders.length; i++)
      subReaders[i].close();
  }

  
  public Collection getFieldNames (IndexReader.FieldOption fieldNames) {
    
    Set fieldSet = new HashSet();
    for (int i = 0; i < subReaders.length; i++) {
      IndexReader reader = subReaders[i];
      Collection names = reader.getFieldNames(fieldNames);
      fieldSet.addAll(names);
    }
    return fieldSet;
  }
}

class MultiTermEnum extends TermEnum {
  private SegmentMergeQueue queue;

  private Term term;
  private int docFreq;

  public MultiTermEnum(IndexReader[] readers, int[] starts, Term t)
    throws IOException {
    queue = new SegmentMergeQueue(readers.length);
    for (int i = 0; i < readers.length; i++) {
      IndexReader reader = readers[i];
      TermEnum termEnum;

      if (t != null) {
        termEnum = reader.terms(t);
      } else
        termEnum = reader.terms();

      SegmentMergeInfo smi = new SegmentMergeInfo(starts[i], termEnum, reader);
      if (t == null ? smi.next() : termEnum.term() != null)
        queue.put(smi);          
      else
        smi.close();
    }

    if (t != null && queue.size() > 0) {
      next();
    }
  }

  public boolean next() throws IOException {
    SegmentMergeInfo top = (SegmentMergeInfo)queue.top();
    if (top == null) {
      term = null;
      return false;
    }

    term = top.term;
    docFreq = 0;

    while (top != null && term.compareTo(top.term) == 0) {
      queue.pop();
      docFreq += top.termEnum.docFreq();    
      if (top.next())
        queue.put(top);          
      else
        top.close();          
      top = (SegmentMergeInfo)queue.top();
    }
    return true;
  }

  public Term term() {
    return term;
  }

  public int docFreq() {
    return docFreq;
  }

  public void close() throws IOException {
    queue.close();
  }
}

class MultiTermDocs implements TermDocs {
  protected IndexReader[] readers;
  protected int[] starts;
  protected Term term;

  protected int base = 0;
  protected int pointer = 0;

  private TermDocs[] readerTermDocs;
  protected TermDocs current;              

  public MultiTermDocs(IndexReader[] r, int[] s) {
    readers = r;
    starts = s;

    readerTermDocs = new TermDocs[r.length];
  }

  public int doc() {
    return base + current.doc();
  }
  public int freq() {
    return current.freq();
  }

  public void seek(Term term) {
    this.term = term;
    this.base = 0;
    this.pointer = 0;
    this.current = null;
  }

  public void seek(TermEnum termEnum) throws IOException {
    seek(termEnum.term());
  }

  public boolean next() throws IOException {
    if (current != null && current.next()) {
      return true;
    } else if (pointer < readers.length) {
      base = starts[pointer];
      current = termDocs(pointer++);
      return next();
    } else
      return false;
  }

  
  public int read(final int[] docs, final int[] freqs) throws IOException {
    while (true) {
      while (current == null) {
        if (pointer < readers.length) {      
          base = starts[pointer];
          current = termDocs(pointer++);
        } else {
          return 0;
        }
      }
      int end = current.read(docs, freqs);
      if (end == 0) {          
        current = null;
      } else {            
        final int b = base;        
        for (int i = 0; i < end; i++)
         docs[i] += b;
        return end;
      }
    }
  }

  
  public boolean skipTo(int target) throws IOException {
    do {
      if (!next())
        return false;
    } while (target > doc());
      return true;
  }

  private TermDocs termDocs(int i) throws IOException {
    if (term == null)
      return null;
    TermDocs result = readerTermDocs[i];
    if (result == null)
      result = readerTermDocs[i] = termDocs(readers[i]);
    result.seek(term);
    return result;
  }

  protected TermDocs termDocs(IndexReader reader)
    throws IOException {
    return reader.termDocs();
  }

  public void close() throws IOException {
    for (int i = 0; i < readerTermDocs.length; i++) {
      if (readerTermDocs[i] != null)
        readerTermDocs[i].close();
    }
  }
}

class MultiTermPositions extends MultiTermDocs implements TermPositions {
  public MultiTermPositions(IndexReader[] r, int[] s) {
    super(r,s);
  }

  protected TermDocs termDocs(IndexReader reader) throws IOException {
    return (TermDocs)reader.termPositions();
  }

  public int nextPosition() throws IOException {
    return ((TermPositions)current).nextPosition();
  }

}
"
lucene,2,org.apache.lucene.search.spans.SpanScorer,7,2,0,6,25,0,1,5,5,0.520833333,201,1.0,2,0.571428571,0.30952381,1,3,26.57142857,1,0.8571,2,"package org.apache.lucene.search.spans;



import java.io.IOException;

import org.apache.lucene.search.Weight;
import org.apache.lucene.search.Scorer;
import org.apache.lucene.search.Explanation;
import org.apache.lucene.search.Similarity;


class SpanScorer extends Scorer {
  private Spans spans;
  private Weight weight;
  private byte[] norms;
  private float value;

  private boolean firstTime = true;
  private boolean more = true;

  private int doc;
  private float freq;

  SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms)
    throws IOException {
    super(similarity);
    this.spans = spans;
    this.norms = norms;
    this.weight = weight;
    this.value = weight.getValue();
    doc = -1;
  }

  public boolean next() throws IOException {
    if (firstTime) {
      more = spans.next();
      firstTime = false;
    }
    return setFreqCurrentDoc();
  }

  public boolean skipTo(int target) throws IOException {
    if (firstTime) {
      more = spans.skipTo(target);
      firstTime = false;
    }
    if (! more) {
      return false;
    }
    if (spans.doc() < target) { 
      more = spans.skipTo(target);
    }
    return setFreqCurrentDoc();
  }

  private boolean setFreqCurrentDoc() throws IOException {
    if (! more) {
      return false;
    }
    doc = spans.doc();
    freq = 0.0f;
    while (more && doc == spans.doc()) {
      int matchLength = spans.end() - spans.start();
      freq += getSimilarity().sloppyFreq(matchLength);
      more = spans.next();
    }
    return more || (freq != 0);
  }

  public int doc() { return doc; }

  public float score() throws IOException {
    float raw = getSimilarity().tf(freq) * value; 
    return raw * Similarity.decodeNorm(norms[doc]); 
  }

  public Explanation explain(final int doc) throws IOException {
    Explanation tfExplanation = new Explanation();

    skipTo(doc);

    float phraseFreq = (doc() == doc) ? freq : 0.0f;
    tfExplanation.setValue(getSimilarity().tf(phraseFreq));
    tfExplanation.setDescription(""tf(phraseFreq="" + phraseFreq + "")"");

    return tfExplanation;
  }

}
"
lucene,2,org.apache.lucene.search.spans.SpanWeight,7,1,0,11,37,0,1,11,7,0.69047619,348,1.0,2,0.0,0.30952381,0,0,47.71428571,1,0.8571,2,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.HashSet;
import java.util.Iterator;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;

import org.apache.lucene.search.Query;
import org.apache.lucene.search.Weight;
import org.apache.lucene.search.Searcher;
import org.apache.lucene.search.Scorer;
import org.apache.lucene.search.Explanation;
import org.apache.lucene.search.Similarity;

class SpanWeight implements Weight {
  private Similarity similarity;
  private float value;
  private float idf;
  private float queryNorm;
  private float queryWeight;

  private Set terms;
  private SpanQuery query;

  public SpanWeight(SpanQuery query, Searcher searcher)
    throws IOException {
    this.similarity = query.getSimilarity(searcher);
    this.query = query;
    terms=new HashSet();
    query.extractTerms(terms);

    idf = this.query.getSimilarity(searcher).idf(terms, searcher);
  }

  public Query getQuery() { return query; }
  public float getValue() { return value; }

  public float sumOfSquaredWeights() throws IOException {
    queryWeight = idf * query.getBoost();         
    return queryWeight * queryWeight;             
  }

  public void normalize(float queryNorm) {
    this.queryNorm = queryNorm;
    queryWeight *= queryNorm;                     
    value = queryWeight * idf;                    
  }

  public Scorer scorer(IndexReader reader) throws IOException {
    return new SpanScorer(query.getSpans(reader), this,
                          similarity,
                          reader.norms(query.getField()));
  }

  public Explanation explain(IndexReader reader, int doc)
    throws IOException {

    Explanation result = new Explanation();
    result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");
    String field = ((SpanQuery)getQuery()).getField();

    StringBuffer docFreqs = new StringBuffer();
    Iterator i = terms.iterator();
    while (i.hasNext()) {
      Term term = (Term)i.next();
      docFreqs.append(term.text());
      docFreqs.append(""="");
      docFreqs.append(reader.docFreq(term));

      if (i.hasNext()) {
        docFreqs.append("" "");
      }
    }

    Explanation idfExpl =
      new Explanation(idf, ""idf("" + field + "": "" + docFreqs + "")"");

    
    Explanation queryExpl = new Explanation();
    queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

    Explanation boostExpl = new Explanation(getQuery().getBoost(), ""boost"");
    if (getQuery().getBoost() != 1.0f)
      queryExpl.addDetail(boostExpl);
    queryExpl.addDetail(idfExpl);

    Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
    queryExpl.addDetail(queryNormExpl);

    queryExpl.setValue(boostExpl.getValue() *
                       idfExpl.getValue() *
                       queryNormExpl.getValue());

    result.addDetail(queryExpl);

    
    Explanation fieldExpl = new Explanation();
    fieldExpl.setDescription(""fieldWeight(""+field+"":""+query.toString(field)+
                             "" in ""+doc+""), product of:"");

    Explanation tfExpl = scorer(reader).explain(doc);
    fieldExpl.addDetail(tfExpl);
    fieldExpl.addDetail(idfExpl);

    Explanation fieldNormExpl = new Explanation();
    byte[] fieldNorms = reader.norms(field);
    float fieldNorm =
      fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
    fieldNormExpl.setValue(fieldNorm);
    fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
    fieldExpl.addDetail(fieldNormExpl);

    fieldExpl.setValue(tfExpl.getValue() *
                       idfExpl.getValue() *
                       fieldNormExpl.getValue());

    result.addDetail(fieldExpl);

    
    result.setValue(queryExpl.getValue() * fieldExpl.getValue());

    if (queryExpl.getValue() == 1.0f)
      return fieldExpl;

    return result;
  }
}
"
lucene,2,org.apache.lucene.queryParser.CharStream,10,1,0,3,10,45,3,0,10,2.0,10,0.0,0,0.0,0.6,0,0,0.0,1,1.0,0,"
package org.apache.lucene.queryParser;



public interface CharStream {

  
  char readChar() throws java.io.IOException;

  
  int getEndColumn();

  
  int getEndLine();

  
  int getBeginColumn();

  
  int getBeginLine();

  
  void backup(int amount);

  
  char BeginToken() throws java.io.IOException;

  
  String GetImage();

  
  char[] GetSuffix(int len);

  
  void Done();

}
"
lucene,2,org.apache.lucene.search.PhrasePositions,5,1,0,5,12,0,4,1,0,0.583333333,94,0.0,2,0.0,0.533333333,0,0,16.6,1,0.8,1,"package org.apache.lucene.search;



import java.io.IOException;
import org.apache.lucene.index.*;

final class PhrasePositions {
  int doc;					  
  int position;					  
  int count;					  
  int offset;					  
  TermPositions tp;				  
  PhrasePositions next;				  

  PhrasePositions(TermPositions t, int o) {
    tp = t;
    offset = o;
  }

  final boolean next() throws IOException {	  
    if (!tp.next()) {
      tp.close();				  
      doc = Integer.MAX_VALUE;			  
      return false;
    }
    doc = tp.doc();
    position = 0;
    return true;
  }

  final boolean skipTo(int target) throws IOException {
    if (!tp.skipTo(target)) {
      tp.close();				  
      doc = Integer.MAX_VALUE;			  
      return false;
    }
    doc = tp.doc();
    position = 0;
    return true;
  }


  final void firstPosition() throws IOException {
    count = tp.freq();				  
    nextPosition();
  }

  final boolean nextPosition() throws IOException {
    if (count-- > 0) {				  
      position = tp.nextPosition() - offset;
      return true;
    } else
      return false;
  }
}
"
lucene,2,org.apache.lucene.search.SortComparator,3,1,0,6,7,3,3,5,2,2.0,21,0.0,0,0.0,0.666666667,0,0,6.0,1,0.6667,0,"package org.apache.lucene.search;

import org.apache.lucene.index.IndexReader;

import java.io.IOException;


public abstract class SortComparator
implements SortComparatorSource {

  
  public ScoreDocComparator newComparator (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final Comparable[] cachedValues = FieldCache.DEFAULT.getCustom (reader, field, SortComparator.this);
    
    return new ScoreDocComparator() {

      public int compare (ScoreDoc i, ScoreDoc j) {
        return cachedValues[i.doc].compareTo (cachedValues[j.doc]);
      }

      public Comparable sortValue (ScoreDoc i) {
        return cachedValues[i.doc];
      }

      public int sortType(){
        return SortField.CUSTOM;
      }
    };
  }

  
  protected abstract Comparable getComparable (String termtext);

}"
lucene,2,org.apache.lucene.index.FieldInfos,19,1,0,18,51,145,12,6,15,0.920634921,437,0.285714286,0,0.0,0.257309942,0,0,21.63157895,7,1.4737,1,"package org.apache.lucene.index;



import java.util.*;
import java.io.IOException;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.IndexInput;


final class FieldInfos {
  
  static final byte IS_INDEXED = 0x1;
  static final byte STORE_TERMVECTOR = 0x2;
  static final byte STORE_POSITIONS_WITH_TERMVECTOR = 0x4;
  static final byte STORE_OFFSET_WITH_TERMVECTOR = 0x8;
  static final byte OMIT_NORMS = 0x10;
  
  private ArrayList byNumber = new ArrayList();
  private HashMap byName = new HashMap();

  FieldInfos() { }

  
  FieldInfos(Directory d, String name) throws IOException {
    IndexInput input = d.openInput(name);
    try {
      read(input);
    } finally {
      input.close();
    }
  }

  
  public void add(Document doc) {
    Enumeration fields = doc.fields();
    while (fields.hasMoreElements()) {
      Field field = (Field) fields.nextElement();
      add(field.name(), field.isIndexed(), field.isTermVectorStored(), field.isStorePositionWithTermVector(),
              field.isStoreOffsetWithTermVector(), field.getOmitNorms());
    }
  }
  
  
  public void addIndexed(Collection names, boolean storeTermVectors, boolean storePositionWithTermVector, 
                         boolean storeOffsetWithTermVector) {
    Iterator i = names.iterator();
    while (i.hasNext()) {
      add((String)i.next(), true, storeTermVectors, storePositionWithTermVector, storeOffsetWithTermVector);
    }
  }

  
  public void add(Collection names, boolean isIndexed) {
    Iterator i = names.iterator();
    while (i.hasNext()) {
      add((String)i.next(), isIndexed);
    }
  }

  
  public void add(String name, boolean isIndexed) {
    add(name, isIndexed, false, false, false, false);
  }

  
  public void add(String name, boolean isIndexed, boolean storeTermVector){
    add(name, isIndexed, storeTermVector, false, false, false);
  }
  
  
  public void add(String name, boolean isIndexed, boolean storeTermVector,
                  boolean storePositionWithTermVector, boolean storeOffsetWithTermVector) {

    add(name, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, false);
  }

    
  public void add(String name, boolean isIndexed, boolean storeTermVector,
                  boolean storePositionWithTermVector, boolean storeOffsetWithTermVector, boolean omitNorms) {
    FieldInfo fi = fieldInfo(name);
    if (fi == null) {
      addInternal(name, isIndexed, storeTermVector, storePositionWithTermVector, storeOffsetWithTermVector, omitNorms);
    } else {
      if (fi.isIndexed != isIndexed) {
        fi.isIndexed = true;                      
      }
      if (fi.storeTermVector != storeTermVector) {
        fi.storeTermVector = true;                
      }
      if (fi.storePositionWithTermVector != storePositionWithTermVector) {
        fi.storePositionWithTermVector = true;                
      }
      if (fi.storeOffsetWithTermVector != storeOffsetWithTermVector) {
        fi.storeOffsetWithTermVector = true;                
      }
      if (fi.omitNorms != omitNorms) {
        fi.omitNorms = false;                
      }

    }
  }


  private void addInternal(String name, boolean isIndexed,
                           boolean storeTermVector, boolean storePositionWithTermVector, 
                           boolean storeOffsetWithTermVector, boolean omitNorms) {
    FieldInfo fi =
      new FieldInfo(name, isIndexed, byNumber.size(), storeTermVector, storePositionWithTermVector,
              storeOffsetWithTermVector, omitNorms);
    byNumber.add(fi);
    byName.put(name, fi);
  }

  public int fieldNumber(String fieldName) {
    try {
      FieldInfo fi = fieldInfo(fieldName);
      if (fi != null)
        return fi.number;
    }
    catch (IndexOutOfBoundsException ioobe) {
      return -1;
    }
    return -1;
  }

  public FieldInfo fieldInfo(String fieldName) {
    return (FieldInfo) byName.get(fieldName);
  }

    
  public String fieldName(int fieldNumber) {
    try {
      return fieldInfo(fieldNumber).name;
    }
    catch (NullPointerException npe) {
      return """";
    }
  }

    
  public FieldInfo fieldInfo(int fieldNumber) {
    try {
      return (FieldInfo) byNumber.get(fieldNumber);
    }
    catch (IndexOutOfBoundsException ioobe) {
      return null;
    }
  }

  public int size() {
    return byNumber.size();
  }

  public boolean hasVectors() {
    boolean hasVectors = false;
    for (int i = 0; i < size(); i++) {
      if (fieldInfo(i).storeTermVector) {
        hasVectors = true;
        break;
      }
    }
    return hasVectors;
  }

  public void write(Directory d, String name) throws IOException {
    IndexOutput output = d.createOutput(name);
    try {
      write(output);
    } finally {
      output.close();
    }
  }

  public void write(IndexOutput output) throws IOException {
    output.writeVInt(size());
    for (int i = 0; i < size(); i++) {
      FieldInfo fi = fieldInfo(i);
      byte bits = 0x0;
      if (fi.isIndexed) bits |= IS_INDEXED;
      if (fi.storeTermVector) bits |= STORE_TERMVECTOR;
      if (fi.storePositionWithTermVector) bits |= STORE_POSITIONS_WITH_TERMVECTOR;
      if (fi.storeOffsetWithTermVector) bits |= STORE_OFFSET_WITH_TERMVECTOR;
      if (fi.omitNorms) bits |= OMIT_NORMS;
      output.writeString(fi.name);
      output.writeByte(bits);
    }
  }

  private void read(IndexInput input) throws IOException {
    int size = input.readVInt();
    for (int i = 0; i < size; i++) {
      String name = input.readString().intern();
      byte bits = input.readByte();
      boolean isIndexed = (bits & IS_INDEXED) != 0;
      boolean storeTermVector = (bits & STORE_TERMVECTOR) != 0;
      boolean storePositionsWithTermVector = (bits & STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      boolean storeOffsetWithTermVector = (bits & STORE_OFFSET_WITH_TERMVECTOR) != 0;
      boolean omitNorms = (bits & OMIT_NORMS) != 0;

      addInternal(name, isIndexed, storeTermVector, storePositionsWithTermVector, storeOffsetWithTermVector, omitNorms);
    }    
  }

}
"
lucene,2,org.apache.lucene.index.CompoundFileWriter,6,1,0,6,39,0,1,5,5,0.6,337,1.0,1,0.0,0.333333333,0,0,54.33333333,4,1.3333,1,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.IndexInput;
import java.util.LinkedList;
import java.util.HashSet;
import java.util.Iterator;
import java.io.IOException;



final class CompoundFileWriter {

    private static final class FileEntry {
        
        String file;

        
        long directoryOffset;

        
        long dataOffset;
    }


    private Directory directory;
    private String fileName;
    private HashSet ids;
    private LinkedList entries;
    private boolean merged = false;


    
    public CompoundFileWriter(Directory dir, String name) {
        if (dir == null)
            throw new NullPointerException(""directory cannot be null"");
        if (name == null)
            throw new NullPointerException(""name cannot be null"");

        directory = dir;
        fileName = name;
        ids = new HashSet();
        entries = new LinkedList();
    }

    
    public Directory getDirectory() {
        return directory;
    }

    
    public String getName() {
        return fileName;
    }

    
    public void addFile(String file) {
        if (merged)
            throw new IllegalStateException(
                ""Can't add extensions after merge has been called"");

        if (file == null)
            throw new NullPointerException(
                ""file cannot be null"");

        if (! ids.add(file))
            throw new IllegalArgumentException(
                ""File "" + file + "" already added"");

        FileEntry entry = new FileEntry();
        entry.file = file;
        entries.add(entry);
    }

    
    public void close() throws IOException {
        if (merged)
            throw new IllegalStateException(
                ""Merge already performed"");

        if (entries.isEmpty())
            throw new IllegalStateException(
                ""No entries to merge have been defined"");

        merged = true;

        
        IndexOutput os = null;
        try {
            os = directory.createOutput(fileName);

            
            os.writeVInt(entries.size());

            
            
            
            Iterator it = entries.iterator();
            while(it.hasNext()) {
                FileEntry fe = (FileEntry) it.next();
                fe.directoryOffset = os.getFilePointer();
                os.writeLong(0);    
                os.writeString(fe.file);
            }

            
            
            byte buffer[] = new byte[1024];
            it = entries.iterator();
            while(it.hasNext()) {
                FileEntry fe = (FileEntry) it.next();
                fe.dataOffset = os.getFilePointer();
                copyFile(fe, os, buffer);
            }

            
            it = entries.iterator();
            while(it.hasNext()) {
                FileEntry fe = (FileEntry) it.next();
                os.seek(fe.directoryOffset);
                os.writeLong(fe.dataOffset);
            }

            
            
            
            
            IndexOutput tmp = os;
            os = null;
            tmp.close();

        } finally {
            if (os != null) try { os.close(); } catch (IOException e) { }
        }
    }

    
    private void copyFile(FileEntry source, IndexOutput os, byte buffer[])
    throws IOException
    {
        IndexInput is = null;
        try {
            long startPtr = os.getFilePointer();

            is = directory.openInput(source.file);
            long length = is.length();
            long remainder = length;
            int chunk = buffer.length;

            while(remainder > 0) {
                int len = (int) Math.min(chunk, remainder);
                is.readBytes(buffer, 0, len);
                os.writeBytes(buffer, len);
                remainder -= len;
            }

            
            if (remainder != 0)
                throw new IOException(
                    ""Non-zero remainder length after copying: "" + remainder
                    + "" (id: "" + source.file + "", length: "" + length
                    + "", buffer size: "" + chunk + "")"");

            
            long endPtr = os.getFilePointer();
            long diff = endPtr - startPtr;
            if (diff != length)
                throw new IOException(
                    ""Difference in the output file offsets "" + diff
                    + "" does not match the original file length "" + length);

        } finally {
            if (is != null) is.close();
        }
    }
}
"
lucene,2,org.apache.lucene.index.ParallelReader,27,2,0,13,80,193,3,13,21,0.814102564,479,1.0,0,0.679012346,0.181481481,1,6,16.51851852,2,1.037,6,"package org.apache.lucene.index;



import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Enumeration;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.SortedMap;
import java.util.TreeMap;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;


public class ParallelReader extends IndexReader {
  private List readers = new ArrayList();
  private SortedMap fieldToReader = new TreeMap();
  private List storedFieldReaders = new ArrayList(); 

  private int maxDoc;
  private int numDocs;
  private boolean hasDeletions;

 
  public ParallelReader() throws IOException { super(null); }
    
 
  public void add(IndexReader reader) throws IOException {
    add(reader, false);
  }

 
  public void add(IndexReader reader, boolean ignoreStoredFields)
    throws IOException {

    if (readers.size() == 0) {
      this.maxDoc = reader.maxDoc();
      this.numDocs = reader.numDocs();
      this.hasDeletions = reader.hasDeletions();
    }

    if (reader.maxDoc() != maxDoc)                
      throw new IllegalArgumentException
        (""All readers must have same maxDoc: ""+maxDoc+""!=""+reader.maxDoc());
    if (reader.numDocs() != numDocs)
      throw new IllegalArgumentException
        (""All readers must have same numDocs: ""+numDocs+""!=""+reader.numDocs());
    
    Iterator i = reader.getFieldNames(IndexReader.FieldOption.ALL).iterator();
    while (i.hasNext()) {                         
      String field = (String)i.next();
      if (fieldToReader.get(field) == null)
        fieldToReader.put(field, reader);
    }

    if (!ignoreStoredFields)
      storedFieldReaders.add(reader);             
    readers.add(reader);
  }

  public int numDocs() { return numDocs; }

  public int maxDoc() { return maxDoc; }

  public boolean hasDeletions() { return hasDeletions; }

  
  public boolean isDeleted(int n) {
    if (readers.size() > 0)
      return ((IndexReader)readers.get(0)).isDeleted(n);
    return false;
  }

  
  protected void doDelete(int n) throws IOException {
    for (int i = 0; i < readers.size(); i++) {
      ((IndexReader)readers.get(i)).deleteDocument(n);
    }
    hasDeletions = true;
  }

  
  protected void doUndeleteAll() throws IOException {
    for (int i = 0; i < readers.size(); i++) {
      ((IndexReader)readers.get(i)).undeleteAll();
    }
    hasDeletions = false;
  }

  
  public Document document(int n) throws IOException {
    Document result = new Document();
    for (int i = 0; i < storedFieldReaders.size(); i++) {
      IndexReader reader = (IndexReader)storedFieldReaders.get(i);
      Enumeration fields = reader.document(n).fields();
      while (fields.hasMoreElements()) {
        result.add((Field)fields.nextElement());
      }
    }
    return result;
  }

  
  public TermFreqVector[] getTermFreqVectors(int n) throws IOException {
    ArrayList results = new ArrayList();
    Iterator i = fieldToReader.entrySet().iterator();
    while (i.hasNext()) {
      Map.Entry e = (Map.Entry)i.next();
      String field = (String)e.getKey();
      IndexReader reader = (IndexReader)e.getValue();
      TermFreqVector vector = reader.getTermFreqVector(n, field);
      if (vector != null)
        results.add(vector);
    }
    return (TermFreqVector[])
      results.toArray(new TermFreqVector[results.size()]);
  }

  public TermFreqVector getTermFreqVector(int n, String field)
    throws IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    return reader==null ? null : reader.getTermFreqVector(n, field);
  }

  public boolean hasNorms(String field) throws IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    return reader==null ? false : reader.hasNorms(field);
  }

  public byte[] norms(String field) throws IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    return reader==null ? null : reader.norms(field);
  }

  public void norms(String field, byte[] result, int offset)
    throws IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    if (reader!=null)
      reader.norms(field, result, offset);
  }

  protected void doSetNorm(int n, String field, byte value)
    throws IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(field));
    if (reader!=null)
      reader.doSetNorm(n, field, value);
  }

  public TermEnum terms() throws IOException {
    return new ParallelTermEnum();
  }

  public TermEnum terms(Term term) throws IOException {
    return new ParallelTermEnum(term);
  }

  public int docFreq(Term term) throws IOException {
    IndexReader reader = ((IndexReader)fieldToReader.get(term.field()));
    return reader==null ? 0 : reader.docFreq(term);
  }

  public TermDocs termDocs(Term term) throws IOException {
    return new ParallelTermDocs(term);
  }

  public TermDocs termDocs() throws IOException {
    return new ParallelTermDocs();
  }

  public TermPositions termPositions(Term term) throws IOException {
    return new ParallelTermPositions(term);
  }

  public TermPositions termPositions() throws IOException {
    return new ParallelTermPositions();
  }

  protected void doCommit() throws IOException {
    for (int i = 0; i < readers.size(); i++)
      ((IndexReader)readers.get(i)).commit();
  }

  protected synchronized void doClose() throws IOException {
    for (int i = 0; i < readers.size(); i++)
      ((IndexReader)readers.get(i)).close();
  }


  public Collection getFieldNames (IndexReader.FieldOption fieldNames) {
    Set fieldSet = new HashSet();
    for (int i = 0; i < readers.size(); i++) {
      IndexReader reader = ((IndexReader)readers.get(i));
      Collection names = reader.getFieldNames(fieldNames);
      fieldSet.addAll(names);
    }
    return fieldSet;
  }

  private class ParallelTermEnum extends TermEnum {
    private String field;
    private TermEnum termEnum;

    public ParallelTermEnum() throws IOException {
      field = (String)fieldToReader.firstKey();
      if (field != null)
        termEnum = ((IndexReader)fieldToReader.get(field)).terms();
    }

    public ParallelTermEnum(Term term) throws IOException {
      field = term.field();
      IndexReader reader = ((IndexReader)fieldToReader.get(field));
      if (reader!=null)
        termEnum = reader.terms(term);
    }

    public boolean next() throws IOException {
      if (termEnum == null)
        return false;

      boolean next = termEnum.next();

      
      if (next && termEnum.term().field() == field)
        return true;                              

      termEnum.close();                           

      
      field = (String)fieldToReader.tailMap(field).firstKey();
      if (field != null) {
        termEnum = ((IndexReader)fieldToReader.get(field)).terms();
        return true;
      }

      return false;                               

    }

    public Term term() {
      if (termEnum==null)
        return null;

      return termEnum.term();
    }

    public int docFreq() {
      if (termEnum==null)
        return 0;

      return termEnum.docFreq();
    }

    public void close() throws IOException {
      if (termEnum!=null)
        termEnum.close();
    }

  }

  
  private class ParallelTermDocs implements TermDocs {
    protected TermDocs termDocs;

    public ParallelTermDocs() {}
    public ParallelTermDocs(Term term) throws IOException { seek(term); }

    public int doc() { return termDocs.doc(); }
    public int freq() { return termDocs.freq(); }

    public void seek(Term term) throws IOException {
      IndexReader reader = ((IndexReader)fieldToReader.get(term.field()));
      termDocs = reader!=null ? reader.termDocs(term) : null;
    }

    public void seek(TermEnum termEnum) throws IOException {
      seek(termEnum.term());
    }

    public boolean next() throws IOException {
      if (termDocs==null)
        return false;

      return termDocs.next();
    }

    public int read(final int[] docs, final int[] freqs) throws IOException {
      if (termDocs==null)
        return 0;

      return termDocs.read(docs, freqs);
    }

    public boolean skipTo(int target) throws IOException {
      if (termDocs==null)
        return false;

      return termDocs.skipTo(target);
    }

    public void close() throws IOException {
      if (termDocs!=null)
        termDocs.close();
    }

  }

  private class ParallelTermPositions
    extends ParallelTermDocs implements TermPositions {

    public ParallelTermPositions() {}
    public ParallelTermPositions(Term term) throws IOException { seek(term); }

    public void seek(Term term) throws IOException {
      IndexReader reader = ((IndexReader)fieldToReader.get(term.field()));
      termDocs = reader!=null ? reader.termPositions(term) : null;
    }

    public int nextPosition() throws IOException {
      
      return ((TermPositions)termDocs).nextPosition();
    }

  }

}

"
lucene,2,org.apache.lucene.search.TermScorer,9,2,0,10,32,0,1,9,7,0.545454545,409,1.0,2,0.5,0.285714286,1,3,43.22222222,2,1.0,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.TermDocs;


final class TermScorer extends Scorer {
  private Weight weight;
  private TermDocs termDocs;
  private byte[] norms;
  private float weightValue;
  private int doc;

  private final int[] docs = new int[32];         
  private final int[] freqs = new int[32];        
  private int pointer;
  private int pointerMax;

  private static final int SCORE_CACHE_SIZE = 32;
  private float[] scoreCache = new float[SCORE_CACHE_SIZE];

  
  TermScorer(Weight weight, TermDocs td, Similarity similarity,
             byte[] norms) {
    super(similarity);
    this.weight = weight;
    this.termDocs = td;
    this.norms = norms;
    this.weightValue = weight.getValue();

    for (int i = 0; i < SCORE_CACHE_SIZE; i++)
      scoreCache[i] = getSimilarity().tf(i) * weightValue;
  }

  public void score(HitCollector hc) throws IOException {
    next();
    score(hc, Integer.MAX_VALUE);
  }

  protected boolean score(HitCollector c, int end) throws IOException {
    Similarity similarity = getSimilarity();      
    float[] normDecoder = Similarity.getNormDecoder();
    while (doc < end) {                           
      int f = freqs[pointer];
      float score =                               
        f < SCORE_CACHE_SIZE                      
         ? scoreCache[f]                          
         : similarity.tf(f)*weightValue;          

      score *= normDecoder[norms[doc] & 0xFF];    

      c.collect(doc, score);                      

      if (++pointer >= pointerMax) {
        pointerMax = termDocs.read(docs, freqs);  
        if (pointerMax != 0) {
          pointer = 0;
        } else {
          termDocs.close();                       
          doc = Integer.MAX_VALUE;                
          return false;
        }
      } 
      doc = docs[pointer];
    }
    return true;
  }

  
  public int doc() { return doc; }

  
  public boolean next() throws IOException {
    pointer++;
    if (pointer >= pointerMax) {
      pointerMax = termDocs.read(docs, freqs);    
      if (pointerMax != 0) {
        pointer = 0;
      } else {
        termDocs.close();                         
        doc = Integer.MAX_VALUE;                  
        return false;
      }
    } 
    doc = docs[pointer];
    return true;
  }

  public float score() {
    int f = freqs[pointer];
    float raw =                                   
      f < SCORE_CACHE_SIZE                        
      ? scoreCache[f]                             
      : getSimilarity().tf(f)*weightValue;        

    return raw * Similarity.decodeNorm(norms[doc]); 
  }

  
  public boolean skipTo(int target) throws IOException {
    
    for (pointer++; pointer < pointerMax; pointer++) {
      if (docs[pointer] >= target) {
        doc = docs[pointer];
        return true;
      }
    }

    
    boolean result = termDocs.skipTo(target);
    if (result) {
      pointerMax = 1;
      pointer = 0;
      docs[pointer] = doc = termDocs.doc();
      freqs[pointer] = termDocs.freq();
    } else {
      doc = Integer.MAX_VALUE;
    }
    return result;
  }

  
  public Explanation explain(int doc) throws IOException {
    TermQuery query = (TermQuery)weight.getQuery();
    Explanation tfExplanation = new Explanation();
    int tf = 0;
    while (pointer < pointerMax) {
      if (docs[pointer] == doc)
        tf = freqs[pointer];
      pointer++;
    }
    if (tf == 0) {
      while (termDocs.next()) {
        if (termDocs.doc() == doc) {
          tf = termDocs.freq();
        }
      }
    }
    termDocs.close();
    tfExplanation.setValue(getSimilarity().tf(tf));
    tfExplanation.setDescription(""tf(termFreq(""+query.getTerm()+"")=""+tf+"")"");
    
    return tfExplanation;
  }

  
  public String toString() { return ""scorer("" + weight + "")""; }
}
"
lucene,2,org.apache.lucene.search.FilteredQuery,9,2,0,8,25,0,1,8,8,0.3125,133,0.0,2,0.6,0.222222222,2,4,13.55555556,4,1.2222,4,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;
import java.util.BitSet;
import java.util.Set;



public class FilteredQuery
extends Query {

  Query query;
  Filter filter;

  
  public FilteredQuery (Query query, Filter filter) {
    this.query = query;
    this.filter = filter;
  }



  
  protected Weight createWeight (final Searcher searcher) throws IOException {
    final Weight weight = query.createWeight (searcher);
    final Similarity similarity = query.getSimilarity(searcher);
    return new Weight() {

      
      public float getValue() { return weight.getValue(); }
      public float sumOfSquaredWeights() throws IOException { return weight.sumOfSquaredWeights(); }
      public void normalize (float v) { weight.normalize(v); }
      public Explanation explain (IndexReader ir, int i) throws IOException { return weight.explain (ir, i); }

      
      public Query getQuery() { return FilteredQuery.this; }

      
       public Scorer scorer (IndexReader indexReader) throws IOException {
        final Scorer scorer = weight.scorer (indexReader);
        final BitSet bitset = filter.bits (indexReader);
        return new Scorer (similarity) {

          public boolean next() throws IOException {
            do {
              if (! scorer.next()) {
                return false;
              }
            } while (! bitset.get(scorer.doc()));
            
            return true;
          }
          public int doc() { return scorer.doc(); }

          public boolean skipTo(int i) throws IOException {
            if (! scorer.skipTo(i)) {
              return false;
            }
            while (! bitset.get(scorer.doc())) {
              int nextFiltered = bitset.nextSetBit(scorer.doc() + 1);
              if (nextFiltered == -1) {
                return false;
              } else if (! scorer.skipTo(nextFiltered)) {
                return false;
              }
            }
            return true;
           }

          public float score() throws IOException { return scorer.score(); }

          
          public Explanation explain (int i) throws IOException {
            Explanation exp = scorer.explain (i);
            if (bitset.get(i))
              exp.setDescription (""allowed by filter: ""+exp.getDescription());
            else
              exp.setDescription (""removed by filter: ""+exp.getDescription());
            return exp;
          }
        };
      }
    };
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    Query rewritten = query.rewrite(reader);
    if (rewritten != query) {
      FilteredQuery clone = (FilteredQuery)this.clone();
      clone.query = rewritten;
      return clone;
    } else {
      return this;
    }
  }

  public Query getQuery() {
    return query;
  }

  public Filter getFilter() {
    return filter;
  }

  
  public void extractTerms(Set terms) {
      getQuery().extractTerms(terms);
  }

  
  public String toString (String s) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""filtered("");
    buffer.append(query.toString(s));
    buffer.append("")->"");
    buffer.append(filter);
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (o instanceof FilteredQuery) {
      FilteredQuery fq = (FilteredQuery) o;
      return (query.equals(fq.query) && filter.equals(fq.filter));
    }
    return false;
  }

  
  public int hashCode() {
    return query.hashCode() ^ filter.hashCode();
  }
}
"
lucene,2,org.apache.lucene.util.PriorityQueue,12,1,10,13,13,0,13,0,8,0.454545455,275,1.0,0,0.0,0.444444444,0,0,21.66666667,7,2.0833,0,"package org.apache.lucene.util;




public abstract class PriorityQueue {
  private Object[] heap;
  private int size;
  private int maxSize;

  
  protected abstract boolean lessThan(Object a, Object b);

  
  protected final void initialize(int maxSize) {
    size = 0;
    int heapSize = maxSize + 1;
    heap = new Object[heapSize];
    this.maxSize = maxSize;
  }

  
  public final void put(Object element) {
    size++;
    heap[size] = element;
    upHeap();
  }

  
  public boolean insert(Object element){
    if(size < maxSize){
      put(element);
      return true;
    }
    else if(size > 0 && !lessThan(element, top())){
      heap[1] = element;
      adjustTop();
      return true;
    }
    else
      return false;
   }

  
  public final Object top() {
    if (size > 0)
      return heap[1];
    else
      return null;
  }

  
  public final Object pop() {
    if (size > 0) {
      Object result = heap[1];			  
      heap[1] = heap[size];			  
      heap[size] = null;			  
      size--;
      downHeap();				  
      return result;
    } else
      return null;
  }

  
  public final void adjustTop() {
    downHeap();
  }


  
  public final int size() {
    return size;
  }

  
  public final void clear() {
    for (int i = 0; i <= size; i++)
      heap[i] = null;
    size = 0;
  }

  private final void upHeap() {
    int i = size;
    Object node = heap[i];			  
    int j = i >>> 1;
    while (j > 0 && lessThan(node, heap[j])) {
      heap[i] = heap[j];			  
      i = j;
      j = j >>> 1;
    }
    heap[i] = node;				  
  }

  private final void downHeap() {
    int i = 1;
    Object node = heap[i];			  
    int j = i << 1;				  
    int k = j + 1;
    if (k <= size && lessThan(heap[k], heap[j])) {
      j = k;
    }
    while (j <= size && lessThan(heap[j], node)) {
      heap[i] = heap[j];			  
      i = j;
      j = i << 1;
      k = j + 1;
      if (k <= size && lessThan(heap[k], heap[j])) {
	j = k;
      }
    }
    heap[i] = node;				  
  }
}
"
lucene,2,org.apache.lucene.search.Similarity,16,1,2,42,25,108,40,4,15,0.866666667,91,1.0,1,0.0,0.185185185,0,0,4.5625,1,0.875,3,"package org.apache.lucene.search;



import java.io.IOException;
import java.io.Serializable;

import java.util.Collection;
import java.util.Iterator;

import org.apache.lucene.index.Term;

import org.apache.lucene.index.IndexReader;       
import org.apache.lucene.index.IndexWriter;       
import org.apache.lucene.document.Field;          
import org.apache.lucene.util.SmallFloat;


public abstract class Similarity implements Serializable {
  
  private static Similarity defaultImpl = new DefaultSimilarity();

  
  public static void setDefault(Similarity similarity) {
    Similarity.defaultImpl = similarity;
  }

  
  public static Similarity getDefault() {
    return Similarity.defaultImpl;
  }

  
  private static final float[] NORM_TABLE = new float[256];

  static {
    for (int i = 0; i < 256; i++)
      NORM_TABLE[i] = SmallFloat.byte315ToFloat((byte)i);
  }

  
  public static float decodeNorm(byte b) {
    return NORM_TABLE[b & 0xFF];  
  }

  
  public static float[] getNormDecoder() {
    return NORM_TABLE;
  }

  
  public abstract float lengthNorm(String fieldName, int numTokens);

  
  public abstract float queryNorm(float sumOfSquaredWeights);

  
  public static byte encodeNorm(float f) {
    return SmallFloat.floatToByte315(f);
  }


  
  public float tf(int freq) {
    return tf((float)freq);
  }

  
  public abstract float sloppyFreq(int distance);

  
  public abstract float tf(float freq);

  
  public float idf(Term term, Searcher searcher) throws IOException {
    return idf(searcher.docFreq(term), searcher.maxDoc());
  }

  
  public float idf(Collection terms, Searcher searcher) throws IOException {
    float idf = 0.0f;
    Iterator i = terms.iterator();
    while (i.hasNext()) {
      idf += idf((Term)i.next(), searcher);
    }
    return idf;
  }

  
  public abstract float idf(int docFreq, int numDocs);

  
  public abstract float coord(int overlap, int maxOverlap);
}
"
lucene,2,org.apache.lucene.search.FuzzyTermEnum,14,3,0,5,29,53,1,4,6,0.692307692,514,1.0,1,0.541666667,0.333333333,1,4,34.92857143,14,2.2857,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;

import java.io.IOException;


public final class FuzzyTermEnum extends FilteredTermEnum {

  
  private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19;

  
  private int[][] d;

  private float similarity;
  private boolean endEnum = false;

  private Term searchTerm = null;
  private final String field;
  private final String text;
  private final String prefix;

  private final float minimumSimilarity;
  private final float scale_factor;
  private final int[] maxDistances = new int[TYPICAL_LONGEST_WORD_IN_INDEX];

  
  public FuzzyTermEnum(IndexReader reader, Term term) throws IOException {
    this(reader, term, FuzzyQuery.defaultMinSimilarity, FuzzyQuery.defaultPrefixLength);
  }
    
  
  public FuzzyTermEnum(IndexReader reader, Term term, float minSimilarity) throws IOException {
    this(reader, term, minSimilarity, FuzzyQuery.defaultPrefixLength);
  }
    
  
  public FuzzyTermEnum(IndexReader reader, Term term, final float minSimilarity, final int prefixLength) throws IOException {
    super();
    
    if (minSimilarity >= 1.0f)
      throw new IllegalArgumentException(""minimumSimilarity cannot be greater than or equal to 1"");
    else if (minSimilarity < 0.0f)
      throw new IllegalArgumentException(""minimumSimilarity cannot be less than 0"");
    if(prefixLength < 0)
      throw new IllegalArgumentException(""prefixLength cannot be less than 0"");

    this.minimumSimilarity = minSimilarity;
    this.scale_factor = 1.0f / (1.0f - minimumSimilarity);
    this.searchTerm = term;
    this.field = searchTerm.field();

    
    
    final int fullSearchTermLength = searchTerm.text().length();
    final int realPrefixLength = prefixLength > fullSearchTermLength ? fullSearchTermLength : prefixLength;

    this.text = searchTerm.text().substring(realPrefixLength);
    this.prefix = searchTerm.text().substring(0, realPrefixLength);

    initializeMaxDistances();
    this.d = initDistanceArray();

    setEnum(reader.terms(new Term(searchTerm.field(), prefix)));
  }

  
  protected final boolean termCompare(Term term) {
    if (field == term.field() && term.text().startsWith(prefix)) {
        final String target = term.text().substring(prefix.length());
        this.similarity = similarity(target);
        return (similarity > minimumSimilarity);
    }
    endEnum = true;
    return false;
  }
  
  public final float difference() {
    return (float)((similarity - minimumSimilarity) * scale_factor);
  }
  
  public final boolean endEnum() {
    return endEnum;
  }
  
  
  
  
  private static final int min(int a, int b, int c) {
    final int t = (a < b) ? a : b;
    return (t < c) ? t : c;
  }

  private final int[][] initDistanceArray(){
    return new int[this.text.length() + 1][TYPICAL_LONGEST_WORD_IN_INDEX];
  }

  
  private synchronized final float similarity(final String target) {
    final int m = target.length();
    final int n = text.length();
    if (n == 0)  {
      
      
      return prefix.length() == 0 ? 0.0f : 1.0f - ((float) m / prefix.length());
    }
    if (m == 0) {
      return prefix.length() == 0 ? 0.0f : 1.0f - ((float) n / prefix.length());
    }

    final int maxDistance = getMaxDistance(m);

    if (maxDistance < Math.abs(m-n)) {
      
      
      
      
      
      
      
      return 0.0f;
    }

    
    if (d[0].length <= m) {
      growDistanceArray(m);
    }

    
    for (int i = 0; i <= n; i++) d[i][0] = i;
    for (int j = 0; j <= m; j++) d[0][j] = j;
    
    
    for (int i = 1; i <= n; i++) {
      int bestPossibleEditDistance = m;
      final char s_i = text.charAt(i - 1);
      for (int j = 1; j <= m; j++) {
        if (s_i != target.charAt(j-1)) {
            d[i][j] = min(d[i-1][j], d[i][j-1], d[i-1][j-1])+1;
        }
        else {
          d[i][j] = min(d[i-1][j]+1, d[i][j-1]+1, d[i-1][j-1]);
        }
        bestPossibleEditDistance = Math.min(bestPossibleEditDistance, d[i][j]);
      }

      
      
      

      if (i > maxDistance && bestPossibleEditDistance > maxDistance) {  
        
        
        return 0.0f;
      }
    }

    
    
    
    
    
    return 1.0f - ((float)d[n][m] / (float) (prefix.length() + Math.min(n, m)));
  }

  
  private void growDistanceArray(int m) {
    for (int i = 0; i < d.length; i++) {
      d[i] = new int[m+1];
    }
  }

  
  private final int getMaxDistance(int m) {
    return (m < maxDistances.length) ? maxDistances[m] : calculateMaxDistance(m);
  }

  private void initializeMaxDistances() {
    for (int i = 0; i < maxDistances.length; i++) {
      maxDistances[i] = calculateMaxDistance(i);
    }
  }
  
  private int calculateMaxDistance(int m) {
    return (int) ((1-minimumSimilarity) * (Math.min(text.length(), m) + prefix.length()));
  }

  public void close() throws IOException {
    super.close();  
  }
  
}
"
lucene,2,org.apache.lucene.store.Lock,6,1,2,16,14,13,16,0,5,0.8,58,0.0,0,0.0,0.6,0,0,8.5,1,0.6667,2,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class Lock {
  public static long LOCK_POLL_INTERVAL = 1000;

  
  public abstract boolean obtain() throws IOException;

  
  public boolean obtain(long lockWaitTimeout) throws IOException {
    boolean locked = obtain();
    int maxSleepCount = (int)(lockWaitTimeout / LOCK_POLL_INTERVAL);
    int sleepCount = 0;
    while (!locked) {
      if (sleepCount++ == maxSleepCount) {
        throw new IOException(""Lock obtain timed out: "" + this.toString());
      }
      try {
        Thread.sleep(LOCK_POLL_INTERVAL);
      } catch (InterruptedException e) {
        throw new IOException(e.toString());
      }
      locked = obtain();
    }
    return locked;
  }

  
  public abstract void release();

  
  public abstract boolean isLocked();


  
  public abstract static class With {
    private Lock lock;
    private long lockWaitTimeout;


    
    public With(Lock lock, long lockWaitTimeout) {
      this.lock = lock;
      this.lockWaitTimeout = lockWaitTimeout;
    }

    
    protected abstract Object doBody() throws IOException;

    
    public Object run() throws IOException {
      boolean locked = false;
      try {
         locked = lock.obtain(lockWaitTimeout);
         return doBody();
      } finally {
        if (locked)
	      lock.release();
      }
    }
  }

}
"
lucene,2,org.apache.lucene.search.spans.SpanFirstQuery,13,3,0,6,30,0,1,6,11,0.416666667,176,1.0,1,0.571428571,0.192307692,2,2,12.38461538,6,1.3077,0,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Query;
import org.apache.lucene.util.ToStringUtils;


public class SpanFirstQuery extends SpanQuery {
  private SpanQuery match;
  private int end;

  
  public SpanFirstQuery(SpanQuery match, int end) {
    this.match = match;
    this.end = end;
  }

  
  public SpanQuery getMatch() { return match; }

  
  public int getEnd() { return end; }

  public String getField() { return match.getField(); }

  
  public Collection getTerms() { return match.getTerms(); }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""spanFirst("");
    buffer.append(match.toString(field));
    buffer.append("", "");
    buffer.append(end);
    buffer.append("")"");
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }
  
  public void extractTerms(Set terms) {
	    match.extractTerms(terms);
  }  

  public Spans getSpans(final IndexReader reader) throws IOException {
    return new Spans() {
        private Spans spans = match.getSpans(reader);

        public boolean next() throws IOException {
          while (spans.next()) {                  
            if (end() <= end)
              return true;
          }
          return false;
        }

        public boolean skipTo(int target) throws IOException {
          if (!spans.skipTo(target))
            return false;

          if (spans.end() <= end)                 
            return true;

          return next();                          
        }

        public int doc() { return spans.doc(); }
        public int start() { return spans.start(); }
        public int end() { return spans.end(); }

        public String toString() {
          return ""spans("" + SpanFirstQuery.this.toString() + "")"";
        }

      };
  }

  public Query rewrite(IndexReader reader) throws IOException {
    SpanFirstQuery clone = null;

    SpanQuery rewritten = (SpanQuery) match.rewrite(reader);
    if (rewritten != match) {
      clone = (SpanFirstQuery) this.clone();
      clone.match = rewritten;
    }

    if (clone != null) {
      return clone;                        
    } else {
      return this;                         
    }
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof SpanFirstQuery)) return false;

    SpanFirstQuery other = (SpanFirstQuery)o;
    return this.end == other.end
         && this.match.equals(other.match)
         && this.getBoost() == other.getBoost();
  }

  public int hashCode() {
    int h = match.hashCode();
    h ^= (h << 8) | (h >>> 25);  
    h ^= Float.floatToRawIntBits(getBoost()) ^ end;
    return h;
  }


}
"
lucene,2,org.apache.lucene.search.TopFieldDocCollector,3,3,0,11,13,1,1,10,3,2.0,70,0.0,0,0.666666667,0.533333333,1,3,22.33333333,2,1.3333,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;


public class TopFieldDocCollector extends TopDocCollector {

  
  public TopFieldDocCollector(IndexReader reader, Sort sort, int numHits)
    throws IOException {
    super(numHits, new FieldSortedHitQueue(reader, sort.fields, numHits));
  }

  
  public void collect(int doc, float score) {
    if (score > 0.0f) {
      totalHits++;
      hq.insert(new FieldDoc(doc, score));
    }
  }

  
  public TopDocs topDocs() {
    FieldSortedHitQueue fshq = (FieldSortedHitQueue)hq;
    ScoreDoc[] scoreDocs = new ScoreDoc[fshq.size()];
    for (int i = fshq.size()-1; i >= 0; i--)      
      scoreDocs[i] = fshq.fillFields ((FieldDoc) fshq.pop());

    return new TopFieldDocs(totalHits, scoreDocs,
                            fshq.getFields(), fshq.getMaxScore());
  }
}
"
lucene,2,org.apache.lucene.index.IndexFileNameFilter,2,1,0,2,9,1,1,1,2,2.0,48,0.0,0,0.0,0.666666667,0,0,23.0,6,3.0,0,"package org.apache.lucene.index;



import java.io.File;
import java.io.FilenameFilter;


public class IndexFileNameFilter implements FilenameFilter {

  
  public boolean accept(File dir, String name) {
    for (int i = 0; i < IndexFileNames.INDEX_EXTENSIONS.length; i++) {
      if (name.endsWith("".""+IndexFileNames.INDEX_EXTENSIONS[i]))
        return true;
    }
    if (name.equals(IndexFileNames.DELETABLE)) return true;
    else if (name.equals(IndexFileNames.SEGMENTS)) return true;
    else if (name.matches("".+\\.f\\d+"")) return true;
    return false;
  }

}
"
lucene,2,org.apache.lucene.analysis.LowerCaseTokenizer,2,5,0,3,4,1,2,1,1,2.0,9,0.0,0,0.875,0.666666667,1,1,3.5,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;


public final class LowerCaseTokenizer extends LetterTokenizer {
  
  public LowerCaseTokenizer(Reader in) {
    super(in);
  }

  
  protected char normalize(char c) {
    return Character.toLowerCase(c);
  }
}
"
lucene,2,org.apache.lucene.search.Hit,8,1,0,3,19,2,1,2,6,0.178571429,116,1.0,2,0.0,0.34375,0,0,13.0,2,1.0,1,"

package org.apache.lucene.search;

import java.io.IOException;

import org.apache.lucene.document.Document;


public class Hit implements java.io.Serializable {

  private Document doc = null;

  private boolean resolved = false;

  private Hits hits = null;
  private int hitNumber;

  
  Hit(Hits hits, int hitNumber) {
    this.hits = hits;
    this.hitNumber = hitNumber;
  }

  
  public Document getDocument() throws IOException {
    if (!resolved) fetchTheHit();
    return doc;
  }

  
  public float getScore() throws IOException {
    return hits.score(hitNumber);
  }

  
  public int getId() throws IOException {
    return hits.id(hitNumber);
  }

  private void fetchTheHit() throws IOException {
    doc = hits.doc(hitNumber);
    resolved = true;
  }

  

  
  public float getBoost() throws IOException {
    return getDocument().getBoost();
  }

  
  public String get(String name) throws IOException {
    return getDocument().get(name);
  }

  
  public String toString() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""Hit<"");
    buffer.append(hits.toString());
    buffer.append("" ["");
    buffer.append(hitNumber);
    buffer.append(""] "");
    if (resolved) {
        buffer.append(""resolved"");
    } else {
        buffer.append(""unresolved"");
    }
    buffer.append("">"");
    return buffer.toString();
  }


}
"
lucene,2,org.apache.lucene.search.DisjunctionMaxQuery,14,2,0,6,38,0,1,6,11,0.384615385,318,1.0,0,0.5,0.171428571,2,5,21.57142857,6,1.5714,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Collection;
import java.util.Set;


public class DisjunctionMaxQuery extends Query {

  
  private ArrayList disjuncts = new ArrayList();

  
  private float tieBreakerMultiplier = 0.0f;

  
  public DisjunctionMaxQuery(float tieBreakerMultiplier) {
    this.tieBreakerMultiplier = tieBreakerMultiplier;
  }

  
  public DisjunctionMaxQuery(Collection disjuncts, float tieBreakerMultiplier) {
    this.tieBreakerMultiplier = tieBreakerMultiplier;
    add(disjuncts);
  }

  
  public void add(Query query) {
    disjuncts.add(query);
  }

  
  public void add(Collection disjuncts) {
    this.disjuncts.addAll(disjuncts);
  }

  
  public Iterator iterator() {
    return disjuncts.iterator();
  }

  
  private class DisjunctionMaxWeight implements Weight {

    private Searcher searcher;       
    private ArrayList weights = new ArrayList();  

    
    public DisjunctionMaxWeight(Searcher searcher) throws IOException {
      this.searcher = searcher;
      for (int i = 0; i < disjuncts.size(); i++)
        weights.add(((Query) disjuncts.get(i)).createWeight(searcher));
    }

    
    public Query getQuery() { return DisjunctionMaxQuery.this; }

    
    public float getValue() { return getBoost(); }

    
    public float sumOfSquaredWeights() throws IOException {
      float max = 0.0f, sum = 0.0f;
      for (int i = 0; i < weights.size(); i++) {
        float sub = ((Weight) weights.get(i)).sumOfSquaredWeights();
        sum += sub;
        max = Math.max(max, sub);
      }
      return (((sum - max) * tieBreakerMultiplier * tieBreakerMultiplier) + max) * getBoost() * getBoost();
    }

    
    public void normalize(float norm) {
      norm *= getBoost();  
      for (int i = 0 ; i < weights.size(); i++)
        ((Weight) weights.get(i)).normalize(norm);
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      DisjunctionMaxScorer result = new DisjunctionMaxScorer(tieBreakerMultiplier, getSimilarity(searcher));
      for (int i = 0 ; i < weights.size(); i++) {
        Weight w = (Weight) weights.get(i);
        Scorer subScorer = w.scorer(reader);
        if (subScorer == null) return null;
        result.add(subScorer);
      }
      return result;
    }

    
    public Explanation explain(IndexReader reader, int doc) throws IOException {
      if ( disjuncts.size() == 1) return ((Weight) weights.get(0)).explain(reader,doc);
      Explanation result = new Explanation();
      float max = 0.0f, sum = 0.0f;
      result.setDescription(tieBreakerMultiplier == 0.0f ? ""max of:"" : ""max plus "" + tieBreakerMultiplier + "" times others of:"");
      for (int i = 0 ; i < weights.size(); i++) {
        Explanation e = ((Weight) weights.get(i)).explain(reader, doc);
        if (e.getValue() > 0) {
          result.addDetail(e);
          sum += e.getValue();
          max = Math.max(max, e.getValue());
        }
      }
      result.setValue(max + (sum - max)*tieBreakerMultiplier);
      return result;
    }

  }  

  
  protected Weight createWeight(Searcher searcher) throws IOException {
    return new DisjunctionMaxWeight(searcher);
  }

  
  public Query rewrite(IndexReader reader) throws IOException {
    if (disjuncts.size() == 1) {
      Query singleton = (Query) disjuncts.get(0);
      Query result = singleton.rewrite(reader);
      if (getBoost() != 1.0f) {
        if (result == singleton) result = (Query)result.clone();
        result.setBoost(getBoost() * result.getBoost());
      }
      return result;
    }
    DisjunctionMaxQuery clone = null;
    for (int i = 0 ; i < disjuncts.size(); i++) {
      Query clause = (Query) disjuncts.get(i);
      Query rewrite = clause.rewrite(reader);
      if (rewrite != clause) {
        if (clone == null) clone = (DisjunctionMaxQuery)this.clone();
        clone.disjuncts.set(i, rewrite);
      }
    }
    if (clone != null) return clone;
    else return this;
  }

  
  public Object clone() {
    DisjunctionMaxQuery clone = (DisjunctionMaxQuery)super.clone();
    clone.disjuncts = (ArrayList)this.disjuncts.clone();
    return clone;
  }


  
  public void extractTerms(Set terms) {
      for (int i = 0; i < disjuncts.size(); i++) {
          ((Query)disjuncts.get(i)).extractTerms(terms);
      }
  }


  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""("");
    for (int i = 0 ; i < disjuncts.size(); i++) {
      Query subquery = (Query) disjuncts.get(i);
      if (subquery instanceof BooleanQuery) {   
        buffer.append(""("");
        buffer.append(subquery.toString(field));
        buffer.append("")"");
      }
      else buffer.append(subquery.toString(field));
      if (i != disjuncts.size()-1) buffer.append("" | "");
    }
    buffer.append("")"");
    if (tieBreakerMultiplier != 0.0f) {
      buffer.append(""~"");
      buffer.append(tieBreakerMultiplier);
    }
    if (getBoost() != 1.0) {
      buffer.append(""^"");
      buffer.append(getBoost());
    }
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (! (o instanceof DisjunctionMaxQuery) ) return false;
    DisjunctionMaxQuery other = (DisjunctionMaxQuery)o;
    return this.getBoost() == other.getBoost()
            && this.tieBreakerMultiplier == other.tieBreakerMultiplier
            && this.disjuncts.equals(other.disjuncts);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost())
            + Float.floatToIntBits(tieBreakerMultiplier)
            + disjuncts.hashCode();
  }

}
"
lucene,2,org.apache.lucene.index.FieldsWriter,4,1,0,7,38,0,2,5,0,0.888888889,224,0.5,3,0.0,0.375,0,0,53.5,2,1.0,2,"package org.apache.lucene.index;



import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.util.Enumeration;
import java.util.zip.Deflater;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexOutput;

final class FieldsWriter
{
  static final byte FIELD_IS_TOKENIZED = 0x1;
  static final byte FIELD_IS_BINARY = 0x2;
  static final byte FIELD_IS_COMPRESSED = 0x4;
  
    private FieldInfos fieldInfos;

    private IndexOutput fieldsStream;

    private IndexOutput indexStream;

    FieldsWriter(Directory d, String segment, FieldInfos fn) throws IOException {
        fieldInfos = fn;
        fieldsStream = d.createOutput(segment + "".fdt"");
        indexStream = d.createOutput(segment + "".fdx"");
    }

    final void close() throws IOException {
        fieldsStream.close();
        indexStream.close();
    }

    final void addDocument(Document doc) throws IOException {
        indexStream.writeLong(fieldsStream.getFilePointer());

        int storedCount = 0;
        Enumeration fields = doc.fields();
        while (fields.hasMoreElements()) {
            Field field = (Field) fields.nextElement();
            if (field.isStored())
                storedCount++;
        }
        fieldsStream.writeVInt(storedCount);

        fields = doc.fields();
        while (fields.hasMoreElements()) {
            Field field = (Field) fields.nextElement();
            if (field.isStored()) {
                fieldsStream.writeVInt(fieldInfos.fieldNumber(field.name()));

                byte bits = 0;
                if (field.isTokenized())
                    bits |= FieldsWriter.FIELD_IS_TOKENIZED;
                if (field.isBinary())
                    bits |= FieldsWriter.FIELD_IS_BINARY;
                if (field.isCompressed())
                    bits |= FieldsWriter.FIELD_IS_COMPRESSED;
                
                fieldsStream.writeByte(bits);
                
                if (field.isCompressed()) {
                  
                  byte[] data = null;
                  
                  if (field.isBinary()) {
                    data = compress(field.binaryValue());
                  }
                  else {
                    data = compress(field.stringValue().getBytes(""UTF-8""));
                  }
                  final int len = data.length;
                  fieldsStream.writeVInt(len);
                  fieldsStream.writeBytes(data, len);
                }
                else {
                  
                  if (field.isBinary()) {
                    byte[] data = field.binaryValue();
                    final int len = data.length;
                    fieldsStream.writeVInt(len);
                    fieldsStream.writeBytes(data, len);
                  }
                  else {
                    fieldsStream.writeString(field.stringValue());
                  }
                }
            }
        }
    }

    private final byte[] compress (byte[] input) {

      
      Deflater compressor = new Deflater();
      compressor.setLevel(Deflater.BEST_COMPRESSION);

      
      compressor.setInput(input);
      compressor.finish();

      
      ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length);

      
      byte[] buf = new byte[1024];
      while (!compressor.finished()) {
        int count = compressor.deflate(buf);
        bos.write(buf, 0, count);
      }
      
      compressor.end();

      
      return bos.toByteArray();
    }
}
"
lucene,2,org.apache.lucene.index.SegmentTermPositions,8,2,0,5,17,0,1,5,4,0.523809524,108,1.0,1,0.611111111,0.3,1,3,12.125,1,0.875,4,"package org.apache.lucene.index;



import java.io.IOException;

import org.apache.lucene.store.IndexInput;

final class SegmentTermPositions
extends SegmentTermDocs implements TermPositions {
  private IndexInput proxStream;
  private int proxCount;
  private int position;
  
  SegmentTermPositions(SegmentReader p) {
    super(p);
    this.proxStream = (IndexInput)parent.proxStream.clone();
  }

  final void seek(TermInfo ti) throws IOException {
    super.seek(ti);
    if (ti != null)
      proxStream.seek(ti.proxPointer);
    proxCount = 0;
  }

  public final void close() throws IOException {
    super.close();
    proxStream.close();
  }

  public final int nextPosition() throws IOException {
    proxCount--;
    return position += proxStream.readVInt();
  }

  protected final void skippingDoc() throws IOException {
    for (int f = freq; f > 0; f--)		  
      proxStream.readVInt();
  }

  public final boolean next() throws IOException {
    for (int f = proxCount; f > 0; f--)		  
      proxStream.readVInt();

    if (super.next()) {				  
      proxCount = freq;				  
      position = 0;				  
      return true;
    }
    return false;
  }

  public final int read(final int[] docs, final int[] freqs) {
    throw new UnsupportedOperationException(""TermPositions does not support processing multiple documents in one call. Use TermDocs instead."");
  }


  
  protected void skipProx(long proxPointer) throws IOException {
    proxStream.seek(proxPointer);
    proxCount = 0;
  }

}
"
lucene,2,org.apache.lucene.search.FilteredTermEnum,9,2,2,7,14,8,5,2,6,0.5,103,1.0,2,0.384615385,0.407407407,1,2,10.22222222,2,1.0,0,"package org.apache.lucene.search;



import java.io.IOException;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;


public abstract class FilteredTermEnum extends TermEnum {
    private Term currentTerm = null;
    private TermEnum actualEnum = null;
    
    public FilteredTermEnum() {}

    
    protected abstract boolean termCompare(Term term);
    
    
    public abstract float difference();

    
    protected abstract boolean endEnum();
    
    protected void setEnum(TermEnum actualEnum) throws IOException {
        this.actualEnum = actualEnum;
        
        Term term = actualEnum.term();
        if (term != null && termCompare(term)) 
            currentTerm = term;
        else next();
    }
    
    
    public int docFreq() {
        if (actualEnum == null) return -1;
        return actualEnum.docFreq();
    }
    
    
    public boolean next() throws IOException {
        if (actualEnum == null) return false; 
        currentTerm = null;
        while (currentTerm == null) {
            if (endEnum()) return false;
            if (actualEnum.next()) {
                Term term = actualEnum.term();
                if (termCompare(term)) {
                    currentTerm = term;
                    return true;
                }
            }
            else return false;
        }
        currentTerm = null;
        return false;
    }
    
    
    public Term term() {
        return currentTerm;
    }
    
    
    public void close() throws IOException {
        actualEnum.close();
        currentTerm = null;
        actualEnum = null;
    }
}
"
lucene,2,org.apache.lucene.index.TermDocs,8,1,0,19,8,28,17,2,8,2.0,8,0.0,0,0.0,0.3,0,0,0.0,1,1.0,0,"package org.apache.lucene.index;



import java.io.IOException;



public interface TermDocs {
  
  void seek(Term term) throws IOException;

  
  void seek(TermEnum termEnum) throws IOException;

  
  int doc();

  
  int freq();

  
  boolean next() throws IOException;

  
  int read(int[] docs, int[] freqs) throws IOException;

  
  boolean skipTo(int target) throws IOException;

  
  void close() throws IOException;
}


"
lucene,2,org.apache.lucene.index.SegmentReader,40,2,0,29,123,576,6,26,19,0.883861237,1200,0.470588235,8,0.591397849,0.136752137,1,5,28.575,26,1.75,11,"package org.apache.lucene.index;



import java.io.IOException;
import java.util.*;

import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.Directory;
import org.apache.lucene.util.BitVector;
import org.apache.lucene.search.DefaultSimilarity;


class SegmentReader extends IndexReader {
  private String segment;

  FieldInfos fieldInfos;
  private FieldsReader fieldsReader;

  TermInfosReader tis;
  TermVectorsReader termVectorsReaderOrig = null;
  ThreadLocal termVectorsLocal = new ThreadLocal();

  BitVector deletedDocs = null;
  private boolean deletedDocsDirty = false;
  private boolean normsDirty = false;
  private boolean undeleteAll = false;

  IndexInput freqStream;
  IndexInput proxStream;

  
  CompoundFileReader cfsReader = null;

  private class Norm {
    public Norm(IndexInput in, int number)
    {
      this.in = in;
      this.number = number;
    }

    private IndexInput in;
    private byte[] bytes;
    private boolean dirty;
    private int number;

    private void reWrite() throws IOException {
      
      IndexOutput out = directory().createOutput(segment + "".tmp"");
      try {
        out.writeBytes(bytes, maxDoc());
      } finally {
        out.close();
      }
      String fileName;
      if(cfsReader == null)
          fileName = segment + "".f"" + number;
      else{
          
          fileName = segment + "".s"" + number;
      }
      directory().renameFile(segment + "".tmp"", fileName);
      this.dirty = false;
    }
  }

  private Hashtable norms = new Hashtable();

  
  private static Class IMPL;
  static {
    try {
      String name =
        System.getProperty(""org.apache.lucene.SegmentReader.class"",
                           SegmentReader.class.getName());
      IMPL = Class.forName(name);
    } catch (ClassNotFoundException e) {
      throw new RuntimeException(""cannot load SegmentReader class: "" + e, e);
    } catch (SecurityException se) {
      try {
        IMPL = Class.forName(SegmentReader.class.getName());
      } catch (ClassNotFoundException e) {
        throw new RuntimeException(""cannot load default SegmentReader class: "" + e, e);
      }
    }
  }

  protected SegmentReader() { super(null); }

  public static SegmentReader get(SegmentInfo si) throws IOException {
    return get(si.dir, si, null, false, false);
  }

  public static SegmentReader get(SegmentInfos sis, SegmentInfo si,
                                  boolean closeDir) throws IOException {
    return get(si.dir, si, sis, closeDir, true);
  }

  public static SegmentReader get(Directory dir, SegmentInfo si,
                                  SegmentInfos sis,
                                  boolean closeDir, boolean ownDir)
    throws IOException {
    SegmentReader instance;
    try {
      instance = (SegmentReader)IMPL.newInstance();
    } catch (Exception e) {
      throw new RuntimeException(""cannot load SegmentReader class: "" + e, e);
    }
    instance.init(dir, sis, closeDir, ownDir);
    instance.initialize(si);
    return instance;
  }

   private void initialize(SegmentInfo si) throws IOException {
    segment = si.name;

    
    Directory cfsDir = directory();
    if (directory().fileExists(segment + "".cfs"")) {
      cfsReader = new CompoundFileReader(directory(), segment + "".cfs"");
      cfsDir = cfsReader;
    }

    
    fieldInfos = new FieldInfos(cfsDir, segment + "".fnm"");
    fieldsReader = new FieldsReader(cfsDir, segment, fieldInfos);

    tis = new TermInfosReader(cfsDir, segment, fieldInfos);

    
    if (hasDeletions(si))
      deletedDocs = new BitVector(directory(), segment + "".del"");

    
    
    freqStream = cfsDir.openInput(segment + "".frq"");
    proxStream = cfsDir.openInput(segment + "".prx"");
    openNorms(cfsDir);

    if (fieldInfos.hasVectors()) { 
      termVectorsReaderOrig = new TermVectorsReader(cfsDir, segment, fieldInfos);
    }
  }

   protected void finalize() {
     
     termVectorsLocal.set(null);
     super.finalize();
   }

  protected void doCommit() throws IOException {
    if (deletedDocsDirty) {               
      deletedDocs.write(directory(), segment + "".tmp"");
      directory().renameFile(segment + "".tmp"", segment + "".del"");
    }
    if(undeleteAll && directory().fileExists(segment + "".del"")){
      directory().deleteFile(segment + "".del"");
    }
    if (normsDirty) {               
      Enumeration values = norms.elements();
      while (values.hasMoreElements()) {
        Norm norm = (Norm) values.nextElement();
        if (norm.dirty) {
          norm.reWrite();
        }
      }
    }
    deletedDocsDirty = false;
    normsDirty = false;
    undeleteAll = false;
  }

  protected void doClose() throws IOException {
    fieldsReader.close();
    tis.close();

    if (freqStream != null)
      freqStream.close();
    if (proxStream != null)
      proxStream.close();

    closeNorms();

    if (termVectorsReaderOrig != null)
      termVectorsReaderOrig.close();

    if (cfsReader != null)
      cfsReader.close();
  }

  static boolean hasDeletions(SegmentInfo si) throws IOException {
    return si.dir.fileExists(si.name + "".del"");
  }

  public boolean hasDeletions() {
    return deletedDocs != null;
  }


  static boolean usesCompoundFile(SegmentInfo si) throws IOException {
    return si.dir.fileExists(si.name + "".cfs"");
  }

  static boolean hasSeparateNorms(SegmentInfo si) throws IOException {
    String[] result = si.dir.list();
    String pattern = si.name + "".s"";
    int patternLength = pattern.length();
    for(int i = 0; i < result.length; i++){
      if(result[i].startsWith(pattern) && Character.isDigit(result[i].charAt(patternLength)))
        return true;
    }
    return false;
  }

  protected void doDelete(int docNum) {
    if (deletedDocs == null)
      deletedDocs = new BitVector(maxDoc());
    deletedDocsDirty = true;
    undeleteAll = false;
    deletedDocs.set(docNum);
  }

  protected void doUndeleteAll() {
      deletedDocs = null;
      deletedDocsDirty = false;
      undeleteAll = true;
  }

  Vector files() throws IOException {
    Vector files = new Vector(16);

    for (int i = 0; i < IndexFileNames.INDEX_EXTENSIONS.length; i++) {
      String name = segment + ""."" + IndexFileNames.INDEX_EXTENSIONS[i];
      if (directory().fileExists(name))
        files.addElement(name);
    }

    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed  && !fi.omitNorms){
        String name;
        if(cfsReader == null)
            name = segment + "".f"" + i;
        else
            name = segment + "".s"" + i;
        if (directory().fileExists(name))
            files.addElement(name);
      }
    }
    return files;
  }

  public TermEnum terms() {
    return tis.terms();
  }

  public TermEnum terms(Term t) throws IOException {
    return tis.terms(t);
  }

  public synchronized Document document(int n) throws IOException {
    if (isDeleted(n))
      throw new IllegalArgumentException
              (""attempt to access a deleted document"");
    return fieldsReader.doc(n);
  }

  public synchronized boolean isDeleted(int n) {
    return (deletedDocs != null && deletedDocs.get(n));
  }

  public TermDocs termDocs() throws IOException {
    return new SegmentTermDocs(this);
  }

  public TermPositions termPositions() throws IOException {
    return new SegmentTermPositions(this);
  }

  public int docFreq(Term t) throws IOException {
    TermInfo ti = tis.get(t);
    if (ti != null)
      return ti.docFreq;
    else
      return 0;
  }

  public int numDocs() {
    int n = maxDoc();
    if (deletedDocs != null)
      n -= deletedDocs.count();
    return n;
  }

  public int maxDoc() {
    return fieldsReader.size();
  }

  
  public Collection getFieldNames(IndexReader.FieldOption fieldOption) {

    Set fieldSet = new HashSet();
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fieldOption == IndexReader.FieldOption.ALL) {
        fieldSet.add(fi.name);
      }
      else if (!fi.isIndexed && fieldOption == IndexReader.FieldOption.UNINDEXED) {
        fieldSet.add(fi.name);
      }
      else if (fi.isIndexed && fieldOption == IndexReader.FieldOption.INDEXED) {
        fieldSet.add(fi.name);
      }
      else if (fi.isIndexed && fi.storeTermVector == false && fieldOption == IndexReader.FieldOption.INDEXED_NO_TERMVECTOR) {
        fieldSet.add(fi.name);
      }
      else if (fi.storeTermVector == true &&
               fi.storePositionWithTermVector == false &&
               fi.storeOffsetWithTermVector == false &&
               fieldOption == IndexReader.FieldOption.TERMVECTOR) {
        fieldSet.add(fi.name);
      }
      else if (fi.isIndexed && fi.storeTermVector && fieldOption == IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR) {
        fieldSet.add(fi.name);
      }
      else if (fi.storePositionWithTermVector && fi.storeOffsetWithTermVector == false && fieldOption == IndexReader.FieldOption.TERMVECTOR_WITH_POSITION) {
        fieldSet.add(fi.name);
      }
      else if (fi.storeOffsetWithTermVector && fi.storePositionWithTermVector == false && fieldOption == IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET) {
        fieldSet.add(fi.name);
      }
      else if ((fi.storeOffsetWithTermVector && fi.storePositionWithTermVector) &&
                fieldOption == IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET) {
        fieldSet.add(fi.name);
      }
    }
    return fieldSet;
  }


  public synchronized boolean hasNorms(String field) {
    return norms.containsKey(field);
  }

  static byte[] createFakeNorms(int size) {
    byte[] ones = new byte[size];
    Arrays.fill(ones, DefaultSimilarity.encodeNorm(1.0f));
    return ones;
  }

  private byte[] ones;
  private byte[] fakeNorms() {
    if (ones==null) ones=createFakeNorms(maxDoc());
    return ones;
  }

  
  protected synchronized byte[] getNorms(String field) throws IOException {
    Norm norm = (Norm) norms.get(field);
    if (norm == null) return null;  

    if (norm.bytes == null) {                     
      byte[] bytes = new byte[maxDoc()];
      norms(field, bytes, 0);
      norm.bytes = bytes;                         
    }
    return norm.bytes;
  }

  
  public synchronized byte[] norms(String field) throws IOException {
    byte[] bytes = getNorms(field);
    if (bytes==null) bytes=fakeNorms();
    return bytes;
  }

  protected void doSetNorm(int doc, String field, byte value)
          throws IOException {
    Norm norm = (Norm) norms.get(field);
    if (norm == null)                             
      return;
    norm.dirty = true;                            
    normsDirty = true;

    norms(field)[doc] = value;                    
  }

  
  public synchronized void norms(String field, byte[] bytes, int offset)
    throws IOException {

    Norm norm = (Norm) norms.get(field);
    if (norm == null) {
      System.arraycopy(fakeNorms(), 0, bytes, offset, maxDoc());
      return;
    }

    if (norm.bytes != null) {                     
      System.arraycopy(norm.bytes, 0, bytes, offset, maxDoc());
      return;
    }

    IndexInput normStream = (IndexInput) norm.in.clone();
    try {                                         
      normStream.seek(0);
      normStream.readBytes(bytes, offset, maxDoc());
    } finally {
      normStream.close();
    }
  }


  private void openNorms(Directory cfsDir) throws IOException {
    for (int i = 0; i < fieldInfos.size(); i++) {
      FieldInfo fi = fieldInfos.fieldInfo(i);
      if (fi.isIndexed && !fi.omitNorms) {
        
        String fileName = segment + "".s"" + fi.number;
        Directory d = directory();
        if(!d.fileExists(fileName)){
            fileName = segment + "".f"" + fi.number;
            d = cfsDir;
        }
        norms.put(fi.name, new Norm(d.openInput(fileName), fi.number));
      }
    }
  }

  private void closeNorms() throws IOException {
    synchronized (norms) {
      Enumeration enumerator = norms.elements();
      while (enumerator.hasMoreElements()) {
        Norm norm = (Norm) enumerator.nextElement();
        norm.in.close();
      }
    }
  }
  
  
  private TermVectorsReader getTermVectorsReader() {
    TermVectorsReader tvReader = (TermVectorsReader)termVectorsLocal.get();
    if (tvReader == null) {
      tvReader = (TermVectorsReader)termVectorsReaderOrig.clone();
      termVectorsLocal.set(tvReader);
    }
    return tvReader;
  }
  
  
  public TermFreqVector getTermFreqVector(int docNumber, String field) throws IOException {
    
    FieldInfo fi = fieldInfos.fieldInfo(field);
    if (fi == null || !fi.storeTermVector || termVectorsReaderOrig == null) 
      return null;
    
    TermVectorsReader termVectorsReader = getTermVectorsReader();
    if (termVectorsReader == null)
      return null;
    
    return termVectorsReader.get(docNumber, field);
  }


  
  public TermFreqVector[] getTermFreqVectors(int docNumber) throws IOException {
    if (termVectorsReaderOrig == null)
      return null;
    
    TermVectorsReader termVectorsReader = getTermVectorsReader();
    if (termVectorsReader == null)
      return null;
    
    return termVectorsReader.get(docNumber);
  }
}
"
lucene,2,org.apache.lucene.search.FieldSortedHitQueue,16,2,0,15,55,98,1,14,4,0.833333333,498,0.75,2,0.44,0.296296296,1,3,29.875,7,1.5625,2,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.PriorityQueue;

import java.io.IOException;
import java.util.WeakHashMap;
import java.util.HashMap;
import java.util.Map;
import java.util.Locale;
import java.text.Collator;


public class FieldSortedHitQueue
extends PriorityQueue {

  
  public FieldSortedHitQueue (IndexReader reader, SortField[] fields, int size)
  throws IOException {
    final int n = fields.length;
    comparators = new ScoreDocComparator[n];
    this.fields = new SortField[n];
    for (int i=0; i<n; ++i) {
      String fieldname = fields[i].getField();
      comparators[i] = getCachedComparator (reader, fieldname, fields[i].getType(), fields[i].getLocale(), fields[i].getFactory());
      
      if (comparators[i].sortType() == SortField.STRING) {
    	  this.fields[i] = new SortField (fieldname, fields[i].getLocale(), fields[i].getReverse());
      } else {
    	  this.fields[i] = new SortField (fieldname, comparators[i].sortType(), fields[i].getReverse());
      }
    }
    initialize (size);
  }


  
  protected ScoreDocComparator[] comparators;

  
  protected SortField[] fields;

  
  protected float maxscore = Float.NEGATIVE_INFINITY;

  
  public float getMaxScore() {
    return maxscore;
  }

  
  
  
  public boolean insert(FieldDoc fdoc) {
    maxscore = Math.max(maxscore,fdoc.score);
    return super.insert(fdoc);
  }

  
  
  
  public boolean insert(Object fdoc) {
    return insert((FieldDoc)fdoc);
  }

  
  protected boolean lessThan (final Object a, final Object b) {
    final ScoreDoc docA = (ScoreDoc) a;
    final ScoreDoc docB = (ScoreDoc) b;

    
    final int n = comparators.length;
    int c = 0;
    for (int i=0; i<n && c==0; ++i) {
      c = (fields[i].reverse) ? comparators[i].compare (docB, docA)
                              : comparators[i].compare (docA, docB);
    }
    
    if (c == 0)
      return docA.doc > docB.doc;
    return c > 0;
  }


  
  FieldDoc fillFields (final FieldDoc doc) {
    final int n = comparators.length;
    final Comparable[] fields = new Comparable[n];
    for (int i=0; i<n; ++i)
      fields[i] = comparators[i].sortValue(doc);
    doc.fields = fields;
    
    return doc;
  }


  
  SortField[] getFields() {
    return fields;
  }

  
  static final Map Comparators = new WeakHashMap();

  
  static ScoreDocComparator lookup (IndexReader reader, String field, int type, Locale locale, Object factory) {
    FieldCacheImpl.Entry entry = (factory != null)
      ? new FieldCacheImpl.Entry (field, factory)
      : new FieldCacheImpl.Entry (field, type, locale);
    synchronized (Comparators) {
      HashMap readerCache = (HashMap)Comparators.get(reader);
      if (readerCache == null) return null;
      return (ScoreDocComparator) readerCache.get (entry);
    }
  }

  
  static Object store (IndexReader reader, String field, int type, Locale locale, Object factory, Object value) {
    FieldCacheImpl.Entry entry = (factory != null)
      ? new FieldCacheImpl.Entry (field, factory)
      : new FieldCacheImpl.Entry (field, type, locale);
    synchronized (Comparators) {
      HashMap readerCache = (HashMap)Comparators.get(reader);
      if (readerCache == null) {
        readerCache = new HashMap();
        Comparators.put(reader,readerCache);
      }
      return readerCache.put (entry, value);
    }
  }

  static ScoreDocComparator getCachedComparator (IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory)
  throws IOException {
    if (type == SortField.DOC) return ScoreDocComparator.INDEXORDER;
    if (type == SortField.SCORE) return ScoreDocComparator.RELEVANCE;
    ScoreDocComparator comparator = lookup (reader, fieldname, type, locale, factory);
    if (comparator == null) {
      switch (type) {
        case SortField.AUTO:
          comparator = comparatorAuto (reader, fieldname);
          break;
        case SortField.INT:
          comparator = comparatorInt (reader, fieldname);
          break;
        case SortField.FLOAT:
          comparator = comparatorFloat (reader, fieldname);
          break;
        case SortField.STRING:
          if (locale != null) comparator = comparatorStringLocale (reader, fieldname, locale);
          else comparator = comparatorString (reader, fieldname);
          break;
        case SortField.CUSTOM:
          comparator = factory.newComparator (reader, fieldname);
          break;
        default:
          throw new RuntimeException (""unknown field type: ""+type);
      }
      store (reader, fieldname, type, locale, factory, comparator);
    }
    return comparator;
  }

  
  static ScoreDocComparator comparatorInt (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final int[] fieldOrder = FieldCache.DEFAULT.getInts (reader, field);
    return new ScoreDocComparator() {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        final int fi = fieldOrder[i.doc];
        final int fj = fieldOrder[j.doc];
        if (fi < fj) return -1;
        if (fi > fj) return 1;
        return 0;
      }

      public Comparable sortValue (final ScoreDoc i) {
        return new Integer (fieldOrder[i.doc]);
      }

      public int sortType() {
        return SortField.INT;
      }
    };
  }

  
  static ScoreDocComparator comparatorFloat (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final float[] fieldOrder = FieldCache.DEFAULT.getFloats (reader, field);
    return new ScoreDocComparator () {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        final float fi = fieldOrder[i.doc];
        final float fj = fieldOrder[j.doc];
        if (fi < fj) return -1;
        if (fi > fj) return 1;
        return 0;
      }

      public Comparable sortValue (final ScoreDoc i) {
        return new Float (fieldOrder[i.doc]);
      }

      public int sortType() {
        return SortField.FLOAT;
      }
    };
  }

  
  static ScoreDocComparator comparatorString (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    final FieldCache.StringIndex index = FieldCache.DEFAULT.getStringIndex (reader, field);
    return new ScoreDocComparator () {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        final int fi = index.order[i.doc];
        final int fj = index.order[j.doc];
        if (fi < fj) return -1;
        if (fi > fj) return 1;
        return 0;
      }

      public Comparable sortValue (final ScoreDoc i) {
        return index.lookup[index.order[i.doc]];
      }

      public int sortType() {
        return SortField.STRING;
      }
    };
  }

  
  static ScoreDocComparator comparatorStringLocale (final IndexReader reader, final String fieldname, final Locale locale)
  throws IOException {
    final Collator collator = Collator.getInstance (locale);
    final String field = fieldname.intern();
    final String[] index = FieldCache.DEFAULT.getStrings (reader, field);
    return new ScoreDocComparator() {

      public final int compare (final ScoreDoc i, final ScoreDoc j) {
        return collator.compare (index[i.doc], index[j.doc]);
      }

      public Comparable sortValue (final ScoreDoc i) {
        return index[i.doc];
      }

      public int sortType() {
        return SortField.STRING;
      }
    };
  }

  
  static ScoreDocComparator comparatorAuto (final IndexReader reader, final String fieldname)
  throws IOException {
    final String field = fieldname.intern();
    Object lookupArray = FieldCache.DEFAULT.getAuto (reader, field);
    if (lookupArray instanceof FieldCache.StringIndex) {
      return comparatorString (reader, field);
    } else if (lookupArray instanceof int[]) {
      return comparatorInt (reader, field);
    } else if (lookupArray instanceof float[]) {
      return comparatorFloat (reader, field);
    } else if (lookupArray instanceof String[]) {
      return comparatorString (reader, field);
    } else {
      throw new RuntimeException (""unknown data type in field '""+field+""'"");
    }
  }
}
"
lucene,2,org.apache.lucene.analysis.PerFieldAnalyzerWrapper,4,2,0,2,13,0,0,2,4,0.166666667,57,1.0,1,0.4,0.5625,0,0,12.75,2,1.0,1,"package org.apache.lucene.analysis;



import java.io.Reader;
import java.util.Map;
import java.util.HashMap;


public class PerFieldAnalyzerWrapper extends Analyzer {
  private Analyzer defaultAnalyzer;
  private Map analyzerMap = new HashMap();


  
  public PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer) {
    this.defaultAnalyzer = defaultAnalyzer;
  }

  
  public void addAnalyzer(String fieldName, Analyzer analyzer) {
    analyzerMap.put(fieldName, analyzer);
  }

  public TokenStream tokenStream(String fieldName, Reader reader) {
    Analyzer analyzer = (Analyzer) analyzerMap.get(fieldName);
    if (analyzer == null) {
      analyzer = defaultAnalyzer;
    }

    return analyzer.tokenStream(fieldName, reader);
  }
  
  public String toString() {
    return ""PerFieldAnalyzerWrapper("" + analyzerMap + "", default="" + defaultAnalyzer + "")"";
  }
}
"
lucene,2,org.apache.lucene.search.BooleanQuery,22,2,0,20,60,79,12,12,19,0.742857143,439,1.0,0,0.387096774,0.119047619,2,6,18.72727273,12,1.7273,4,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;

import java.io.IOException;
import java.util.Iterator;
import java.util.Set;
import java.util.Vector;


public class BooleanQuery extends Query {

  
  private static int maxClauseCount = 1024;

  
  public static class TooManyClauses extends RuntimeException {}

  
  public static int getMaxClauseCount() { return maxClauseCount; }

  
  public static void setMaxClauseCount(int maxClauseCount) {
    if (maxClauseCount < 1)
      throw new IllegalArgumentException(""maxClauseCount must be >= 1"");
    BooleanQuery.maxClauseCount = maxClauseCount;
  }

  private Vector clauses = new Vector();
  private boolean disableCoord;

  
  public BooleanQuery() {}

  
  public BooleanQuery(boolean disableCoord) {
    this.disableCoord = disableCoord;
  }

  
  public boolean isCoordDisabled() { return disableCoord; }

  
  
  public Similarity getSimilarity(Searcher searcher) {
    Similarity result = super.getSimilarity(searcher);
    if (disableCoord) {                           
      result = new SimilarityDelegator(result) {
          public float coord(int overlap, int maxOverlap) {
            return 1.0f;
          }
        };
    }
    return result;
  }

  
  public void setMinimumNumberShouldMatch(int min) {
    this.minNrShouldMatch = min;
  }
  protected int minNrShouldMatch = 0;

  
  public int getMinimumNumberShouldMatch() {
    return minNrShouldMatch;
  }

  
  public void add(Query query, BooleanClause.Occur occur) {
    add(new BooleanClause(query, occur));
  }

  
  public void add(BooleanClause clause) {
    if (clauses.size() >= maxClauseCount)
      throw new TooManyClauses();

    clauses.addElement(clause);
  }

  
  public BooleanClause[] getClauses() {
    return (BooleanClause[])clauses.toArray(new BooleanClause[0]);
  }

  private class BooleanWeight implements Weight {
    protected Similarity similarity;
    protected Vector weights = new Vector();

    public BooleanWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);
      for (int i = 0 ; i < clauses.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        weights.add(c.getQuery().createWeight(searcher));
      }
    }

    public Query getQuery() { return BooleanQuery.this; }
    public float getValue() { return getBoost(); }

    public float sumOfSquaredWeights() throws IOException {
      float sum = 0.0f;
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        Weight w = (Weight)weights.elementAt(i);
        if (!c.isProhibited())
          sum += w.sumOfSquaredWeights();         
      }

      sum *= getBoost() * getBoost();             

      return sum ;
    }


    public void normalize(float norm) {
      norm *= getBoost();                         
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        Weight w = (Weight)weights.elementAt(i);
        if (!c.isProhibited())
          w.normalize(norm);
      }
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      
      
      
      
      
      
      boolean allRequired = true;
      boolean noneBoolean = true;
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        if (!c.isRequired())
          allRequired = false;
        if (c.getQuery() instanceof BooleanQuery)
          noneBoolean = false;
      }

      if (allRequired && noneBoolean) {           
        ConjunctionScorer result =
          new ConjunctionScorer(similarity);
        for (int i = 0 ; i < weights.size(); i++) {
          Weight w = (Weight)weights.elementAt(i);
          Scorer subScorer = w.scorer(reader);
          if (subScorer == null)
            return null;
          result.add(subScorer);
        }
        return result;
      }

      
      BooleanScorer result = new BooleanScorer(similarity);

      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        Weight w = (Weight)weights.elementAt(i);
        Scorer subScorer = w.scorer(reader);
        if (subScorer != null)
          result.add(subScorer, c.isRequired(), c.isProhibited());
        else if (c.isRequired())
          return null;
      }

      return result;
    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {
      Explanation sumExpl = new Explanation();
      sumExpl.setDescription(""sum of:"");
      int coord = 0;
      int maxCoord = 0;
      float sum = 0.0f;
      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        Weight w = (Weight)weights.elementAt(i);
        Explanation e = w.explain(reader, doc);
        if (!c.isProhibited()) maxCoord++;
        if (e.getValue() > 0) {
          if (!c.isProhibited()) {
            sumExpl.addDetail(e);
            sum += e.getValue();
            coord++;
          } else {
            return new Explanation(0.0f, ""match prohibited"");
          }
        } else if (c.isRequired()) {
          return new Explanation(0.0f, ""match required"");
        }
      }
      sumExpl.setValue(sum);

      if (coord == 1)                               
        sumExpl = sumExpl.getDetails()[0];          

      float coordFactor = similarity.coord(coord, maxCoord);
      if (coordFactor == 1.0f)                      
        return sumExpl;                             
      else {
        Explanation result = new Explanation();
        result.setDescription(""product of:"");
        result.addDetail(sumExpl);
        result.addDetail(new Explanation(coordFactor,
                                         ""coord(""+coord+""/""+maxCoord+"")""));
        result.setValue(sum*coordFactor);
        return result;
      }
    }
  }

  private class BooleanWeight2 extends BooleanWeight {
    
    public BooleanWeight2(Searcher searcher)
      throws IOException {
        super(searcher);
    }

    
    public Scorer scorer(IndexReader reader) throws IOException {
      BooleanScorer2 result = new BooleanScorer2(similarity,
                                                 minNrShouldMatch);

      for (int i = 0 ; i < weights.size(); i++) {
        BooleanClause c = (BooleanClause)clauses.elementAt(i);
        Weight w = (Weight)weights.elementAt(i);
        Scorer subScorer = w.scorer(reader);
        if (subScorer != null)
          result.add(subScorer, c.isRequired(), c.isProhibited());
        else if (c.isRequired())
          return null;
      }

      return result;
    }
  }

  
  private static boolean useScorer14 = false;

  public static void setUseScorer14(boolean use14) {
    useScorer14 = use14;
  }

  public static boolean getUseScorer14() {
    return useScorer14;
  }

  protected Weight createWeight(Searcher searcher) throws IOException {

    if (0 < minNrShouldMatch) {
      
      return new BooleanWeight2(searcher);
    }

    return getUseScorer14() ? (Weight) new BooleanWeight(searcher)
                            : (Weight) new BooleanWeight2(searcher);
  }

  public Query rewrite(IndexReader reader) throws IOException {
    if (clauses.size() == 1) {                    
      BooleanClause c = (BooleanClause)clauses.elementAt(0);
      if (!c.isProhibited()) {			  

        Query query = c.getQuery().rewrite(reader);    

        if (getBoost() != 1.0f) {                 
          if (query == c.getQuery())                   
            query = (Query)query.clone();         
          query.setBoost(getBoost() * query.getBoost());
        }

        return query;
      }
    }

    BooleanQuery clone = null;                    
    for (int i = 0 ; i < clauses.size(); i++) {
      BooleanClause c = (BooleanClause)clauses.elementAt(i);
      Query query = c.getQuery().rewrite(reader);
      if (query != c.getQuery()) {                     
        if (clone == null)
          clone = (BooleanQuery)this.clone();
        clone.clauses.setElementAt
          (new BooleanClause(query, c.getOccur()), i);
      }
    }
    if (clone != null) {
      return clone;                               
    } else
      return this;                                
  }

  
  public void extractTerms(Set terms) {
      for (Iterator i = clauses.iterator(); i.hasNext();) {
          BooleanClause clause = (BooleanClause) i.next();
          clause.getQuery().extractTerms(terms);
        }
  }

  public Object clone() {
    BooleanQuery clone = (BooleanQuery)super.clone();
    clone.clauses = (Vector)this.clauses.clone();
    return clone;
  }

  
  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    boolean needParens=(getBoost() != 1.0) || (getMinimumNumberShouldMatch()>0) ;
    if (needParens) {
      buffer.append(""("");
    }

    for (int i = 0 ; i < clauses.size(); i++) {
      BooleanClause c = (BooleanClause)clauses.elementAt(i);
      if (c.isProhibited())
        buffer.append(""-"");
      else if (c.isRequired())
        buffer.append(""+"");

      Query subQuery = c.getQuery();
      if (subQuery instanceof BooleanQuery) {	  
        buffer.append(""("");
        buffer.append(c.getQuery().toString(field));
        buffer.append("")"");
      } else
        buffer.append(c.getQuery().toString(field));

      if (i != clauses.size()-1)
        buffer.append("" "");
    }

    if (needParens) {
      buffer.append("")"");
    }

    if (getMinimumNumberShouldMatch()>0) {
      buffer.append('~');
      buffer.append(getMinimumNumberShouldMatch());
    }

    if (getBoost() != 1.0f)
    {
      buffer.append(ToStringUtils.boost(getBoost()));
    }

    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof BooleanQuery))
      return false;
    BooleanQuery other = (BooleanQuery)o;
    return (this.getBoost() == other.getBoost())
        && this.clauses.equals(other.clauses)
        && this.getMinimumNumberShouldMatch() == other.getMinimumNumberShouldMatch();
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ clauses.hashCode()
           + getMinimumNumberShouldMatch();
  }

}
"
lucene,2,org.apache.lucene.index.TermInfo,5,1,0,8,6,0,8,0,0,0.125,100,0.0,0,0.0,0.55,0,0,18.2,1,0.4,0,"package org.apache.lucene.index;





final class TermInfo {
  
  int docFreq = 0;

  long freqPointer = 0;
  long proxPointer = 0;
  int skipOffset;

  TermInfo() {}

  TermInfo(int df, long fp, long pp) {
    docFreq = df;
    freqPointer = fp;
    proxPointer = pp;
  }

  TermInfo(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }

  final void set(int docFreq,
                 long freqPointer, long proxPointer, int skipOffset) {
    this.docFreq = docFreq;
    this.freqPointer = freqPointer;
    this.proxPointer = proxPointer;
    this.skipOffset = skipOffset;
  }

  final void set(TermInfo ti) {
    docFreq = ti.docFreq;
    freqPointer = ti.freqPointer;
    proxPointer = ti.proxPointer;
    skipOffset = ti.skipOffset;
  }
}
"
lucene,2,org.apache.lucene.index.Term,12,1,0,58,21,0,58,0,9,0.136363636,128,0.0,0,0.0,0.291666667,1,1,9.5,4,1.1667,1,"package org.apache.lucene.index;





public final class Term implements Comparable, java.io.Serializable {
  String field;
  String text;

  
  public Term(String fld, String txt) {
    this(fld, txt, true);
  }
  Term(String fld, String txt, boolean intern) {
    field = intern ? fld.intern() : fld;	  
    text = txt;					  
  }

  
  public final String field() { return field; }

  
  public final String text() { return text; }
  
  
  public Term createTerm(String text)
  {
      return new Term(field,text,false);
  }

  
  public final boolean equals(Object o) {
    if (o == null)
      return false;
    Term other = (Term)o;
    return field == other.field && text.equals(other.text);
  }

  
  public final int hashCode() {
    return field.hashCode() + text.hashCode();
  }

  public int compareTo(Object other) {
    return compareTo((Term)other);
  }

  
  public final int compareTo(Term other) {
    if (field == other.field)			  
      return text.compareTo(other.text);
    else
      return field.compareTo(other.field);
  }

  
  final void set(String fld, String txt) {
    field = fld;
    text = txt;
  }

  public final String toString() { return field + "":"" + text; }

  private void readObject(java.io.ObjectInputStream in)
    throws java.io.IOException, ClassNotFoundException
  {
      in.defaultReadObject();
      field = field.intern();
  }
}
"
lucene,2,org.apache.lucene.search.ConstantScoreQuery,7,2,0,8,18,9,3,6,6,0.5,89,1.0,1,0.666666667,0.265306122,2,3,11.57142857,5,1.5714,1,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;
import java.util.BitSet;
import java.util.Set;


public class ConstantScoreQuery extends Query {
  protected final Filter filter;

  public ConstantScoreQuery(Filter filter) {
    this.filter=filter;
  }

  public Query rewrite(IndexReader reader) throws IOException {
    return this;
  }

  public void extractTerms(Set terms) {
    
    
  }

  protected class ConstantWeight implements Weight {
    private Similarity similarity;
    private float queryNorm;
    private float queryWeight;

    public ConstantWeight(Searcher searcher) {
      this.similarity = getSimilarity(searcher);
    }

    public Query getQuery() {
      return ConstantScoreQuery.this;
    }

    public float getValue() {
      return queryWeight;
    }

    public float sumOfSquaredWeights() throws IOException {
      queryWeight = getBoost();
      return queryWeight * queryWeight;
    }

    public void normalize(float norm) {
      this.queryNorm = norm;
      queryWeight *= this.queryNorm;
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      return new ConstantScorer(similarity, reader, this);
    }

    public Explanation explain(IndexReader reader, int doc) throws IOException {

      ConstantScorer cs = (ConstantScorer)scorer(reader);
      boolean exists = cs.bits.get(doc);

      Explanation result = new Explanation();

      if (exists) {
        result.setDescription(""ConstantScoreQuery("" + filter
        + ""), product of:"");
        result.setValue(queryWeight);
        result.addDetail(new Explanation(getBoost(), ""boost""));
        result.addDetail(new Explanation(queryNorm,""queryNorm""));
      } else {
        result.setDescription(""ConstantScoreQuery("" + filter
        + "") doesn't match id "" + doc);
        result.setValue(0);
      }
      return result;
    }
  }

  protected class ConstantScorer extends Scorer {
    final BitSet bits;
    final float theScore;
    int doc=-1;

    public ConstantScorer(Similarity similarity, IndexReader reader, Weight w) throws IOException {
      super(similarity);
      theScore = w.getValue();
      bits = filter.bits(reader);
    }

    public boolean next() throws IOException {
      doc = bits.nextSetBit(doc+1);
      return doc >= 0;
    }

    public int doc() {
      return doc;
    }

    public float score() throws IOException {
      return theScore;
    }

    public boolean skipTo(int target) throws IOException {
      doc = bits.nextSetBit(target);  
      return doc >= 0;
    }

    public Explanation explain(int doc) throws IOException {
      throw new UnsupportedOperationException();
    }
  }


  protected Weight createWeight(Searcher searcher) {
    return new ConstantScoreQuery.ConstantWeight(searcher);
  }


  
  public String toString(String field)
  {
    return ""ConstantScore("" + filter.toString()
      + (getBoost()==1.0 ? "")"" : ""^"" + getBoost());
  }

  
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof ConstantScoreQuery)) return false;
    ConstantScoreQuery other = (ConstantScoreQuery)o;
    return this.getBoost()==other.getBoost() && filter.equals(other.filter);
  }

  
  public int hashCode() {
    
    return filter.hashCode() + Float.floatToIntBits(getBoost());
  }

}


"
lucene,2,org.apache.lucene.search.RemoteSearchable,12,4,0,12,29,0,0,12,12,0.0,113,1.0,1,0.620689655,0.21969697,0,0,8.333333333,1,0.9167,2,"package org.apache.lucene.search;



import org.apache.lucene.document.Document;
import org.apache.lucene.index.Term;

import java.io.IOException;
import java.rmi.Naming;
import java.rmi.RMISecurityManager;
import java.rmi.RemoteException;
import java.rmi.server.UnicastRemoteObject;


public class RemoteSearchable
  extends UnicastRemoteObject
  implements Searchable {
  
  private Searchable local;
  
  
  public RemoteSearchable(Searchable local) throws RemoteException {
    super();
    this.local = local;
  }


  public void search(Weight weight, Filter filter, HitCollector results)
    throws IOException {
    local.search(weight, filter, results);
  }

  public void close() throws IOException {
    local.close();
  }

  public int docFreq(Term term) throws IOException {
    return local.docFreq(term);
  }


  public int[] docFreqs(Term[] terms) throws IOException {
    return local.docFreqs(terms);
  }

  public int maxDoc() throws IOException {
    return local.maxDoc();
  }

  public TopDocs search(Weight weight, Filter filter, int n) throws IOException {
    return local.search(weight, filter, n);
  }


  public TopFieldDocs search (Weight weight, Filter filter, int n, Sort sort)
  throws IOException {
    return local.search (weight, filter, n, sort);
  }

  public Document doc(int i) throws IOException {
    return local.doc(i);
  }

  public Query rewrite(Query original) throws IOException {
    return local.rewrite(original);
  }

  public Explanation explain(Weight weight, int doc) throws IOException {
    return local.explain(weight, doc);
  }

  /** Exports a searcher for the index in args[0] named
   * ""
  public static void main(String args[]) throws Exception {
    String indexName = null;
    
    if (args != null && args.length == 1)
      indexName = args[0];
    
    if (indexName == null) {
      System.out.println(""Usage: org.apache.lucene.search.RemoteSearchable <index>"");
      return;
    }
    
    
    if (System.getSecurityManager() == null) {
      System.setSecurityManager(new RMISecurityManager());
    }
    
    Searchable local = new IndexSearcher(indexName);
    RemoteSearchable impl = new RemoteSearchable(local);
      
    
    Naming.rebind(""
  }

}
"
lucene,2,org.apache.lucene.index.FilterIndexReader,24,2,0,9,49,0,0,9,19,0.0,142,1.0,1,0.705128205,0.21875,1,5,4.875,1,0.9583,4,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;

import java.io.IOException;
import java.util.Collection;


public class FilterIndexReader extends IndexReader {

  
  public static class FilterTermDocs implements TermDocs {
    protected TermDocs in;

    public FilterTermDocs(TermDocs in) { this.in = in; }

    public void seek(Term term) throws IOException { in.seek(term); }
    public void seek(TermEnum termEnum) throws IOException { in.seek(termEnum); }
    public int doc() { return in.doc(); }
    public int freq() { return in.freq(); }
    public boolean next() throws IOException { return in.next(); }
    public int read(int[] docs, int[] freqs) throws IOException {
      return in.read(docs, freqs);
    }
    public boolean skipTo(int i) throws IOException { return in.skipTo(i); }
    public void close() throws IOException { in.close(); }
  }

  
  public static class FilterTermPositions
          extends FilterTermDocs implements TermPositions {

    public FilterTermPositions(TermPositions in) { super(in); }

    public int nextPosition() throws IOException {
      return ((TermPositions) this.in).nextPosition();
    }
  }

  
  public static class FilterTermEnum extends TermEnum {
    protected TermEnum in;

    public FilterTermEnum(TermEnum in) { this.in = in; }

    public boolean next() throws IOException { return in.next(); }
    public Term term() { return in.term(); }
    public int docFreq() { return in.docFreq(); }
    public void close() throws IOException { in.close(); }
  }

  protected IndexReader in;

  
  public FilterIndexReader(IndexReader in) {
    super(in.directory());
    this.in = in;
  }

  public TermFreqVector[] getTermFreqVectors(int docNumber)
          throws IOException {
    return in.getTermFreqVectors(docNumber);
  }

  public TermFreqVector getTermFreqVector(int docNumber, String field)
          throws IOException {
    return in.getTermFreqVector(docNumber, field);
  }

  public int numDocs() { return in.numDocs(); }
  public int maxDoc() { return in.maxDoc(); }

  public Document document(int n) throws IOException { return in.document(n); }

  public boolean isDeleted(int n) { return in.isDeleted(n); }
  public boolean hasDeletions() { return in.hasDeletions(); }
  protected void doUndeleteAll() throws IOException { in.undeleteAll(); }

  public boolean hasNorms(String field) throws IOException {
    return in.hasNorms(field);
  }

  public byte[] norms(String f) throws IOException { return in.norms(f); }
  public void norms(String f, byte[] bytes, int offset) throws IOException {
    in.norms(f, bytes, offset);
  }
  protected void doSetNorm(int d, String f, byte b) throws IOException {
    in.setNorm(d, f, b);
  }

  public TermEnum terms() throws IOException { return in.terms(); }
  public TermEnum terms(Term t) throws IOException { return in.terms(t); }

  public int docFreq(Term t) throws IOException { return in.docFreq(t); }

  public TermDocs termDocs() throws IOException { return in.termDocs(); }

  public TermPositions termPositions() throws IOException {
    return in.termPositions();
  }

  protected void doDelete(int n) throws IOException { in.deleteDocument(n); }
  protected void doCommit() throws IOException { in.commit(); }
  protected void doClose() throws IOException { in.close(); }

  
  public Collection getFieldNames(IndexReader.FieldOption fieldNames) {
    return in.getFieldNames(fieldNames);
  }

  public long getVersion() { return in.getVersion(); }
  public boolean isCurrent() throws IOException { return in.isCurrent(); }
}
"
lucene,2,org.apache.lucene.queryParser.MultiFieldQueryParser,10,2,0,9,27,15,0,9,4,0.333333333,382,1.0,0,0.842105263,0.3375,1,6,37.1,1,0.9,1,"package org.apache.lucene.queryParser;



import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.MultiPhraseQuery;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;

import java.util.Vector;


public class MultiFieldQueryParser extends QueryParser
{
  
  private String[] fields;

  
  public MultiFieldQueryParser(String[] fields, Analyzer analyzer) {
    super(null, analyzer);
    this.fields = fields;
  }
  
  protected Query getFieldQuery(String field, String queryText, int slop) throws ParseException {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        Query q = super.getFieldQuery(fields[i], queryText);
        if (q != null) {
          if (q instanceof PhraseQuery) {
            ((PhraseQuery) q).setSlop(slop);
          }
          if (q instanceof MultiPhraseQuery) {
            ((MultiPhraseQuery) q).setSlop(slop);
          }
          clauses.add(new BooleanClause(q, BooleanClause.Occur.SHOULD));
        }
      }
      if (clauses.size() == 0)  
        return null;
      return getBooleanQuery(clauses, true);
    }
    return super.getFieldQuery(field, queryText);
  }
  

  protected Query getFieldQuery(String field, String queryText) throws ParseException {
    return getFieldQuery(field, queryText, 0);
  }


  protected Query getFuzzyQuery(String field, String termStr, float minSimilarity) throws ParseException
  {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(super.getFuzzyQuery(fields[i], termStr, minSimilarity),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getFuzzyQuery(field, termStr, minSimilarity);
  }

  protected Query getPrefixQuery(String field, String termStr) throws ParseException
  {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(super.getPrefixQuery(fields[i], termStr),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getPrefixQuery(field, termStr);
  }

  protected Query getWildcardQuery(String field, String termStr) throws ParseException {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(super.getWildcardQuery(fields[i], termStr),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getWildcardQuery(field, termStr);
  }

 
  protected Query getRangeQuery(String field, String part1, String part2, boolean inclusive) throws ParseException {
    if (field == null) {
      Vector clauses = new Vector();
      for (int i = 0; i < fields.length; i++) {
        clauses.add(new BooleanClause(super.getRangeQuery(fields[i], part1, part2, inclusive),
            BooleanClause.Occur.SHOULD));
      }
      return getBooleanQuery(clauses, true);
    }
    return super.getRangeQuery(field, part1, part2, inclusive);
  }
 



  
  public static Query parse(String[] queries, String[] fields,
      Analyzer analyzer) throws ParseException
  {
    if (queries.length != fields.length)
      throw new IllegalArgumentException(""queries.length != fields.length"");
    BooleanQuery bQuery = new BooleanQuery();
    for (int i = 0; i < fields.length; i++)
    {
      QueryParser qp = new QueryParser(fields[i], analyzer);
      Query q = qp.parse(queries[i]);
      bQuery.add(q, BooleanClause.Occur.SHOULD);
    }
    return bQuery;
  }


  
  public static Query parse(String query, String[] fields,
      BooleanClause.Occur[] flags, Analyzer analyzer) throws ParseException {
    if (fields.length != flags.length)
      throw new IllegalArgumentException(""fields.length != flags.length"");
    BooleanQuery bQuery = new BooleanQuery();
    for (int i = 0; i < fields.length; i++) {
      QueryParser qp = new QueryParser(fields[i], analyzer);
      Query q = qp.parse(query);
      bQuery.add(q, flags[i]);
    }
    return bQuery;
  }

  
  
  public static Query parse(String[] queries, String[] fields, BooleanClause.Occur[] flags,
      Analyzer analyzer) throws ParseException
  {
    if (!(queries.length == fields.length && queries.length == flags.length))
      throw new IllegalArgumentException(""queries, fields, and flags array have have different length"");
    BooleanQuery bQuery = new BooleanQuery();
    for (int i = 0; i < fields.length; i++)
    {
      QueryParser qp = new QueryParser(fields[i], analyzer);
      Query q = qp.parse(queries[i]);
      bQuery.add(q, flags[i]);
    }
    return bQuery;
  }

}
"
lucene,2,org.apache.lucene.index.SegmentMergeQueue,3,2,0,5,9,3,2,3,0,2.0,47,0.0,0,0.846153846,0.555555556,1,3,14.66666667,4,1.6667,0,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.util.PriorityQueue;

final class SegmentMergeQueue extends PriorityQueue {
  SegmentMergeQueue(int size) {
    initialize(size);
  }

  protected final boolean lessThan(Object a, Object b) {
    SegmentMergeInfo stiA = (SegmentMergeInfo)a;
    SegmentMergeInfo stiB = (SegmentMergeInfo)b;
    int comparison = stiA.term.compareTo(stiB.term);
    if (comparison == 0)
      return stiA.base < stiB.base; 
    else
      return comparison < 0;
  }

  final void close() throws IOException {
    while (top() != null)
      ((SegmentMergeInfo)pop()).close();
  }

}
"
lucene,2,org.apache.lucene.util.ToStringUtils,2,1,0,15,7,1,15,0,2,2.0,21,0.0,0,0.0,0.5,0,0,9.5,2,1.0,0,"package org.apache.lucene.util;



public class ToStringUtils {
  public static String boost(float boost) {
    if (boost != 1.0f) {
      return ""^"" + Float.toString(boost);
    } else return """";
  }
}
"
lucene,2,org.apache.lucene.search.ScoreDoc,1,1,1,19,2,0,19,0,1,2.0,12,0.0,0,0.0,1.0,0,0,9.0,0,0.0,0,"package org.apache.lucene.search;




public class ScoreDoc implements java.io.Serializable {
  
  public float score;

  
  public int doc;

  
  public ScoreDoc(int doc, float score) {
    this.doc = doc;
    this.score = score;
  }
}
"
lucene,2,org.apache.lucene.analysis.LengthFilter,2,3,0,3,6,0,0,3,2,0.0,41,0.0,0,0.75,0.666666667,0,0,18.5,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.IOException;


public final class LengthFilter extends TokenFilter {

  final int min;
  final int max;

  
  public LengthFilter(TokenStream in, int min, int max)
  {
    super(in);
    this.min = min;
    this.max = max;
  }

  
  public final Token next() throws IOException
  {
    
    for (Token token = input.next(); token != null; token = input.next())
    {
      int len = token.termText().length();
      if (len >= min && len <= max) {
          return token;
      }
      
    }
    
    return null;
  }
}
"
lucene,2,org.apache.lucene.search.IndexSearcher,14,2,0,19,32,1,3,17,13,0.346153846,157,0.5,1,0.6875,0.202380952,1,3,10.07142857,1,0.7143,2,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.BitSet;

import org.apache.lucene.store.Directory;
import org.apache.lucene.document.Document;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;


public class IndexSearcher extends Searcher {
  IndexReader reader;
  private boolean closeReader;

  
  public IndexSearcher(String path) throws IOException {
    this(IndexReader.open(path), true);
  }

  
  public IndexSearcher(Directory directory) throws IOException {
    this(IndexReader.open(directory), true);
  }

  
  public IndexSearcher(IndexReader r) {
    this(r, false);
  }
  
  private IndexSearcher(IndexReader r, boolean closeReader) {
    reader = r;
    this.closeReader = closeReader;
  }

  
  public IndexReader getIndexReader() {
    return reader;
  }

  
  public void close() throws IOException {
    if(closeReader)
      reader.close();
  }

  
  public int docFreq(Term term) throws IOException {
    return reader.docFreq(term);
  }

  
  public Document doc(int i) throws IOException {
    return reader.document(i);
  }

  
  public int maxDoc() throws IOException {
    return reader.maxDoc();
  }

  
  public TopDocs search(Weight weight, Filter filter, final int nDocs)
       throws IOException {

    if (nDocs <= 0)  
      throw new IllegalArgumentException(""nDocs must be > 0"");

    TopDocCollector collector = new TopDocCollector(nDocs);
    search(weight, filter, collector);
    return collector.topDocs();
  }

  
  public TopFieldDocs search(Weight weight, Filter filter, final int nDocs,
                             Sort sort)
      throws IOException {

    TopFieldDocCollector collector =
      new TopFieldDocCollector(reader, sort, nDocs);
    search(weight, filter, collector);
    return (TopFieldDocs)collector.topDocs();
  }

  
  public void search(Weight weight, Filter filter,
                     final HitCollector results) throws IOException {
    HitCollector collector = results;
    if (filter != null) {
      final BitSet bits = filter.bits(reader);
      collector = new HitCollector() {
          public final void collect(int doc, float score) {
            if (bits.get(doc)) {                  
              results.collect(doc, score);
            }
          }
        };
    }

    Scorer scorer = weight.scorer(reader);
    if (scorer == null)
      return;
    scorer.score(collector);
  }

  public Query rewrite(Query original) throws IOException {
    Query query = original;
    for (Query rewrittenQuery = query.rewrite(reader); rewrittenQuery != query;
         rewrittenQuery = query.rewrite(reader)) {
      query = rewrittenQuery;
    }
    return query;
  }

  public Explanation explain(Weight weight, int doc) throws IOException {
    return weight.explain(reader, doc);
  }
}
"
lucene,2,org.apache.lucene.queryParser.ParseException,5,3,0,3,18,0,2,1,4,0.55,387,0.4,1,0.866666667,0.4,1,1,75.4,14,4.8,0,"
package org.apache.lucene.queryParser;


public class ParseException extends Exception {

  
  public ParseException(Token currentTokenVal,
                        int[][] expectedTokenSequencesVal,
                        String[] tokenImageVal
                       )
  {
    super("""");
    specialConstructor = true;
    currentToken = currentTokenVal;
    expectedTokenSequences = expectedTokenSequencesVal;
    tokenImage = tokenImageVal;
  }

  

  public ParseException() {
    super();
    specialConstructor = false;
  }

  public ParseException(String message) {
    super(message);
    specialConstructor = false;
  }

  
  protected boolean specialConstructor;

  
  public Token currentToken;

  
  public int[][] expectedTokenSequences;

  
  public String[] tokenImage;

  
  public String getMessage() {
    if (!specialConstructor) {
      return super.getMessage();
    }
    String expected = """";
    int maxSize = 0;
    for (int i = 0; i < expectedTokenSequences.length; i++) {
      if (maxSize < expectedTokenSequences[i].length) {
        maxSize = expectedTokenSequences[i].length;
      }
      for (int j = 0; j < expectedTokenSequences[i].length; j++) {
        expected += tokenImage[expectedTokenSequences[i][j]] + "" "";
      }
      if (expectedTokenSequences[i][expectedTokenSequences[i].length - 1] != 0) {
        expected += ""..."";
      }
      expected += eol + ""    "";
    }
    String retval = ""Encountered \"""";
    Token tok = currentToken.next;
    for (int i = 0; i < maxSize; i++) {
      if (i != 0) retval += "" "";
      if (tok.kind == 0) {
        retval += tokenImage[0];
        break;
      }
      retval += add_escapes(tok.image);
      tok = tok.next; 
    }
    retval += ""\"" at line "" + currentToken.next.beginLine + "", column "" + currentToken.next.beginColumn;
    retval += ""."" + eol;
    if (expectedTokenSequences.length == 1) {
      retval += ""Was expecting:"" + eol + ""    "";
    } else {
      retval += ""Was expecting one of:"" + eol + ""    "";
    }
    retval += expected;
    return retval;
  }

  
  protected String eol = System.getProperty(""line.separator"", ""\n"");
 
  
  protected String add_escapes(String str) {
      StringBuffer retval = new StringBuffer();
      char ch;
      for (int i = 0; i < str.length(); i++) {
        switch (str.charAt(i))
        {
           case 0 :
              continue;
           case '\b':
              retval.append(""\\b"");
              continue;
           case '\t':
              retval.append(""\\t"");
              continue;
           case '\n':
              retval.append(""\\n"");
              continue;
           case '\f':
              retval.append(""\\f"");
              continue;
           case '\r':
              retval.append(""\\r"");
              continue;
           case '\""':
              retval.append(""\\\"""");
              continue;
           case '\'':
              retval.append(""\\\'"");
              continue;
           case '\\':
              retval.append(""\\\\"");
              continue;
           default:
              if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {
                 String s = ""0000"" + Integer.toString(ch, 16);
                 retval.append(""\\u"" + s.substring(s.length() - 4, s.length()));
              } else {
                 retval.append(ch);
              }
              continue;
        }
      }
      return retval.toString();
   }

}
"
lucene,2,org.apache.lucene.search.Weight,6,1,0,40,6,15,37,4,6,2.0,6,0.0,0,0.0,0.416666667,0,0,0.0,1,1.0,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;


public interface Weight extends java.io.Serializable {
  
  Query getQuery();

  
  float getValue();

  
  float sumOfSquaredWeights() throws IOException;

  
  void normalize(float norm);

  
  Scorer scorer(IndexReader reader) throws IOException;

  
  Explanation explain(IndexReader reader, int doc) throws IOException;
}
"
lucene,2,org.apache.lucene.search.Scorer,9,1,15,33,11,34,30,3,7,0.875,47,1.0,1,0.0,0.416666667,0,0,4.111111111,1,0.8889,0,"package org.apache.lucene.search;



import java.io.IOException;


public abstract class Scorer {
  private Similarity similarity;

  
  protected Scorer(Similarity similarity) {
    this.similarity = similarity;
  }

  
  public Similarity getSimilarity() {
    return this.similarity;
  }

  
  public void score(HitCollector hc) throws IOException {
    while (next()) {
      hc.collect(doc(), score());
    }
  }

  
  protected boolean score(HitCollector hc, int max) throws IOException {
    while (doc() < max) {
      hc.collect(doc(), score());
      if (!next())
        return false;
    }
    return true;
  }

  
  public abstract boolean next() throws IOException;

  
  public abstract int doc();

  
  public abstract float score() throws IOException;

  
  public abstract boolean skipTo(int target) throws IOException;

  
  public abstract Explanation explain(int doc) throws IOException;

}
"
lucene,2,org.apache.lucene.index.IndexReader,57,1,4,80,108,1504,66,16,43,0.867346939,724,1.0,3,0.0,0.115288221,0,0,11.57894737,12,1.1754,11,"package org.apache.lucene.index;



import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.Lock;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.Arrays;
import java.util.Collection;


public abstract class IndexReader {
  
  public static final class FieldOption {
    private String option;
    private FieldOption() { }
    private FieldOption(String option) {
      this.option = option;
    } 
    public String toString() {
      return this.option;
    }
    
    public static final FieldOption ALL = new FieldOption (""ALL"");
    
    public static final FieldOption INDEXED = new FieldOption (""INDEXED"");
    
    public static final FieldOption UNINDEXED = new FieldOption (""UNINDEXED"");
    
    public static final FieldOption INDEXED_WITH_TERMVECTOR = new FieldOption (""INDEXED_WITH_TERMVECTOR"");
    
    public static final FieldOption INDEXED_NO_TERMVECTOR = new FieldOption (""INDEXED_NO_TERMVECTOR"");
    
    public static final FieldOption TERMVECTOR = new FieldOption (""TERMVECTOR"");
    
    public static final FieldOption TERMVECTOR_WITH_POSITION = new FieldOption (""TERMVECTOR_WITH_POSITION"");
    
    public static final FieldOption TERMVECTOR_WITH_OFFSET = new FieldOption (""TERMVECTOR_WITH_OFFSET"");
    
    public static final FieldOption TERMVECTOR_WITH_POSITION_OFFSET = new FieldOption (""TERMVECTOR_WITH_POSITION_OFFSET"");
  }
  
  
  protected IndexReader(Directory directory) {
    this.directory = directory;
  }
  
  
  IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory) {
    init(directory, segmentInfos, closeDirectory, true);
  }

  void init(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory, boolean directoryOwner) {
    this.directory = directory;
    this.segmentInfos = segmentInfos;
    this.directoryOwner = directoryOwner;
    this.closeDirectory = closeDirectory;
  }

  private Directory directory;
  private boolean directoryOwner;
  private boolean closeDirectory;

  private SegmentInfos segmentInfos;
  private Lock writeLock;
  private boolean stale;
  private boolean hasChanges;
  

  
  public static IndexReader open(String path) throws IOException {
    return open(FSDirectory.getDirectory(path, false), true);
  }

  
  public static IndexReader open(File path) throws IOException {
    return open(FSDirectory.getDirectory(path, false), true);
  }
  
  
  public static IndexReader open(final Directory directory) throws IOException {
    return open(directory, false);
  }

  private static IndexReader open(final Directory directory, final boolean closeDirectory) throws IOException {
    synchronized (directory) {			  
      return (IndexReader)new Lock.With(
          directory.makeLock(IndexWriter.COMMIT_LOCK_NAME),
          IndexWriter.COMMIT_LOCK_TIMEOUT) {
          public Object doBody() throws IOException {
            SegmentInfos infos = new SegmentInfos();
            infos.read(directory);
            if (infos.size() == 1) {		  
              return SegmentReader.get(infos, infos.info(0), closeDirectory);
            }
            IndexReader[] readers = new IndexReader[infos.size()];
            for (int i = 0; i < infos.size(); i++)
              readers[i] = SegmentReader.get(infos.info(i));
            return new MultiReader(directory, infos, closeDirectory, readers);
            
          }
        }.run();
    }
  }

  
  public Directory directory() { return directory; }

  
  public static long lastModified(String directory) throws IOException {
    return lastModified(new File(directory));
  }

  
  public static long lastModified(File directory) throws IOException {
    return FSDirectory.fileModified(directory, IndexFileNames.SEGMENTS);
  }

  
  public static long lastModified(Directory directory) throws IOException {
    return directory.fileModified(IndexFileNames.SEGMENTS);
  }

  
  public static long getCurrentVersion(String directory) throws IOException {
    return getCurrentVersion(new File(directory));
  }

  
  public static long getCurrentVersion(File directory) throws IOException {
    Directory dir = FSDirectory.getDirectory(directory, false);
    long version = getCurrentVersion(dir);
    dir.close();
    return version;
  }

  
  public static long getCurrentVersion(Directory directory) throws IOException {
    synchronized (directory) {                 
      Lock commitLock=directory.makeLock(IndexWriter.COMMIT_LOCK_NAME);
      
      boolean locked=false;
      
      try {
         locked=commitLock.obtain(IndexWriter.COMMIT_LOCK_TIMEOUT);
         
         return SegmentInfos.readCurrentVersion(directory);
      } finally {
        if (locked) {
          commitLock.release();
        }
      }
    }
  }
  
  
  public long getVersion() {
    return segmentInfos.getVersion();
  }

  
  public boolean isCurrent() throws IOException {
    synchronized (directory) {                 
      Lock commitLock=directory.makeLock(IndexWriter.COMMIT_LOCK_NAME);
      
      boolean locked=false;
      
      try {
         locked=commitLock.obtain(IndexWriter.COMMIT_LOCK_TIMEOUT);
         
         return SegmentInfos.readCurrentVersion(directory) == segmentInfos.getVersion();
      } finally {
        if (locked) {
          commitLock.release();
        }
      }
    }
  }

  
  abstract public TermFreqVector[] getTermFreqVectors(int docNumber)
          throws IOException;

  
  
  abstract public TermFreqVector getTermFreqVector(int docNumber, String field)
          throws IOException;
 
  
  public static boolean indexExists(String directory) {
    return (new File(directory, IndexFileNames.SEGMENTS)).exists();
  }

  
  public static boolean indexExists(File directory) {
    return (new File(directory, IndexFileNames.SEGMENTS)).exists();
  }

  
  public static boolean indexExists(Directory directory) throws IOException {
    return directory.fileExists(IndexFileNames.SEGMENTS);
  }

  
  public abstract int numDocs();

  
  public abstract int maxDoc();

  
  public abstract Document document(int n) throws IOException;

  
  public abstract boolean isDeleted(int n);

  
  public abstract boolean hasDeletions();
  
  
  public boolean hasNorms(String field) throws IOException {
    
    
    return norms(field) != null;
  }

  
  public abstract byte[] norms(String field) throws IOException;

  
  public abstract void norms(String field, byte[] bytes, int offset)
    throws IOException;

  
  public final synchronized  void setNorm(int doc, String field, byte value)
          throws IOException{
    if(directoryOwner)
      aquireWriteLock();
    doSetNorm(doc, field, value);
    hasChanges = true;
  }
          
  
  protected abstract void doSetNorm(int doc, String field, byte value) 
          throws IOException;

  
  public void setNorm(int doc, String field, float value)
          throws IOException {
    setNorm(doc, field, Similarity.encodeNorm(value));
  }

  
  public abstract TermEnum terms() throws IOException;

  
  public abstract TermEnum terms(Term t) throws IOException;

  
  public abstract int docFreq(Term t) throws IOException;

  
  public TermDocs termDocs(Term term) throws IOException {
    TermDocs termDocs = termDocs();
    termDocs.seek(term);
    return termDocs;
  }

  
  public abstract TermDocs termDocs() throws IOException;

  
  public TermPositions termPositions(Term term) throws IOException {
    TermPositions termPositions = termPositions();
    termPositions.seek(term);
    return termPositions;
  }

  
  public abstract TermPositions termPositions() throws IOException;

  
  private void aquireWriteLock() throws IOException {
    if (stale)
      throw new IOException(""IndexReader out of date and no longer valid for delete, undelete, or setNorm operations"");

    if (writeLock == null) {
      Lock writeLock = directory.makeLock(IndexWriter.WRITE_LOCK_NAME);
      if (!writeLock.obtain(IndexWriter.WRITE_LOCK_TIMEOUT)) 
        throw new IOException(""Index locked for write: "" + writeLock);
      this.writeLock = writeLock;

      
      
      if (SegmentInfos.readCurrentVersion(directory) > segmentInfos.getVersion()) {
        stale = true;
        this.writeLock.release();
        this.writeLock = null;
        throw new IOException(""IndexReader out of date and no longer valid for delete, undelete, or setNorm operations"");
      }
    }
  }


  
  public final synchronized void deleteDocument(int docNum) throws IOException {
    if(directoryOwner)
      aquireWriteLock();
    doDelete(docNum);
    hasChanges = true;
  }


  
  protected abstract void doDelete(int docNum) throws IOException;


  
  public final int deleteDocuments(Term term) throws IOException {
    TermDocs docs = termDocs(term);
    if (docs == null) return 0;
    int n = 0;
    try {
      while (docs.next()) {
        deleteDocument(docs.doc());
        n++;
      }
    } finally {
      docs.close();
    }
    return n;
  }

  
  public final synchronized void undeleteAll() throws IOException{
    if(directoryOwner)
      aquireWriteLock();
    doUndeleteAll();
    hasChanges = true;
  }
  
  
  protected abstract void doUndeleteAll() throws IOException;

  
  protected final synchronized void commit() throws IOException{
    if(hasChanges){
      if(directoryOwner){
        synchronized (directory) {      
           new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME),
                   IndexWriter.COMMIT_LOCK_TIMEOUT) {
             public Object doBody() throws IOException {
               doCommit();
               segmentInfos.write(directory);
               return null;
             }
           }.run();
         }
        if (writeLock != null) {
          writeLock.release();  
          writeLock = null;
        }
      }
      else
        doCommit();
    }
    hasChanges = false;
  }
  
  
  protected abstract void doCommit() throws IOException;
  
  
  public final synchronized void close() throws IOException {
    commit();
    doClose();
    if(closeDirectory)
      directory.close();
  }

  
  protected abstract void doClose() throws IOException;

  
  protected void finalize() {
    if (writeLock != null) {
      writeLock.release();                        
      writeLock = null;
    }
  }

  
  
  public abstract Collection getFieldNames(FieldOption fldOption);

  
  public static boolean isLocked(Directory directory) throws IOException {
    return
            directory.makeLock(IndexWriter.WRITE_LOCK_NAME).isLocked() ||
            directory.makeLock(IndexWriter.COMMIT_LOCK_NAME).isLocked();
  }

  
  public static boolean isLocked(String directory) throws IOException {
    Directory dir = FSDirectory.getDirectory(directory, false);
    boolean result = isLocked(dir);
    dir.close();
    return result;
  }

  
  public static void unlock(Directory directory) throws IOException {
    directory.makeLock(IndexWriter.WRITE_LOCK_NAME).release();
    directory.makeLock(IndexWriter.COMMIT_LOCK_NAME).release();
  }
  
  
  public static void main(String [] args) {
    String filename = null;
    boolean extract = false;

    for (int i = 0; i < args.length; ++i) {
      if (args[i].equals(""-extract"")) {
        extract = true;
      } else if (filename == null) {
        filename = args[i];
      }
    }

    if (filename == null) {
      System.out.println(""Usage: org.apache.lucene.index.IndexReader [-extract] <cfsfile>"");
      return;
    }

    Directory dir = null;
    CompoundFileReader cfr = null;
      
    try {
      File file = new File(filename);
      String dirname = file.getAbsoluteFile().getParent();
      filename = file.getName();
      dir = FSDirectory.getDirectory(dirname, false);
      cfr = new CompoundFileReader(dir, filename);

      String [] files = cfr.list();
      Arrays.sort(files);   
      
      for (int i = 0; i < files.length; ++i) {
        long len = cfr.fileLength(files[i]);

        if (extract) {
          System.out.println(""extract "" + files[i] + "" with "" + len + "" bytes to local directory..."");
          IndexInput ii = cfr.openInput(files[i]);

          FileOutputStream f = new FileOutputStream(files[i]);
          
          
          byte[] buffer = new byte[1024];
          int chunk = buffer.length;
          while(len > 0) {
            final int bufLen = (int) Math.min(chunk, len);
            ii.readBytes(buffer, 0, bufLen);
            f.write(buffer, 0, bufLen);
            len -= bufLen;
          }
          
          f.close();
          ii.close();
        }
        else
          System.out.println(files[i] + "": "" + len + "" bytes"");
      }
    } catch (IOException ioe) {
      ioe.printStackTrace();
    }
    finally {
      try {
        if (dir != null)
          dir.close();
        if (cfr != null)
          cfr.close();
      }
      catch (IOException ioe) {
        ioe.printStackTrace();
      }
    }
  }
}
"
lucene,2,org.apache.lucene.analysis.StopAnalyzer,7,2,0,6,13,0,1,5,6,0.5,197,0.5,0,0.666666667,0.333333333,0,0,26.85714286,1,0.1429,0,"package org.apache.lucene.analysis;



import java.io.File;
import java.io.IOException;
import java.io.Reader;
import java.util.Set;



public final class StopAnalyzer extends Analyzer {
  private Set stopWords;

  
  public static final String[] ENGLISH_STOP_WORDS = {
    ""a"", ""an"", ""and"", ""are"", ""as"", ""at"", ""be"", ""but"", ""by"",
    ""for"", ""if"", ""in"", ""into"", ""is"", ""it"",
    ""no"", ""not"", ""of"", ""on"", ""or"", ""s"", ""such"",
    ""t"", ""that"", ""the"", ""their"", ""then"", ""there"", ""these"",
    ""they"", ""this"", ""to"", ""was"", ""will"", ""with""
  };

  
  public StopAnalyzer() {
    stopWords = StopFilter.makeStopSet(ENGLISH_STOP_WORDS);
  }

  
  public StopAnalyzer(Set stopWords) {
    this.stopWords = stopWords;
  }

  
  public StopAnalyzer(String[] stopWords) {
    this.stopWords = StopFilter.makeStopSet(stopWords);
  }
  
  
  public StopAnalyzer(File stopwordsFile) throws IOException {
    stopWords = WordlistLoader.getWordSet(stopwordsFile);
  }

  
  public StopAnalyzer(Reader stopwords) throws IOException {
    stopWords = WordlistLoader.getWordSet(stopwords);
  }

  
  public TokenStream tokenStream(String fieldName, Reader reader) {
    return new StopFilter(new LowerCaseTokenizer(reader), stopWords);
  }
}

"
lucene,2,org.apache.lucene.index.TermVectorsReader,9,1,0,8,36,8,1,7,0,0.625,648,1.0,4,0.0,0.24691358,0,0,70.22222222,4,1.2222,2,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;

import java.io.IOException;


class TermVectorsReader implements Cloneable {
  private FieldInfos fieldInfos;

  private IndexInput tvx;
  private IndexInput tvd;
  private IndexInput tvf;
  private int size;
  
  private int tvdFormat;
  private int tvfFormat;

  TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos)
    throws IOException {
    if (d.fileExists(segment + TermVectorsWriter.TVX_EXTENSION)) {
      tvx = d.openInput(segment + TermVectorsWriter.TVX_EXTENSION);
      checkValidFormat(tvx);
      tvd = d.openInput(segment + TermVectorsWriter.TVD_EXTENSION);
      tvdFormat = checkValidFormat(tvd);
      tvf = d.openInput(segment + TermVectorsWriter.TVF_EXTENSION);
      tvfFormat = checkValidFormat(tvf);
      size = (int) tvx.length() / 8;
    }

    this.fieldInfos = fieldInfos;
  }
  
  private int checkValidFormat(IndexInput in) throws IOException
  {
    int format = in.readInt();
    if (format > TermVectorsWriter.FORMAT_VERSION)
    {
      throw new IOException(""Incompatible format version: "" + format + "" expected "" 
              + TermVectorsWriter.FORMAT_VERSION + "" or less"");
    }
    return format;
  }

  void close() throws IOException {
  	
  	
  	IOException keep = null;
  	if (tvx != null) try { tvx.close(); } catch (IOException e) { if (keep == null) keep = e; }
  	if (tvd != null) try { tvd.close(); } catch (IOException e) { if (keep == null) keep = e; }
  	if (tvf  != null) try {  tvf.close(); } catch (IOException e) { if (keep == null) keep = e; }
  	if (keep != null) throw (IOException) keep.fillInStackTrace();
  }

  
  int size() {
    return size;
  }

   
  TermFreqVector get(int docNum, String field) throws IOException {
    
    int fieldNumber = fieldInfos.fieldNumber(field);
    TermFreqVector result = null;
    if (tvx != null) {
      
      
      
      
      tvx.seek((docNum * 8L) + TermVectorsWriter.FORMAT_SIZE);
      
      long position = tvx.readLong();

      tvd.seek(position);
      int fieldCount = tvd.readVInt();
      
      
      
      
      int number = 0;
      int found = -1;
      for (int i = 0; i < fieldCount; i++) {
        if(tvdFormat == TermVectorsWriter.FORMAT_VERSION)
          number = tvd.readVInt();
        else
          number += tvd.readVInt();
        
        if (number == fieldNumber)
          found = i;
      }

      
      
      if (found != -1) {
        
        position = 0;
        for (int i = 0; i <= found; i++)
          position += tvd.readVLong();

        result = readTermVector(field, position);
      } else {
        
      }
    } else {
      
    }
    return result;
  }

  
  TermFreqVector[] get(int docNum) throws IOException {
    TermFreqVector[] result = null;
    
    if (tvx != null) {
      
      tvx.seek((docNum * 8L) + TermVectorsWriter.FORMAT_SIZE);
      long position = tvx.readLong();

      tvd.seek(position);
      int fieldCount = tvd.readVInt();

      
      if (fieldCount != 0) {
        int number = 0;
        String[] fields = new String[fieldCount];
        
        for (int i = 0; i < fieldCount; i++) {
          if(tvdFormat == TermVectorsWriter.FORMAT_VERSION)
            number = tvd.readVInt();
          else
            number += tvd.readVInt();

          fields[i] = fieldInfos.fieldName(number);
        }

        
        position = 0;
        long[] tvfPointers = new long[fieldCount];
        for (int i = 0; i < fieldCount; i++) {
          position += tvd.readVLong();
          tvfPointers[i] = position;
        }

        result = readTermVectors(fields, tvfPointers);
      }
    } else {
      
    }
    return result;
  }


  private SegmentTermVector[] readTermVectors(String fields[], long tvfPointers[])
          throws IOException {
    SegmentTermVector res[] = new SegmentTermVector[fields.length];
    for (int i = 0; i < fields.length; i++) {
      res[i] = readTermVector(fields[i], tvfPointers[i]);
    }
    return res;
  }

   
  private SegmentTermVector readTermVector(String field, long tvfPointer)
          throws IOException {

    
    
    tvf.seek(tvfPointer);

    int numTerms = tvf.readVInt();
    
    
    if (numTerms == 0) 
      return new SegmentTermVector(field, null, null);
    
    boolean storePositions;
    boolean storeOffsets;
    
    if(tvfFormat == TermVectorsWriter.FORMAT_VERSION){
      byte bits = tvf.readByte();
      storePositions = (bits & TermVectorsWriter.STORE_POSITIONS_WITH_TERMVECTOR) != 0;
      storeOffsets = (bits & TermVectorsWriter.STORE_OFFSET_WITH_TERMVECTOR) != 0;
    }
    else{
      tvf.readVInt();
      storePositions = false;
      storeOffsets = false;
    }

    String terms[] = new String[numTerms];
    int termFreqs[] = new int[numTerms];
    
    
    int positions[][] = null;
    TermVectorOffsetInfo offsets[][] = null;
    if(storePositions)
      positions = new int[numTerms][];
    if(storeOffsets)
      offsets = new TermVectorOffsetInfo[numTerms][];
    
    int start = 0;
    int deltaLength = 0;
    int totalLength = 0;
    char [] buffer = new char[10];    
    char[] previousBuffer = {};
    
    for (int i = 0; i < numTerms; i++) {
      start = tvf.readVInt();
      deltaLength = tvf.readVInt();
      totalLength = start + deltaLength;
      if (buffer.length < totalLength) {  
        buffer = null;    
        buffer = new char[totalLength];
        
        if (start > 0)  
          System.arraycopy(previousBuffer, 0, buffer, 0, start);
      }
      
      tvf.readChars(buffer, start, deltaLength);
      terms[i] = new String(buffer, 0, totalLength);
      previousBuffer = buffer;
      int freq = tvf.readVInt();
      termFreqs[i] = freq;
      
      if (storePositions) { 
        int [] pos = new int[freq];
        positions[i] = pos;
        int prevPosition = 0;
        for (int j = 0; j < freq; j++)
        {
          pos[j] = prevPosition + tvf.readVInt();
          prevPosition = pos[j];
        }
      }
      
      if (storeOffsets) {
        TermVectorOffsetInfo[] offs = new TermVectorOffsetInfo[freq];
        offsets[i] = offs;
        int prevOffset = 0;
        for (int j = 0; j < freq; j++) {
          int startOffset = prevOffset + tvf.readVInt();
          int endOffset = startOffset + tvf.readVInt();
          offs[j] = new TermVectorOffsetInfo(startOffset, endOffset);
          prevOffset = endOffset;
        }
      }
    }
    
    SegmentTermVector tv;
    if (storePositions || storeOffsets){
      tv = new SegmentTermPositionVector(field, terms, termFreqs, positions, offsets);
    }
    else {
      tv = new SegmentTermVector(field, terms, termFreqs);
    }
    return tv;
  }

  protected Object clone() {
    
    if (tvx == null || tvd == null || tvf == null)
      return null;
    
    TermVectorsReader clone = null;
    try {
      clone = (TermVectorsReader) super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.tvx = (IndexInput) tvx.clone();
    clone.tvd = (IndexInput) tvd.clone();
    clone.tvf = (IndexInput) tvf.clone();
    
    return clone;
  }
}
"
lucene,2,org.apache.lucene.analysis.standard.StandardTokenizerTokenManager,22,1,0,5,38,153,1,4,7,0.848484848,3709,0.121212121,1,0.0,0.380952381,0,0,166.0909091,236,13.7727,1,"
package org.apache.lucene.analysis.standard;
import java.io.*;

public class StandardTokenizerTokenManager implements StandardTokenizerConstants
{
  public  java.io.PrintStream debugStream = System.out;
  public  void setDebugStream(java.io.PrintStream ds) { debugStream = ds; }
private final int jjMoveStringLiteralDfa0_0()
{
   return jjMoveNfa_0(0, 0);
}
private final void jjCheckNAdd(int state)
{
   if (jjrounds[state] != jjround)
   {
      jjstateSet[jjnewStateCnt++] = state;
      jjrounds[state] = jjround;
   }
}
private final void jjAddStates(int start, int end)
{
   do {
      jjstateSet[jjnewStateCnt++] = jjnextStates[start];
   } while (start++ != end);
}
private final void jjCheckNAddTwoStates(int state1, int state2)
{
   jjCheckNAdd(state1);
   jjCheckNAdd(state2);
}
private final void jjCheckNAddStates(int start, int end)
{
   do {
      jjCheckNAdd(jjnextStates[start]);
   } while (start++ != end);
}
private final void jjCheckNAddStates(int start)
{
   jjCheckNAdd(jjnextStates[start]);
   jjCheckNAdd(jjnextStates[start + 1]);
}
static final long[] jjbitVec0 = {
   0x1ff0000000000000L, 0xffffffffffffc000L, 0xffffffffL, 0x600000000000000L
};
static final long[] jjbitVec2 = {
   0x0L, 0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffffffL
};
static final long[] jjbitVec3 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffL, 0x0L
};
static final long[] jjbitVec4 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0x0L, 0x0L
};
static final long[] jjbitVec5 = {
   0x3fffffffffffL, 0x0L, 0x0L, 0x0L
};
static final long[] jjbitVec6 = {
   0x0L, 0x0L, 0xfffff00000000000L, 0x7fffffL
};
static final long[] jjbitVec7 = {
   0xffffffffffffffffL, 0xffffffffffffffffL, 0xffffffffffffL, 0x0L
};
static final long[] jjbitVec8 = {
   0xfffffffeL, 0x0L, 0x0L, 0x0L
};
static final long[] jjbitVec9 = {
   0x0L, 0x0L, 0x0L, 0xff7fffffff7fffffL
};
static final long[] jjbitVec10 = {
   0x1600L, 0x0L, 0x0L, 0x0L
};
static final long[] jjbitVec11 = {
   0x0L, 0xffc000000000L, 0x0L, 0xffc000000000L
};
static final long[] jjbitVec12 = {
   0x0L, 0x3ff00000000L, 0x0L, 0x3ff000000000000L
};
static final long[] jjbitVec13 = {
   0x0L, 0xffc000000000L, 0x0L, 0xff8000000000L
};
static final long[] jjbitVec14 = {
   0x0L, 0xffc000000000L, 0x0L, 0x0L
};
static final long[] jjbitVec15 = {
   0x0L, 0x3ff0000L, 0x0L, 0x3ff0000L
};
static final long[] jjbitVec16 = {
   0x0L, 0x3ffL, 0x0L, 0x0L
};
static final long[] jjbitVec17 = {
   0xfffffffeL, 0x0L, 0xfffff00000000000L, 0x7fffffL
};
private final int jjMoveNfa_0(int startState, int curPos)
{
   int[] nextStates;
   int startsAt = 0;
   jjnewStateCnt = 75;
   int i = 1;
   jjstateSet[0] = startState;
   int j, kind = 0x7fffffff;
   for (;;)
   {
      if (++jjround == 0x7fffffff)
         ReInitRounds();
      if (curChar < 64)
      {
         long l = 1L << curChar;
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x3ff000000000000L & l) != 0L)
                  {
                     if (kind > 1)
                        kind = 1;
                     jjCheckNAddStates(0, 11);
                  }
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(12, 17);
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 2:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 3:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(3, 4);
                  break;
               case 4:
               case 5:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(5, 6);
                  break;
               case 6:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(7);
                  break;
               case 7:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(7);
                  break;
               case 8:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(8, 9);
                  break;
               case 9:
               case 10:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 11:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(12);
                  break;
               case 12:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(12, 13);
                  break;
               case 13:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 14:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 15:
               case 16:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 17:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(17, 18);
                  break;
               case 18:
               case 19:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(19, 20);
                  break;
               case 20:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(21);
                  break;
               case 21:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(21, 22);
                  break;
               case 22:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 23:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 24:
               case 25:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(25, 26);
                  break;
               case 26:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(27);
                  break;
               case 27:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(22, 27);
                  break;
               case 28:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(12, 17);
                  break;
               case 29:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAddStates(0, 11);
                  break;
               case 30:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAdd(30);
                  break;
               case 31:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(24, 26);
                  break;
               case 32:
                  if ((0x600000000000L & l) != 0L)
                     jjCheckNAdd(33);
                  break;
               case 33:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddStates(27, 29);
                  break;
               case 35:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(35, 36);
                  break;
               case 36:
                  if ((0x600000000000L & l) != 0L)
                     jjCheckNAdd(37);
                  break;
               case 37:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 5)
                     kind = 5;
                  jjCheckNAddTwoStates(36, 37);
                  break;
               case 38:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(38, 39);
                  break;
               case 39:
                  if (curChar == 46)
                     jjCheckNAdd(40);
                  break;
               case 40:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 6)
                     kind = 6;
                  jjCheckNAddTwoStates(39, 40);
                  break;
               case 41:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(41, 42);
                  break;
               case 42:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 43:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 44:
               case 45:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(45);
                  break;
               case 46:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(46, 47);
                  break;
               case 47:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 48:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 49:
               case 50:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(50, 51);
                  break;
               case 51:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(52);
                  break;
               case 52:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(47, 52);
                  break;
               case 53:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(53, 54);
                  break;
               case 54:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 55:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 56:
               case 57:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 58:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAdd(59);
                  break;
               case 59:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(59, 60);
                  break;
               case 60:
                  if ((0xf00000000000L & l) != 0L)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 61:
                  if ((0x3ff000000000000L & l) != 0L)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 62:
               case 63:
                  if ((0x3ff000000000000L & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 66:
                  if (curChar == 39)
                     jjstateSet[jjnewStateCnt++] = 67;
                  break;
               case 69:
                  if (curChar == 46)
                     jjCheckNAdd(70);
                  break;
               case 71:
                  if (curChar != 46)
                     break;
                  if (kind > 3)
                     kind = 3;
                  jjCheckNAdd(70);
                  break;
               case 73:
                  if (curChar == 38)
                     jjstateSet[jjnewStateCnt++] = 74;
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else if (curChar < 128)
      {
         long l = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(30, 35);
                  if ((0x7fffffe07fffffeL & l) != 0L)
                  {
                     if (kind > 1)
                        kind = 1;
                     jjCheckNAddStates(0, 11);
                  }
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 2:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(18, 23);
                  break;
               case 3:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(3, 4);
                  break;
               case 5:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(36, 37);
                  break;
               case 6:
                  if (curChar == 95)
                     jjCheckNAdd(7);
                  break;
               case 7:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(7);
                  break;
               case 8:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(8, 9);
                  break;
               case 10:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 11:
                  if (curChar == 95)
                     jjCheckNAdd(12);
                  break;
               case 12:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(12, 13);
                  break;
               case 13:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 14:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(14, 15);
                  break;
               case 16:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 17:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(17, 18);
                  break;
               case 19:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(38, 39);
                  break;
               case 20:
                  if (curChar == 95)
                     jjCheckNAdd(21);
                  break;
               case 21:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(21, 22);
                  break;
               case 22:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 23:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(23, 24);
                  break;
               case 25:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(40, 41);
                  break;
               case 26:
                  if (curChar == 95)
                     jjCheckNAdd(27);
                  break;
               case 27:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(22, 27);
                  break;
               case 29:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAddStates(0, 11);
                  break;
               case 30:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAdd(30);
                  break;
               case 31:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(24, 26);
                  break;
               case 32:
                  if (curChar == 95)
                     jjCheckNAdd(33);
                  break;
               case 33:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(27, 29);
                  break;
               case 34:
                  if (curChar == 64)
                     jjCheckNAdd(35);
                  break;
               case 35:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(35, 36);
                  break;
               case 37:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 5)
                     kind = 5;
                  jjCheckNAddTwoStates(36, 37);
                  break;
               case 38:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(38, 39);
                  break;
               case 40:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 6)
                     kind = 6;
                  jjCheckNAddTwoStates(39, 40);
                  break;
               case 41:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(41, 42);
                  break;
               case 42:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 43:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(43, 44);
                  break;
               case 45:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjstateSet[jjnewStateCnt++] = 45;
                  break;
               case 46:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(46, 47);
                  break;
               case 47:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 48:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(48, 49);
                  break;
               case 50:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(42, 43);
                  break;
               case 51:
                  if (curChar == 95)
                     jjCheckNAdd(52);
                  break;
               case 52:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(47, 52);
                  break;
               case 53:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(53, 54);
                  break;
               case 54:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 55:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(55, 56);
                  break;
               case 57:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 58:
                  if (curChar == 95)
                     jjCheckNAdd(59);
                  break;
               case 59:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(59, 60);
                  break;
               case 60:
                  if (curChar == 95)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 61:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(61, 62);
                  break;
               case 63:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 64:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddStates(30, 35);
                  break;
               case 65:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(65, 66);
                  break;
               case 67:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 2)
                     kind = 2;
                  jjCheckNAddTwoStates(66, 67);
                  break;
               case 68:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(68, 69);
                  break;
               case 70:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjAddStates(44, 45);
                  break;
               case 72:
                  if ((0x7fffffe07fffffeL & l) != 0L)
                     jjCheckNAddTwoStates(72, 73);
                  break;
               case 73:
                  if (curChar == 64)
                     jjCheckNAdd(74);
                  break;
               case 74:
                  if ((0x7fffffe07fffffeL & l) == 0L)
                     break;
                  if (kind > 4)
                     kind = 4;
                  jjCheckNAdd(74);
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      else
      {
         int hiByte = (int)(curChar >> 8);
         int i1 = hiByte >> 6;
         long l1 = 1L << (hiByte & 077);
         int i2 = (curChar & 0xff) >> 6;
         long l2 = 1L << (curChar & 077);
         MatchLoop: do
         {
            switch(jjstateSet[--i])
            {
               case 0:
                  if (jjCanMove_0(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 12)
                        kind = 12;
                  }
                  if (jjCanMove_1(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 13)
                        kind = 13;
                  }
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(18, 23);
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(12, 17);
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                  {
                     if (kind > 1)
                        kind = 1;
                     jjCheckNAddStates(0, 11);
                  }
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(30, 35);
                  break;
               case 1:
                  if (jjCanMove_1(hiByte, i1, i2, l1, l2) && kind > 13)
                     kind = 13;
                  break;
               case 2:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(18, 23);
                  break;
               case 3:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(3, 4);
                  break;
               case 4:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(5, 6);
                  break;
               case 5:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(5, 6);
                  break;
               case 7:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjstateSet[jjnewStateCnt++] = 7;
                  break;
               case 8:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(8, 9);
                  break;
               case 9:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 10:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(10, 11);
                  break;
               case 12:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjAddStates(46, 47);
                  break;
               case 14:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(48, 49);
                  break;
               case 15:
                  if (!jjCanMove_3(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 16:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(11, 16);
                  break;
               case 17:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(17, 18);
                  break;
               case 18:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(19, 20);
                  break;
               case 19:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(19, 20);
                  break;
               case 21:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(21, 22);
                  break;
               case 23:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(50, 51);
                  break;
               case 24:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(25, 26);
                  break;
               case 25:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(25, 26);
                  break;
               case 27:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(22, 27);
                  break;
               case 28:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(12, 17);
                  break;
               case 29:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAddStates(0, 11);
                  break;
               case 30:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 1)
                     kind = 1;
                  jjCheckNAdd(30);
                  break;
               case 31:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(24, 26);
                  break;
               case 33:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(27, 29);
                  break;
               case 35:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(35, 36);
                  break;
               case 37:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 5)
                     kind = 5;
                  jjCheckNAddTwoStates(36, 37);
                  break;
               case 38:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(38, 39);
                  break;
               case 40:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 6)
                     kind = 6;
                  jjCheckNAddTwoStates(39, 40);
                  break;
               case 41:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(41, 42);
                  break;
               case 43:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(52, 53);
                  break;
               case 44:
                  if (!jjCanMove_3(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(45);
                  break;
               case 45:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAdd(45);
                  break;
               case 46:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(46, 47);
                  break;
               case 48:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(54, 55);
                  break;
               case 49:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(50, 51);
                  break;
               case 50:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(50, 51);
                  break;
               case 52:
                  if (!jjCanMove_4(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(47, 52);
                  break;
               case 53:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(53, 54);
                  break;
               case 55:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(56, 57);
                  break;
               case 56:
                  if (jjCanMove_3(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 57:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(57, 58);
                  break;
               case 59:
                  if (jjCanMove_4(hiByte, i1, i2, l1, l2))
                     jjAddStates(58, 59);
                  break;
               case 61:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(60, 61);
                  break;
               case 62:
                  if (!jjCanMove_3(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 63:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 7)
                     kind = 7;
                  jjCheckNAddTwoStates(58, 63);
                  break;
               case 64:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddStates(30, 35);
                  break;
               case 65:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(65, 66);
                  break;
               case 67:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 2)
                     kind = 2;
                  jjCheckNAddTwoStates(66, 67);
                  break;
               case 68:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(68, 69);
                  break;
               case 70:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjAddStates(44, 45);
                  break;
               case 72:
                  if (jjCanMove_2(hiByte, i1, i2, l1, l2))
                     jjCheckNAddTwoStates(72, 73);
                  break;
               case 74:
                  if (!jjCanMove_2(hiByte, i1, i2, l1, l2))
                     break;
                  if (kind > 4)
                     kind = 4;
                  jjstateSet[jjnewStateCnt++] = 74;
                  break;
               default : break;
            }
         } while(i != startsAt);
      }
      if (kind != 0x7fffffff)
      {
         jjmatchedKind = kind;
         jjmatchedPos = curPos;
         kind = 0x7fffffff;
      }
      ++curPos;
      if ((i = jjnewStateCnt) == (startsAt = 75 - (jjnewStateCnt = startsAt)))
         return curPos;
      try { curChar = input_stream.readChar(); }
      catch(java.io.IOException e) { return curPos; }
   }
}
static final int[] jjnextStates = {
   30, 31, 32, 34, 38, 39, 41, 42, 46, 47, 53, 54, 5, 6, 10, 11, 
   19, 20, 3, 4, 8, 9, 17, 18, 31, 32, 34, 32, 33, 34, 65, 66, 
   68, 69, 72, 73, 5, 6, 19, 20, 25, 26, 50, 51, 70, 71, 12, 13, 
   14, 15, 23, 24, 43, 44, 48, 49, 55, 56, 59, 60, 61, 62, 
};
private static final boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 48:
         return ((jjbitVec2[i2] & l2) != 0L);
      case 49:
         return ((jjbitVec3[i2] & l2) != 0L);
      case 51:
         return ((jjbitVec4[i2] & l2) != 0L);
      case 61:
         return ((jjbitVec5[i2] & l2) != 0L);
      default : 
         if ((jjbitVec0[i1] & l1) != 0L)
            return true;
         return false;
   }
}
private static final boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 215:
         return ((jjbitVec7[i2] & l2) != 0L);
      default : 
         if ((jjbitVec6[i1] & l1) != 0L)
            return true;
         return false;
   }
}
private static final boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 0:
         return ((jjbitVec9[i2] & l2) != 0L);
      default : 
         if ((jjbitVec8[i1] & l1) != 0L)
            return true;
         return false;
   }
}
private static final boolean jjCanMove_3(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 6:
         return ((jjbitVec12[i2] & l2) != 0L);
      case 11:
         return ((jjbitVec13[i2] & l2) != 0L);
      case 13:
         return ((jjbitVec14[i2] & l2) != 0L);
      case 14:
         return ((jjbitVec15[i2] & l2) != 0L);
      case 16:
         return ((jjbitVec16[i2] & l2) != 0L);
      default : 
         if ((jjbitVec10[i1] & l1) != 0L)
            if ((jjbitVec11[i2] & l2) == 0L)
               return false;
            else
            return true;
         return false;
   }
}
private static final boolean jjCanMove_4(int hiByte, int i1, int i2, long l1, long l2)
{
   switch(hiByte)
   {
      case 0:
         return ((jjbitVec9[i2] & l2) != 0L);
      case 215:
         return ((jjbitVec7[i2] & l2) != 0L);
      default : 
         if ((jjbitVec17[i1] & l1) != 0L)
            return true;
         return false;
   }
}
public static final String[] jjstrLiteralImages = {
"""", null, null, null, null, null, null, null, null, null, null, null, null, 
null, null, null, };
public static final String[] lexStateNames = {
   ""DEFAULT"", 
};
static final long[] jjtoToken = {
   0x30ffL, 
};
static final long[] jjtoSkip = {
   0x8000L, 
};
protected CharStream input_stream;
private final int[] jjrounds = new int[75];
private final int[] jjstateSet = new int[150];
protected char curChar;
public StandardTokenizerTokenManager(CharStream stream)
{
   input_stream = stream;
}
public StandardTokenizerTokenManager(CharStream stream, int lexState)
{
   this(stream);
   SwitchTo(lexState);
}
public void ReInit(CharStream stream)
{
   jjmatchedPos = jjnewStateCnt = 0;
   curLexState = defaultLexState;
   input_stream = stream;
   ReInitRounds();
}
private final void ReInitRounds()
{
   int i;
   jjround = 0x80000001;
   for (i = 75; i-- > 0;)
      jjrounds[i] = 0x80000000;
}
public void ReInit(CharStream stream, int lexState)
{
   ReInit(stream);
   SwitchTo(lexState);
}
public void SwitchTo(int lexState)
{
   if (lexState >= 1 || lexState < 0)
      throw new TokenMgrError(""Error: Ignoring invalid lexical state : "" + lexState + "". State unchanged."", TokenMgrError.INVALID_LEXICAL_STATE);
   else
      curLexState = lexState;
}

protected Token jjFillToken()
{
   Token t = Token.newToken(jjmatchedKind);
   t.kind = jjmatchedKind;
   String im = jjstrLiteralImages[jjmatchedKind];
   t.image = (im == null) ? input_stream.GetImage() : im;
   t.beginLine = input_stream.getBeginLine();
   t.beginColumn = input_stream.getBeginColumn();
   t.endLine = input_stream.getEndLine();
   t.endColumn = input_stream.getEndColumn();
   return t;
}

int curLexState = 0;
int defaultLexState = 0;
int jjnewStateCnt;
int jjround;
int jjmatchedPos;
int jjmatchedKind;

public Token getNextToken() 
{
  int kind;
  Token specialToken = null;
  Token matchedToken;
  int curPos = 0;

  EOFLoop :
  for (;;)
  {   
   try   
   {     
      curChar = input_stream.BeginToken();
   }     
   catch(java.io.IOException e)
   {        
      jjmatchedKind = 0;
      matchedToken = jjFillToken();
      return matchedToken;
   }

   jjmatchedKind = 0x7fffffff;
   jjmatchedPos = 0;
   curPos = jjMoveStringLiteralDfa0_0();
   if (jjmatchedPos == 0 && jjmatchedKind > 15)
   {
      jjmatchedKind = 15;
   }
   if (jjmatchedKind != 0x7fffffff)
   {
      if (jjmatchedPos + 1 < curPos)
         input_stream.backup(curPos - jjmatchedPos - 1);
      if ((jjtoToken[jjmatchedKind >> 6] & (1L << (jjmatchedKind & 077))) != 0L)
      {
         matchedToken = jjFillToken();
         return matchedToken;
      }
      else
      {
         continue EOFLoop;
      }
   }
   int error_line = input_stream.getEndLine();
   int error_column = input_stream.getEndColumn();
   String error_after = null;
   boolean EOFSeen = false;
   try { input_stream.readChar(); input_stream.backup(1); }
   catch (java.io.IOException e1) {
      EOFSeen = true;
      error_after = curPos <= 1 ? """" : input_stream.GetImage();
      if (curChar == '\n' || curChar == '\r') {
         error_line++;
         error_column = 0;
      }
      else
         error_column++;
   }
   if (!EOFSeen) {
      input_stream.backup(1);
      error_after = curPos <= 1 ? """" : input_stream.GetImage();
   }
   throw new TokenMgrError(EOFSeen, curLexState, error_line, error_column, error_after, curChar, TokenMgrError.LEXICAL_ERROR);
  }
}

}
"
lucene,2,org.apache.lucene.analysis.ISOLatin1AccentFilter,3,3,0,3,16,3,0,3,3,2.0,178,0.0,0,0.6,0.444444444,0,0,58.33333333,3,1.3333,1,"package org.apache.lucene.analysis;




public class ISOLatin1AccentFilter extends TokenFilter {
	public ISOLatin1AccentFilter(TokenStream input) {
		super(input);
	}

	public final Token next() throws java.io.IOException {
		final Token t = input.next();
		if (t == null)
			return null;
		
		return new Token(removeAccents(t.termText()), t.startOffset(), t.endOffset(), t.type());
	}

	
	public final static String removeAccents(String input) {
		final StringBuffer output = new StringBuffer();
		for (int i = 0; i < input.length(); i++) {
			switch (input.charAt(i)) {
				case '\u00C0' : 
				case '\u00C1' : 
				case '\u00C2' : 
				case '\u00C3' : 
				case '\u00C4' : 
				case '\u00C5' : 
					output.append(""A"");
					break;
				case '\u00C6' : 
					output.append(""AE"");
					break;
				case '\u00C7' : 
					output.append(""C"");
					break;
				case '\u00C8' : 
				case '\u00C9' : 
				case '\u00CA' : 
				case '\u00CB' : 
					output.append(""E"");
					break;
				case '\u00CC' : 
				case '\u00CD' : 
				case '\u00CE' : 
				case '\u00CF' : 
					output.append(""I"");
					break;
				case '\u00D0' : 
					output.append(""D"");
					break;
				case '\u00D1' : 
					output.append(""N"");
					break;
				case '\u00D2' : 
				case '\u00D3' : 
				case '\u00D4' : 
				case '\u00D5' : 
				case '\u00D6' : 
				case '\u00D8' : 
					output.append(""O"");
					break;
				case '\u0152' : 
					output.append(""OE"");
					break;
				case '\u00DE' : 
					output.append(""TH"");
					break;
				case '\u00D9' : 
				case '\u00DA' : 
				case '\u00DB' : 
				case '\u00DC' : 
					output.append(""U"");
					break;
				case '\u00DD' : 
				case '\u0178' : 
					output.append(""Y"");
					break;
				case '\u00E0' : 
				case '\u00E1' : 
				case '\u00E2' : 
				case '\u00E3' : 
				case '\u00E4' : 
				case '\u00E5' : 
					output.append(""a"");
					break;
				case '\u00E6' : 
					output.append(""ae"");
					break;
				case '\u00E7' : 
					output.append(""c"");
					break;
				case '\u00E8' : 
				case '\u00E9' : 
				case '\u00EA' : 
				case '\u00EB' : 
					output.append(""e"");
					break;
				case '\u00EC' : 
				case '\u00ED' : 
				case '\u00EE' : 
				case '\u00EF' : 
					output.append(""i"");
					break;
				case '\u00F0' : 
					output.append(""d"");
					break;
				case '\u00F1' : 
					output.append(""n"");
					break;
				case '\u00F2' : 
				case '\u00F3' : 
				case '\u00F4' : 
				case '\u00F5' : 
				case '\u00F6' : 
				case '\u00F8' : 
					output.append(""o"");
					break;
				case '\u0153' : 
					output.append(""oe"");
					break;
				case '\u00DF' : 
					output.append(""ss"");
					break;
				case '\u00FE' : 
					output.append(""th"");
					break;
				case '\u00F9' : 
				case '\u00FA' : 
				case '\u00FB' : 
				case '\u00FC' : 
					output.append(""u"");
					break;
				case '\u00FD' : 
				case '\u00FF' : 
					output.append(""y"");
					break;
				default :
					output.append(input.charAt(i));
					break;
			}
		}
		return output.toString();
	}
}"
lucene,2,org.apache.lucene.search.SortField,15,1,0,9,22,0,8,1,14,0.852040816,297,0.285714286,3,0.0,0.380952381,0,0,17.86666667,7,0.8,0,"package org.apache.lucene.search;



import java.io.Serializable;
import java.util.Locale;


public class SortField
implements Serializable {

  
  public static final int SCORE = 0;

  
  public static final int DOC = 1;

  
  public static final int AUTO = 2;

  
  public static final int STRING = 3;

  
  public static final int INT = 4;

  
  public static final int FLOAT = 5;

  
  public static final int CUSTOM = 9;

  
  
  


  
  public static final SortField FIELD_SCORE = new SortField (null, SCORE);

  
  public static final SortField FIELD_DOC = new SortField (null, DOC);


  private String field;
  private int type = AUTO;  
  private Locale locale;    
  boolean reverse = false;  
  private SortComparatorSource factory;

  
  public SortField (String field) {
    this.field = field.intern();
  }

  
  public SortField (String field, boolean reverse) {
    this.field = field.intern();
    this.reverse = reverse;
  }

  
  public SortField (String field, int type) {
    this.field = (field != null) ? field.intern() : field;
    this.type = type;
  }

  
  public SortField (String field, int type, boolean reverse) {
    this.field = (field != null) ? field.intern() : field;
    this.type = type;
    this.reverse = reverse;
  }

  
  public SortField (String field, Locale locale) {
    this.field = field.intern();
    this.type = STRING;
    this.locale = locale;
  }

  
  public SortField (String field, Locale locale, boolean reverse) {
    this.field = field.intern();
    this.type = STRING;
    this.locale = locale;
    this.reverse = reverse;
  }

  
  public SortField (String field, SortComparatorSource comparator) {
    this.field = (field != null) ? field.intern() : field;
    this.type = CUSTOM;
    this.factory = comparator;
  }

  
  public SortField (String field, SortComparatorSource comparator, boolean reverse) {
    this.field = (field != null) ? field.intern() : field;
    this.type = CUSTOM;
    this.reverse = reverse;
    this.factory = comparator;
  }

  
  public String getField() {
    return field;
  }

  
  public int getType() {
    return type;
  }

  
  public Locale getLocale() {
    return locale;
  }

  
  public boolean getReverse() {
    return reverse;
  }

  public SortComparatorSource getFactory() {
    return factory;
  }

  public String toString() {
    StringBuffer buffer = new StringBuffer();
    switch (type) {
      case SCORE: buffer.append(""<score>"");
                  break;

      case DOC: buffer.append(""<doc>"");
                break;

      case CUSTOM: buffer.append (""<custom:\"""" + field + ""\"": ""
                                               + factory + "">"");
                break;

      default: buffer.append(""\"""" + field + ""\"""");
               break;
    }

    if (locale != null) buffer.append (""(""+locale+"")"");
    if (reverse) buffer.append('!');

    return buffer.toString();
  }
}
"
lucene,2,org.apache.lucene.queryParser.FastCharStream,14,1,0,2,25,3,1,1,13,0.602564103,237,0.0,0,0.0,0.404761905,0,0,15.5,1,0.9286,0,"
package org.apache.lucene.queryParser;



import java.io.*;


public final class FastCharStream implements CharStream {
  char[] buffer = null;

  int bufferLength = 0;				  
  int bufferPosition = 0;			  

  int tokenStart = 0;				  
  int bufferStart = 0;				  

  Reader input;					  

  
  public FastCharStream(Reader r) {
    input = r;
  }

  public final char readChar() throws IOException {
    if (bufferPosition >= bufferLength)
      refill();
    return buffer[bufferPosition++];
  }

  private final void refill() throws IOException {
    int newPosition = bufferLength - tokenStart;

    if (tokenStart == 0) {			  
      if (buffer == null) {			  
	buffer = new char[2048];
      } else if (bufferLength == buffer.length) { 
	char[] newBuffer = new char[buffer.length*2];
	System.arraycopy(buffer, 0, newBuffer, 0, bufferLength);
	buffer = newBuffer;
      }
    } else {					  
      System.arraycopy(buffer, tokenStart, buffer, 0, newPosition);
    }

    bufferLength = newPosition;			  
    bufferPosition = newPosition;
    bufferStart += tokenStart;
    tokenStart = 0;

    int charsRead =				  
      input.read(buffer, newPosition, buffer.length-newPosition);
    if (charsRead == -1)
      throw new IOException(""read past eof"");
    else
      bufferLength += charsRead;
  }

  public final char BeginToken() throws IOException {
    tokenStart = bufferPosition;
    return readChar();
  }

  public final void backup(int amount) {
    bufferPosition -= amount;
  }

  public final String GetImage() {
    return new String(buffer, tokenStart, bufferPosition - tokenStart);
  }

  public final char[] GetSuffix(int len) {
    char[] value = new char[len];
    System.arraycopy(buffer, bufferPosition - len, value, 0, len);
    return value;
  }

  public final void Done() {
    try {
      input.close();
    } catch (IOException e) {
      System.err.println(""Caught: "" + e + ""; ignoring."");
    }
  }

  public final int getColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getLine() {
    return 1;
  }
  public final int getEndColumn() {
    return bufferStart + bufferPosition;
  }
  public final int getEndLine() {
    return 1;
  }
  public final int getBeginColumn() {
    return bufferStart + tokenStart;
  }
  public final int getBeginLine() {
    return 1;
  }
}
"
lucene,2,org.apache.lucene.search.WildcardTermEnum,6,3,0,5,20,5,1,4,5,0.825,247,0.0,1,0.722222222,0.333333333,1,4,38.83333333,16,3.6667,0,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;


public class WildcardTermEnum extends FilteredTermEnum {
  Term searchTerm;
  String field = """";
  String text = """";
  String pre = """";
  int preLen = 0;
  boolean endEnum = false;

  
  public WildcardTermEnum(IndexReader reader, Term term) throws IOException {
    super();
    searchTerm = term;
    field = searchTerm.field();
    text = searchTerm.text();

    int sidx = text.indexOf(WILDCARD_STRING);
    int cidx = text.indexOf(WILDCARD_CHAR);
    int idx = sidx;
    if (idx == -1) {
      idx = cidx;
    }
    else if (cidx >= 0) {
      idx = Math.min(idx, cidx);
    }

    pre = searchTerm.text().substring(0,idx);
    preLen = pre.length();
    text = text.substring(preLen);
    setEnum(reader.terms(new Term(searchTerm.field(), pre)));
  }

  protected final boolean termCompare(Term term) {
    if (field == term.field()) {
      String searchText = term.text();
      if (searchText.startsWith(pre)) {
        return wildcardEquals(text, 0, searchText, preLen);
      }
    }
    endEnum = true;
    return false;
  }

  public final float difference() {
    return 1.0f;
  }

  public final boolean endEnum() {
    return endEnum;
  }

  

  public static final char WILDCARD_STRING = '*';
  public static final char WILDCARD_CHAR = '?';

  
  public static final boolean wildcardEquals(String pattern, int patternIdx,
    String string, int stringIdx)
  {
    int p = patternIdx;
    
    for (int s = stringIdx; ; ++p, ++s)
      {
        
        boolean sEnd = (s >= string.length());
        
        boolean pEnd = (p >= pattern.length());

        
        if (sEnd)
        {
          
          boolean justWildcardsLeft = true;

          
          int wildcardSearchPos = p;
          
          
          while (wildcardSearchPos < pattern.length() && justWildcardsLeft)
          {
            
            char wildchar = pattern.charAt(wildcardSearchPos);
            
            
            
            if (wildchar != WILDCARD_CHAR && wildchar != WILDCARD_STRING)
            {
              justWildcardsLeft = false;
            }
            else
            {
              
              if (wildchar == WILDCARD_CHAR) {
                return false;
              }
              
              
              wildcardSearchPos++;
            }
          }

          
          
          if (justWildcardsLeft)
          {
            return true;
          }
        }

        
        
        if (sEnd || pEnd)
        {
          break;
        }

        
        if (pattern.charAt(p) == WILDCARD_CHAR)
        {
          continue;
        }

        
        if (pattern.charAt(p) == WILDCARD_STRING)
        {
          
          ++p;
          
          for (int i = string.length(); i >= s; --i)
          {
            if (wildcardEquals(pattern, p, string, i))
            {
              return true;
            }
          }
          break;
        }
        if (pattern.charAt(p) != string.charAt(s))
        {
          break;
        }
      }
      return false;
  }

  public void close() throws IOException
  {
    super.close();
    searchTerm = null;
    field = null;
    text = null;
  }
}
"
lucene,2,org.apache.lucene.search.Sort,14,1,0,12,22,61,11,1,13,0.692307692,175,0.0,3,0.0,0.320512821,0,0,11.28571429,3,0.7143,0,"package org.apache.lucene.search;



import java.io.Serializable;



public class Sort
implements Serializable {

  
  public static final Sort RELEVANCE = new Sort();

  
  public static final Sort INDEXORDER = new Sort(SortField.FIELD_DOC);

  
  SortField[] fields;

  
  public Sort() {
    this(new SortField[] { SortField.FIELD_SCORE, SortField.FIELD_DOC });
  }

  
  public Sort(String field) {
    setSort(field, false);
  }

  
  public Sort(String field, boolean reverse) {
    setSort(field, reverse);
  }

  
  public Sort(String[] fields) {
    setSort(fields);
  }

  
  public Sort(SortField field) {
    setSort(field);
  }

  
  public Sort(SortField[] fields) {
    setSort(fields);
  }

  
  public final void setSort(String field) {
    setSort(field, false);
  }

  
  public void setSort(String field, boolean reverse) {
    SortField[] nfields = new SortField[] {
        new SortField(field, SortField.AUTO, reverse), SortField.FIELD_DOC };
    fields = nfields;
  }

  
  public void setSort(String[] fieldnames) {
    final int n = fieldnames.length;
    SortField[] nfields = new SortField[n];
    for (int i = 0; i < n; ++i) {
      nfields[i] = new SortField(fieldnames[i], SortField.AUTO);
    }
    fields = nfields;
  }

  
  public void setSort(SortField field) {
    this.fields = new SortField[] { field };
  }

  
  public void setSort(SortField[] fields) {
    this.fields = fields;
  }
  
  
  public SortField[] getSort() {
    return fields;
  }

  public String toString() {
    StringBuffer buffer = new StringBuffer();

    for (int i = 0; i < fields.length; i++) {
      buffer.append(fields[i].toString());
      if ((i+1) < fields.length)
        buffer.append(',');
    }

    return buffer.toString();
  }
}
"
lucene,2,org.apache.lucene.search.DefaultSimilarity,7,2,0,3,10,21,3,1,7,2.0,54,0.0,0,0.7,0.5,1,2,6.714285714,1,0.8571,0,"package org.apache.lucene.search;




public class DefaultSimilarity extends Similarity {
  
  public float lengthNorm(String fieldName, int numTerms) {
    return (float)(1.0 / Math.sqrt(numTerms));
  }
  
  
  public float queryNorm(float sumOfSquaredWeights) {
    return (float)(1.0 / Math.sqrt(sumOfSquaredWeights));
  }

  
  public float tf(float freq) {
    return (float)Math.sqrt(freq);
  }
    
  
  public float sloppyFreq(int distance) {
    return 1.0f / (distance + 1);
  }
    
  
  public float idf(int docFreq, int numDocs) {
    return (float)(Math.log(numDocs/(double)(docFreq+1)) + 1.0);
  }
    
  
  public float coord(int overlap, int maxOverlap) {
    return overlap / (float)maxOverlap;
  }
}
"
lucene,2,org.apache.lucene.search.ConstantScoreRangeQuery,10,2,0,5,24,0,0,5,10,0.444444444,313,1.0,0,0.571428571,0.3,2,3,29.8,13,3.1,0,"package org.apache.lucene.search;



import org.apache.lucene.index.IndexReader;

import java.io.IOException;



public class ConstantScoreRangeQuery extends Query
{
  private final String fieldName;
  private final String lowerVal;
  private final String upperVal;
  private final boolean includeLower;
  private final boolean includeUpper;


  public ConstantScoreRangeQuery(String fieldName, String lowerVal, String upperVal, boolean includeLower, boolean includeUpper)
  {
    
    
    if (lowerVal==null) {
      includeLower=true;
    } else if (includeLower && lowerVal.equals("""")) {
      lowerVal=null;
    }
    if (upperVal==null) {
      includeUpper=true;
    }


    this.fieldName = fieldName.intern();  
    this.lowerVal = lowerVal;
    this.upperVal = upperVal;
    this.includeLower = includeLower;
    this.includeUpper = includeUpper;
  }

  
  public String getField() { return fieldName; }
  
  public String getLowerVal() { return lowerVal; }
  
  public String getUpperVal() { return upperVal; }
  
  public boolean includesLower() { return includeLower; }
  
  public boolean includesUpper() { return includeUpper; }

  public Query rewrite(IndexReader reader) throws IOException {
    
    RangeFilter rangeFilt = new RangeFilter(fieldName,
            lowerVal!=null?lowerVal:"""",
            upperVal, lowerVal==""""?false:includeLower, upperVal==null?false:includeUpper);
    Query q = new ConstantScoreQuery(rangeFilt);
    q.setBoost(getBoost());
    return q;
  }

    
    public String toString(String field)
    {
        StringBuffer buffer = new StringBuffer();
        if (!getField().equals(field))
        {
            buffer.append(getField());
            buffer.append("":"");
        }
        buffer.append(includeLower ? '[' : '{');
        buffer.append(lowerVal != null ? lowerVal : ""*"");
        buffer.append("" TO "");
        buffer.append(upperVal != null ? upperVal : ""*"");
        buffer.append(includeUpper ? ']' : '}');
        if (getBoost() != 1.0f)
        {
            buffer.append(""^"");
            buffer.append(Float.toString(getBoost()));
        }
        return buffer.toString();
    }

    
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof ConstantScoreRangeQuery)) return false;
        ConstantScoreRangeQuery other = (ConstantScoreRangeQuery) o;

        if (this.fieldName != other.fieldName  
            || this.includeLower != other.includeLower
            || this.includeUpper != other.includeUpper
           ) { return false; }
        if (this.lowerVal != null ? !this.lowerVal.equals(other.lowerVal) : other.lowerVal != null) return false;
        if (this.upperVal != null ? !this.upperVal.equals(other.upperVal) : other.upperVal != null) return false;
        return this.getBoost() == other.getBoost();
    }

    
    public int hashCode() {
      int h = Float.floatToIntBits(getBoost()) ^ fieldName.hashCode();
      
      h ^= lowerVal != null ? lowerVal.hashCode() : 0x965a965a;
      
      
      h ^= (h << 17) | (h >>> 16);  
      h ^= (upperVal != null ? (upperVal.hashCode()) : 0x5a695a69);
      h ^= (includeLower ? 0x665599aa : 0)
         ^ (includeUpper ? 0x99aa5566 : 0);
      return h;
    }
}
"
lucene,2,org.apache.lucene.analysis.TokenFilter,2,2,6,7,4,0,6,1,1,0.0,13,1.0,1,0.666666667,0.75,0,0,5.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.IOException;



public abstract class TokenFilter extends TokenStream {
  
  protected TokenStream input;

  
  protected TokenFilter(TokenStream input) {
    this.input = input;
  }

  
  public void close() throws IOException {
    input.close();
  }

}

"
lucene,2,org.apache.lucene.search.PhraseQueue,2,2,0,5,4,1,3,2,0,2.0,37,0.0,0,0.916666667,0.666666667,1,3,17.5,4,2.0,1,"package org.apache.lucene.search;



import org.apache.lucene.util.PriorityQueue;

final class PhraseQueue extends PriorityQueue {
  PhraseQueue(int size) {
    initialize(size);
  }

  protected final boolean lessThan(Object o1, Object o2) {
    PhrasePositions pp1 = (PhrasePositions)o1;
    PhrasePositions pp2 = (PhrasePositions)o2;
    if (pp1.doc == pp2.doc) 
      return pp1.position < pp2.position;
    else
      return pp1.doc < pp2.doc;
  }
}
"
lucene,2,org.apache.lucene.store.MMapDirectory,2,3,0,5,10,1,0,5,2,1.0,48,1.0,0,0.972222222,0.75,0,0,22.5,1,0.5,0,"package org.apache.lucene.store;


 
import java.io.IOException;
import java.io.File;
import java.io.RandomAccessFile;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.channels.FileChannel.MapMode;


public class MMapDirectory extends FSDirectory {

  private static class MMapIndexInput extends IndexInput {

    private ByteBuffer buffer;
    private final long length;

    private MMapIndexInput(RandomAccessFile raf) throws IOException {
        this.length = raf.length();
        this.buffer = raf.getChannel().map(MapMode.READ_ONLY, 0, length);
    }

    public byte readByte() throws IOException {
      return buffer.get();
    }

    public void readBytes(byte[] b, int offset, int len)
      throws IOException {
      buffer.get(b, offset, len);
    }

    public long getFilePointer() {
      return buffer.position();
    }

    public void seek(long pos) throws IOException {
      buffer.position((int)pos);
    }

    public long length() {
      return length;
    }

    public Object clone() {
      MMapIndexInput clone = (MMapIndexInput)super.clone();
      clone.buffer = buffer.duplicate();
      return clone;
    }

    public void close() throws IOException {}
  }

  private static class MultiMMapIndexInput extends IndexInput {
  
    private ByteBuffer[] buffers;
    private int[] bufSizes; 
  
    private final long length;
  
    private int curBufIndex;
    private final int maxBufSize;
  
    private ByteBuffer curBuf; 
    private int curAvail; 
  
    
    public MultiMMapIndexInput(RandomAccessFile raf, int maxBufSize)
      throws IOException {
      this.length = raf.length();
      this.maxBufSize = maxBufSize;
      
      if (maxBufSize <= 0)
        throw new IllegalArgumentException(""Non positive maxBufSize: ""
                                           + maxBufSize);
      
      if ((length / maxBufSize) > Integer.MAX_VALUE)
        throw new IllegalArgumentException
          (""RandomAccessFile too big for maximum buffer size: ""
           + raf.toString());
      
      int nrBuffers = (int) (length / maxBufSize);
      if ((nrBuffers * maxBufSize) < length) nrBuffers++;
      
      this.buffers = new ByteBuffer[nrBuffers];
      this.bufSizes = new int[nrBuffers];
      
      long bufferStart = 0;
      FileChannel rafc = raf.getChannel();
      for (int bufNr = 0; bufNr < nrBuffers; bufNr++) { 
        int bufSize = (length > (bufferStart + maxBufSize))
          ? maxBufSize
          : (int) (length - bufferStart);
        this.buffers[bufNr] = rafc.map(MapMode.READ_ONLY,bufferStart,bufSize);
        this.bufSizes[bufNr] = bufSize;
        bufferStart += bufSize;
      }
      seek(0L);
    }
  
    public byte readByte() throws IOException {
      
      
      if (curAvail == 0) {
        curBufIndex++;
        curBuf = buffers[curBufIndex]; 
        curBuf.position(0);
        curAvail = bufSizes[curBufIndex];
      }
      curAvail--;
      return curBuf.get();
    }
  
    public void readBytes(byte[] b, int offset, int len) throws IOException {
      while (len > curAvail) {
        curBuf.get(b, offset, curAvail);
        len -= curAvail;
        offset += curAvail;
        curBufIndex++;
        curBuf = buffers[curBufIndex]; 
        curBuf.position(0);
        curAvail = bufSizes[curBufIndex];
      }
      curBuf.get(b, offset, len);
      curAvail -= len;
    }
  
    public long getFilePointer() {
      return (curBufIndex * (long) maxBufSize) + curBuf.position();
    }
  
    public void seek(long pos) throws IOException {
      curBufIndex = (int) (pos / maxBufSize);
      curBuf = buffers[curBufIndex];
      int bufOffset = (int) (pos - (curBufIndex * maxBufSize));
      curBuf.position(bufOffset);
      curAvail = bufSizes[curBufIndex] - bufOffset;
    }
  
    public long length() {
      return length;
    }
  
    public Object clone() {
      MultiMMapIndexInput clone = (MultiMMapIndexInput)super.clone();
      clone.buffers = new ByteBuffer[buffers.length];
      
      
      
      for (int bufNr = 0; bufNr < buffers.length; bufNr++) {
        clone.buffers[bufNr] = buffers[bufNr].duplicate();
      }
      try {
        clone.seek(getFilePointer());
      } catch(IOException ioe) {
        RuntimeException newException = new RuntimeException(ioe);
        newException.initCause(ioe);
        throw newException;
      };
      return clone;
    }
  
    public void close() throws IOException {}
  }
  
  private final int MAX_BBUF = Integer.MAX_VALUE;

  public IndexInput openInput(String name) throws IOException {
    File f =  new File(getFile(), name);
    RandomAccessFile raf = new RandomAccessFile(f, ""r"");
    try {
      return (raf.length() <= MAX_BBUF)
             ? (IndexInput) new MMapIndexInput(raf)
             : (IndexInput) new MultiMMapIndexInput(raf, MAX_BBUF);
    } finally {
      raf.close();
    }
  }
}
"
lucene,2,org.apache.lucene.search.Explanation,11,1,0,33,19,41,33,0,10,0.633333333,186,1.0,0,0.0,0.309090909,0,0,15.63636364,4,1.4545,2,"package org.apache.lucene.search;



import java.util.ArrayList;


public class Explanation implements java.io.Serializable {
  private float value;                            
  private String description;                     
  private ArrayList details;                      

  public Explanation() {}

  public Explanation(float value, String description) {
    this.value = value;
    this.description = description;
  }

  
  public float getValue() { return value; }
  
  public void setValue(float value) { this.value = value; }

  
  public String getDescription() { return description; }
  
  public void setDescription(String description) {
    this.description = description;
  }

  
  public Explanation[] getDetails() {
    if (details == null)
      return null;
    return (Explanation[])details.toArray(new Explanation[0]);
  }

  
  public void addDetail(Explanation detail) {
    if (details == null)
      details = new ArrayList();
    details.add(detail);
  }

  
  public String toString() {
    return toString(0);
  }
  private String toString(int depth) {
    StringBuffer buffer = new StringBuffer();
    for (int i = 0; i < depth; i++) {
      buffer.append(""  "");
    }
    buffer.append(getValue());
    buffer.append("" = "");
    buffer.append(getDescription());
    buffer.append(""\n"");

    Explanation[] details = getDetails();
    if (details != null) {
      for (int i = 0 ; i < details.length; i++) {
        buffer.append(details[i].toString(depth+1));
      }
    }

    return buffer.toString();
  }


  
  public String toHtml() {
    StringBuffer buffer = new StringBuffer();
    buffer.append(""<ul>\n"");

    buffer.append(""<li>"");
    buffer.append(getValue());
    buffer.append("" = "");
    buffer.append(getDescription());
    buffer.append(""</li>\n"");

    Explanation[] details = getDetails();
    if (details != null) {
      for (int i = 0 ; i < details.length; i++) {
        buffer.append(details[i].toHtml());
      }
    }

    buffer.append(""</ul>\n"");

    return buffer.toString();
  }
}
"
lucene,2,org.apache.lucene.index.SegmentMergeInfo,5,1,0,7,14,0,3,4,0,0.75,108,0.333333333,4,0.0,0.4,0,0,19.4,5,1.6,0,"package org.apache.lucene.index;



import java.io.IOException;

final class SegmentMergeInfo {
  Term term;
  int base;
  TermEnum termEnum;
  IndexReader reader;
  private TermPositions postings;  
  private int[] docMap;  

  SegmentMergeInfo(int b, TermEnum te, IndexReader r)
    throws IOException {
    base = b;
    reader = r;
    termEnum = te;
    term = te.term();
  }

  
  int[] getDocMap() {
    if (docMap == null) {
    
    if (reader.hasDeletions()) {
      int maxDoc = reader.maxDoc();
      docMap = new int[maxDoc];
      int j = 0;
      for (int i = 0; i < maxDoc; i++) {
        if (reader.isDeleted(i))
          docMap[i] = -1;
        else
          docMap[i] = j++;
      }
    }
  }
    return docMap;
  }

  TermPositions getPositions() throws IOException {
    if (postings == null) {
      postings = reader.termPositions();
    }
    return postings;
  }

  final boolean next() throws IOException {
    if (termEnum.next()) {
      term = termEnum.term();
      return true;
    } else {
      term = null;
      return false;
    }
  }

  final void close() throws IOException {
    termEnum.close();
    if (postings != null) {
    postings.close();
  }
}
}

"
lucene,2,org.apache.lucene.index.SegmentTermDocs,12,1,1,11,23,16,2,10,8,0.670454545,420,0.875,4,0.0,0.197916667,0,0,32.66666667,1,0.9167,2,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.util.BitVector;
import org.apache.lucene.store.IndexInput;

class SegmentTermDocs implements TermDocs {
  protected SegmentReader parent;
  protected IndexInput freqStream;
  protected int count;
  protected int df;
  protected BitVector deletedDocs;
  int doc = 0;
  int freq;

  private int skipInterval;
  private int numSkips;
  private int skipCount;
  private IndexInput skipStream;
  private int skipDoc;
  private long freqPointer;
  private long proxPointer;
  private long skipPointer;
  private boolean haveSkipped;

  protected SegmentTermDocs(SegmentReader parent) {
    this.parent = parent;
    this.freqStream = (IndexInput) parent.freqStream.clone();
    this.deletedDocs = parent.deletedDocs;
    this.skipInterval = parent.tis.getSkipInterval();
  }

  public void seek(Term term) throws IOException {
    TermInfo ti = parent.tis.get(term);
    seek(ti);
  }

  public void seek(TermEnum termEnum) throws IOException {
    TermInfo ti;
    
    
    if (termEnum instanceof SegmentTermEnum && ((SegmentTermEnum) termEnum).fieldInfos == parent.fieldInfos)          
      ti = ((SegmentTermEnum) termEnum).termInfo();
    else                                          
      ti = parent.tis.get(termEnum.term());
      
    seek(ti);
  }

  void seek(TermInfo ti) throws IOException {
    count = 0;
    if (ti == null) {
      df = 0;
    } else {
      df = ti.docFreq;
      doc = 0;
      skipDoc = 0;
      skipCount = 0;
      numSkips = df / skipInterval;
      freqPointer = ti.freqPointer;
      proxPointer = ti.proxPointer;
      skipPointer = freqPointer + ti.skipOffset;
      freqStream.seek(freqPointer);
      haveSkipped = false;
    }
  }

  public void close() throws IOException {
    freqStream.close();
    if (skipStream != null)
      skipStream.close();
  }

  public final int doc() { return doc; }
  public final int freq() { return freq; }

  protected void skippingDoc() throws IOException {
  }

  public boolean next() throws IOException {
    while (true) {
      if (count == df)
        return false;

      int docCode = freqStream.readVInt();
      doc += docCode >>> 1;			  
      if ((docCode & 1) != 0)			  
        freq = 1;				  
      else
        freq = freqStream.readVInt();		  

      count++;

      if (deletedDocs == null || !deletedDocs.get(doc))
        break;
      skippingDoc();
    }
    return true;
  }

  
  public int read(final int[] docs, final int[] freqs)
          throws IOException {
    final int length = docs.length;
    int i = 0;
    while (i < length && count < df) {

      
      final int docCode = freqStream.readVInt();
      doc += docCode >>> 1;			  
      if ((docCode & 1) != 0)			  
        freq = 1;				  
      else
        freq = freqStream.readVInt();		  
      count++;

      if (deletedDocs == null || !deletedDocs.get(doc)) {
        docs[i] = doc;
        freqs[i] = freq;
        ++i;
      }
    }
    return i;
  }

  
  protected void skipProx(long proxPointer) throws IOException {}

  
  public boolean skipTo(int target) throws IOException {
    if (df >= skipInterval) {                      

      if (skipStream == null)
        skipStream = (IndexInput) freqStream.clone(); 

      if (!haveSkipped) {                          
        skipStream.seek(skipPointer);
        haveSkipped = true;
      }

      
      int lastSkipDoc = skipDoc;
      long lastFreqPointer = freqStream.getFilePointer();
      long lastProxPointer = -1;
      int numSkipped = -1 - (count % skipInterval);

      while (target > skipDoc) {
        lastSkipDoc = skipDoc;
        lastFreqPointer = freqPointer;
        lastProxPointer = proxPointer;
        
        if (skipDoc != 0 && skipDoc >= doc)
          numSkipped += skipInterval;
        
        if(skipCount >= numSkips)
          break;

        skipDoc += skipStream.readVInt();
        freqPointer += skipStream.readVInt();
        proxPointer += skipStream.readVInt();

        skipCount++;
      }
      
      
      if (lastFreqPointer > freqStream.getFilePointer()) {
        freqStream.seek(lastFreqPointer);
        skipProx(lastProxPointer);

        doc = lastSkipDoc;
        count += numSkipped;
      }

    }

    
    do {
      if (!next())
        return false;
    } while (target > doc);
    return true;
  }

}
"
lucene,2,org.apache.lucene.index.CompoundFileReader,14,2,0,10,38,43,3,7,14,0.75,246,1.0,2,0.458333333,0.595238095,0,0,16.28571429,1,0.9286,1,"package org.apache.lucene.index;



import org.apache.lucene.store.Directory;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.BufferedIndexInput;
import org.apache.lucene.store.IndexOutput;
import org.apache.lucene.store.Lock;

import java.util.HashMap;
import java.io.IOException;



class CompoundFileReader extends Directory {

    private static final class FileEntry {
        long offset;
        long length;
    }


    
    private Directory directory;
    private String fileName;

    private IndexInput stream;
    private HashMap entries = new HashMap();


    public CompoundFileReader(Directory dir, String name)
    throws IOException
    {
        directory = dir;
        fileName = name;

        boolean success = false;

        try {
            stream = dir.openInput(name);

            
            int count = stream.readVInt();
            FileEntry entry = null;
            for (int i=0; i<count; i++) {
                long offset = stream.readLong();
                String id = stream.readString();

                if (entry != null) {
                    
                    entry.length = offset - entry.offset;
                }

                entry = new FileEntry();
                entry.offset = offset;
                entries.put(id, entry);
            }

            
            if (entry != null) {
                entry.length = stream.length() - entry.offset;
            }

            success = true;

        } finally {
            if (! success && (stream != null)) {
                try {
                    stream.close();
                } catch (IOException e) { }
            }
        }
    }

    public Directory getDirectory() {
        return directory;
    }

    public String getName() {
        return fileName;
    }

    public synchronized void close() throws IOException {
        if (stream == null)
            throw new IOException(""Already closed"");

        entries.clear();
        stream.close();
        stream = null;
    }

    public synchronized IndexInput openInput(String id)
    throws IOException
    {
        if (stream == null)
            throw new IOException(""Stream closed"");

        FileEntry entry = (FileEntry) entries.get(id);
        if (entry == null)
            throw new IOException(""No sub-file with id "" + id + "" found"");

        return new CSIndexInput(stream, entry.offset, entry.length);
    }

    
    public String[] list() {
        String res[] = new String[entries.size()];
        return (String[]) entries.keySet().toArray(res);
    }

    
    public boolean fileExists(String name) {
        return entries.containsKey(name);
    }

    
    public long fileModified(String name) throws IOException {
        return directory.fileModified(fileName);
    }

    
    public void touchFile(String name) throws IOException {
        directory.touchFile(fileName);
    }

    
    public void deleteFile(String name)
    {
        throw new UnsupportedOperationException();
    }

    
    public void renameFile(String from, String to)
    {
        throw new UnsupportedOperationException();
    }

    
    public long fileLength(String name)
    throws IOException
    {
        FileEntry e = (FileEntry) entries.get(name);
        if (e == null)
            throw new IOException(""File "" + name + "" does not exist"");
        return e.length;
    }

    
    public IndexOutput createOutput(String name)
    {
        throw new UnsupportedOperationException();
    }

    
    public Lock makeLock(String name)
    {
        throw new UnsupportedOperationException();
    }

    
    static final class CSIndexInput extends BufferedIndexInput {

        IndexInput base;
        long fileOffset;
        long length;

        CSIndexInput(final IndexInput base, final long fileOffset, final long length)
        {
            this.base = base;
            this.fileOffset = fileOffset;
            this.length = length;
        }

        
        protected void readInternal(byte[] b, int offset, int len)
        throws IOException
        {
            synchronized (base) {
              long start = getFilePointer();
              if(start + len > length)
                throw new IOException(""read past EOF"");
              base.seek(fileOffset + start);
              base.readBytes(b, offset, len);
            }
        }

        
        protected void seekInternal(long pos) {}

        
        public void close() {}

        public long length() {
          return length;
        }


    }
    
}
"
lucene,2,org.apache.lucene.search.PhraseQuery,15,2,0,9,43,0,3,7,11,0.589285714,302,1.0,0,0.461538462,0.191666667,2,3,18.86666667,6,1.8,0,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Set;
import java.util.Vector;

import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.ToStringUtils;


public class PhraseQuery extends Query {
  private String field;
  private Vector terms = new Vector();
  private Vector positions = new Vector();
  private int slop = 0;

  
  public PhraseQuery() {}

  
  public void setSlop(int s) { slop = s; }
  
  public int getSlop() { return slop; }

  
  public void add(Term term) {
    int position = 0;
    if(positions.size() > 0)
        position = ((Integer) positions.lastElement()).intValue() + 1;

    add(term, position);
  }

  
  public void add(Term term, int position) {
      if (terms.size() == 0)
          field = term.field();
      else if (term.field() != field)
          throw new IllegalArgumentException(""All phrase terms must be in the same field: "" + term);

      terms.addElement(term);
      positions.addElement(new Integer(position));
  }

  
  public Term[] getTerms() {
    return (Term[])terms.toArray(new Term[0]);
  }

  
  public int[] getPositions() {
      int[] result = new int[positions.size()];
      for(int i = 0; i < positions.size(); i++)
          result[i] = ((Integer) positions.elementAt(i)).intValue();
      return result;
  }

  private class PhraseWeight implements Weight {
    private Similarity similarity;
    private float value;
    private float idf;
    private float queryNorm;
    private float queryWeight;

    public PhraseWeight(Searcher searcher)
      throws IOException {
      this.similarity = getSimilarity(searcher);

      idf = similarity.idf(terms, searcher);
    }

    public String toString() { return ""weight("" + PhraseQuery.this + "")""; }

    public Query getQuery() { return PhraseQuery.this; }
    public float getValue() { return value; }

    public float sumOfSquaredWeights() {
      queryWeight = idf * getBoost();             
      return queryWeight * queryWeight;           
    }

    public void normalize(float queryNorm) {
      this.queryNorm = queryNorm;
      queryWeight *= queryNorm;                   
      value = queryWeight * idf;                  
    }

    public Scorer scorer(IndexReader reader) throws IOException {
      if (terms.size() == 0)			  
        return null;

      TermPositions[] tps = new TermPositions[terms.size()];
      for (int i = 0; i < terms.size(); i++) {
        TermPositions p = reader.termPositions((Term)terms.elementAt(i));
        if (p == null)
          return null;
        tps[i] = p;
      }

      if (slop == 0)				  
        return new ExactPhraseScorer(this, tps, getPositions(), similarity,
                                     reader.norms(field));
      else
        return
          new SloppyPhraseScorer(this, tps, getPositions(), similarity, slop,
                                 reader.norms(field));

    }

    public Explanation explain(IndexReader reader, int doc)
      throws IOException {

      Explanation result = new Explanation();
      result.setDescription(""weight(""+getQuery()+"" in ""+doc+""), product of:"");

      StringBuffer docFreqs = new StringBuffer();
      StringBuffer query = new StringBuffer();
      query.append('\""');
      for (int i = 0; i < terms.size(); i++) {
        if (i != 0) {
          docFreqs.append("" "");
          query.append("" "");
        }

        Term term = (Term)terms.elementAt(i);

        docFreqs.append(term.text());
        docFreqs.append(""="");
        docFreqs.append(reader.docFreq(term));

        query.append(term.text());
      }
      query.append('\""');

      Explanation idfExpl =
        new Explanation(idf, ""idf("" + field + "": "" + docFreqs + "")"");

      
      Explanation queryExpl = new Explanation();
      queryExpl.setDescription(""queryWeight("" + getQuery() + ""), product of:"");

      Explanation boostExpl = new Explanation(getBoost(), ""boost"");
      if (getBoost() != 1.0f)
        queryExpl.addDetail(boostExpl);
      queryExpl.addDetail(idfExpl);

      Explanation queryNormExpl = new Explanation(queryNorm,""queryNorm"");
      queryExpl.addDetail(queryNormExpl);

      queryExpl.setValue(boostExpl.getValue() *
                         idfExpl.getValue() *
                         queryNormExpl.getValue());

      result.addDetail(queryExpl);

      
      Explanation fieldExpl = new Explanation();
      fieldExpl.setDescription(""fieldWeight(""+field+"":""+query+"" in ""+doc+
                               ""), product of:"");

      Explanation tfExpl = scorer(reader).explain(doc);
      fieldExpl.addDetail(tfExpl);
      fieldExpl.addDetail(idfExpl);

      Explanation fieldNormExpl = new Explanation();
      byte[] fieldNorms = reader.norms(field);
      float fieldNorm =
        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;
      fieldNormExpl.setValue(fieldNorm);
      fieldNormExpl.setDescription(""fieldNorm(field=""+field+"", doc=""+doc+"")"");
      fieldExpl.addDetail(fieldNormExpl);

      fieldExpl.setValue(tfExpl.getValue() *
                         idfExpl.getValue() *
                         fieldNormExpl.getValue());

      result.addDetail(fieldExpl);

      
      result.setValue(queryExpl.getValue() * fieldExpl.getValue());

      if (queryExpl.getValue() == 1.0f)
        return fieldExpl;

      return result;
    }
  }

  protected Weight createWeight(Searcher searcher) throws IOException {
    if (terms.size() == 1) {			  
      Term term = (Term)terms.elementAt(0);
      Query termQuery = new TermQuery(term);
      termQuery.setBoost(getBoost());
      return termQuery.createWeight(searcher);
    }
    return new PhraseWeight(searcher);
  }

  
  public void extractTerms(Set queryTerms) {
    queryTerms.addAll(terms);
  }

  
  public String toString(String f) {
    StringBuffer buffer = new StringBuffer();
    if (!field.equals(f)) {
      buffer.append(field);
      buffer.append("":"");
    }

    buffer.append(""\"""");
    for (int i = 0; i < terms.size(); i++) {
      buffer.append(((Term)terms.elementAt(i)).text());
      if (i != terms.size()-1)
  buffer.append("" "");
    }
    buffer.append(""\"""");

    if (slop != 0) {
      buffer.append(""~"");
      buffer.append(slop);
    }

    buffer.append(ToStringUtils.boost(getBoost()));

    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof PhraseQuery))
      return false;
    PhraseQuery other = (PhraseQuery)o;
    return (this.getBoost() == other.getBoost())
      && (this.slop == other.slop)
      &&  this.terms.equals(other.terms)
      && this.positions.equals(other.positions);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost())
      ^ slop
      ^ terms.hashCode()
      ^ positions.hashCode();
  }

}
"
lucene,2,org.apache.lucene.search.spans.NearSpans,22,1,0,6,52,95,3,6,7,0.748917749,563,1.0,5,0.0,0.194805195,0,0,24.09090909,5,1.5,1,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.List;
import java.util.ArrayList;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.util.PriorityQueue;

class NearSpans implements Spans {
  private SpanNearQuery query;

  private List ordered = new ArrayList();         
  private int slop;                               
  private boolean inOrder;                        

  private SpansCell first;                        
  private SpansCell last;                         

  private int totalLength;                        

  private CellQueue queue;                        
  private SpansCell max;                          

  private boolean more = true;                    
  private boolean firstTime = true;               

  private class CellQueue extends PriorityQueue {
    public CellQueue(int size) {
      initialize(size);
    }
    
    protected final boolean lessThan(Object o1, Object o2) {
      SpansCell spans1 = (SpansCell)o1;
      SpansCell spans2 = (SpansCell)o2;
      if (spans1.doc() == spans2.doc()) {
        if (spans1.start() == spans2.start()) {
          if (spans1.end() == spans2.end()) {
            return spans1.index > spans2.index;
          } else {
            return spans1.end() < spans2.end();
          }
        } else {
          return spans1.start() < spans2.start();
        }
      } else {
        return spans1.doc() < spans2.doc();
      }
    }
  }


  
  private class SpansCell implements Spans {
    private Spans spans;
    private SpansCell next;
    private int length = -1;
    private int index;

    public SpansCell(Spans spans, int index) {
      this.spans = spans;
      this.index = index;
    }

    public boolean next() throws IOException {
      if (length != -1)                           
        totalLength -= length;

      boolean more = spans.next();                

      if (more) {
        length = end() - start();                 
        totalLength += length;                    

        if (max == null || doc() > max.doc() ||   
            (doc() == max.doc() && end() > max.end()))
          max = this;
      }

      return more;
    }

    public boolean skipTo(int target) throws IOException {
      if (length != -1)                           
        totalLength -= length;

      boolean more = spans.skipTo(target);        

      if (more) {
        length = end() - start();                 
        totalLength += length;                    

        if (max == null || doc() > max.doc() ||   
            (doc() == max.doc() && end() > max.end()))
          max = this;
      }

      return more;
    }

    public int doc() { return spans.doc(); }
    public int start() { return spans.start(); }
    public int end() { return spans.end(); }

    public String toString() { return spans.toString() + ""#"" + index; }
  }

  public NearSpans(SpanNearQuery query, IndexReader reader)
    throws IOException {
    this.query = query;
    this.slop = query.getSlop();
    this.inOrder = query.isInOrder();

    SpanQuery[] clauses = query.getClauses();     
    queue = new CellQueue(clauses.length);
    for (int i = 0; i < clauses.length; i++) {
      SpansCell cell =                            
        new SpansCell(clauses[i].getSpans(reader), i);
      ordered.add(cell);                          
    }
  }

  public boolean next() throws IOException {
    if (firstTime) {
      initList(true);
      listToQueue();                              
      firstTime = false;
    } else if (more) {
      more = min().next();                        
      if (more)
        queue.adjustTop();                        
    }

    while (more) {

      boolean queueStale = false;

      if (min().doc() != max.doc()) {             
        queueToList();
        queueStale = true;
      }

      

      while (more && first.doc() < last.doc()) {
        more = first.skipTo(last.doc());          
        firstToLast();                            
        queueStale = true;
      }

      if (!more) return false;

      

      if (queueStale) {                           
        listToQueue();
        queueStale = false;
      }

      if (atMatch())
        return true;
      
      
      if (inOrder && checkSlop()) {
        
        more = firstNonOrderedNextToPartialList();
        if (more) {
          partialListToQueue();                            
        }
      } else {
        more = min().next();
        if (more) {
          queue.adjustTop();                      
        }
      }
    }
    return false;                                 
  }

  public boolean skipTo(int target) throws IOException {
    if (firstTime) {                              
      initList(false);
      for (SpansCell cell = first; more && cell!=null; cell=cell.next) {
        more = cell.skipTo(target);               
      }
      if (more) {
        listToQueue();
      }
      firstTime = false;
    } else {                                      
      while (more && min().doc() < target) {      
        more = min().skipTo(target);
        if (more)
          queue.adjustTop();
      }
    }
    if (more) {

      if (atMatch())                              
        return true;

      return next();                              
    }

    return false;
  }

  private SpansCell min() { return (SpansCell)queue.top(); }

  public int doc() { return min().doc(); }
  public int start() { return min().start(); }
  public int end() { return max.end(); }


  public String toString() {
    return ""spans(""+query.toString()+"")@""+
      (firstTime?""START"":(more?(doc()+"":""+start()+""-""+end()):""END""));
  }

  private void initList(boolean next) throws IOException {
    for (int i = 0; more && i < ordered.size(); i++) {
      SpansCell cell = (SpansCell)ordered.get(i);
      if (next)
        more = cell.next();                       
      if (more) {
        addToList(cell);                          
      }
    }
  }

  private void addToList(SpansCell cell) {
    if (last != null) {			  
      last.next = cell;
    } else
      first = cell;
    last = cell;
    cell.next = null;
  }

  private void firstToLast() {
    last.next = first;			  
    last = first;
    first = first.next;
    last.next = null;
  }

  private void queueToList() {
    last = first = null;
    while (queue.top() != null) {
      addToList((SpansCell)queue.pop());
    }
  }
  
  private boolean firstNonOrderedNextToPartialList() throws IOException {
    
    last = first = null;
    int orderedIndex = 0;
    while (queue.top() != null) {
      SpansCell cell = (SpansCell)queue.pop();
      addToList(cell);
      if (cell.index == orderedIndex) {
        orderedIndex++;
      } else {
        return cell.next();
        
        
        
        
        
      }
    }
    throw new RuntimeException(""Unexpected: ordered"");
  }

  private void listToQueue() {
    queue.clear(); 
    partialListToQueue();
  }

  private void partialListToQueue() {
    for (SpansCell cell = first; cell != null; cell = cell.next) {
      queue.put(cell);                      
    }
  }

  private boolean atMatch() {
    return (min().doc() == max.doc())
          && checkSlop()
          && (!inOrder || matchIsOrdered());
  }
  
  private boolean checkSlop() {
    int matchLength = max.end() - min().start();
    return (matchLength - totalLength) <= slop;
  }

  private boolean matchIsOrdered() {
    int lastStart = -1;
    for (int i = 0; i < ordered.size(); i++) {
      int start = ((SpansCell)ordered.get(i)).start();
      if (!(start > lastStart))
        return false;
      lastStart = start;
    }
    return true;
  }
}
"
lucene,2,org.apache.lucene.search.Hits,11,1,0,12,28,19,3,11,5,0.64,338,1.0,6,0.0,0.324675325,0,0,28.81818182,4,1.1818,1,"package org.apache.lucene.search;



import java.io.IOException;
import java.util.Vector;
import java.util.Iterator;

import org.apache.lucene.document.Document;


public final class Hits {
  private Weight weight;
  private Searcher searcher;
  private Filter filter = null;
  private Sort sort = null;

  private int length;				  
  private Vector hitDocs = new Vector();	  

  private HitDoc first;         
  private HitDoc last;          
  private int numDocs = 0;      
  private int maxDocs = 200;    

  Hits(Searcher s, Query q, Filter f) throws IOException {
    weight = q.weight(s);
    searcher = s;
    filter = f;
    getMoreDocs(50); 
  }

  Hits(Searcher s, Query q, Filter f, Sort o) throws IOException {
    weight = q.weight(s);
    searcher = s;
    filter = f;
    sort = o;
    getMoreDocs(50); 
  }

  
  private final void getMoreDocs(int min) throws IOException {
    if (hitDocs.size() > min) {
      min = hitDocs.size();
    }

    int n = min * 2;	
    TopDocs topDocs = (sort == null) ? searcher.search(weight, filter, n) : searcher.search(weight, filter, n, sort);
    length = topDocs.totalHits;
    ScoreDoc[] scoreDocs = topDocs.scoreDocs;

    float scoreNorm = 1.0f;
    
    if (length > 0 && topDocs.getMaxScore() > 1.0f) {
      scoreNorm = 1.0f / topDocs.getMaxScore();
    }

    int end = scoreDocs.length < length ? scoreDocs.length : length;
    for (int i = hitDocs.size(); i < end; i++) {
      hitDocs.addElement(new HitDoc(scoreDocs[i].score * scoreNorm,
                                    scoreDocs[i].doc));
    }
  }

  
  public final int length() {
    return length;
  }

  
  public final Document doc(int n) throws IOException {
    HitDoc hitDoc = hitDoc(n);

    
    remove(hitDoc);               
    addToFront(hitDoc);           
    if (numDocs > maxDocs) {      
      HitDoc oldLast = last;
      remove(last);             
      oldLast.doc = null;       
    }

    if (hitDoc.doc == null) {
      hitDoc.doc = searcher.doc(hitDoc.id);  
    }

    return hitDoc.doc;
  }

  
  public final float score(int n) throws IOException {
    return hitDoc(n).score;
  }

  
  public final int id(int n) throws IOException {
    return hitDoc(n).id;
  }

  
  public Iterator iterator() {
    return new HitIterator(this);
  }

  private final HitDoc hitDoc(int n) throws IOException {
    if (n >= length) {
      throw new IndexOutOfBoundsException(""Not a valid hit number: "" + n);
    }

    if (n >= hitDocs.size()) {
      getMoreDocs(n);
    }

    return (HitDoc) hitDocs.elementAt(n);
  }

  private final void addToFront(HitDoc hitDoc) {  
    if (first == null) {
      last = hitDoc;
    } else {
      first.prev = hitDoc;
    }

    hitDoc.next = first;
    first = hitDoc;
    hitDoc.prev = null;

    numDocs++;
  }

  private final void remove(HitDoc hitDoc) {	  
    if (hitDoc.doc == null) {     
      return;					  
    }

    if (hitDoc.next == null) {
      last = hitDoc.prev;
    } else {
      hitDoc.next.prev = hitDoc.prev;
    }

    if (hitDoc.prev == null) {
      first = hitDoc.next;
    } else {
      hitDoc.prev.next = hitDoc.next;
    }

    numDocs--;
  }
}

final class HitDoc {
  float score;
  int id;
  Document doc = null;

  HitDoc next;  
  HitDoc prev;  

  HitDoc(float s, int i) {
    score = s;
    id = i;
  }
}
"
lucene,2,org.apache.lucene.queryParser.Token,3,1,0,4,4,3,4,0,3,1.4375,23,0.0,2,0.0,0.5,0,0,4.0,2,1.0,0,"
package org.apache.lucene.queryParser;



public class Token {

  
  public int kind;

  
  public int beginLine, beginColumn, endLine, endColumn;

  
  public String image;

  
  public Token next;

  
  public Token specialToken;

  
  public String toString()
  {
     return image;
  }

  
  public static final Token newToken(int ofKind)
  {
     switch(ofKind)
     {
       default : return new Token();
     }
  }

}
"
lucene,2,org.apache.lucene.search.spans.SpanTermQuery,10,3,0,6,27,0,1,6,9,0.111111111,116,1.0,1,0.64,0.214285714,2,2,10.5,4,1.3,1,"package org.apache.lucene.search.spans;



import java.io.IOException;

import java.util.Collection;
import java.util.ArrayList;
import java.util.Set;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermPositions;
import org.apache.lucene.util.ToStringUtils;


public class SpanTermQuery extends SpanQuery {
  private Term term;

  
  public SpanTermQuery(Term term) { this.term = term; }

  
  public Term getTerm() { return term; }

  public String getField() { return term.field(); }
  
  
  public Collection getTerms() {
    Collection terms = new ArrayList();
    terms.add(term);
    return terms;
  }
  public void extractTerms(Set terms) {
	  terms.add(term);
  }

  public String toString(String field) {
    StringBuffer buffer = new StringBuffer();
    if (term.field().equals(field))
      buffer.append(term.text());
    else
      buffer.append(term.toString());
    buffer.append(ToStringUtils.boost(getBoost()));
    return buffer.toString();
  }

  
  public boolean equals(Object o) {
    if (!(o instanceof SpanTermQuery))
      return false;
    SpanTermQuery other = (SpanTermQuery)o;
    return (this.getBoost() == other.getBoost())
      && this.term.equals(other.term);
  }

  
  public int hashCode() {
    return Float.floatToIntBits(getBoost()) ^ term.hashCode() ^ 0xD23FE494;
  }

  public Spans getSpans(final IndexReader reader) throws IOException {
    return new Spans() {
        private TermPositions positions = reader.termPositions(term);

        private int doc = -1;
        private int freq;
        private int count;
        private int position;

        public boolean next() throws IOException {
          if (count == freq) {
            if (!positions.next()) {
              doc = Integer.MAX_VALUE;
              return false;
            }
            doc = positions.doc();
            freq = positions.freq();
            count = 0;
          }
          position = positions.nextPosition();
          count++;
          return true;
        }

        public boolean skipTo(int target) throws IOException {
          
          if (doc >= target) {
            return true;
          }

          if (!positions.skipTo(target)) {
            doc = Integer.MAX_VALUE;
            return false;
          }

          doc = positions.doc();
          freq = positions.freq();
          count = 0;

          position = positions.nextPosition();
          count++;

          return true;
        }

        public int doc() { return doc; }
        public int start() { return position; }
        public int end() { return position + 1; }

        public String toString() {
          return ""spans("" + SpanTermQuery.this.toString() + "")@""+
            (doc==-1?""START"":(doc==Integer.MAX_VALUE)?""END"":doc+""-""+position);
        }

      };
  }

}
"
lucene,2,org.apache.lucene.util.StringHelper,2,1,0,2,5,1,2,0,1,2.0,36,0.0,0,0.0,0.5,0,0,17.0,4,2.0,0,"package org.apache.lucene.util;





public abstract class StringHelper {

  
  public static final int stringDifference(String s1, String s2) {
    int len1 = s1.length();
    int len2 = s2.length();
    int len = len1 < len2 ? len1 : len2;
    for (int i = 0; i < len; i++) {
      if (s1.charAt(i) != s2.charAt(i)) {
	      return i;
      }
    }
    return len;
  }


  private StringHelper() {
  }
}
"
lucene,2,org.apache.lucene.store.RAMInputStream,5,3,0,3,8,2,1,2,5,0.666666667,93,1.0,1,0.84,0.36,1,5,17.0,3,1.2,2,"package org.apache.lucene.store;





class RAMInputStream extends BufferedIndexInput implements Cloneable {
  private RAMFile file;
  private long pointer = 0;
  private long length;

  public RAMInputStream(RAMFile f) {
    file = f;
    length = file.length;
  }

  public void readInternal(byte[] dest, int destOffset, int len) {
    int remainder = len;
    long start = pointer;
    while (remainder != 0) {
      int bufferNumber = (int)(start/BUFFER_SIZE);
      int bufferOffset = (int)(start%BUFFER_SIZE);
      int bytesInBuffer = BUFFER_SIZE - bufferOffset;
      int bytesToCopy = bytesInBuffer >= remainder ? remainder : bytesInBuffer;
      byte[] buffer = (byte[])file.buffers.elementAt(bufferNumber);
      System.arraycopy(buffer, bufferOffset, dest, destOffset, bytesToCopy);
      destOffset += bytesToCopy;
      start += bytesToCopy;
      remainder -= bytesToCopy;
    }
    pointer += len;
  }

  public void close() {
  }

  public void seekInternal(long pos) {
    pointer = pos;
  }

  public long length() {
    return length;
  }

}
"
lucene,2,org.apache.lucene.search.Searcher,23,1,3,34,28,247,24,13,22,0.909090909,131,1.0,1,0.0,0.273913043,0,0,4.652173913,1,0.9565,1,"package org.apache.lucene.search;



import java.io.IOException;

import org.apache.lucene.index.Term;
import org.apache.lucene.document.Document;


public abstract class Searcher implements Searchable {

  
  public final Hits search(Query query) throws IOException {
    return search(query, (Filter)null);
  }

  
  public Hits search(Query query, Filter filter) throws IOException {
    return new Hits(this, query, filter);
  }

  
  public Hits search(Query query, Sort sort)
    throws IOException {
    return new Hits(this, query, null, sort);
  }

  
  public Hits search(Query query, Filter filter, Sort sort)
    throws IOException {
    return new Hits(this, query, filter, sort);
  }

  
  public TopFieldDocs search(Query query, Filter filter, int n,
                             Sort sort) throws IOException {
    return search(createWeight(query), filter, n, sort);
  }

  
  public void search(Query query, HitCollector results)
    throws IOException {
    search(query, (Filter)null, results);
  }

  
  public void search(Query query, Filter filter, HitCollector results)
    throws IOException {
    search(createWeight(query), filter, results);
  }

  
  public TopDocs search(Query query, Filter filter, int n)
    throws IOException {
    return search(createWeight(query), filter, n);
  }

  
  public Explanation explain(Query query, int doc) throws IOException {
    return explain(createWeight(query), doc);
  }

  
  private Similarity similarity = Similarity.getDefault();

  
  public void setSimilarity(Similarity similarity) {
    this.similarity = similarity;
  }

  
  public Similarity getSimilarity() {
    return this.similarity;
  }

  
  protected Weight createWeight(Query query) throws IOException {
      return query.weight(this);
  }

  
  public int[] docFreqs(Term[] terms) throws IOException {
    int[] result = new int[terms.length];
    for (int i = 0; i < terms.length; i++) {
      result[i] = docFreq(terms[i]);
    }
    return result;
  }

  
  abstract public void search(Weight weight, Filter filter, HitCollector results) throws IOException;
  abstract public void close() throws IOException;
  abstract public int docFreq(Term term) throws IOException;
  abstract public int maxDoc() throws IOException;
  abstract public TopDocs search(Weight weight, Filter filter, int n) throws IOException;
  abstract public Document doc(int i) throws IOException;
  abstract public Query rewrite(Query query) throws IOException;
  abstract public Explanation explain(Weight weight, int doc) throws IOException;
  abstract public TopFieldDocs search(Weight weight, Filter filter, int n, Sort sort) throws IOException;
  
}
"
lucene,2,org.apache.lucene.analysis.Analyzer,3,1,6,13,4,3,12,1,3,2.0,8,0.0,0,0.0,0.666666667,0,0,1.666666667,1,0.6667,0,"package org.apache.lucene.analysis;



import java.io.Reader;


public abstract class Analyzer {
  
  public abstract TokenStream tokenStream(String fieldName, Reader reader);


  
  public int getPositionIncrementGap(String fieldName)
  {
    return 0;
  }
}

"
lucene,2,org.apache.lucene.search.DisjunctionSumScorer,10,2,1,6,34,1,3,4,8,0.46031746,288,1.0,1,0.5,0.5,1,3,27.1,1,0.8,1,"package org.apache.lucene.search;



import java.util.List;
import java.util.Iterator;
import java.io.IOException;

import org.apache.lucene.util.PriorityQueue;


class DisjunctionSumScorer extends Scorer {
   
  private final int nrScorers;
  
  
  protected final List subScorers;
  
  
  private final int minimumNrMatchers;
  
  
  private ScorerQueue scorerQueue = null;
  
  
  private int currentDoc = -1;

  
  protected int nrMatchers = -1;

  private float currentScore = Float.NaN;
  
  
  public DisjunctionSumScorer( List subScorers, int minimumNrMatchers) {
    super(null);
    
    nrScorers = subScorers.size();

    if (minimumNrMatchers <= 0) {
      throw new IllegalArgumentException(""Minimum nr of matchers must be positive"");
    }
    if (nrScorers <= 1) {
      throw new IllegalArgumentException(""There must be at least 2 subScorers"");
    }

    this.minimumNrMatchers = minimumNrMatchers;
    this.subScorers = subScorers;
  }
  
  
  public DisjunctionSumScorer(List subScorers) {
    this(subScorers, 1);
  }

  
  private void initScorerQueue() throws IOException {
    Iterator si = subScorers.iterator();
    scorerQueue = new ScorerQueue(nrScorers);
    while (si.hasNext()) {
      Scorer se = (Scorer) si.next();
      if (se.next()) { 
        scorerQueue.insert(se);
      }
    }
  }

  
  private class ScorerQueue extends PriorityQueue {
    ScorerQueue(int size) {
      initialize(size);
    }

    protected boolean lessThan(Object o1, Object o2) {
      return ((Scorer)o1).doc() < ((Scorer)o2).doc();
    }
  }
  
  public boolean next() throws IOException {
    if (scorerQueue == null) {
      initScorerQueue();
    }
    if (scorerQueue.size() < minimumNrMatchers) {
      return false;
    } else {
      return advanceAfterCurrent();
    }
  }


  
  protected boolean advanceAfterCurrent() throws IOException {
    do { 
      Scorer top = (Scorer) scorerQueue.top();
      currentDoc = top.doc();
      currentScore = top.score();
      nrMatchers = 1;
      do { 
        if (top.next()) {
          scorerQueue.adjustTop();
        } else {
          scorerQueue.pop();
          if (scorerQueue.size() < (minimumNrMatchers - nrMatchers)) {
            
            
            return false;
          }
          if (scorerQueue.size() == 0) {
            break; 
          }
        }
        top = (Scorer) scorerQueue.top();
        if (top.doc() != currentDoc) {
          break; 
        } else {
          currentScore += top.score();
          nrMatchers++;
        }
      } while (true);
      
      if (nrMatchers >= minimumNrMatchers) {
        return true;
      } else if (scorerQueue.size() < minimumNrMatchers) {
        return false;
      }
    } while (true);
  }
  
  
  public float score() throws IOException { return currentScore; }
   
  public int doc() { return currentDoc; }

  
  public int nrMatchers() {
    return nrMatchers;
  }

  
  public boolean skipTo(int target) throws IOException {
    if (scorerQueue == null) {
      initScorerQueue();
    }
    if (scorerQueue.size() < minimumNrMatchers) {
      return false;
    }
    if (target <= currentDoc) {
      return true;
    }
    do {
      Scorer top = (Scorer) scorerQueue.top();
      if (top.doc() >= target) {
        return advanceAfterCurrent();
      } else if (top.skipTo(target)) {
        scorerQueue.adjustTop();
      } else {
        scorerQueue.pop();
        if (scorerQueue.size() < minimumNrMatchers) {
          return false;
        }
      }
    } while (true);
  }

 
  public Explanation explain(int doc) throws IOException {
    Explanation res = new Explanation();
    res.setDescription(""At least "" + minimumNrMatchers + "" of"");
    Iterator ssi = subScorers.iterator();
    while (ssi.hasNext()) {
      res.addDetail( ((Scorer) ssi.next()).explain(doc));
    }
    return res;
  }
}
"
lucene,2,org.apache.lucene.index.TermBuffer,11,1,0,4,25,0,1,3,6,0.52,241,1.0,1,0.0,0.242857143,0,0,20.45454545,3,1.4545,0,"package org.apache.lucene.index;



import java.io.IOException;
import org.apache.lucene.store.IndexInput;

final class TermBuffer implements Cloneable {
  private static final char[] NO_CHARS = new char[0];

  private String field;
  private char[] text = NO_CHARS;
  private int textLength;
  private Term term;                            

  public final int compareTo(TermBuffer other) {
    if (field == other.field)			  
      return compareChars(text, textLength, other.text, other.textLength);
    else
      return field.compareTo(other.field);
  }

  private static final int compareChars(char[] v1, int len1,
                                        char[] v2, int len2) {
    int end = Math.min(len1, len2);
    for (int k = 0; k < end; k++) {
      char c1 = v1[k];
      char c2 = v2[k];
      if (c1 != c2) {
        return c1 - c2;
      }
    }
    return len1 - len2;
  }

  private final void setTextLength(int newLength) {
    if (text.length < newLength) {
      char[] newText = new char[newLength];
      System.arraycopy(text, 0, newText, 0, textLength);
      text = newText;
    }
    textLength = newLength;
  }

  public final void read(IndexInput input, FieldInfos fieldInfos)
    throws IOException {
    this.term = null;                           
    int start = input.readVInt();
    int length = input.readVInt();
    int totalLength = start + length;
    setTextLength(totalLength);
    input.readChars(this.text, start, length);
    this.field = fieldInfos.fieldName(input.readVInt());
  }

  public final void set(Term term) {
    if (term == null) {
      reset();
      return;
    }

    
    setTextLength(term.text().length());
    term.text().getChars(0, term.text().length(), text, 0);

    this.field = term.field();
    this.term = term;
  }

  public final void set(TermBuffer other) {
    setTextLength(other.textLength);
    System.arraycopy(other.text, 0, text, 0, textLength);

    this.field = other.field;
    this.term = other.term;
  }

  public void reset() {
    this.field = null;
    this.textLength = 0;
    this.term = null;
  }

  public Term toTerm() {
    if (field == null)                            
      return null;

    if (term == null)
      term = new Term(field, new String(text, 0, textLength), false);

    return term;
  }

  protected Object clone() {
    TermBuffer clone = null;
    try {
      clone = (TermBuffer)super.clone();
    } catch (CloneNotSupportedException e) {}

    clone.text = new char[text.length];
    System.arraycopy(text, 0, clone.text, 0, textLength);

    return clone;
  }
}
"
lucene,2,org.apache.lucene.store.BufferedIndexOutput,9,2,2,3,11,8,2,1,8,0.5,175,0.75,0,0.619047619,0.333333333,1,3,18.0,1,0.8889,2,"package org.apache.lucene.store;



import java.io.IOException;


public abstract class BufferedIndexOutput extends IndexOutput {
  static final int BUFFER_SIZE = 1024;

  private final byte[] buffer = new byte[BUFFER_SIZE];
  private long bufferStart = 0;			  
  private int bufferPosition = 0;		  

  
  public void writeByte(byte b) throws IOException {
    if (bufferPosition >= BUFFER_SIZE)
      flush();
    buffer[bufferPosition++] = b;
  }

  
  public void writeBytes(byte[] b, int length) throws IOException {
    int bytesLeft = BUFFER_SIZE - bufferPosition;
    
    if (bytesLeft >= length) {
      
      System.arraycopy(b, 0, buffer, bufferPosition, length);
      bufferPosition += length;
      
      if (BUFFER_SIZE - bufferPosition == 0)
        flush();
    } else {
      
      if (length > BUFFER_SIZE) {
        
        if (bufferPosition > 0)
          flush();
        
        flushBuffer(b, length);
        bufferStart += length;
      } else {
        
        int pos = 0; 
        int pieceLength;
        while (pos < length) {
          pieceLength = (length - pos < bytesLeft) ? length - pos : bytesLeft;
          System.arraycopy(b, pos, buffer, bufferPosition, pieceLength);
          pos += pieceLength;
          bufferPosition += pieceLength;
          
          bytesLeft = BUFFER_SIZE - bufferPosition;
          if (bytesLeft == 0) {
            flush();
            bytesLeft = BUFFER_SIZE;
          }
        }
      }
    }
  }

  
  public void flush() throws IOException {
    flushBuffer(buffer, bufferPosition);
    bufferStart += bufferPosition;
    bufferPosition = 0;
  }

  
  protected abstract void flushBuffer(byte[] b, int len) throws IOException;

  
  public void close() throws IOException {
    flush();
  }

  
  public long getFilePointer() {
    return bufferStart + bufferPosition;
  }

  
  public void seek(long pos) throws IOException {
    flush();
    bufferStart = pos;
  }

  
  public abstract long length() throws IOException;


}
"
lucene,2,org.apache.lucene.index.TermVectorOffsetInfo,9,1,0,7,10,2,7,0,8,0.666666667,83,0.666666667,1,0.0,0.5,1,1,7.888888889,5,1.1111,0,"package org.apache.lucene.index;



public class TermVectorOffsetInfo {
    public static final TermVectorOffsetInfo [] EMPTY_OFFSET_INFO = new TermVectorOffsetInfo[0];
    private int startOffset;
    private int endOffset;

  public TermVectorOffsetInfo() {
  }

  public TermVectorOffsetInfo(int startOffset, int endOffset) {
    this.endOffset = endOffset;
    this.startOffset = startOffset;
  }

  public int getEndOffset() {
    return endOffset;
  }

  public void setEndOffset(int endOffset) {
    this.endOffset = endOffset;
  }

  public int getStartOffset() {
    return startOffset;
  }

  public void setStartOffset(int startOffset) {
    this.startOffset = startOffset;
  }

  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof TermVectorOffsetInfo)) return false;

    final TermVectorOffsetInfo termVectorOffsetInfo = (TermVectorOffsetInfo) o;

    if (endOffset != termVectorOffsetInfo.endOffset) return false;
    if (startOffset != termVectorOffsetInfo.startOffset) return false;

    return true;
  }

  public int hashCode() {
    int result;
    result = startOffset;
    result = 29 * result + endOffset;
    return result;
  }
}
"
lucene,2,org.apache.lucene.document.Field,23,1,0,9,34,93,6,3,22,0.704545455,726,1.0,0,0.0,0.198067633,0,0,30.04347826,17,1.8261,1,"package org.apache.lucene.document;



import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.Hits;
import org.apache.lucene.search.Similarity;
import org.apache.lucene.util.Parameter;

import java.io.Reader;
import java.io.Serializable;



public final class Field implements Serializable {
  private String name = ""body"";
  
  
  private Object fieldsData = null;
  
  private boolean storeTermVector = false;
  private boolean storeOffsetWithTermVector = false; 
  private boolean storePositionWithTermVector = false;
  private boolean omitNorms = false;
  private boolean isStored = false;
  private boolean isIndexed = true;
  private boolean isTokenized = true;
  private boolean isBinary = false;
  private boolean isCompressed = false;
  
  private float boost = 1.0f;
  
  
  public static final class Store extends Parameter implements Serializable {

    private Store(String name) {
      super(name);
    }

    
    public static final Store COMPRESS = new Store(""COMPRESS"");

    
    public static final Store YES = new Store(""YES"");

    
    public static final Store NO = new Store(""NO"");
  }

  
  public static final class Index extends Parameter implements Serializable {

    private Index(String name) {
      super(name);
    }

    
    public static final Index NO = new Index(""NO"");

    
    public static final Index TOKENIZED = new Index(""TOKENIZED"");

    
    public static final Index UN_TOKENIZED = new Index(""UN_TOKENIZED"");

    
    public static final Index NO_NORMS = new Index(""NO_NORMS"");

  }

  
  public static final class TermVector  extends Parameter implements Serializable {
    
    private TermVector(String name) {
      super(name);
    }
    
    
    public static final TermVector NO = new TermVector(""NO"");
    
    
    public static final TermVector YES = new TermVector(""YES"");
    
     
    public static final TermVector WITH_POSITIONS = new TermVector(""WITH_POSITIONS"");
    
     
    public static final TermVector WITH_OFFSETS = new TermVector(""WITH_OFFSETS"");
    
     
    public static final TermVector WITH_POSITIONS_OFFSETS = new TermVector(""WITH_POSITIONS_OFFSETS"");
  }
  
  
  public void setBoost(float boost) {
    this.boost = boost;
  }

  
  public float getBoost() {
    return boost;
  }
  
  public String name()    { return name; }

  
  public String stringValue()   { return fieldsData instanceof String ? (String)fieldsData : null; }
  
  
  public Reader readerValue()   { return fieldsData instanceof Reader ? (Reader)fieldsData : null; }
  
  
  public byte[] binaryValue()   { return fieldsData instanceof byte[] ? (byte[])fieldsData : null; }
  
  
  public Field(String name, String value, Store store, Index index) {
    this(name, value, store, index, TermVector.NO);
  }
  
   
  public Field(String name, String value, Store store, Index index, TermVector termVector) {
    if (name == null)
      throw new NullPointerException(""name cannot be null"");
    if (value == null)
      throw new NullPointerException(""value cannot be null"");
    if (name.length() == 0 && value.length() == 0)
      throw new IllegalArgumentException(""name and value cannot both be empty"");
    if (index == Index.NO && store == Store.NO)
      throw new IllegalArgumentException(""it doesn't make sense to have a field that ""
         + ""is neither indexed nor stored"");
    if (index == Index.NO && termVector != TermVector.NO)
      throw new IllegalArgumentException(""cannot store term vector information ""
         + ""for a field that is not indexed"");
          
    this.name = name.intern();        
    this.fieldsData = value;

    if (store == Store.YES){
      this.isStored = true;
      this.isCompressed = false;
    }
    else if (store == Store.COMPRESS) {
      this.isStored = true;
      this.isCompressed = true;
    }
    else if (store == Store.NO){
      this.isStored = false;
      this.isCompressed = false;
    }
    else
      throw new IllegalArgumentException(""unknown store parameter "" + store);
   
    if (index == Index.NO) {
      this.isIndexed = false;
      this.isTokenized = false;
    } else if (index == Index.TOKENIZED) {
      this.isIndexed = true;
      this.isTokenized = true;
    } else if (index == Index.UN_TOKENIZED) {
      this.isIndexed = true;
      this.isTokenized = false;
    } else if (index == Index.NO_NORMS) {
      this.isIndexed = true;
      this.isTokenized = false;
      this.omitNorms = true;
    } else {
      throw new IllegalArgumentException(""unknown index parameter "" + index);
    }
    
    this.isBinary = false;

    setStoreTermVector(termVector);
  }

  
  public Field(String name, Reader reader) {
    this(name, reader, TermVector.NO);
  }

   
  public Field(String name, Reader reader, TermVector termVector) {
    if (name == null)
      throw new NullPointerException(""name cannot be null"");
    if (reader == null)
      throw new NullPointerException(""reader cannot be null"");
    
    this.name = name.intern();        
    this.fieldsData = reader;
    
    this.isStored = false;
    this.isCompressed = false;
    
    this.isIndexed = true;
    this.isTokenized = true;
    
    this.isBinary = false;
    
    setStoreTermVector(termVector);
  }


  
  
  public Field(String name, byte[] value, Store store) {
    if (name == null)
      throw new IllegalArgumentException(""name cannot be null"");
    if (value == null)
      throw new IllegalArgumentException(""value cannot be null"");
    
    this.name = name.intern();
    this.fieldsData = value;
    
    if (store == Store.YES){
      this.isStored = true;
      this.isCompressed = false;
    }
    else if (store == Store.COMPRESS) {
      this.isStored = true;
      this.isCompressed = true;
    }
    else if (store == Store.NO)
      throw new IllegalArgumentException(""binary values can't be unstored"");
    else
      throw new IllegalArgumentException(""unknown store parameter "" + store);
    
    this.isIndexed   = false;
    this.isTokenized = false;
    
    this.isBinary    = true;
    
    setStoreTermVector(TermVector.NO);
  }
  
  private void setStoreTermVector(TermVector termVector) {
    if (termVector == TermVector.NO) {
      this.storeTermVector = false;
      this.storePositionWithTermVector = false;
      this.storeOffsetWithTermVector = false;
    } 
    else if (termVector == TermVector.YES) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = false;
      this.storeOffsetWithTermVector = false;
    }
    else if (termVector == TermVector.WITH_POSITIONS) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = true;
      this.storeOffsetWithTermVector = false;
    } 
    else if (termVector == TermVector.WITH_OFFSETS) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = false;
      this.storeOffsetWithTermVector = true;
    } 
    else if (termVector == TermVector.WITH_POSITIONS_OFFSETS) {
      this.storeTermVector = true;
      this.storePositionWithTermVector = true;
      this.storeOffsetWithTermVector = true;
    } 
    else {
      throw new IllegalArgumentException(""unknown termVector parameter "" + termVector);
    }
  }
  
  
  public final boolean  isStored()  { return isStored; }

  
  public final boolean  isIndexed()   { return isIndexed; }

  
  public final boolean  isTokenized()   { return isTokenized; }
  
  
  public final boolean  isCompressed()   { return isCompressed; }

  
  public final boolean isTermVectorStored() { return storeTermVector; }
  
  
  public boolean isStoreOffsetWithTermVector(){ 
    return storeOffsetWithTermVector; 
  } 
  
  
  public boolean isStorePositionWithTermVector(){ 
    return storePositionWithTermVector; 
  }
      
  
  public final boolean  isBinary()      { return isBinary; }
  
  
  public boolean getOmitNorms() { return omitNorms; }

  
  public void setOmitNorms(boolean omitNorms) { this.omitNorms=omitNorms; }
  
  
  public final String toString() {
    StringBuffer result = new StringBuffer();
    if (isStored) {
      result.append(""stored"");
      if (isCompressed)
        result.append(""/compressed"");
      else
        result.append(""/uncompressed"");
    }
    if (isIndexed) {
      if (result.length() > 0)
        result.append("","");
      result.append(""indexed"");
    }
    if (isTokenized) {
      if (result.length() > 0)
        result.append("","");
      result.append(""tokenized"");
    }
    if (storeTermVector) {
      if (result.length() > 0)
        result.append("","");
      result.append(""termVector"");
    }
    if (storeOffsetWithTermVector) { 
      if (result.length() > 0) 
        result.append("",""); 
      result.append(""termVectorOffsets""); 
    } 
    if (storePositionWithTermVector) { 
      if (result.length() > 0) 
        result.append("",""); 
      result.append(""termVectorPosition""); 
    } 
    if (isBinary) {
      if (result.length() > 0)
        result.append("","");
      result.append(""binary"");
    }
    if (omitNorms) {
      result.append("",omitNorms"");
    }
    result.append('<');
    result.append(name);
    result.append(':');
    
    if (fieldsData != null) {
      result.append(fieldsData);
    }
    
    result.append('>');
    return result.toString();
  }

}
"
lucene,2,org.apache.lucene.analysis.KeywordAnalyzer,2,2,0,3,4,1,0,3,2,2.0,10,0.0,0,0.666666667,0.666666667,0,0,4.0,1,0.5,0,"package org.apache.lucene.analysis;



import java.io.Reader;


public class KeywordAnalyzer extends Analyzer {
  public TokenStream tokenStream(String fieldName,
                                 final Reader reader) {
    return new KeywordTokenizer(reader);
  }
}"
lucene,2,org.apache.lucene.store.FSDirectory,26,2,1,13,80,53,6,8,18,0.854545455,938,0.818181818,0,0.314285714,0.296,0,0,34.65384615,2,1.0,14,"package org.apache.lucene.store;



import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.Hashtable;

import org.apache.lucene.index.IndexFileNameFilter;


public class FSDirectory extends Directory {
    
  
  private static final Hashtable DIRECTORIES = new Hashtable();

  private static boolean disableLocks = false;

  
  public static void setDisableLocks(boolean doDisableLocks) {
    FSDirectory.disableLocks = doDisableLocks;
  }

  
  public static boolean getDisableLocks() {
    return FSDirectory.disableLocks;
  }

  
  public static final String LOCK_DIR =
    System.getProperty(""org.apache.lucene.lockDir"",
      System.getProperty(""java.io.tmpdir""));

  
  private static Class IMPL;
  static {
    try {
      String name =
        System.getProperty(""org.apache.lucene.FSDirectory.class"",
                           FSDirectory.class.getName());
      IMPL = Class.forName(name);
    } catch (ClassNotFoundException e) {
      throw new RuntimeException(""cannot load FSDirectory class: "" + e.toString(), e);
    } catch (SecurityException se) {
      try {
        IMPL = Class.forName(FSDirectory.class.getName());
      } catch (ClassNotFoundException e) {
        throw new RuntimeException(""cannot load default FSDirectory class: "" + e.toString(), e);
      }
    }
  }

  private static MessageDigest DIGESTER;

  static {
    try {
      DIGESTER = MessageDigest.getInstance(""MD5"");
    } catch (NoSuchAlgorithmException e) {
        throw new RuntimeException(e.toString(), e);
    }
  }

  
  private byte[] buffer = null;

  
  public static FSDirectory getDirectory(String path, boolean create)
      throws IOException {
    return getDirectory(new File(path), create);
  }

  
  public static FSDirectory getDirectory(File file, boolean create)
    throws IOException {
    file = new File(file.getCanonicalPath());
    FSDirectory dir;
    synchronized (DIRECTORIES) {
      dir = (FSDirectory)DIRECTORIES.get(file);
      if (dir == null) {
        try {
          dir = (FSDirectory)IMPL.newInstance();
        } catch (Exception e) {
          throw new RuntimeException(""cannot load FSDirectory class: "" + e.toString(), e);
        }
        dir.init(file, create);
        DIRECTORIES.put(file, dir);
      } else if (create) {
        dir.create();
      }
    }
    synchronized (dir) {
      dir.refCount++;
    }
    return dir;
  }

  private File directory = null;
  private int refCount;
  private File lockDir;

  protected FSDirectory() {};                     

  private void init(File path, boolean create) throws IOException {
    directory = path;

    if (LOCK_DIR == null) {
      lockDir = directory;
    }
    else {
      lockDir = new File(LOCK_DIR);
    }
    
    if (!lockDir.exists()) {
      if (!lockDir.mkdirs())
        throw new IOException(""Cannot create directory: "" + lockDir.getAbsolutePath());
    } else if (!lockDir.isDirectory()) {
      throw new IOException(""Found regular file where directory expected: "" + 
          lockDir.getAbsolutePath());
    }
    if (create) {
      create();
    }

    if (!directory.isDirectory())
      throw new IOException(path + "" not a directory"");
  }

  private synchronized void create() throws IOException {
    if (!directory.exists())
      if (!directory.mkdirs())
        throw new IOException(""Cannot create directory: "" + directory);

    if (!directory.isDirectory())
      throw new IOException(directory + "" not a directory"");

    String[] files = directory.list(new IndexFileNameFilter());            
    if (files == null)
      throw new IOException(""Cannot read directory "" + directory.getAbsolutePath());
    for (int i = 0; i < files.length; i++) {
      File file = new File(directory, files[i]);
      if (!file.delete())
        throw new IOException(""Cannot delete "" + file);
    }

    String lockPrefix = getLockPrefix().toString(); 
    files = lockDir.list();
    if (files == null)
      throw new IOException(""Cannot read lock directory "" + lockDir.getAbsolutePath());
    for (int i = 0; i < files.length; i++) {
      if (!files[i].startsWith(lockPrefix))
        continue;
      File lockFile = new File(lockDir, files[i]);
      if (!lockFile.delete())
        throw new IOException(""Cannot delete "" + lockFile);
    }
  }

  
  public String[] list() {
    return directory.list();
  }

  
  public boolean fileExists(String name) {
    File file = new File(directory, name);
    return file.exists();
  }

  
  public long fileModified(String name) {
    File file = new File(directory, name);
    return file.lastModified();
  }

  
  public static long fileModified(File directory, String name) {
    File file = new File(directory, name);
    return file.lastModified();
  }

  
  public void touchFile(String name) {
    File file = new File(directory, name);
    file.setLastModified(System.currentTimeMillis());
  }

  
  public long fileLength(String name) {
    File file = new File(directory, name);
    return file.length();
  }

  
  public void deleteFile(String name) throws IOException {
    File file = new File(directory, name);
    if (!file.delete())
      throw new IOException(""Cannot delete "" + file);
  }

  
  public synchronized void renameFile(String from, String to)
      throws IOException {
    File old = new File(directory, from);
    File nu = new File(directory, to);

    

    if (nu.exists())
      if (!nu.delete())
        throw new IOException(""Cannot delete "" + nu);

    
    
    
    if (!old.renameTo(nu)) {
      java.io.InputStream in = null;
      java.io.OutputStream out = null;
      try {
        in = new FileInputStream(old);
        out = new FileOutputStream(nu);
        
        
        
        if (buffer == null) {
          buffer = new byte[1024];
        }
        int len;
        while ((len = in.read(buffer)) >= 0) {
          out.write(buffer, 0, len);
        }

        
        old.delete();
      }
      catch (IOException ioe) {
        IOException newExc = new IOException(""Cannot rename "" + old + "" to "" + nu);
        newExc.initCause(ioe);
        throw newExc;
      }
      finally {
        if (in != null) {
          try {
            in.close();
          } catch (IOException e) {
            throw new RuntimeException(""Cannot close input stream: "" + e.toString(), e);
          }
        }
        if (out != null) {
          try {
            out.close();
          } catch (IOException e) {
            throw new RuntimeException(""Cannot close output stream: "" + e.toString(), e);
          }
        }
      }
    }
  }

  
  public IndexOutput createOutput(String name) throws IOException {
    File file = new File(directory, name);
    if (file.exists() && !file.delete())          
      throw new IOException(""Cannot overwrite: "" + file);

    return new FSIndexOutput(file);
  }

  
  public IndexInput openInput(String name) throws IOException {
    return new FSIndexInput(new File(directory, name));
  }

  
  private static final char[] HEX_DIGITS =
  {'0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f'};

  
  public Lock makeLock(String name) {
    StringBuffer buf = getLockPrefix();
    buf.append(""-"");
    buf.append(name);

    
    final File lockFile = new File(lockDir, buf.toString());

    return new Lock() {
      public boolean obtain() throws IOException {
        if (disableLocks)
          return true;

        if (!lockDir.exists()) {
          if (!lockDir.mkdirs()) {
            throw new IOException(""Cannot create lock directory: "" + lockDir);
          }
        }

        return lockFile.createNewFile();
      }
      public void release() {
        if (disableLocks)
          return;
        lockFile.delete();
      }
      public boolean isLocked() {
        if (disableLocks)
          return false;
        return lockFile.exists();
      }

      public String toString() {
        return ""Lock@"" + lockFile;
      }
    };
  }

  private StringBuffer getLockPrefix() {
    String dirName;                               
    try {
      dirName = directory.getCanonicalPath();
    } catch (IOException e) {
      throw new RuntimeException(e.toString(), e);
    }

    byte digest[];
    synchronized (DIGESTER) {
      digest = DIGESTER.digest(dirName.getBytes());
    }
    StringBuffer buf = new StringBuffer();
    buf.append(""lucene-"");
    for (int i = 0; i < digest.length; i++) {
      int b = digest[i];
      buf.append(HEX_DIGITS[(b >> 4) & 0xf]);
      buf.append(HEX_DIGITS[b & 0xf]);
    }

    return buf;
  }

  
  public synchronized void close() {
    if (--refCount <= 0) {
      synchronized (DIRECTORIES) {
        DIRECTORIES.remove(directory);
      }
    }
  }

  public File getFile() {
    return directory;
  }

  
  public String toString() {
    return this.getClass().getName() + ""@"" + directory;
  }
}


class FSIndexInput extends BufferedIndexInput {

  private class Descriptor extends RandomAccessFile {
    public long position;
    public Descriptor(File file, String mode) throws IOException {
      super(file, mode);
    }
  }

  private Descriptor file = null;
  boolean isClone;
  private long length;

  public FSIndexInput(File path) throws IOException {
    file = new Descriptor(path, ""r"");
    length = file.length();
  }

  
  protected void readInternal(byte[] b, int offset, int len)
       throws IOException {
    synchronized (file) {
      long position = getFilePointer();
      if (position != file.position) {
        file.seek(position);
        file.position = position;
      }
      int total = 0;
      do {
        int i = file.read(b, offset+total, len-total);
        if (i == -1)
          throw new IOException(""read past EOF"");
        file.position += i;
        total += i;
      } while (total < len);
    }
  }

  public void close() throws IOException {
    if (!isClone)
      file.close();
  }

  protected void seekInternal(long position) {
  }

  public long length() {
    return length;
  }

  protected void finalize() throws IOException {
    close();            
  }

  public Object clone() {
    FSIndexInput clone = (FSIndexInput)super.clone();
    clone.isClone = true;
    return clone;
  }

  
  boolean isFDValid() throws IOException {
    return file.getFD().valid();
  }
}


class FSIndexOutput extends BufferedIndexOutput {
  RandomAccessFile file = null;

  public FSIndexOutput(File path) throws IOException {
    file = new RandomAccessFile(path, ""rw"");
  }

  
  public void flushBuffer(byte[] b, int size) throws IOException {
    file.write(b, 0, size);
  }
  public void close() throws IOException {
    super.close();
    file.close();
  }

  
  public void seek(long pos) throws IOException {
    super.seek(pos);
    file.seek(pos);
  }
  public long length() throws IOException {
    return file.length();
  }

  protected void finalize() throws IOException {
    file.close();          
  }

}
"
lucene,2,org.apache.lucene.search.BooleanClause,10,1,0,7,18,0,6,2,10,0.333333333,107,1.0,2,0.0,0.375,1,1,9.5,4,1.4,1,"package org.apache.lucene.search;

import org.apache.lucene.util.Parameter;




public class BooleanClause implements java.io.Serializable {
  
  
  public static final class Occur extends Parameter implements java.io.Serializable {
    
    private Occur(String name) {
      
      super(name);
    }

    public String toString() {
      if (this == MUST) return ""+"";
      if (this == MUST_NOT) return ""-"";
      return """";
    }

    
    public static final Occur MUST = new Occur(""MUST"");
    
    public static final Occur SHOULD = new Occur(""SHOULD"");
    
    public static final Occur MUST_NOT = new Occur(""MUST_NOT"");
    
  }

  
  private Query query;    

  private Occur occur = Occur.SHOULD;


   
  public BooleanClause(Query query, Occur occur) {
    this.query = query;
    this.occur = occur;
    
  }

  public Occur getOccur() {
    return occur;
  }

  public void setOccur(Occur occur) {
    this.occur = occur;

  }

  public Query getQuery() {
    return query;
  }

  public void setQuery(Query query) {
    this.query = query;
  }
  
  public boolean isProhibited() {
    return Occur.MUST_NOT.equals(occur);
  }

  public boolean isRequired() {
    return Occur.MUST.equals(occur);
  }



  
  public boolean equals(Object o) {
    if (!(o instanceof BooleanClause))
      return false;
    BooleanClause other = (BooleanClause)o;
    return this.query.equals(other.query)
      && this.occur.equals(other.occur);
  }

  
  public int hashCode() {
    return query.hashCode() ^ (Occur.MUST.equals(occur)?1:0) ^ (Occur.MUST_NOT.equals(occur)?2:0);
  }


  public String toString() {
    return occur.toString() + query.toString();
  }
}
"
